####################
/var/spool/slurmd/job5231379/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_3B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-20_13-49-52_llm_triton_qwen_3b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0.
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 210  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.6e+03     |
|    ep_rew_mean          | 1.52e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 416         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012678469 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.7        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0214     |
|    std                  | 1           |
|    value_loss           | 46          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.6e+03     |
|    ep_rew_mean          | 1.52e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 621         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009524794 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | -0.416      |
|    learning_rate        | 0.0003      |
|    loss                 | 19.5        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.999       |
|    value_loss           | 41.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 826         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.010837367 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.352       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.1        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.996       |
|    value_loss           | 39.7        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-100.01 +/- 0.03
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009478572 |
|    clip_fraction        | 0.096       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.81        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.994       |
|    value_loss           | 27.2        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2832     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.34e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3038        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.009221924 |
|    clip_fraction        | 0.0749      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.000134   |
|    learning_rate        | 0.0003      |
|    loss                 | 21.7        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.995       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.45e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3243        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008799758 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.42        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.993       |
|    value_loss           | 34.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.4e+03      |
|    ep_rew_mean          | 1.45e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 8            |
|    time_elapsed         | 3449         |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0075571667 |
|    clip_fraction        | 0.0603       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.306        |
|    learning_rate        | 0.0003       |
|    loss                 | 8.51         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0132      |
|    std                  | 0.994        |
|    value_loss           | 28.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.44e+03     |
|    ep_rew_mean          | 1.52e+03     |
| time/                   |              |
|    fps                  | 5            |
|    iterations           | 9            |
|    time_elapsed         | 3654         |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0076200697 |
|    clip_fraction        | 0.0746       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.307        |
|    learning_rate        | 0.0003       |
|    loss                 | 8.83         |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.0152      |
|    std                  | 0.991        |
|    value_loss           | 26.4         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-100.04 +/- 0.04
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.014529776 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.447      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.11        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00258    |
|    std                  | 0.99        |
|    value_loss           | 3.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5660     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.42e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 5866         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0032800224 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.00755      |
|    learning_rate        | 0.0003       |
|    loss                 | 99.1         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00253     |
|    std                  | 0.991        |
|    value_loss           | 1.07e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.37e+03     |
|    ep_rew_mean          | 1.48e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 12           |
|    time_elapsed         | 6071         |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0056816232 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.605        |
|    learning_rate        | 0.0003       |
|    loss                 | 6.9          |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00872     |
|    std                  | 0.99         |
|    value_loss           | 12.7         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.37e+03     |
|    ep_rew_mean          | 1.48e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 13           |
|    time_elapsed         | 6276         |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0075184517 |
|    clip_fraction        | 0.0568       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.876       |
|    learning_rate        | 0.0003       |
|    loss                 | 4.05         |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.0124      |
|    std                  | 0.988        |
|    value_loss           | 13.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.4e+03      |
|    ep_rew_mean          | 1.52e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 14           |
|    time_elapsed         | 6482         |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0068267775 |
|    clip_fraction        | 0.0408       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.421        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.27         |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00951     |
|    std                  | 0.985        |
|    value_loss           | 8.74         |
------------------------------------------
Eval num_timesteps=30000, episode_reward=-99.88 +/- 0.17
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.017867208 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.108      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.762       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.994       |
|    value_loss           | 1.8         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8490     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 8695        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.009943565 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.00213     |
|    learning_rate        | 0.0003      |
|    loss                 | 10.2        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00517    |
|    std                  | 0.994       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 8901        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.013751599 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.305      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.99        |
|    value_loss           | 2.83        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.5e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9108        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.007140415 |
|    clip_fraction        | 0.0856      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -2.18       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.62        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0097     |
|    std                  | 0.989       |
|    value_loss           | 14.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | 1.53e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9314        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.009852309 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.95        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00921    |
|    std                  | 0.99        |
|    value_loss           | 7.9         |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.97 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.009601696 |
|    clip_fraction        | 0.0415      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.51        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00872    |
|    std                  | 0.99        |
|    value_loss           | 6.47        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11319    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.49e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 11525        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0018511938 |
|    clip_fraction        | 0.00439      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.00689      |
|    learning_rate        | 0.0003       |
|    loss                 | 1.06e+03     |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00183     |
|    std                  | 0.99         |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11730       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.014869841 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0455     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.982       |
|    value_loss           | 2.89        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11936       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.007909171 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.0747      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.4         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00422    |
|    std                  | 0.98        |
|    value_loss           | 5.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.55e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12141       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.015989212 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.062       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00507    |
|    std                  | 0.982       |
|    value_loss           | 1.85        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.95 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.01993754 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.801      |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.981      |
|    value_loss           | 1.7        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.52e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14148    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.52e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 14354        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0065237805 |
|    clip_fraction        | 0.0671       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.0193       |
|    learning_rate        | 0.0003       |
|    loss                 | 22           |
|    n_updates            | 250          |
|    policy_gradient_loss | 0.00139      |
|    std                  | 0.981        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14559       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.015135951 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.0726      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.985       |
|    value_loss           | 1.84        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14764       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.004624401 |
|    clip_fraction        | 0.0456      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.0003      |
|    loss                 | 21.2        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0014     |
|    std                  | 0.985       |
|    value_loss           | 66.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 1.58e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 29           |
|    time_elapsed         | 14970        |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0013170488 |
|    clip_fraction        | 0.00479      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.744        |
|    learning_rate        | 0.0003       |
|    loss                 | 6.92         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.0065      |
|    std                  | 0.985        |
|    value_loss           | 20.6         |
------------------------------------------
Eval num_timesteps=60000, episode_reward=-99.83 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.008944588 |
|    clip_fraction        | 0.0412      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.23        |
|    learning_rate        | 0.0003      |
|    loss                 | 5.65        |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.985       |
|    value_loss           | 13.1        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16977    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17182       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.001250291 |
|    clip_fraction        | 0.000928    |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.000629   |
|    learning_rate        | 0.0003      |
|    loss                 | 442         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00226    |
|    std                  | 0.985       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17388       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.012539665 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.278      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00869    |
|    std                  | 0.985       |
|    value_loss           | 3.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17593       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.017248522 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.302       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.799       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00852    |
|    std                  | 0.985       |
|    value_loss           | 2.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17798       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.019256093 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.948       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.981       |
|    value_loss           | 2.44        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.80 +/- 0.17
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.019110521 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.682       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00746    |
|    std                  | 0.977       |
|    value_loss           | 1.48        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.57e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19807    |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 1.6e+03      |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 36           |
|    time_elapsed         | 20012        |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0074154134 |
|    clip_fraction        | 0.0795       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | -0.00271     |
|    learning_rate        | 0.0003       |
|    loss                 | 6.22         |
|    n_updates            | 350          |
|    policy_gradient_loss | -3.04e-05    |
|    std                  | 0.977        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20217       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.018689573 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.117      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.983       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.975       |
|    value_loss           | 1.82        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20423       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.019443016 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.691       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.976       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20629       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.015113406 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.85        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.974       |
|    value_loss           | 1.73        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.83 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.008781485 |
|    clip_fraction        | 0.0821      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.126       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25        |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.973       |
|    value_loss           | 4.74        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22635    |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.61e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 41           |
|    time_elapsed         | 22840        |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0046491255 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -0.000409    |
|    learning_rate        | 0.0003       |
|    loss                 | 5.23         |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00193     |
|    std                  | 0.973        |
|    value_loss           | 1.05e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 42         |
|    time_elapsed         | 23046      |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.01898318 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | -0.392     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.799      |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.975      |
|    value_loss           | 2.4        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23251       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.025256023 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.605       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.972       |
|    value_loss           | 1.32        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.79 +/- 0.12
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.02358023 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.564      |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.00759   |
|    std                  | 0.971      |
|    value_loss           | 1.44       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25258    |
|    total_timesteps | 90112    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 45         |
|    time_elapsed         | 25463      |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.00904339 |
|    clip_fraction        | 0.113      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | -0.00128   |
|    learning_rate        | 0.0003     |
|    loss                 | 325        |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.00504   |
|    std                  | 0.97       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25669       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.021153271 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.155      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.742       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.966       |
|    value_loss           | 1.53        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.63e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 47         |
|    time_elapsed         | 25874      |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.01543358 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.133      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.797      |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.965      |
|    value_loss           | 1.53       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26079       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.010003503 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.3        |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00361    |
|    std                  | 0.965       |
|    value_loss           | 35.8        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.79 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.009740125 |
|    clip_fraction        | 0.049       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.38        |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0051     |
|    std                  | 0.964       |
|    value_loss           | 6.91        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28087    |
|    total_timesteps | 100352   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.63e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 50           |
|    time_elapsed         | 28293        |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0026152933 |
|    clip_fraction        | 0.00991      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.0504       |
|    learning_rate        | 0.0003       |
|    loss                 | 3.46e+03     |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.00316     |
|    std                  | 0.964        |
|    value_loss           | 1.06e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 51         |
|    time_elapsed         | 28498      |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.02255525 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | -0.2       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 500        |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.963      |
|    value_loss           | 1.5        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28704       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.018895864 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -1.97       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.571       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00839    |
|    std                  | 0.959       |
|    value_loss           | 1.95        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28909       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.021201711 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.163       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.954       |
|    value_loss           | 1.46        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.86 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 110000     |
| train/                  |            |
|    approx_kl            | 0.02381144 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.359     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.703      |
|    n_updates            | 530        |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.952      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.65e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30915    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31121       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.017158177 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.000349    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.54        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0088     |
|    std                  | 0.951       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31326       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.020675797 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.633      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.83        |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.95        |
|    value_loss           | 2.74        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31531       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.023306154 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.624       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.95        |
|    value_loss           | 1.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31737       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.018917788 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.561       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00976    |
|    std                  | 0.949       |
|    value_loss           | 1.43        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.85 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.01854495 |
|    clip_fraction        | 0.222      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.526      |
|    n_updates            | 580        |
|    policy_gradient_loss | -0.00979   |
|    std                  | 0.949      |
|    value_loss           | 1.25       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33744    |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 60         |
|    time_elapsed         | 33950      |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.01527453 |
|    clip_fraction        | 0.196      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.000519   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.36       |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.00939   |
|    std                  | 0.947      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34155       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.006958889 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.634       |
|    learning_rate        | 0.0003      |
|    loss                 | 44.3        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.000987   |
|    std                  | 0.947       |
|    value_loss           | 37.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34361       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.019760054 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.106       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.771       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.943       |
|    value_loss           | 1.6         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34567       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.031614874 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.386       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00229    |
|    std                  | 0.941       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.85 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.021438943 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.526       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.942       |
|    value_loss           | 1.24        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36575    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 36780       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.015544078 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.204       |
|    learning_rate        | 0.0003      |
|    loss                 | 358         |
|    n_updates            | 640         |
|    policy_gradient_loss | 0.00591     |
|    std                  | 0.942       |
|    value_loss           | 1.08e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 36985       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.021753948 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.922      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.79        |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.94        |
|    value_loss           | 7.59        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37191       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.022046993 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0921      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.418       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.934       |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37396       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.019492432 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0836     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.666       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.936       |
|    value_loss           | 2.25        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.88 +/- 0.02
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.013523038 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.34        |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00608    |
|    std                  | 0.936       |
|    value_loss           | 25.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.71e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39402    |
|    total_timesteps | 141312   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.71e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 70           |
|    time_elapsed         | 39608        |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0054980544 |
|    clip_fraction        | 0.0509       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 8.83e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.95e+03     |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00223     |
|    std                  | 0.936        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39814       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.020327691 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -1.08       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08        |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00606    |
|    std                  | 0.936       |
|    value_loss           | 3.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40019       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.013341535 |
|    clip_fraction        | 0.0872      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32        |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.935       |
|    value_loss           | 5.27        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.74e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 73        |
|    time_elapsed         | 40225     |
|    total_timesteps      | 149504    |
| train/                  |           |
|    approx_kl            | 0.0461865 |
|    clip_fraction        | 0.316     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.8     |
|    explained_variance   | 0.1       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.387     |
|    n_updates            | 720       |
|    policy_gradient_loss | 0.00228   |
|    std                  | 0.934     |
|    value_loss           | 0.963     |
---------------------------------------
Eval num_timesteps=150000, episode_reward=-99.85 +/- 0.02
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.025054581 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.162       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.68        |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00559    |
|    std                  | 0.933       |
|    value_loss           | 1.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42231    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42437       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.025665015 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00137     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.62        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00376    |
|    std                  | 0.935       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42642       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.032035634 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0625     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00316    |
|    std                  | 0.936       |
|    value_loss           | 1.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42848       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.024350423 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00914    |
|    std                  | 0.938       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43054       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.019109653 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.7        |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.000173   |
|    std                  | 0.938       |
|    value_loss           | 16.5        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.85 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.030972064 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.493       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.93        |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45060    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45265       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.011531195 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 19.3        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00164    |
|    std                  | 0.93        |
|    value_loss           | 1.07e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 81         |
|    time_elapsed         | 45471      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.02881916 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.614     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.711      |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.00138   |
|    std                  | 0.927      |
|    value_loss           | 1.37       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45676       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.024083238 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.564       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00114    |
|    std                  | 0.926       |
|    value_loss           | 1.13        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 83         |
|    time_elapsed         | 45882      |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.04140257 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17       |
|    n_updates            | 820        |
|    policy_gradient_loss | 0.000568   |
|    std                  | 0.925      |
|    value_loss           | 12.3       |
----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.55 +/- 0.44
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.030658796 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.773       |
|    n_updates            | 830         |
|    policy_gradient_loss | 0.00265     |
|    std                  | 0.925       |
|    value_loss           | 1.29        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47889    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48095       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.014581302 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00075    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.98        |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00239    |
|    std                  | 0.926       |
|    value_loss           | 923         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.78e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 86        |
|    time_elapsed         | 48301     |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.1056789 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.7     |
|    explained_variance   | -2.9      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.529     |
|    n_updates            | 850       |
|    policy_gradient_loss | 0.01      |
|    std                  | 0.924     |
|    value_loss           | 4.3       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 87         |
|    time_elapsed         | 48506      |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.03488175 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.146      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.475      |
|    n_updates            | 860        |
|    policy_gradient_loss | 0.000964   |
|    std                  | 0.922      |
|    value_loss           | 1.2        |
----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.84 +/- 0.07
Episode length: 3598.20 +/- 4.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.026883366 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.81        |
|    n_updates            | 870         |
|    policy_gradient_loss | 0.00259     |
|    std                  | 0.922       |
|    value_loss           | 16          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50512    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50718       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.011662241 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0101     |
|    learning_rate        | 0.0003      |
|    loss                 | 67.2        |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.000714    |
|    std                  | 0.922       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 50923      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.03500075 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.936     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 890        |
|    policy_gradient_loss | 0.00445    |
|    std                  | 0.916      |
|    value_loss           | 1.18       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51128       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.016768258 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.33        |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00511    |
|    std                  | 0.916       |
|    value_loss           | 9.55        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 92         |
|    time_elapsed         | 51334      |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.03126833 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.155      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.722      |
|    n_updates            | 910        |
|    policy_gradient_loss | 0.00122    |
|    std                  | 0.911      |
|    value_loss           | 1.27       |
----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.89 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.018017936 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.09        |
|    n_updates            | 920         |
|    policy_gradient_loss | 0.00486     |
|    std                  | 0.911       |
|    value_loss           | 18          |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53340    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53545       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.009428271 |
|    clip_fraction        | 0.059       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0286      |
|    learning_rate        | 0.0003      |
|    loss                 | 44.4        |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0051     |
|    std                  | 0.91        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53751       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.030052941 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00331     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.607       |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.00698     |
|    std                  | 0.909       |
|    value_loss           | 1.32        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 96         |
|    time_elapsed         | 53957      |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.02969929 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.0636     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.551      |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.000477  |
|    std                  | 0.905      |
|    value_loss           | 4.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54162       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.049534246 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 960         |
|    policy_gradient_loss | 0.00477     |
|    std                  | 0.904       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.88 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 200000    |
| train/                  |           |
|    approx_kl            | 0.0385534 |
|    clip_fraction        | 0.319     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | 0.187     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.469     |
|    n_updates            | 970       |
|    policy_gradient_loss | 0.0024    |
|    std                  | 0.9       |
|    value_loss           | 1.15      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56170    |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 99         |
|    time_elapsed         | 56375      |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.04925336 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.000836   |
|    learning_rate        | 0.0003     |
|    loss                 | 11.1       |
|    n_updates            | 980        |
|    policy_gradient_loss | 0.00426    |
|    std                  | 0.902      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56580       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.032419067 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.11        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.657       |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.000257    |
|    std                  | 0.904       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56786       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.029051067 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.183       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.752       |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.00128     |
|    std                  | 0.904       |
|    value_loss           | 1.25        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 102        |
|    time_elapsed         | 56991      |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.02675189 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.193      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.691      |
|    n_updates            | 1010       |
|    policy_gradient_loss | -0.0018    |
|    std                  | 0.904      |
|    value_loss           | 1.27       |
----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.88 +/- 0.05
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.013587771 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 41.9        |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00136    |
|    std                  | 0.904       |
|    value_loss           | 36.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 58997    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59202       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.022204015 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00149     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.16        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00186    |
|    std                  | 0.905       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 59408      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.03333792 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.145      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.00733    |
|    std                  | 0.904      |
|    value_loss           | 1.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 59613       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.011071772 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.7        |
|    n_updates            | 1050        |
|    policy_gradient_loss | -2.22e-05   |
|    std                  | 0.904       |
|    value_loss           | 25.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 59820       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.036600694 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.209       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.531       |
|    n_updates            | 1060        |
|    policy_gradient_loss | 0.00583     |
|    std                  | 0.894       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.91 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.030059526 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.354       |
|    n_updates            | 1070        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.891       |
|    value_loss           | 0.986       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61826    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62033       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.030725157 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.000116    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+03    |
|    n_updates            | 1080        |
|    policy_gradient_loss | 0.000456    |
|    std                  | 0.891       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 62239       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.037530303 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0792     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.53        |
|    n_updates            | 1090        |
|    policy_gradient_loss | 0.00522     |
|    std                  | 0.897       |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62444       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.010264559 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 20.1        |
|    n_updates            | 1100        |
|    policy_gradient_loss | 0.00776     |
|    std                  | 0.896       |
|    value_loss           | 39.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 62650      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.03619202 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.75       |
|    n_updates            | 1110       |
|    policy_gradient_loss | 0.00077    |
|    std                  | 0.89       |
|    value_loss           | 1.24       |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.82 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.027533954 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.225       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.41        |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.000722    |
|    std                  | 0.885       |
|    value_loss           | 0.968       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64656    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64861       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.013911283 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | 12          |
|    n_updates            | 1130        |
|    policy_gradient_loss | 0.00275     |
|    std                  | 0.885       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65066       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.031067234 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.823      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.581       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00854    |
|    std                  | 0.885       |
|    value_loss           | 1.29        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.86e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 116          |
|    time_elapsed         | 65272        |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 0.0105804205 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.3        |
|    explained_variance   | 0.897        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.54         |
|    n_updates            | 1150         |
|    policy_gradient_loss | -0.00708     |
|    std                  | 0.884        |
|    value_loss           | 12.8         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 117        |
|    time_elapsed         | 65477      |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.00937765 |
|    clip_fraction        | 0.0841     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.0003     |
|    loss                 | 8.31       |
|    n_updates            | 1160       |
|    policy_gradient_loss | -0.0134    |
|    std                  | 0.883      |
|    value_loss           | 19.6       |
----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.84 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.037274037 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00115    |
|    std                  | 0.881       |
|    value_loss           | 5.55        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67483    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67689       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.036430143 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.000999   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.00058     |
|    std                  | 0.882       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67894       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.111057416 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.269      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.638       |
|    n_updates            | 1190        |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.886       |
|    value_loss           | 1.24        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.86e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 121       |
|    time_elapsed         | 68101     |
|    total_timesteps      | 247808    |
| train/                  |           |
|    approx_kl            | 0.0333299 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.3     |
|    explained_variance   | 0.183     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.56      |
|    n_updates            | 1200      |
|    policy_gradient_loss | 0.006     |
|    std                  | 0.888     |
|    value_loss           | 1.2       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68307       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.032243513 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.615       |
|    n_updates            | 1210        |
|    policy_gradient_loss | 0.0051      |
|    std                  | 0.888       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.76 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.034207605 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.518       |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00406     |
|    std                  | 0.886       |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70313    |
|    total_timesteps | 251904   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.87e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 124          |
|    time_elapsed         | 70519        |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0143642835 |
|    clip_fraction        | 0.299        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.3        |
|    explained_variance   | 0.0826       |
|    learning_rate        | 0.0003       |
|    loss                 | 20.3         |
|    n_updates            | 1230         |
|    policy_gradient_loss | 0.00657      |
|    std                  | 0.886        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70724       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.026854176 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.572      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.533       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.00163    |
|    std                  | 0.888       |
|    value_loss           | 1.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70930       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.038620107 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.802       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00542    |
|    std                  | 0.889       |
|    value_loss           | 1.25        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.86 +/- 0.02
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.03818103 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.213      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.333      |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.00551   |
|    std                  | 0.884      |
|    value_loss           | 0.994      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72936    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73141       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.020298388 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.000306    |
|    learning_rate        | 0.0003      |
|    loss                 | 138         |
|    n_updates            | 1270        |
|    policy_gradient_loss | -1.8e-05    |
|    std                  | 0.884       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 73346       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.043056414 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0978      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.505       |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.882       |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73552       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.033832412 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 1290        |
|    policy_gradient_loss | 0.0063      |
|    std                  | 0.875       |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.88e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 131       |
|    time_elapsed         | 73757     |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.0379287 |
|    clip_fraction        | 0.281     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | 0.27      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.367     |
|    n_updates            | 1300      |
|    policy_gradient_loss | 0.0043    |
|    std                  | 0.879     |
|    value_loss           | 0.873     |
---------------------------------------
Eval num_timesteps=270000, episode_reward=-99.88 +/- 0.04
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.02787415 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.05       |
|    n_updates            | 1310       |
|    policy_gradient_loss | 0.00433    |
|    std                  | 0.879      |
|    value_loss           | 18.7       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75766    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 75972       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.008423914 |
|    clip_fraction        | 0.0448      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.022       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.85        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00288    |
|    std                  | 0.879       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 134         |
|    time_elapsed         | 76177       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.048242863 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.545       |
|    n_updates            | 1330        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.876       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76383       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.043210004 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.608       |
|    n_updates            | 1340        |
|    policy_gradient_loss | 0.00217     |
|    std                  | 0.873       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 76588       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.046726517 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.844       |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.873       |
|    value_loss           | 1.36        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.83 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.035158202 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.567       |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.00423     |
|    std                  | 0.873       |
|    value_loss           | 1.01        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78594    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78800       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.020628966 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000539   |
|    learning_rate        | 0.0003      |
|    loss                 | 438         |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0071     |
|    std                  | 0.872       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 139        |
|    time_elapsed         | 79005      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.03970495 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.0634     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.58       |
|    n_updates            | 1380       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.865      |
|    value_loss           | 1.11       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79210       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.040496744 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.74        |
|    n_updates            | 1390        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.865       |
|    value_loss           | 13.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 79416      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.06753475 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.433      |
|    n_updates            | 1400       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.862      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.78 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.03384282 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.198      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.328      |
|    n_updates            | 1410       |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.863      |
|    value_loss           | 0.967      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81422    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 81627       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.015613081 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.204       |
|    learning_rate        | 0.0003      |
|    loss                 | 69.4        |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00532    |
|    std                  | 0.863       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 81833       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.055972792 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.361      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.563       |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.00598     |
|    std                  | 0.861       |
|    value_loss           | 1.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82038       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.018977799 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.2        |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.861       |
|    value_loss           | 40.9        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 82243      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.05536314 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.195      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.369      |
|    n_updates            | 1450       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.853      |
|    value_loss           | 0.937      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.83 +/- 0.06
Episode length: 3597.20 +/- 7.11
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 0.0427075 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.94     |
|    explained_variance   | 0.312     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.308     |
|    n_updates            | 1460      |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.849     |
|    value_loss           | 0.728     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84253    |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 148        |
|    time_elapsed         | 84460      |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.03865263 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | -0.000558  |
|    learning_rate        | 0.0003     |
|    loss                 | 135        |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.00369   |
|    std                  | 0.848      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 149        |
|    time_elapsed         | 84665      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.20473915 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | -0.0725    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.448      |
|    n_updates            | 1480       |
|    policy_gradient_loss | 0.0032     |
|    std                  | 0.847      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 84871       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.028721368 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.521       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.3        |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00518    |
|    std                  | 0.848       |
|    value_loss           | 10.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 85076       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.049110666 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.00175     |
|    std                  | 0.845       |
|    value_loss           | 1.47        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-98.09 +/- 1.91
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.1       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.040004954 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.876       |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.0022      |
|    std                  | 0.845       |
|    value_loss           | 4.64        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87084    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 153        |
|    time_elapsed         | 87289      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.03788848 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | -0.0015    |
|    learning_rate        | 0.0003     |
|    loss                 | 395        |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.00382   |
|    std                  | 0.844      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 87495      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.19540438 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | -0.178     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.565      |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.00804    |
|    std                  | 0.846      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 87701       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.047037326 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | -2.03       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.345       |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00214    |
|    std                  | 0.851       |
|    value_loss           | 1.14        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 87906      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.06138703 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 1550       |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.849      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.054306846 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.682       |
|    n_updates            | 1560        |
|    policy_gradient_loss | 0.00545     |
|    std                  | 0.845       |
|    value_loss           | 0.989       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.93e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89912    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90117       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.045188207 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.000156    |
|    learning_rate        | 0.0003      |
|    loss                 | 163         |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00162    |
|    std                  | 0.845       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90323       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.060238604 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | -0.106      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.504       |
|    n_updates            | 1580        |
|    policy_gradient_loss | 0.00335     |
|    std                  | 0.845       |
|    value_loss           | 1.01        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.94e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 160        |
|    time_elapsed         | 90528      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.04107358 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.89      |
|    explained_variance   | -1.24      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17       |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.000367  |
|    std                  | 0.841      |
|    value_loss           | 3.21       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.94e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 161        |
|    time_elapsed         | 90734      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.04017262 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | -3.45      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.452      |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.00395   |
|    std                  | 0.836      |
|    value_loss           | 1.48       |
----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.77 +/- 0.08
Episode length: 3597.20 +/- 7.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.043539647 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.361       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.835       |
|    value_loss           | 0.938       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.94e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92743    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.94e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 92949      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.02322699 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | -0.000519  |
|    learning_rate        | 0.0003     |
|    loss                 | 227        |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.00436   |
|    std                  | 0.836      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.94e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93154       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.041526392 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | -0.0134     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.575       |
|    n_updates            | 1630        |
|    policy_gradient_loss | 0.00596     |
|    std                  | 0.835       |
|    value_loss           | 0.974       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.95e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93360       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.037439525 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.459       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.833       |
|    value_loss           | 0.773       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.95e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 93565      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.04014237 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.76      |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.562      |
|    n_updates            | 1650       |
|    policy_gradient_loss | 0.00439    |
|    std                  | 0.829      |
|    value_loss           | 1.23       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.80 +/- 0.05
Episode length: 3599.40 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.06984052 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.71      |
|    explained_variance   | 0.238      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 1660       |
|    policy_gradient_loss | 0.00441    |
|    std                  | 0.823      |
|    value_loss           | 1.05       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.95e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95572    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.97e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 95778       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.032472447 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.00147     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.26        |
|    n_updates            | 1670        |
|    policy_gradient_loss | 0.000445    |
|    std                  | 0.823       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.97e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 169        |
|    time_elapsed         | 95984      |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.17072164 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.68      |
|    explained_variance   | -0.858     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 1680       |
|    policy_gradient_loss | 0.00611    |
|    std                  | 0.82       |
|    value_loss           | 4.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.98e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 96189      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.05245392 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.65      |
|    explained_variance   | 0.285      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.346      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.00818    |
|    std                  | 0.818      |
|    value_loss           | 0.897      |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.82 +/- 0.07
Episode length: 3598.80 +/- 3.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.049167197 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | -0.46       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.19        |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.00442     |
|    std                  | 0.819       |
|    value_loss           | 4.22        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.97e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98195    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.97e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98401       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.043038845 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | -0.00171    |
|    learning_rate        | 0.0003      |
|    loss                 | 193         |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0041     |
|    std                  | 0.818       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.99e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 173        |
|    time_elapsed         | 98606      |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.11226685 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | 0.111      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.35       |
|    n_updates            | 1720       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.816      |
|    value_loss           | 0.99       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.99e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 98812      |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.03360621 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.61      |
|    explained_variance   | 0.28       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.266      |
|    n_updates            | 1730       |
|    policy_gradient_loss | 0.00829    |
|    std                  | 0.813      |
|    value_loss           | 0.744      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 99017      |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.11625254 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | 0.267      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.811      |
|    value_loss           | 0.803      |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.53 +/- 0.82
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.103398144 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.394       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.00223     |
|    std                  | 0.804       |
|    value_loss           | 0.752       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.99e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101025   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.99e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101231      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.022319872 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.00104     |
|    learning_rate        | 0.0003      |
|    loss                 | 347         |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.00288     |
|    std                  | 0.803       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 101437      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.049947895 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | -0.0487     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.332       |
|    n_updates            | 1770        |
|    policy_gradient_loss | 0.00458     |
|    std                  | 0.801       |
|    value_loss           | 1.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 101642      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.058435336 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.559       |
|    n_updates            | 1780        |
|    policy_gradient_loss | 0.00835     |
|    std                  | 0.796       |
|    value_loss           | 0.894       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 101848      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.040169686 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.259       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.492       |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.00937     |
|    std                  | 0.799       |
|    value_loss           | 0.94        |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 370000    |
| train/                  |           |
|    approx_kl            | 0.0660715 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.42     |
|    explained_variance   | -1.11     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.405     |
|    n_updates            | 1800      |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.798     |
|    value_loss           | 2.91      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103856   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104061      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.037826516 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.000675    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.14        |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00173    |
|    std                  | 0.8         |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 104266      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.089083664 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.45       |
|    explained_variance   | 0.088       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.652       |
|    n_updates            | 1820        |
|    policy_gradient_loss | 0.0202      |
|    std                  | 0.802       |
|    value_loss           | 1.03        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 104472     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.04903597 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.46      |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.521      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.00487    |
|    std                  | 0.805      |
|    value_loss           | 1.11       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 104677      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.045597296 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.802       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-96.27 +/- 1.25
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.3       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.050601967 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -4.1        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.000525   |
|    std                  | 0.8         |
|    value_loss           | 2.11        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106683   |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 187        |
|    time_elapsed         | 106889     |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.04116473 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | 0.00026    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.4e+03    |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.00346   |
|    std                  | 0.799      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 107094     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.07939209 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.41      |
|    explained_variance   | 0.17       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.645      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.798      |
|    value_loss           | 0.992      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107300      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.047736377 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | -2.11       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.796       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.06e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 190       |
|    time_elapsed         | 107505    |
|    total_timesteps      | 389120    |
| train/                  |           |
|    approx_kl            | 0.1500327 |
|    clip_fraction        | 0.299     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.36     |
|    explained_variance   | 0.23      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.434     |
|    n_updates            | 1890      |
|    policy_gradient_loss | 0.00813   |
|    std                  | 0.792     |
|    value_loss           | 0.904     |
---------------------------------------
Eval num_timesteps=390000, episode_reward=-99.69 +/- 0.39
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.08938502 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.32      |
|    explained_variance   | -0.956     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.396      |
|    n_updates            | 1900       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.791      |
|    value_loss           | 0.941      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109512   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 109718     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.03167401 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.33      |
|    explained_variance   | -0.00238   |
|    learning_rate        | 0.0003     |
|    loss                 | 235        |
|    n_updates            | 1910       |
|    policy_gradient_loss | 0.009      |
|    std                  | 0.791      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 109924      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.084247366 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.0039      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.447       |
|    n_updates            | 1920        |
|    policy_gradient_loss | 0.0093      |
|    std                  | 0.791       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110129      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.069343455 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.33        |
|    n_updates            | 1930        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.79        |
|    value_loss           | 0.717       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 195        |
|    time_elapsed         | 110335     |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.06489982 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.411      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.614      |
|    n_updates            | 1940       |
|    policy_gradient_loss | 0.00187    |
|    std                  | 0.789      |
|    value_loss           | 1.33       |
----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.94 +/- 0.02
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.061054517 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.476       |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.785       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112340   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 112546     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.02059058 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.25      |
|    explained_variance   | -0.00105   |
|    learning_rate        | 0.0003     |
|    loss                 | 839        |
|    n_updates            | 1960       |
|    policy_gradient_loss | 0.00206    |
|    std                  | 0.784      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.08e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 198       |
|    time_elapsed         | 112751    |
|    total_timesteps      | 405504    |
| train/                  |           |
|    approx_kl            | 0.3983255 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.26     |
|    explained_variance   | 0.00784   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.326     |
|    n_updates            | 1970      |
|    policy_gradient_loss | 0.00845   |
|    std                  | 0.786     |
|    value_loss           | 0.77      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 112957     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.15801129 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.26      |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.296      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.785      |
|    value_loss           | 0.675      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 113162     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.06638908 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.25      |
|    explained_variance   | 0.185      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.653      |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.783      |
|    value_loss           | 1.2        |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.94 +/- 0.02
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.07817082 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.23      |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.591      |
|    n_updates            | 2000       |
|    policy_gradient_loss | 0.0073     |
|    std                  | 0.781      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115168   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 115374     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.04315696 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | -0.000615  |
|    learning_rate        | 0.0003     |
|    loss                 | 25.6       |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.00383   |
|    std                  | 0.779      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 203       |
|    time_elapsed         | 115580    |
|    total_timesteps      | 415744    |
| train/                  |           |
|    approx_kl            | 0.2777598 |
|    clip_fraction        | 0.371     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.17     |
|    explained_variance   | -0.0793   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.403     |
|    n_updates            | 2020      |
|    policy_gradient_loss | 0.009     |
|    std                  | 0.773     |
|    value_loss           | 1.11      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 115786      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.058228217 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.11        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 2030        |
|    policy_gradient_loss | 0.00558     |
|    std                  | 0.769       |
|    value_loss           | 1.1         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 115991     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.06556764 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | 0.193      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.617      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.00553    |
|    std                  | 0.766      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-92.52 +/- 3.32
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -92.5      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.08804372 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.188      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.621      |
|    n_updates            | 2050       |
|    policy_gradient_loss | 0.00906    |
|    std                  | 0.766      |
|    value_loss           | 1.16       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 117997   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118203      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.032747194 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | -0.00125    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.51        |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00419    |
|    std                  | 0.767       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118408     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.28523135 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.05      |
|    explained_variance   | -0.146     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.455      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.00202    |
|    std                  | 0.763      |
|    value_loss           | 1.18       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 118614      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.046604343 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.0277      |
|    std                  | 0.757       |
|    value_loss           | 0.981       |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.69 +/- 0.39
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.08054564 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.99      |
|    explained_variance   | 0.203      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.302      |
|    n_updates            | 2090       |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.76       |
|    value_loss           | 0.835      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120620   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 211        |
|    time_elapsed         | 120826     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.02999863 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.02      |
|    explained_variance   | 0.000907   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.95e+03   |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.00149   |
|    std                  | 0.762      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121031      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.045462847 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.538       |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.0198      |
|    std                  | 0.763       |
|    value_loss           | 1.14        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 213        |
|    time_elapsed         | 121239     |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.09795682 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.05      |
|    explained_variance   | 0.144      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.57       |
|    n_updates            | 2120       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.766      |
|    value_loss           | 0.975      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 121445     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.04352542 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.126      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.518      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.00188    |
|    std                  | 0.763      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.20767727 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.99      |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.532      |
|    n_updates            | 2140       |
|    policy_gradient_loss | 0.0091     |
|    std                  | 0.757      |
|    value_loss           | 0.925      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123452   |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 216        |
|    time_elapsed         | 123658     |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.04952801 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.94      |
|    explained_variance   | -0.00631   |
|    learning_rate        | 0.0003     |
|    loss                 | 5.24       |
|    n_updates            | 2150       |
|    policy_gradient_loss | 0.00245    |
|    std                  | 0.755      |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 217       |
|    time_elapsed         | 123864    |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 1.0253011 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.9      |
|    explained_variance   | 0.000109  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.575     |
|    n_updates            | 2160      |
|    policy_gradient_loss | 0.0295    |
|    std                  | 0.748     |
|    value_loss           | 1.1       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 218       |
|    time_elapsed         | 124069    |
|    total_timesteps      | 446464    |
| train/                  |           |
|    approx_kl            | 0.8239976 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.85     |
|    explained_variance   | -3.21     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.735     |
|    n_updates            | 2170      |
|    policy_gradient_loss | 0.00853   |
|    std                  | 0.747     |
|    value_loss           | 1.84      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124275      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.059606776 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.83       |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.00935     |
|    std                  | 0.744       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.72 +/- 0.42
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.057241887 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.81       |
|    explained_variance   | -0.668      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.475       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.00519     |
|    std                  | 0.744       |
|    value_loss           | 1.9         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126281   |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 221        |
|    time_elapsed         | 126486     |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.04645206 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.82      |
|    explained_variance   | 0.000349   |
|    learning_rate        | 0.0003     |
|    loss                 | 470        |
|    n_updates            | 2200       |
|    policy_gradient_loss | 1.01e-05   |
|    std                  | 0.745      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 126692     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.13082787 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.8       |
|    explained_variance   | 0.0437     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.541      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.74       |
|    value_loss           | 1.32       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 126897     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.08889671 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.75      |
|    explained_variance   | 0.154      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.543      |
|    n_updates            | 2220       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.737      |
|    value_loss           | 0.895      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127103      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.041525293 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | 0.0928      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11        |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.0171      |
|    std                  | 0.736       |
|    value_loss           | 1.34        |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.69 +/- 0.41
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.048152603 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.72       |
|    explained_variance   | 0.107       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.569       |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.00789     |
|    std                  | 0.736       |
|    value_loss           | 1.06        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129108   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 129314      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.043530688 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.72       |
|    explained_variance   | 0.000132    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 2250        |
|    policy_gradient_loss | 0.00101     |
|    std                  | 0.736       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 129519     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.77155817 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | -0.145     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.601      |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.00731    |
|    std                  | 0.733      |
|    value_loss           | 1.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 129725     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.03267397 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.42       |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.00237    |
|    std                  | 0.73       |
|    value_loss           | 2.35       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 129930      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.037206694 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.33        |
|    n_updates            | 2280        |
|    policy_gradient_loss | 0.0143      |
|    std                  | 0.727       |
|    value_loss           | 0.991       |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.90 +/- 0.04
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.033816498 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.115       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 2290        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.723       |
|    value_loss           | 1.1         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131936   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 132141      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.056100406 |
|    clip_fraction        | 0.444       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | -0.000248   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.26        |
|    n_updates            | 2300        |
|    policy_gradient_loss | 0.00866     |
|    std                  | 0.721       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 132347     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.20198509 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | -0.0105    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.65       |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.717      |
|    value_loss           | 1.18       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 132552     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.39602315 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.000794   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.41       |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.713      |
|    value_loss           | 1.09       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 234       |
|    time_elapsed         | 132758    |
|    total_timesteps      | 479232    |
| train/                  |           |
|    approx_kl            | 1.0443223 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.44     |
|    explained_variance   | 0.015     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.564     |
|    n_updates            | 2330      |
|    policy_gradient_loss | 0.00616   |
|    std                  | 0.709     |
|    value_loss           | 1.13      |
---------------------------------------
Eval num_timesteps=480000, episode_reward=-99.96 +/- 0.02
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.15562922 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.657      |
|    n_updates            | 2340       |
|    policy_gradient_loss | 0.0337     |
|    std                  | 0.711      |
|    value_loss           | 1.05       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134765   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 134970      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.032266065 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | -0.00116    |
|    learning_rate        | 0.0003      |
|    loss                 | 21.5        |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.71        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 237       |
|    time_elapsed         | 135177    |
|    total_timesteps      | 485376    |
| train/                  |           |
|    approx_kl            | 1.3683447 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.41     |
|    explained_variance   | -0.21     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.501     |
|    n_updates            | 2360      |
|    policy_gradient_loss | 0.00764   |
|    std                  | 0.709     |
|    value_loss           | 1.1       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 135382      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.061355185 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.375       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.14        |
|    n_updates            | 2370        |
|    policy_gradient_loss | 0.00996     |
|    std                  | 0.707       |
|    value_loss           | 3.48        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135588     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.06282601 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.34      |
|    explained_variance   | -0.252     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.618      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.036      |
|    std                  | 0.7        |
|    value_loss           | 1.02       |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.94 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.093895145 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | 0.131       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.0187      |
|    std                  | 0.694       |
|    value_loss           | 0.909       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137594   |
|    total_timesteps | 491520   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 241       |
|    time_elapsed         | 137799    |
|    total_timesteps      | 493568    |
| train/                  |           |
|    approx_kl            | 0.1701228 |
|    clip_fraction        | 0.355     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.23     |
|    explained_variance   | -9.3e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 269       |
|    n_updates            | 2400      |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.695     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.22e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 242       |
|    time_elapsed         | 138004    |
|    total_timesteps      | 495616    |
| train/                  |           |
|    approx_kl            | 1.3061378 |
|    clip_fraction        | 0.348     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.25     |
|    explained_variance   | -0.0016   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.837     |
|    n_updates            | 2410      |
|    policy_gradient_loss | 0.0274    |
|    std                  | 0.698     |
|    value_loss           | 1.3       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 138210     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.75998527 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.26      |
|    explained_variance   | -4.15      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.729      |
|    n_updates            | 2420       |
|    policy_gradient_loss | 0.051      |
|    std                  | 0.694      |
|    value_loss           | 2.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138415     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.07135533 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.24      |
|    explained_variance   | -0.0621    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.923      |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.00551    |
|    std                  | 0.696      |
|    value_loss           | 1.67       |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.93 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.074708015 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.302       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 2440        |
|    policy_gradient_loss | 0.0168      |
|    std                  | 0.697       |
|    value_loss           | 1.27        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140421   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 140627     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.03314756 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.26      |
|    explained_variance   | 0.000772   |
|    learning_rate        | 0.0003     |
|    loss                 | 38.2       |
|    n_updates            | 2450       |
|    policy_gradient_loss | 0.00257    |
|    std                  | 0.696      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 140832      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.049888946 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.25       |
|    explained_variance   | 0.0401      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.318       |
|    n_updates            | 2460        |
|    policy_gradient_loss | 0.0202      |
|    std                  | 0.696       |
|    value_loss           | 1.04        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 248        |
|    time_elapsed         | 141037     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.06127464 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.24      |
|    explained_variance   | 0.223      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 2470       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.694      |
|    value_loss           | 1.05       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141243      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.086673945 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | -4.98       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.468       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.0345      |
|    std                  | 0.693       |
|    value_loss           | 2.01        |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.96 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.034878306 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.268       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.69        |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143249   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 143454     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.03926635 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.000944   |
|    learning_rate        | 0.0003     |
|    loss                 | 9.84       |
|    n_updates            | 2500       |
|    policy_gradient_loss | 0.00509    |
|    std                  | 0.689      |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.24e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 252       |
|    time_elapsed         | 143659    |
|    total_timesteps      | 516096    |
| train/                  |           |
|    approx_kl            | 2.4757476 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.18     |
|    explained_variance   | -4.84     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.416     |
|    n_updates            | 2510      |
|    policy_gradient_loss | -0.00576  |
|    std                  | 0.693     |
|    value_loss           | 1.5       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 143865     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.22917289 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.689      |
|    value_loss           | 0.86       |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.94 +/- 0.03
Episode length: 3600.00 +/- 1.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.06149681 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.16      |
|    explained_variance   | -0.215     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.393      |
|    n_updates            | 2530       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.69       |
|    value_loss           | 1.09       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145871   |
|    total_timesteps | 520192   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 255        |
|    time_elapsed         | 146076     |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.07664197 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | -0.00033   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.65       |
|    n_updates            | 2540       |
|    policy_gradient_loss | 0.0408     |
|    std                  | 0.69       |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.26e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 256       |
|    time_elapsed         | 146282    |
|    total_timesteps      | 524288    |
| train/                  |           |
|    approx_kl            | 1.6525455 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.16     |
|    explained_variance   | 0.00272   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.604     |
|    n_updates            | 2550      |
|    policy_gradient_loss | 0.031     |
|    std                  | 0.689     |
|    value_loss           | 1.22      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.26e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 257       |
|    time_elapsed         | 146487    |
|    total_timesteps      | 526336    |
| train/                  |           |
|    approx_kl            | 2.4182692 |
|    clip_fraction        | 0.367     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.13     |
|    explained_variance   | -0.104    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.42      |
|    n_updates            | 2560      |
|    policy_gradient_loss | 0.00482   |
|    std                  | 0.686     |
|    value_loss           | 1.17      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 146692     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.09290468 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.225      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.448      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.683      |
|    value_loss           | 0.84       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.97 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.40291932 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.04      |
|    explained_variance   | 0.248      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.444      |
|    n_updates            | 2580       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.679      |
|    value_loss           | 0.903      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.26e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148698   |
|    total_timesteps | 530432   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.26e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 260       |
|    time_elapsed         | 148904    |
|    total_timesteps      | 532480    |
| train/                  |           |
|    approx_kl            | 0.0414624 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.02     |
|    explained_variance   | -0.00649  |
|    learning_rate        | 0.0003    |
|    loss                 | 2.75e+03  |
|    n_updates            | 2590      |
|    policy_gradient_loss | -0.000548 |
|    std                  | 0.68      |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.27e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 261       |
|    time_elapsed         | 149109    |
|    total_timesteps      | 534528    |
| train/                  |           |
|    approx_kl            | 1.1913303 |
|    clip_fraction        | 0.294     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.01     |
|    explained_variance   | 0.00115   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.921     |
|    n_updates            | 2600      |
|    policy_gradient_loss | 0.0025    |
|    std                  | 0.677     |
|    value_loss           | 1.5       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.27e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 262       |
|    time_elapsed         | 149314    |
|    total_timesteps      | 536576    |
| train/                  |           |
|    approx_kl            | 0.7125889 |
|    clip_fraction        | 0.272     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.99     |
|    explained_variance   | 0.134     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.773     |
|    n_updates            | 2610      |
|    policy_gradient_loss | 0.0215    |
|    std                  | 0.675     |
|    value_loss           | 1.57      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 263        |
|    time_elapsed         | 149520     |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.28523976 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.277      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.525      |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.0234     |
|    std                  | 0.673      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.98 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.118394904 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | -0.757      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.455       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.00463     |
|    std                  | 0.673       |
|    value_loss           | 1.62        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151526   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 151731      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.016833922 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | 0.000551    |
|    learning_rate        | 0.0003      |
|    loss                 | 34.7        |
|    n_updates            | 2640        |
|    policy_gradient_loss | 0.00544     |
|    std                  | 0.673       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 151936     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.09502605 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | -0.069     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.64       |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.674      |
|    value_loss           | 1.36       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.28e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 267       |
|    time_elapsed         | 152143    |
|    total_timesteps      | 546816    |
| train/                  |           |
|    approx_kl            | 0.4680776 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.94     |
|    explained_variance   | 0.269     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.464     |
|    n_updates            | 2660      |
|    policy_gradient_loss | 0.0339    |
|    std                  | 0.672     |
|    value_loss           | 0.917     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 152348     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.10810052 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.242      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03       |
|    n_updates            | 2670       |
|    policy_gradient_loss | 0.0432     |
|    std                  | 0.67       |
|    value_loss           | 0.974      |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.94 +/- 0.08
Episode length: 3600.00 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.04801391 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.91      |
|    explained_variance   | -0.358     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.612      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.671      |
|    value_loss           | 0.892      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154354   |
|    total_timesteps | 550912   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.28e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 270       |
|    time_elapsed         | 154560    |
|    total_timesteps      | 552960    |
| train/                  |           |
|    approx_kl            | 0.2695807 |
|    clip_fraction        | 0.269     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.9      |
|    explained_variance   | -0.000639 |
|    learning_rate        | 0.0003    |
|    loss                 | 89.4      |
|    n_updates            | 2690      |
|    policy_gradient_loss | 0.00251   |
|    std                  | 0.67      |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 154765     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.14388944 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.91      |
|    explained_variance   | -1.79      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.609      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.00222    |
|    std                  | 0.671      |
|    value_loss           | 2.67       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 154970      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.032627776 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.92       |
|    explained_variance   | -0.42       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.441       |
|    n_updates            | 2710        |
|    policy_gradient_loss | 0.00869     |
|    std                  | 0.672       |
|    value_loss           | 1.41        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 155177     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.09295368 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | -0.078     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.365      |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.0456     |
|    std                  | 0.675      |
|    value_loss           | 0.983      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.98 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.48769438 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.243      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.548      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.045      |
|    std                  | 0.67       |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157183   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 157388     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.19292793 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | -0.00131   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9e+03    |
|    n_updates            | 2740       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.668      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 157594     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.06195407 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.0534     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.536      |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0361     |
|    std                  | 0.668      |
|    value_loss           | 1.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 157800     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.13658327 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | -0.0266    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.497      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.664      |
|    value_loss           | 1.46       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 158005     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.26499742 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.78      |
|    explained_variance   | 0.22       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.561      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.0252     |
|    std                  | 0.66       |
|    value_loss           | 0.961      |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.89 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.106770016 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.74       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.32        |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.0146      |
|    std                  | 0.657       |
|    value_loss           | 0.979       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160011   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.31e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160216      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.023160174 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.72       |
|    explained_variance   | -0.0079     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.11        |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.00276     |
|    std                  | 0.656       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.32e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 281      |
|    time_elapsed         | 160422   |
|    total_timesteps      | 575488   |
| train/                  |          |
|    approx_kl            | 1.776439 |
|    clip_fraction        | 0.45     |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.67    |
|    explained_variance   | -0.0344  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.637    |
|    n_updates            | 2800     |
|    policy_gradient_loss | 0.0189   |
|    std                  | 0.652    |
|    value_loss           | 1.09     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.33e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 282       |
|    time_elapsed         | 160627    |
|    total_timesteps      | 577536    |
| train/                  |           |
|    approx_kl            | 0.0727743 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.63     |
|    explained_variance   | -0.305    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.466     |
|    n_updates            | 2810      |
|    policy_gradient_loss | 0.019     |
|    std                  | 0.65      |
|    value_loss           | 0.886     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 160832     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.07228145 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | -0.9       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.309      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.00915    |
|    std                  | 0.649      |
|    value_loss           | 0.795      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.94 +/- 0.08
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 580000    |
| train/                  |           |
|    approx_kl            | 0.0853245 |
|    clip_fraction        | 0.336     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.6      |
|    explained_variance   | 0.318     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.432     |
|    n_updates            | 2830      |
|    policy_gradient_loss | 0.0188    |
|    std                  | 0.648     |
|    value_loss           | 0.679     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162840   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163045      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.050047424 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | 0.00126     |
|    learning_rate        | 0.0003      |
|    loss                 | 29.7        |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.0056      |
|    std                  | 0.649       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 163250     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.99799204 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | -1.36      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.351      |
|    n_updates            | 2850       |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.644      |
|    value_loss           | 0.928      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163456     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.11365623 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.176      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.402      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0316     |
|    std                  | 0.644      |
|    value_loss           | 0.842      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 163661     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.15420222 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.452      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.648      |
|    value_loss           | 0.966      |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.89 +/- 0.04
Episode length: 3599.00 +/- 1.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.18807298 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.232      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.311      |
|    n_updates            | 2880       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.647      |
|    value_loss           | 0.81       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165668   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 165874     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.07092568 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | -0.00536   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.57e+03   |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.00152   |
|    std                  | 0.647      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166079     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.08781036 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.134      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.31       |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.644      |
|    value_loss           | 0.971      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 166285     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.07751176 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.49      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 2910       |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.639      |
|    value_loss           | 0.8        |
----------------------------------------
Eval num_timesteps=600000, episode_reward=-100.00 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.36386538 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.46      |
|    explained_variance   | 0.234      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.639      |
|    value_loss           | 0.973      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168292   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168497      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.049791582 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.46       |
|    explained_variance   | -0.000525   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.89        |
|    n_updates            | 2930        |
|    policy_gradient_loss | 4.74e-05    |
|    std                  | 0.639       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 295       |
|    time_elapsed         | 168703    |
|    total_timesteps      | 604160    |
| train/                  |           |
|    approx_kl            | 0.7178569 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.45     |
|    explained_variance   | 0.0377    |
|    learning_rate        | 0.0003    |
|    loss                 | 10.5      |
|    n_updates            | 2940      |
|    policy_gradient_loss | 0.0482    |
|    std                  | 0.639     |
|    value_loss           | 1.02      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 168908     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.04924901 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.638      |
|    value_loss           | 1.28       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 169113     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.37287188 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.41      |
|    explained_variance   | 0.242      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5        |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.0301     |
|    std                  | 0.637      |
|    value_loss           | 0.778      |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.95 +/- 0.07
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.07676334 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | 0.224      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.476      |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.0329     |
|    std                  | 0.634      |
|    value_loss           | 0.991      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171121   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 171326     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.05406398 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | -0.00767   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.2e+03    |
|    n_updates            | 2980       |
|    policy_gradient_loss | 0.00122    |
|    std                  | 0.635      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.38e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 300      |
|    time_elapsed         | 171532   |
|    total_timesteps      | 614400   |
| train/                  |          |
|    approx_kl            | 0.851291 |
|    clip_fraction        | 0.398    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.39    |
|    explained_variance   | 0.0562   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.384    |
|    n_updates            | 2990     |
|    policy_gradient_loss | 0.0321   |
|    std                  | 0.636    |
|    value_loss           | 0.962    |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 301       |
|    time_elapsed         | 171738    |
|    total_timesteps      | 616448    |
| train/                  |           |
|    approx_kl            | 1.4477736 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.4      |
|    explained_variance   | 0.262     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.387     |
|    n_updates            | 3000      |
|    policy_gradient_loss | 0.0256    |
|    std                  | 0.635     |
|    value_loss           | 0.862     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 171943      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.052878585 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.34       |
|    explained_variance   | 0.179       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.446       |
|    n_updates            | 3010        |
|    policy_gradient_loss | 0.0203      |
|    std                  | 0.629       |
|    value_loss           | 0.726       |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.98 +/- 0.04
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -100      |
| time/                   |           |
|    total_timesteps      | 620000    |
| train/                  |           |
|    approx_kl            | 0.1002219 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.29     |
|    explained_variance   | -0.316    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.326     |
|    n_updates            | 3020      |
|    policy_gradient_loss | 0.00769   |
|    std                  | 0.627     |
|    value_loss           | 1.08      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 173949   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 174155      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.054033473 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | 0.0013      |
|    learning_rate        | 0.0003      |
|    loss                 | 728         |
|    n_updates            | 3030        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.628       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 174360    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 1.7617941 |
|    clip_fraction        | 0.404     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.22     |
|    explained_variance   | -0.0119   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.473     |
|    n_updates            | 3040      |
|    policy_gradient_loss | 0.0229    |
|    std                  | 0.618     |
|    value_loss           | 0.907     |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.4e+03  |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 306      |
|    time_elapsed         | 174565   |
|    total_timesteps      | 626688   |
| train/                  |          |
|    approx_kl            | 1.05513  |
|    clip_fraction        | 0.376    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.18    |
|    explained_variance   | 0.00792  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.393    |
|    n_updates            | 3050     |
|    policy_gradient_loss | 0.0371   |
|    std                  | 0.62     |
|    value_loss           | 0.785    |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 307         |
|    time_elapsed         | 174771      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.061559565 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.299       |
|    n_updates            | 3060        |
|    policy_gradient_loss | 0.0254      |
|    std                  | 0.616       |
|    value_loss           | 0.742       |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.91 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.035892744 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | -0.655      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.328       |
|    n_updates            | 3070        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.616       |
|    value_loss           | 2.95        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176777   |
|    total_timesteps | 630784   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 309       |
|    time_elapsed         | 176982    |
|    total_timesteps      | 632832    |
| train/                  |           |
|    approx_kl            | 0.0497608 |
|    clip_fraction        | 0.267     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.12     |
|    explained_variance   | 0.0101    |
|    learning_rate        | 0.0003    |
|    loss                 | 5.67      |
|    n_updates            | 3080      |
|    policy_gradient_loss | 0.00407   |
|    std                  | 0.615     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 310       |
|    time_elapsed         | 177188    |
|    total_timesteps      | 634880    |
| train/                  |           |
|    approx_kl            | 1.1147387 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.1      |
|    explained_variance   | -0.000158 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.332     |
|    n_updates            | 3090      |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.614     |
|    value_loss           | 0.696     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 311        |
|    time_elapsed         | 177394     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.13362074 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.08      |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.228      |
|    n_updates            | 3100       |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.613      |
|    value_loss           | 0.578      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 312        |
|    time_elapsed         | 177599     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.29033425 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.195      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 3110       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.61       |
|    value_loss           | 0.719      |
----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.95 +/- 0.03
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.34454685 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.03      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.171      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.0201     |
|    std                  | 0.609      |
|    value_loss           | 0.67       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179607   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 179814     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.07507014 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.02      |
|    explained_variance   | 0.000494   |
|    learning_rate        | 0.0003     |
|    loss                 | 13.6       |
|    n_updates            | 3130       |
|    policy_gradient_loss | 0.00606    |
|    std                  | 0.609      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 315       |
|    time_elapsed         | 180020    |
|    total_timesteps      | 645120    |
| train/                  |           |
|    approx_kl            | 1.3799517 |
|    clip_fraction        | 0.354     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.99     |
|    explained_variance   | 0.000692  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.336     |
|    n_updates            | 3140      |
|    policy_gradient_loss | 0.0111    |
|    std                  | 0.605     |
|    value_loss           | 0.724     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 316       |
|    time_elapsed         | 180225    |
|    total_timesteps      | 647168    |
| train/                  |           |
|    approx_kl            | 1.4745457 |
|    clip_fraction        | 0.351     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.95     |
|    explained_variance   | 0.0633    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.408     |
|    n_updates            | 3150      |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.602     |
|    value_loss           | 0.706     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 317         |
|    time_elapsed         | 180430      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.090160325 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.91       |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.558       |
|    n_updates            | 3160        |
|    policy_gradient_loss | 0.0425      |
|    std                  | 0.6         |
|    value_loss           | 0.796       |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.92 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.08536324 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.35       |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.007      |
|    std                  | 0.601      |
|    value_loss           | 5.14       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182438   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182643      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.035524353 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.9        |
|    explained_variance   | 0.0608      |
|    learning_rate        | 0.0003      |
|    loss                 | 147         |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.00212    |
|    std                  | 0.601       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 320       |
|    time_elapsed         | 182849    |
|    total_timesteps      | 655360    |
| train/                  |           |
|    approx_kl            | 1.5633414 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.92     |
|    explained_variance   | -0.631    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.474     |
|    n_updates            | 3190      |
|    policy_gradient_loss | 0.0223    |
|    std                  | 0.604     |
|    value_loss           | 1.1       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 183054     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.26880056 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.0803     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.513      |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.606      |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183260     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.11852467 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.661      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.61       |
|    value_loss           | 1.22       |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.79 +/- 0.43
Episode length: 3599.40 +/- 1.96
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 660000    |
| train/                  |           |
|    approx_kl            | 0.1625149 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.01     |
|    explained_variance   | 0.297     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.63      |
|    n_updates            | 3220      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.61      |
|    value_loss           | 0.915     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185268   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 185474     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.08570122 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.02      |
|    explained_variance   | -0.0319    |
|    learning_rate        | 0.0003     |
|    loss                 | 41.6       |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.00428    |
|    std                  | 0.609      |
|    value_loss           | 1.01e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 185679     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.07727178 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.03      |
|    explained_variance   | -0.0678    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.905      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.612      |
|    value_loss           | 1.87       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 326         |
|    time_elapsed         | 185885      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.056009315 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.05       |
|    explained_variance   | -0.0348     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 3250        |
|    policy_gradient_loss | 0.00891     |
|    std                  | 0.613       |
|    value_loss           | 1.94        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 327         |
|    time_elapsed         | 186090      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.015451642 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | -3.41       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 3260        |
|    policy_gradient_loss | 0.00536     |
|    std                  | 0.613       |
|    value_loss           | 5.33        |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.85 +/- 0.15
Episode length: 3598.00 +/- 6.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 670000    |
| train/                  |           |
|    approx_kl            | 1.0093524 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.06     |
|    explained_variance   | -0.423    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.468     |
|    n_updates            | 3270      |
|    policy_gradient_loss | 0.031     |
|    std                  | 0.612     |
|    value_loss           | 1.28      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188096   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 188304     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.39038277 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | -0.038     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5e+03    |
|    n_updates            | 3280       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.612      |
|    value_loss           | 966        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 188509     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.17670083 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | -0.0166    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08       |
|    n_updates            | 3290       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.613      |
|    value_loss           | 1.91       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188714     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.21403536 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | -0.0219    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.722      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.612      |
|    value_loss           | 1.74       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 188920     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.07802904 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | -0.00845   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.895      |
|    n_updates            | 3310       |
|    policy_gradient_loss | 0.00167    |
|    std                  | 0.614      |
|    value_loss           | 1.75       |
----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.82 +/- 0.16
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.099241346 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | 0.00435     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.75        |
|    n_updates            | 3320        |
|    policy_gradient_loss | 0.00375     |
|    std                  | 0.613       |
|    value_loss           | 1.91        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190926   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 334         |
|    time_elapsed         | 191134      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.011503689 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | 0.0431      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.06        |
|    n_updates            | 3330        |
|    policy_gradient_loss | 0.00174     |
|    std                  | 0.613       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 335         |
|    time_elapsed         | 191340      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.058256574 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | -0.241      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.605       |
|    n_updates            | 3340        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.614       |
|    value_loss           | 1.53        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 336       |
|    time_elapsed         | 191545    |
|    total_timesteps      | 688128    |
| train/                  |           |
|    approx_kl            | 0.6081941 |
|    clip_fraction        | 0.373     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.09     |
|    explained_variance   | 0.238     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.566     |
|    n_updates            | 3350      |
|    policy_gradient_loss | 0.0287    |
|    std                  | 0.615     |
|    value_loss           | 1.24      |
---------------------------------------
Eval num_timesteps=690000, episode_reward=-99.88 +/- 0.09
Episode length: 3599.60 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.16979268 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.1       |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.804      |
|    n_updates            | 3360       |
|    policy_gradient_loss | 0.00228    |
|    std                  | 0.617      |
|    value_loss           | 1.57       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193553   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 193759      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.017030522 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | 0.0527      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.39        |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00427    |
|    std                  | 0.617       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 193964     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.03851562 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | -0.0997    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.618      |
|    value_loss           | 1.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 194170     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.08301125 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | 0.992      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.738      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.614      |
|    value_loss           | 1.44       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 194375     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.11374836 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.455      |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.00634    |
|    std                  | 0.613      |
|    value_loss           | 2.47       |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.85 +/- 0.15
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.12654544 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.04      |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.731      |
|    n_updates            | 3410       |
|    policy_gradient_loss | 0.00993    |
|    std                  | 0.611      |
|    value_loss           | 5.97       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196381   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 196586     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.10721485 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.01      |
|    explained_variance   | -0.000357  |
|    learning_rate        | 0.0003     |
|    loss                 | 9.16       |
|    n_updates            | 3420       |
|    policy_gradient_loss | 0.00957    |
|    std                  | 0.61       |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.4e+03  |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 344      |
|    time_elapsed         | 196792   |
|    total_timesteps      | 704512   |
| train/                  |          |
|    approx_kl            | 1.08938  |
|    clip_fraction        | 0.471    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.98    |
|    explained_variance   | -0.206   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.222    |
|    n_updates            | 3430     |
|    policy_gradient_loss | 0.0251   |
|    std                  | 0.608    |
|    value_loss           | 0.785    |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 345         |
|    time_elapsed         | 196998      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.059257768 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.251       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.41        |
|    n_updates            | 3440        |
|    policy_gradient_loss | 0.0221      |
|    std                  | 0.607       |
|    value_loss           | 0.868       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 346        |
|    time_elapsed         | 197203     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.09243417 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.96      |
|    explained_variance   | 0.249      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.581      |
|    n_updates            | 3450       |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.604      |
|    value_loss           | 1.09       |
----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.83 +/- 0.13
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.26130414 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.982      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08       |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.000504   |
|    std                  | 0.602      |
|    value_loss           | 1.86       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199210   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 199416     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.04080342 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | -0.0613    |
|    learning_rate        | 0.0003     |
|    loss                 | 60.1       |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.00495   |
|    std                  | 0.601      |
|    value_loss           | 837        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 349        |
|    time_elapsed         | 199622     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.25915843 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | -3.16      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47       |
|    n_updates            | 3480       |
|    policy_gradient_loss | 0.00404    |
|    std                  | 0.601      |
|    value_loss           | 2.75       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 199827     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.07454234 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.08       |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.00227    |
|    std                  | 0.603      |
|    value_loss           | 3.85       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.39e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 351      |
|    time_elapsed         | 200032   |
|    total_timesteps      | 718848   |
| train/                  |          |
|    approx_kl            | 1.034065 |
|    clip_fraction        | 0.426    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.92    |
|    explained_variance   | -0.261   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.623    |
|    n_updates            | 3500     |
|    policy_gradient_loss | 0.0275   |
|    std                  | 0.606    |
|    value_loss           | 1.23     |
--------------------------------------
Eval num_timesteps=720000, episode_reward=-99.76 +/- 0.19
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.10825432 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.0691     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.582      |
|    n_updates            | 3510       |
|    policy_gradient_loss | 0.0254     |
|    std                  | 0.601      |
|    value_loss           | 1.16       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202039   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 202244      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.047993824 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.0619      |
|    learning_rate        | 0.0003      |
|    loss                 | 446         |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.601       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 202450     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.13503832 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.64       |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.0033     |
|    std                  | 0.601      |
|    value_loss           | 3.55       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 202655     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.07327998 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25       |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.601      |
|    value_loss           | 2.35       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 202861     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.13515495 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.265      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.574      |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.6        |
|    value_loss           | 1.08       |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.76 +/- 0.12
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.060308784 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26        |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.00407    |
|    std                  | 0.601       |
|    value_loss           | 2.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204867   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205073      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.056141272 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 745         |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.00115    |
|    std                  | 0.6         |
|    value_loss           | 1.04e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.39e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 359      |
|    time_elapsed         | 205280   |
|    total_timesteps      | 735232   |
| train/                  |          |
|    approx_kl            | 0.504031 |
|    clip_fraction        | 0.378    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.85    |
|    explained_variance   | 0.344    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.382    |
|    n_updates            | 3580     |
|    policy_gradient_loss | 0.0355   |
|    std                  | 0.598    |
|    value_loss           | 0.899    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 205485     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.28443578 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.408      |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.6        |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 205691     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.11335687 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.364      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.598      |
|    value_loss           | 0.775      |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.89 +/- 0.13
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.07936863 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.603      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.597      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207697   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 207902      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.028696632 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | 0.0996      |
|    learning_rate        | 0.0003      |
|    loss                 | 122         |
|    n_updates            | 3620        |
|    policy_gradient_loss | 0.00109     |
|    std                  | 0.597       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 364         |
|    time_elapsed         | 208108      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.079221904 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | -0.217      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.37        |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.596       |
|    value_loss           | 2.88        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 365       |
|    time_elapsed         | 208313    |
|    total_timesteps      | 747520    |
| train/                  |           |
|    approx_kl            | 1.2669035 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.82     |
|    explained_variance   | 0.971     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.838     |
|    n_updates            | 3640      |
|    policy_gradient_loss | -0.00605  |
|    std                  | 0.593     |
|    value_loss           | 1.34      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 208518      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.087886795 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.468       |
|    n_updates            | 3650        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.591       |
|    value_loss           | 0.85        |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.84 +/- 0.18
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.089871615 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.594       |
|    value_loss           | 0.934       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210524   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 210730     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.02519758 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | -0.0141    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.38       |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.00484   |
|    std                  | 0.595      |
|    value_loss           | 1e+03      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 210938     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.09435932 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.28       |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.00619   |
|    std                  | 0.593      |
|    value_loss           | 2.52       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 370       |
|    time_elapsed         | 211144    |
|    total_timesteps      | 757760    |
| train/                  |           |
|    approx_kl            | 0.8797915 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.79     |
|    explained_variance   | 0.3       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.46      |
|    n_updates            | 3690      |
|    policy_gradient_loss | 0.0272    |
|    std                  | 0.592     |
|    value_loss           | 0.932     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 371       |
|    time_elapsed         | 211350    |
|    total_timesteps      | 759808    |
| train/                  |           |
|    approx_kl            | 0.0965702 |
|    clip_fraction        | 0.315     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.79     |
|    explained_variance   | 0.994     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.597     |
|    n_updates            | 3700      |
|    policy_gradient_loss | 0.00655   |
|    std                  | 0.591     |
|    value_loss           | 1.39      |
---------------------------------------
Eval num_timesteps=760000, episode_reward=-99.86 +/- 0.11
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.62685096 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.0003     |
|    loss                 | 4          |
|    n_updates            | 3710       |
|    policy_gradient_loss | 0.00642    |
|    std                  | 0.589      |
|    value_loss           | 4.33       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213357   |
|    total_timesteps | 761856   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 373       |
|    time_elapsed         | 213563    |
|    total_timesteps      | 763904    |
| train/                  |           |
|    approx_kl            | 0.1589672 |
|    clip_fraction        | 0.29      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.75     |
|    explained_variance   | 0.000209  |
|    learning_rate        | 0.0003    |
|    loss                 | 24.7      |
|    n_updates            | 3720      |
|    policy_gradient_loss | 0.00419   |
|    std                  | 0.589     |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 374       |
|    time_elapsed         | 213768    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 1.2668452 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.75     |
|    explained_variance   | 0.224     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.272     |
|    n_updates            | 3730      |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.588     |
|    value_loss           | 0.697     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 213974     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.04154886 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.72      |
|    explained_variance   | 0.33       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.413      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.586      |
|    value_loss           | 0.954      |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.76 +/- 0.43
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.046872273 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 3750        |
|    policy_gradient_loss | 0.0065      |
|    std                  | 0.584       |
|    value_loss           | 3.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 215980   |
|    total_timesteps | 770048   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 377        |
|    time_elapsed         | 216185     |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.14146276 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.69      |
|    explained_variance   | -8.56e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.41e+03   |
|    n_updates            | 3760       |
|    policy_gradient_loss | -0.00113   |
|    std                  | 0.583      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.38e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 378      |
|    time_elapsed         | 216391   |
|    total_timesteps      | 774144   |
| train/                  |          |
|    approx_kl            | 4.465297 |
|    clip_fraction        | 0.421    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.68    |
|    explained_variance   | 0.00978  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.627    |
|    n_updates            | 3770     |
|    policy_gradient_loss | 0.00557  |
|    std                  | 0.583    |
|    value_loss           | 1.47     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 379       |
|    time_elapsed         | 216596    |
|    total_timesteps      | 776192    |
| train/                  |           |
|    approx_kl            | 2.7124782 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.66     |
|    explained_variance   | 0.000382  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.633     |
|    n_updates            | 3780      |
|    policy_gradient_loss | 0.00401   |
|    std                  | 0.581     |
|    value_loss           | 1.08      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 216801     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.18089676 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.529      |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.00887    |
|    std                  | 0.575      |
|    value_loss           | 0.952      |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.73 +/- 0.39
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.043804325 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | 0.0349      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.504       |
|    n_updates            | 3800        |
|    policy_gradient_loss | 0.0151      |
|    std                  | 0.575       |
|    value_loss           | 0.998       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218808   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 219014     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.08538203 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13e+03   |
|    n_updates            | 3810       |
|    policy_gradient_loss | 0.0036     |
|    std                  | 0.575      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 383       |
|    time_elapsed         | 219220    |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 0.8568463 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.54     |
|    explained_variance   | 0.002     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.634     |
|    n_updates            | 3820      |
|    policy_gradient_loss | 0.0353    |
|    std                  | 0.572     |
|    value_loss           | 0.993     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 384       |
|    time_elapsed         | 219425    |
|    total_timesteps      | 786432    |
| train/                  |           |
|    approx_kl            | 0.3718749 |
|    clip_fraction        | 0.367     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.48     |
|    explained_variance   | -0.00334  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.593     |
|    n_updates            | 3830      |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.568     |
|    value_loss           | 1.1       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 385       |
|    time_elapsed         | 219630    |
|    total_timesteps      | 788480    |
| train/                  |           |
|    approx_kl            | 2.289999  |
|    clip_fraction        | 0.347     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.46     |
|    explained_variance   | -8.34e-07 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.483     |
|    n_updates            | 3840      |
|    policy_gradient_loss | 0.0108    |
|    std                  | 0.568     |
|    value_loss           | 0.995     |
---------------------------------------
Eval num_timesteps=790000, episode_reward=-99.52 +/- 0.45
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.78563446 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | -0.694     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.677      |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.00354    |
|    std                  | 0.566      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221636   |
|    total_timesteps | 790528   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 387       |
|    time_elapsed         | 221842    |
|    total_timesteps      | 792576    |
| train/                  |           |
|    approx_kl            | 0.9671557 |
|    clip_fraction        | 0.268     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.42     |
|    explained_variance   | 0.00917   |
|    learning_rate        | 0.0003    |
|    loss                 | 723       |
|    n_updates            | 3860      |
|    policy_gradient_loss | 0.0274    |
|    std                  | 0.565     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 388       |
|    time_elapsed         | 222047    |
|    total_timesteps      | 794624    |
| train/                  |           |
|    approx_kl            | 0.6935022 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.42     |
|    explained_variance   | 0.0023    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.718     |
|    n_updates            | 3870      |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.567     |
|    value_loss           | 1.47      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 222252     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.49748108 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.669      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.000101   |
|    std                  | 0.567      |
|    value_loss           | 5.47       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 390       |
|    time_elapsed         | 222458    |
|    total_timesteps      | 798720    |
| train/                  |           |
|    approx_kl            | 1.4599243 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.41     |
|    explained_variance   | -0.00414  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.674     |
|    n_updates            | 3890      |
|    policy_gradient_loss | 0.017     |
|    std                  | 0.566     |
|    value_loss           | 1.04      |
---------------------------------------
Eval num_timesteps=800000, episode_reward=-99.96 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.14818195 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | -3.14      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.465      |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.0318     |
|    std                  | 0.563      |
|    value_loss           | 1.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224464   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 224670      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.095059976 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.000892    |
|    learning_rate        | 0.0003      |
|    loss                 | 722         |
|    n_updates            | 3910        |
|    policy_gradient_loss | 0.00169     |
|    std                  | 0.562       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 224875     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.65403223 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.32      |
|    explained_variance   | 0.00781    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.343      |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.00484    |
|    std                  | 0.559      |
|    value_loss           | 1.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 225082      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.096321456 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.3        |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.49        |
|    n_updates            | 3930        |
|    policy_gradient_loss | 0.000269    |
|    std                  | 0.559       |
|    value_loss           | 5.06        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 225288     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.24269173 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0395     |
|    std                  | 0.561      |
|    value_loss           | 0.852      |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.95 +/- 0.04
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -100      |
| time/                   |           |
|    total_timesteps      | 810000    |
| train/                  |           |
|    approx_kl            | 0.1232638 |
|    clip_fraction        | 0.359     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.3      |
|    explained_variance   | -0.124    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.578     |
|    n_updates            | 3950      |
|    policy_gradient_loss | 0.00298   |
|    std                  | 0.558     |
|    value_loss           | 1.34      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227294   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 227499     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.15763682 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.000351   |
|    learning_rate        | 0.0003     |
|    loss                 | 169        |
|    n_updates            | 3960       |
|    policy_gradient_loss | 0.00985    |
|    std                  | 0.557      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 398       |
|    time_elapsed         | 227704    |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 1.0271698 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.24     |
|    explained_variance   | 0.0308    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.381     |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.00674   |
|    std                  | 0.552     |
|    value_loss           | 0.947     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.4e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 399       |
|    time_elapsed         | 227910    |
|    total_timesteps      | 817152    |
| train/                  |           |
|    approx_kl            | 0.3983887 |
|    clip_fraction        | 0.366     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.2      |
|    explained_variance   | -0.703    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.321     |
|    n_updates            | 3980      |
|    policy_gradient_loss | 0.0276    |
|    std                  | 0.551     |
|    value_loss           | 0.776     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 228116     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.19069827 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.19      |
|    explained_variance   | 0.298      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.425      |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.551      |
|    value_loss           | 0.788      |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.96 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.047457203 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.18       |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.569       |
|    n_updates            | 4000        |
|    policy_gradient_loss | 0.017       |
|    std                  | 0.549       |
|    value_loss           | 0.779       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230122   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 230327     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.07685027 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.18      |
|    explained_variance   | 0.000705   |
|    learning_rate        | 0.0003     |
|    loss                 | 913        |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.00348    |
|    std                  | 0.551      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 230533     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.47911912 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.19      |
|    explained_variance   | -0.0497    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.491      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0273     |
|    std                  | 0.551      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 404       |
|    time_elapsed         | 230739    |
|    total_timesteps      | 827392    |
| train/                  |           |
|    approx_kl            | 0.9097297 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.19     |
|    explained_variance   | -0.0197   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.406     |
|    n_updates            | 4030      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.553     |
|    value_loss           | 0.938     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 405       |
|    time_elapsed         | 230945    |
|    total_timesteps      | 829440    |
| train/                  |           |
|    approx_kl            | 0.5553292 |
|    clip_fraction        | 0.337     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.18     |
|    explained_variance   | 0.322     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.294     |
|    n_updates            | 4040      |
|    policy_gradient_loss | 0.0141    |
|    std                  | 0.55      |
|    value_loss           | 0.803     |
---------------------------------------
Eval num_timesteps=830000, episode_reward=-99.90 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.22228399 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | 0.356      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.354      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.551      |
|    value_loss           | 0.574      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 232951   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233156     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.05264099 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | -0.0137    |
|    learning_rate        | 0.0003     |
|    loss                 | 997        |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.00139   |
|    std                  | 0.551      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 233361     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.41698992 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | -0.163     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.353      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.00418    |
|    std                  | 0.551      |
|    value_loss           | 0.918      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 409         |
|    time_elapsed         | 233567      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.043897916 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.17       |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.498       |
|    n_updates            | 4080        |
|    policy_gradient_loss | 0.00555     |
|    std                  | 0.551       |
|    value_loss           | 0.845       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.41e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 410       |
|    time_elapsed         | 233772    |
|    total_timesteps      | 839680    |
| train/                  |           |
|    approx_kl            | 0.1477758 |
|    clip_fraction        | 0.278     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.14     |
|    explained_variance   | 0.221     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.423     |
|    n_updates            | 4090      |
|    policy_gradient_loss | 0.0108    |
|    std                  | 0.549     |
|    value_loss           | 0.741     |
---------------------------------------
Eval num_timesteps=840000, episode_reward=-99.94 +/- 0.04
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.071054205 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.13       |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 4100        |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.55        |
|    value_loss           | 0.728       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235779   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 235985      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.050005108 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.14       |
|    explained_variance   | 0.000912    |
|    learning_rate        | 0.0003      |
|    loss                 | 417         |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00252    |
|    std                  | 0.549       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 413       |
|    time_elapsed         | 236190    |
|    total_timesteps      | 845824    |
| train/                  |           |
|    approx_kl            | 1.0364277 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.1      |
|    explained_variance   | -0.0669   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.475     |
|    n_updates            | 4120      |
|    policy_gradient_loss | 0.025     |
|    std                  | 0.546     |
|    value_loss           | 0.795     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 414       |
|    time_elapsed         | 236395    |
|    total_timesteps      | 847872    |
| train/                  |           |
|    approx_kl            | 0.4025344 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.07     |
|    explained_variance   | 0.388     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.364     |
|    n_updates            | 4130      |
|    policy_gradient_loss | 0.0295    |
|    std                  | 0.546     |
|    value_loss           | 0.526     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 236601     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.19928913 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | -0.557     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.461      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.547      |
|    value_loss           | 0.822      |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.65 +/- 0.45
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.04418747 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.1       |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.3        |
|    n_updates            | 4150       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.547      |
|    value_loss           | 0.656      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238607   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 238812     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.15992472 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | -0.00113   |
|    learning_rate        | 0.0003     |
|    loss                 | 933        |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.00257    |
|    std                  | 0.545      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 239017    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 2.5310326 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.05     |
|    explained_variance   | -3.05     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.801     |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.0145    |
|    std                  | 0.544     |
|    value_loss           | 1.71      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 419         |
|    time_elapsed         | 239223      |
|    total_timesteps      | 858112      |
| train/                  |             |
|    approx_kl            | 0.058645688 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.322       |
|    n_updates            | 4180        |
|    policy_gradient_loss | 0.0171      |
|    std                  | 0.545       |
|    value_loss           | 0.725       |
-----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.87 +/- 0.08
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.2783121 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.112     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.796     |
|    n_updates            | 4190      |
|    policy_gradient_loss | 0.0109    |
|    std                  | 0.543     |
|    value_loss           | 1.37      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241229   |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 421         |
|    time_elapsed         | 241434      |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.039188363 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6          |
|    explained_variance   | 0.000928    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+03    |
|    n_updates            | 4200        |
|    policy_gradient_loss | 0.00043     |
|    std                  | 0.543       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 241640     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.25681132 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | 0.0258     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.295      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.000302   |
|    std                  | 0.545      |
|    value_loss           | 0.764      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 423       |
|    time_elapsed         | 241845    |
|    total_timesteps      | 866304    |
| train/                  |           |
|    approx_kl            | 0.4041986 |
|    clip_fraction        | 0.35      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.04     |
|    explained_variance   | 0.306     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.388     |
|    n_updates            | 4220      |
|    policy_gradient_loss | 0.0243    |
|    std                  | 0.547     |
|    value_loss           | 0.767     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 242050     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.71768653 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.282      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.347      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0401     |
|    std                  | 0.544      |
|    value_loss           | 0.717      |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.82 +/- 0.13
Episode length: 3599.60 +/- 1.96
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.056144718 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.274       |
|    n_updates            | 4240        |
|    policy_gradient_loss | 0.0217      |
|    std                  | 0.543       |
|    value_loss           | 0.633       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244056   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244262     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.17820677 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.04      |
|    explained_variance   | 0.00171    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.43e+03   |
|    n_updates            | 4250       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.549      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 427       |
|    time_elapsed         | 244467    |
|    total_timesteps      | 874496    |
| train/                  |           |
|    approx_kl            | 2.5953841 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.08     |
|    explained_variance   | -0.488    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.278     |
|    n_updates            | 4260      |
|    policy_gradient_loss | 0.0187    |
|    std                  | 0.548     |
|    value_loss           | 0.903     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 428       |
|    time_elapsed         | 244674    |
|    total_timesteps      | 876544    |
| train/                  |           |
|    approx_kl            | 0.3810864 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.07     |
|    explained_variance   | 0.262     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.32      |
|    n_updates            | 4270      |
|    policy_gradient_loss | 0.0229    |
|    std                  | 0.548     |
|    value_loss           | 0.759     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 244879     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.16590023 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.231      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.499      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.55       |
|    value_loss           | 0.838      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.89 +/- 0.08
Episode length: 3598.40 +/- 5.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 880000    |
| train/                  |           |
|    approx_kl            | 0.8928479 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.09     |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.99      |
|    n_updates            | 4290      |
|    policy_gradient_loss | -0.0148   |
|    std                  | 0.55      |
|    value_loss           | 3.88      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246886   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 247091     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.12589823 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.1       |
|    explained_variance   | -0.00184   |
|    learning_rate        | 0.0003     |
|    loss                 | 867        |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.0266     |
|    std                  | 0.553      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 247297    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 1.3847346 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.13     |
|    explained_variance   | 0.00141   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.1       |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.0308    |
|    std                  | 0.555     |
|    value_loss           | 1.29      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.43e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 433      |
|    time_elapsed         | 247502   |
|    total_timesteps      | 886784   |
| train/                  |          |
|    approx_kl            | 1.938848 |
|    clip_fraction        | 0.33     |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.13    |
|    explained_variance   | 0.713    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.15     |
|    n_updates            | 4320     |
|    policy_gradient_loss | 0.0105   |
|    std                  | 0.553    |
|    value_loss           | 1.96     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 434       |
|    time_elapsed         | 247707    |
|    total_timesteps      | 888832    |
| train/                  |           |
|    approx_kl            | 0.0687265 |
|    clip_fraction        | 0.3       |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.11     |
|    explained_variance   | 0.219     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.427     |
|    n_updates            | 4330      |
|    policy_gradient_loss | 0.0068    |
|    std                  | 0.553     |
|    value_loss           | 0.954     |
---------------------------------------
Eval num_timesteps=890000, episode_reward=-99.88 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.053642947 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.536       |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.00626     |
|    std                  | 0.55        |
|    value_loss           | 1.01        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249713   |
|    total_timesteps | 890880   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 436       |
|    time_elapsed         | 249919    |
|    total_timesteps      | 892928    |
| train/                  |           |
|    approx_kl            | 0.0786639 |
|    clip_fraction        | 0.232     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.07     |
|    explained_variance   | 0.0399    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.04e+03  |
|    n_updates            | 4350      |
|    policy_gradient_loss | -0.0059   |
|    std                  | 0.55      |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 437       |
|    time_elapsed         | 250126    |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 1.6672845 |
|    clip_fraction        | 0.322     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.07     |
|    explained_variance   | 0.0145    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.477     |
|    n_updates            | 4360      |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.551     |
|    value_loss           | 0.769     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 250331     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.43395206 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.07      |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.652      |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.549      |
|    value_loss           | 3.3        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 250536     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.21085462 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.04      |
|    explained_variance   | 0.329      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.547      |
|    value_loss           | 0.72       |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.91 +/- 0.06
Episode length: 3600.00 +/- 1.55
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 900000    |
| train/                  |           |
|    approx_kl            | 0.2875563 |
|    clip_fraction        | 0.342     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.594     |
|    n_updates            | 4390      |
|    policy_gradient_loss | 0.0215    |
|    std                  | 0.546     |
|    value_loss           | 3.5       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252542   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 252748      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.015165778 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | -0.00993    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.31        |
|    n_updates            | 4400        |
|    policy_gradient_loss | -0.00297    |
|    std                  | 0.546       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 442       |
|    time_elapsed         | 252953    |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 0.1109964 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6        |
|    explained_variance   | 0.0807    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.359     |
|    n_updates            | 4410      |
|    policy_gradient_loss | 0.0322    |
|    std                  | 0.544     |
|    value_loss           | 0.759     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 253159     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.12021388 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.97      |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.256      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0318     |
|    std                  | 0.544      |
|    value_loss           | 0.653      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 253364     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.13566163 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.95      |
|    explained_variance   | 0.235      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.453      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.0301     |
|    std                  | 0.542      |
|    value_loss           | 0.785      |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.87 +/- 0.05
Episode length: 3598.40 +/- 3.88
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.06459231 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.228      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0337     |
|    std                  | 0.544      |
|    value_loss           | 0.748      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255370   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 255575     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.10381363 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | 0.0488     |
|    learning_rate        | 0.0003     |
|    loss                 | 56.5       |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.00597    |
|    std                  | 0.544      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 255781     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.80661166 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 5.98e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.64       |
|    n_updates            | 4460       |
|    policy_gradient_loss | 0.0311     |
|    std                  | 0.543      |
|    value_loss           | 1.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 255986     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.83489764 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.94      |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.02       |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.543      |
|    value_loss           | 9.93       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 449       |
|    time_elapsed         | 256192    |
|    total_timesteps      | 919552    |
| train/                  |           |
|    approx_kl            | 0.4001183 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.94     |
|    explained_variance   | 0.000246  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.367     |
|    n_updates            | 4480      |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.542     |
|    value_loss           | 0.899     |
---------------------------------------
Eval num_timesteps=920000, episode_reward=-99.91 +/- 0.10
Episode length: 3597.60 +/- 6.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.33436495 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | -3.17e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.546      |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.541      |
|    value_loss           | 0.969      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258201   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 451        |
|    time_elapsed         | 258408     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.12560266 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | -7.39e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 403        |
|    n_updates            | 4500       |
|    policy_gradient_loss | 0.00852    |
|    std                  | 0.544      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 452        |
|    time_elapsed         | 258613     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.41286162 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.93      |
|    explained_variance   | -0.0102    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.396      |
|    n_updates            | 4510       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.545      |
|    value_loss           | 0.922      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 453       |
|    time_elapsed         | 258819    |
|    total_timesteps      | 927744    |
| train/                  |           |
|    approx_kl            | 0.5481498 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.93     |
|    explained_variance   | 3.04e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.439     |
|    n_updates            | 4520      |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.545     |
|    value_loss           | 0.834     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 454       |
|    time_elapsed         | 259024    |
|    total_timesteps      | 929792    |
| train/                  |           |
|    approx_kl            | 0.9303945 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.9      |
|    explained_variance   | 0.00117   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.396     |
|    n_updates            | 4530      |
|    policy_gradient_loss | 0.00517   |
|    std                  | 0.541     |
|    value_loss           | 0.88      |
---------------------------------------
Eval num_timesteps=930000, episode_reward=-99.51 +/- 0.79
Episode length: 3600.00 +/- 0.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.042230256 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | 0.2         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.333       |
|    n_updates            | 4540        |
|    policy_gradient_loss | 0.0232      |
|    std                  | 0.543       |
|    value_loss           | 0.799       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261031   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261237      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.046960823 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.89       |
|    explained_variance   | -0.00145    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+03    |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.00348     |
|    std                  | 0.544       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 261442     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.28273225 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.9       |
|    explained_variance   | 0.43       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.58       |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.0265     |
|    std                  | 0.544      |
|    value_loss           | 25.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 261648     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.52502924 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.88      |
|    explained_variance   | 0.00168    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.506      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.0283     |
|    std                  | 0.542      |
|    value_loss           | 1.12       |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.81 +/- 0.06
Episode length: 3599.60 +/- 2.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 940000    |
| train/                  |           |
|    approx_kl            | 0.8711678 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.86     |
|    explained_variance   | 0.0143    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.463     |
|    n_updates            | 4580      |
|    policy_gradient_loss | 0.0374    |
|    std                  | 0.542     |
|    value_loss           | 0.752     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263654   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 263859     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.11751509 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.86      |
|    explained_variance   | -0.000243  |
|    learning_rate        | 0.0003     |
|    loss                 | 148        |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.00657    |
|    std                  | 0.543      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 264066     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.43233585 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.87      |
|    explained_variance   | 0.00165    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.499      |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.0294     |
|    std                  | 0.544      |
|    value_loss           | 0.997      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264272     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.44741982 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.86      |
|    explained_variance   | -1.51      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.68       |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.00968    |
|    std                  | 0.543      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 264477     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.35161287 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.00285    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.416      |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.541      |
|    value_loss           | 0.984      |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.89 +/- 0.10
Episode length: 3597.40 +/- 7.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 950000    |
| train/                  |           |
|    approx_kl            | 1.1195569 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.8      |
|    explained_variance   | 0.00485   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.345     |
|    n_updates            | 4630      |
|    policy_gradient_loss | 0.0219    |
|    std                  | 0.539     |
|    value_loss           | 0.766     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266485   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 266692     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.05517731 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.133      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.14e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | 0.00133    |
|    std                  | 0.54       |
|    value_loss           | 1.07e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 466       |
|    time_elapsed         | 266897    |
|    total_timesteps      | 954368    |
| train/                  |           |
|    approx_kl            | 0.7585439 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.8      |
|    explained_variance   | 0.0193    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.801     |
|    n_updates            | 4650      |
|    policy_gradient_loss | 0.0291    |
|    std                  | 0.54      |
|    value_loss           | 1.41      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 267103     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.06470223 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.874      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.539      |
|    value_loss           | 9.08       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 468        |
|    time_elapsed         | 267308     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.05512123 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.304      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.34       |
|    n_updates            | 4670       |
|    policy_gradient_loss | 0.0282     |
|    std                  | 0.539      |
|    value_loss           | 0.656      |
----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.89 +/- 0.09
Episode length: 3599.80 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.054084502 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.78       |
|    explained_variance   | 0.244       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.498       |
|    n_updates            | 4680        |
|    policy_gradient_loss | 0.0222      |
|    std                  | 0.537       |
|    value_loss           | 0.746       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269315   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 269520      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.039346423 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.77       |
|    explained_variance   | 0.000777    |
|    learning_rate        | 0.0003      |
|    loss                 | 42.5        |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.0093      |
|    std                  | 0.537       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 471       |
|    time_elapsed         | 269726    |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 0.5487308 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.74     |
|    explained_variance   | -0.0283   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.399     |
|    n_updates            | 4700      |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.536     |
|    value_loss           | 1.17      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 472         |
|    time_elapsed         | 269933      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.106354974 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.71       |
|    explained_variance   | 0.0174      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.351       |
|    n_updates            | 4710        |
|    policy_gradient_loss | 0.032       |
|    std                  | 0.533       |
|    value_loss           | 0.863       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 270138     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.12177546 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.7       |
|    explained_variance   | 0.194      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.533      |
|    value_loss           | 0.913      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.82 +/- 0.20
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.06836689 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.68      |
|    explained_variance   | 0.21       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.515      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.531      |
|    value_loss           | 0.936      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272146   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 272352     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.06143617 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.67      |
|    explained_variance   | 0.000216   |
|    learning_rate        | 0.0003     |
|    loss                 | 816        |
|    n_updates            | 4740       |
|    policy_gradient_loss | 0.0033     |
|    std                  | 0.532      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 272557    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 1.0123584 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.71     |
|    explained_variance   | -6.32e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.506     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0483    |
|    std                  | 0.537     |
|    value_loss           | 1.05      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 272763     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.10275301 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.75      |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.3        |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.537      |
|    value_loss           | 9.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 478         |
|    time_elapsed         | 272968      |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.097777665 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.76       |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 4770        |
|    policy_gradient_loss | 0.0189      |
|    std                  | 0.536       |
|    value_loss           | 0.702       |
-----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.79 +/- 0.16
Episode length: 3598.80 +/- 2.86
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.25422204 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.0598     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.275      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.00719    |
|    std                  | 0.54       |
|    value_loss           | 0.675      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 274974   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275180      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.064263135 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.83       |
|    explained_variance   | 0.000398    |
|    learning_rate        | 0.0003      |
|    loss                 | 864         |
|    n_updates            | 4790        |
|    policy_gradient_loss | 0.0044      |
|    std                  | 0.542       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 275385     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.13814244 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 6.32e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.3        |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.543      |
|    value_loss           | 0.74       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275591     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.18943341 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.83      |
|    explained_variance   | 0.0825     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.326      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.541      |
|    value_loss           | 0.739      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 275796     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.89032054 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.78      |
|    explained_variance   | -2.56e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.291      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.537      |
|    value_loss           | 0.659      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.79 +/- 0.12
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 990000    |
| train/                  |           |
|    approx_kl            | 0.2768747 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.76     |
|    explained_variance   | -4.41e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.36      |
|    n_updates            | 4830      |
|    policy_gradient_loss | 0.0163    |
|    std                  | 0.539     |
|    value_loss           | 0.642     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277802   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 278007     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.10898874 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.76      |
|    explained_variance   | -2.71e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 735        |
|    n_updates            | 4840       |
|    policy_gradient_loss | 0.00204    |
|    std                  | 0.538      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.46e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 486       |
|    time_elapsed         | 278213    |
|    total_timesteps      | 995328    |
| train/                  |           |
|    approx_kl            | 0.6602169 |
|    clip_fraction        | 0.372     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.73     |
|    explained_variance   | 1.79e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.402     |
|    n_updates            | 4850      |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.535     |
|    value_loss           | 0.739     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.47e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 278418    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.7245133 |
|    clip_fraction        | 0.345     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.7      |
|    explained_variance   | 0.016     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.506     |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.534     |
|    value_loss           | 0.721     |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.47e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 488      |
|    time_elapsed         | 278624   |
|    total_timesteps      | 999424   |
| train/                  |          |
|    approx_kl            | 1.709837 |
|    clip_fraction        | 0.342    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.7     |
|    explained_variance   | -0.00577 |
|    learning_rate        | 0.0003   |
|    loss                 | 0.337    |
|    n_updates            | 4870     |
|    policy_gradient_loss | 0.0189   |
|    std                  | 0.533    |
|    value_loss           | 0.808    |
--------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.93 +/- 0.11
Episode length: 3599.80 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.46846735 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.7       |
|    explained_variance   | 2.5e-05    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.533      |
|    value_loss           | 0.854      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280633   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-20_13-49-52_llm_triton_qwen_3b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 5:54:37 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-100.015687 -100.016066 -100.023581 -100.031287  -99.958521]
 [ -99.965402 -100.046192 -100.090809 -100.061066 -100.03477 ]
 [-100.072541  -99.750872 -100.097138  -99.679967  -99.800059]
 [-100.063377  -99.912224  -99.999174  -99.937284  -99.954401]
 [ -99.933239  -99.992471  -99.94058   -99.958474  -99.921711]
 [ -99.836752  -99.876907  -99.865434  -99.714246  -99.839604]
 [ -99.934686  -99.587982  -99.586163  -99.947913  -99.923279]
 [ -99.820536  -99.828563  -99.859388  -99.835149  -99.793157]
 [ -99.897099  -99.856085  -99.63173   -99.674727  -99.908195]
 [ -99.703374  -99.89316   -99.846     -99.736134  -99.796042]
 [ -99.828659  -99.807244  -99.873829  -99.913436  -99.900092]
 [ -99.957479  -99.797608  -99.848369  -99.837736  -99.788525]
 [ -99.867168  -99.872152  -99.812806  -99.805385  -99.874187]
 [ -99.890113  -99.87036   -99.897198  -99.834196  -99.899442]
 [ -99.856996  -99.845261  -99.815007  -99.869159  -99.888306]
 [ -99.795327  -99.869946  -99.886376  -99.872732  -99.835319]
 [ -99.865982  -98.700866  -99.864959  -99.790838  -99.541666]
 [ -99.931243  -99.880083  -99.810324  -99.712979  -99.861935]
 [ -99.806136  -99.908694  -99.897124  -99.923601  -99.902137]
 [ -99.937304  -99.889376  -99.923791  -99.81939   -99.83881 ]
 [ -99.963499  -99.809676  -99.888294  -99.895091  -99.857662]
 [ -99.94363   -99.94078   -99.835843  -99.936385  -99.90293 ]
 [ -99.778714  -99.737874  -99.893422  -99.793269  -99.880112]
 [ -99.897809  -99.742283  -99.831283  -99.885736  -99.864855]
 [ -99.690154  -99.771156  -99.809318  -99.762759  -99.771518]
 [ -99.81854   -99.882669  -99.856118  -99.872503  -99.88275 ]
 [ -99.904145  -99.808798  -99.917515  -99.891774  -99.854746]
 [ -99.911934  -99.864892  -99.753568  -99.833023  -99.778072]
 [ -99.787354  -99.695101  -99.832181  -99.736105  -99.833211]
 [ -99.844675  -99.883351  -99.792951  -99.900375  -99.73302 ]
 [ -95.652121  -99.63549   -99.829132  -95.878596  -99.470178]
 [ -99.861513  -99.834028  -99.806858  -99.88492   -99.728457]
 [ -99.816735  -99.865036  -99.63846   -99.819552  -99.73046 ]
 [ -99.705909  -99.783997  -99.847296  -99.839869  -99.811549]
 [ -99.746106  -99.922458  -99.751453  -99.841117  -99.836946]
 [ -97.882992  -99.973859  -99.922542  -99.954713  -99.891634]
 [ -99.799575  -99.854433  -99.787022  -99.868599  -99.961791]
 [ -97.881439  -96.999263  -94.953684  -96.853399  -94.640421]
 [ -99.912351  -99.893846  -99.879874  -99.864562  -98.914266]
 [ -99.896741  -99.945135  -99.954356  -99.95124   -99.955771]
 [ -99.965728  -99.910327  -99.920727  -99.95757   -99.967899]
 [ -92.607217  -94.558041  -92.515934  -96.413365  -86.52824 ]
 [ -99.923917  -98.89888   -99.870644  -99.848775  -99.893745]
 [ -99.816247  -99.918998  -99.888823  -99.950186  -99.913802]
 [ -99.898527  -99.943157  -99.940029  -98.891253  -99.933032]
 [ -99.916818  -99.783868  -98.883463  -99.902589  -99.955079]
 [ -99.866002  -99.908976  -99.96595   -99.843675  -99.898241]
 [ -99.980866  -99.972065  -99.961325  -99.922965  -99.986844]
 [-100.011023  -99.979342  -99.898599  -99.908359  -99.917752]
 [ -99.903009  -99.903642  -99.963787  -99.948846  -99.947873]
 [ -99.951854  -99.995557  -99.99034   -99.928065  -99.930613]
 [ -99.941492  -99.936355  -99.993389  -99.901086  -99.93868 ]
 [ -99.940431  -99.898747 -100.002753  -99.991161 -100.019869]
 [ -99.987754 -100.028261  -99.956698  -99.918068 -100.014328]
 [ -99.861902 -100.017539  -99.836247 -100.030525  -99.977112]
 [ -99.969289 -100.07019   -99.979498  -99.931602  -99.965463]
 [ -99.893727  -99.737856  -99.911465  -99.953307  -99.976698]
 [ -99.810442 -100.040707  -99.947765  -99.999309  -99.922084]
 [ -99.891134  -99.881822  -99.876147  -99.833384  -99.955898]
 [ -99.937938 -100.012447 -100.054905 -100.006892 -100.004281]
 [-100.03577   -99.996178  -99.954493  -99.889256  -99.852676]
 [ -99.992665 -100.011571  -99.898798  -99.978658 -100.004148]
 [ -99.899886  -99.937579  -99.901748  -99.837826  -99.9535  ]
 [ -99.962478  -99.945819  -99.981205  -99.973027  -99.895368]
 [ -99.98061   -99.90709   -99.863046  -99.938769  -99.905074]
 [ -99.944338 -100.01426   -98.937711 -100.004804 -100.051476]
 [ -99.981954  -99.955066  -99.701502  -99.618149  -99.976065]
 [ -99.660474 -100.017173  -99.894397  -99.91251   -99.614903]
 [ -99.903142  -99.712248  -99.886679  -99.989286  -99.884176]
 [ -99.664389  -99.669144  -99.973598  -99.922516 -100.005606]
 [ -99.927031  -99.96743   -99.904837  -99.65029   -99.709484]
 [ -99.606019  -99.621824  -99.573182  -99.991836  -99.99093 ]
 [ -99.712082  -99.97784   -99.795432  -99.650261  -99.678915]
 [ -99.978952  -99.657798 -100.020467  -99.910636  -99.895487]
 [ -99.600982  -99.652509 -100.000948  -99.917257 -100.013143]
 [ -99.898547  -99.938593  -99.888359  -99.631676  -99.923111]
 [ -99.96506   -99.984924  -99.98375   -98.893995  -99.959184]
 [ -99.959171  -99.866896  -99.921542  -98.958653  -99.929907]
 [ -98.936743  -98.998696  -99.886186  -99.963694  -99.822021]
 [ -99.89527   -99.958896 -100.020558 -100.010519  -99.89105 ]
 [-100.005833  -99.952269  -99.974078  -99.8925    -99.931115]
 [ -99.890375 -100.024274 -100.011454  -99.88783   -99.972896]
 [ -99.902509  -99.922591  -99.856714  -99.853287  -99.948394]
 [ -99.881934  -99.949876  -99.995992  -99.928453  -99.956248]
 [ -99.906126  -99.821581  -99.901961  -98.759747  -99.882966]
 [ -99.836948  -99.798058  -99.998777  -99.92696   -99.781675]
 [ -99.864416  -99.741697  -99.595415  -99.963984  -99.92325 ]
 [ -99.915255  -99.999188  -99.856447  -99.904996  -99.756848]
 [ -99.904687  -99.914433  -99.961081  -99.851977  -99.779105]
 [ -99.913     -99.857781  -99.954657  -99.844413  -99.989858]
 [ -99.913002  -99.776307  -99.894439  -99.841083  -99.909515]
 [ -99.868253  -99.75599   -99.965054  -99.898801 -100.044465]
 [ -99.966886  -99.745563  -99.915161  -97.932705  -99.976208]
 [ -99.890128  -99.826581  -99.700252  -99.794035  -99.832428]
 [ -99.831845  -99.935879  -99.978556  -99.729497  -99.998761]
 [ -99.735959  -99.959775  -99.925079  -99.975948  -99.871806]
 [ -99.967531  -99.935928  -99.688725  -99.490314 -100.020467]
 [ -99.595044  -99.934404  -99.604611  -99.846041  -99.951572]
 [ -99.640459  -99.936367  -99.873024  -99.862664  -99.657115]
 [-100.001079 -100.02003   -99.897435 -100.002034  -99.724378]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3595 3601 3601]
 [3591 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3600 3601 3600 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3600 3601 3601]
 [3586 3601 3601 3601 3601]
 [3601 3601 3600 3599 3590]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3583 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3600]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3583 3601]
 [3601 3601 3601 3595 3601]
 [3596 3601 3601 3601 3601]
 [3601 3600 3601 3583 3601]
 [3601 3601 3601 3601 3593]
 [3592 3601 3601 3601 3599]
 [3601 3601 3601 3586 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3586 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3601 3601 3601 3594 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3598 3601 3601 3600 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3598 3601 3601 3601 3599]
 [3601 3601 3601 3600 3601]
 [3599 3601 3601 3601 3601]
 [3600 3601 3601 3597 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3599 3601 3601 3598 3596]
 [3601 3601 3601 3600 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3598 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3597 3597]
 [3601 3601 3601 3586 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3598 3597 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3592 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3594 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3601 3596 3599]
 [3601 3601 3588 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3600 3601 3597 3601]
 [3601 3591 3601 3601 3598]
 [3601 3600 3601 3601 3585]
 [3600 3601 3601 3599 3599]
 [3594 3601 3601 3601 3601]
 [3601 3601 3601 3583 3601]
 [3601 3601 3599 3597 3601]
 [3601 3600 3601 3601 3601]
 [3601 3594 3601 3601 3597]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3595 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-20_13-49-52_llm_triton_qwen_3b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-20_13-49-52_llm_triton_qwen_3b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/model
