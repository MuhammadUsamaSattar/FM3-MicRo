####################
/var/spool/slurmd/job5304950/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_14B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-24_14-30-15_llm_triton_qwen_14b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0.
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 214  |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.56e+03     |
|    ep_rew_mean          | 1.66e+03     |
| time/                   |              |
|    fps                  | 9            |
|    iterations           | 2            |
|    time_elapsed         | 422          |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0095106345 |
|    clip_fraction        | 0.0883       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.0047       |
|    learning_rate        | 0.0003       |
|    loss                 | 22           |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.017       |
|    std                  | 0.999        |
|    value_loss           | 52.1         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.56e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 628         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010871742 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.354      |
|    learning_rate        | 0.0003      |
|    loss                 | 12.4        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.999       |
|    value_loss           | 39.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.57e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 834         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.009956082 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.252       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.4        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0212     |
|    std                  | 1           |
|    value_loss           | 49.7        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.98 +/- 0.02
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009808804 |
|    clip_fraction        | 0.0965      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.297       |
|    learning_rate        | 0.0003      |
|    loss                 | 20.1        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.998       |
|    value_loss           | 40          |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2840     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.47e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3046        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.005066288 |
|    clip_fraction        | 0.019       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0106     |
|    learning_rate        | 0.0003      |
|    loss                 | 35.7        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00691    |
|    std                  | 0.997       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3251        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.010217631 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.572       |
|    learning_rate        | 0.0003      |
|    loss                 | 16.5        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.997       |
|    value_loss           | 35.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3457        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.008719528 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.502       |
|    learning_rate        | 0.0003      |
|    loss                 | 10.6        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.994       |
|    value_loss           | 34.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.43e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3662        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.017189872 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.233       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.89        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.992       |
|    value_loss           | 19.5        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.99 +/- 0.05
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.016475393 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.726      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00709    |
|    std                  | 0.986       |
|    value_loss           | 5.91        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5675     |
|    total_timesteps | 20480    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 11         |
|    time_elapsed         | 5882       |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.00783469 |
|    clip_fraction        | 0.102      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | -0.0276    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.29e+03   |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.00554   |
|    std                  | 0.986      |
|    value_loss           | 1.09e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6088        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.013438899 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.243      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.37        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.979       |
|    value_loss           | 5.71        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6293        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.002198664 |
|    clip_fraction        | 0.00562     |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.482      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.43        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0016     |
|    std                  | 0.979       |
|    value_loss           | 56.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.39e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6499        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.011312624 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -1.04       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.4         |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00662    |
|    std                  | 0.978       |
|    value_loss           | 11.6        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.95 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.011272524 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.753      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.974       |
|    value_loss           | 5.83        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8507     |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.75e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 8712         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0026801643 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -0.0282      |
|    learning_rate        | 0.0003       |
|    loss                 | 246          |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00432     |
|    std                  | 0.973        |
|    value_loss           | 1.06e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 1.8e+03      |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 17           |
|    time_elapsed         | 8918         |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0010266792 |
|    clip_fraction        | 0.00112      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.471        |
|    learning_rate        | 0.0003       |
|    loss                 | 18.2         |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00263     |
|    std                  | 0.973        |
|    value_loss           | 40.6         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 1.8e+03      |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 18           |
|    time_elapsed         | 9124         |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0010636495 |
|    clip_fraction        | 0.000684     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.81         |
|    learning_rate        | 0.0003       |
|    loss                 | 13.4         |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.973        |
|    value_loss           | 29           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9329        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.016288452 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.0833     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.974       |
|    value_loss           | 2.89        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.93 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.009081349 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.951      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.41        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00995    |
|    std                  | 0.972       |
|    value_loss           | 21.8        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11337    |
|    total_timesteps | 40960    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.33e+03      |
|    ep_rew_mean          | 1.8e+03       |
| time/                   |               |
|    fps                  | 3             |
|    iterations           | 21            |
|    time_elapsed         | 11543         |
|    total_timesteps      | 43008         |
| train/                  |               |
|    approx_kl            | 0.00015875485 |
|    clip_fraction        | 9.77e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -11.1         |
|    explained_variance   | 0.0759        |
|    learning_rate        | 0.0003        |
|    loss                 | 200           |
|    n_updates            | 200           |
|    policy_gradient_loss | -0.000994     |
|    std                  | 0.972         |
|    value_loss           | 1.06e+03      |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11750       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.014445173 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.876      |
|    learning_rate        | 0.0003      |
|    loss                 | 1           |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.97        |
|    value_loss           | 2.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11956       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.011769719 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.236      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.52        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00553    |
|    std                  | 0.971       |
|    value_loss           | 21.2        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.37e+03     |
|    ep_rew_mean          | 1.88e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 24           |
|    time_elapsed         | 12161        |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0015175247 |
|    clip_fraction        | 0.00176      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.786        |
|    learning_rate        | 0.0003       |
|    loss                 | 21.2         |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00227     |
|    std                  | 0.971        |
|    value_loss           | 30.4         |
------------------------------------------
Eval num_timesteps=50000, episode_reward=-99.92 +/- 0.02
Episode length: 3600.20 +/- 1.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.9        |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0049255933 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.71         |
|    learning_rate        | 0.0003       |
|    loss                 | 2.02         |
|    n_updates            | 240          |
|    policy_gradient_loss | -0.00765     |
|    std                  | 0.97         |
|    value_loss           | 10.5         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14168    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.85e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 14374        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0014181426 |
|    clip_fraction        | 0.00166      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.0719       |
|    learning_rate        | 0.0003       |
|    loss                 | 57.8         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00257     |
|    std                  | 0.97         |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14580       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.021890733 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -7.61       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.968       |
|    value_loss           | 4.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14786       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.010222998 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | 10.9        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0029     |
|    std                  | 0.968       |
|    value_loss           | 13          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14991       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.007168227 |
|    clip_fraction        | 0.0505      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.3        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.966       |
|    value_loss           | 11.4        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.92 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.018539477 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.325      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.965       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.96        |
|    value_loss           | 2.48        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 17000    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17206       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.007953397 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00666     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+03    |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.000944   |
|    std                  | 0.96        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17411       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.017676428 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.045      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00824    |
|    std                  | 0.964       |
|    value_loss           | 2.19        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 1.92e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 33           |
|    time_elapsed         | 17617        |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0142447045 |
|    clip_fraction        | 0.127        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | -0.0428      |
|    learning_rate        | 0.0003       |
|    loss                 | 4.71         |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00995     |
|    std                  | 0.962        |
|    value_loss           | 8.56         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17823       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.020399138 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.11       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.693       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.952       |
|    value_loss           | 1.95        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.80 +/- 0.08
Episode length: 3596.60 +/- 7.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.018543407 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0961      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.762       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00941    |
|    std                  | 0.951       |
|    value_loss           | 1.97        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19832    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20040       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.009948404 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.000276    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.16        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00512    |
|    std                  | 0.951       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20245       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.018178001 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0949     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0099     |
|    std                  | 0.951       |
|    value_loss           | 1.77        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20451       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.018180156 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0486      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.733       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.952       |
|    value_loss           | 1.67        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.96e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 39         |
|    time_elapsed         | 20656      |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.01387216 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.0528     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.813      |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.00531   |
|    std                  | 0.947      |
|    value_loss           | 1.58       |
----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.80 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.014394147 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0301      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.9         |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.947       |
|    value_loss           | 1.57        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.94e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22664    |
|    total_timesteps | 81920    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.98e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 41         |
|    time_elapsed         | 22870      |
|    total_timesteps      | 83968      |
| train/                  |            |
|    approx_kl            | 0.01685713 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.000252  |
|    learning_rate        | 0.0003     |
|    loss                 | 683        |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.00566   |
|    std                  | 0.95       |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23075       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.022825154 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.00377     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.936       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00832    |
|    std                  | 0.942       |
|    value_loss           | 1.84        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23281       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.015974512 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00818     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.828       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00612    |
|    std                  | 0.931       |
|    value_loss           | 1.46        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.85 +/- 0.09
Episode length: 3598.80 +/- 4.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.016101234 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.047       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.645       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00691    |
|    std                  | 0.934       |
|    value_loss           | 1.42        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.99e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25290    |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.99e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 45           |
|    time_elapsed         | 25497        |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0039203414 |
|    clip_fraction        | 0.0468       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.315        |
|    learning_rate        | 0.0003       |
|    loss                 | 23.9         |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.0022      |
|    std                  | 0.934        |
|    value_loss           | 1.05e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.02e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 46           |
|    time_elapsed         | 25703        |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0006869287 |
|    clip_fraction        | 0.00132      |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.927        |
|    learning_rate        | 0.0003       |
|    loss                 | 6.37         |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.00239     |
|    std                  | 0.934        |
|    value_loss           | 27.9         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25908       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.023164589 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00496     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.578       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00248    |
|    std                  | 0.93        |
|    value_loss           | 1.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26114       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.026407268 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.00324     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.405       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00145    |
|    std                  | 0.929       |
|    value_loss           | 1.31        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.84 +/- 0.03
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.018619765 |
|    clip_fraction        | 0.0915      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.0003      |
|    loss                 | 47.4        |
|    n_updates            | 480         |
|    policy_gradient_loss | 0.00101     |
|    std                  | 0.929       |
|    value_loss           | 36.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28123    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 28329       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.005141275 |
|    clip_fraction        | 0.0201      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0003      |
|    loss                 | 49.1        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00296    |
|    std                  | 0.929       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28535       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.005915746 |
|    clip_fraction        | 0.0272      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0003      |
|    loss                 | 22.6        |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00964    |
|    std                  | 0.929       |
|    value_loss           | 35.5        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 52         |
|    time_elapsed         | 28740      |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.02506653 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.565     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.00632   |
|    std                  | 0.926      |
|    value_loss           | 1.24       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 2.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 53         |
|    time_elapsed         | 28946      |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.02873202 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.0018     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.6        |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.0013    |
|    std                  | 0.916      |
|    value_loss           | 1.24       |
----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.81 +/- 0.09
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.021152535 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.00355     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.725       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00549    |
|    std                  | 0.921       |
|    value_loss           | 1.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30953    |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 55         |
|    time_elapsed         | 31160      |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.01939675 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.0234    |
|    learning_rate        | 0.0003     |
|    loss                 | 31         |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.00275   |
|    std                  | 0.922      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 56         |
|    time_elapsed         | 31366      |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.02131458 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.000806  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.512      |
|    n_updates            | 550        |
|    policy_gradient_loss | 0.00399    |
|    std                  | 0.914      |
|    value_loss           | 1.2        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31572       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.028887808 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00382     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.615       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00748    |
|    std                  | 0.908       |
|    value_loss           | 1.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31777       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.015568327 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.663       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00155    |
|    std                  | 0.906       |
|    value_loss           | 1.11        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.83 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.006142283 |
|    clip_fraction        | 0.0944      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.66        |
|    n_updates            | 580         |
|    policy_gradient_loss | 0.000875    |
|    std                  | 0.905       |
|    value_loss           | 27.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33785    |
|    total_timesteps | 120832   |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.33e+03      |
|    ep_rew_mean          | 2.04e+03      |
| time/                   |               |
|    fps                  | 3             |
|    iterations           | 60            |
|    time_elapsed         | 33990         |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 0.00063553127 |
|    clip_fraction        | 0.00337       |
|    clip_range           | 0.2           |
|    entropy_loss         | -10.5         |
|    explained_variance   | 0.756         |
|    learning_rate        | 0.0003        |
|    loss                 | 566           |
|    n_updates            | 590           |
|    policy_gradient_loss | -0.00128      |
|    std                  | 0.905         |
|    value_loss           | 1.09e+03      |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34196       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.022308806 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0019      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.535       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.906       |
|    value_loss           | 0.874       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34402       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.017223686 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.0003      |
|    loss                 | 43.5        |
|    n_updates            | 610         |
|    policy_gradient_loss | 0.00721     |
|    std                  | 0.906       |
|    value_loss           | 65.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34607       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.027231999 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00484    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.599       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0032     |
|    std                  | 0.897       |
|    value_loss           | 0.956       |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.89 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.021299593 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00552     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.464       |
|    n_updates            | 630         |
|    policy_gradient_loss | 0.00152     |
|    std                  | 0.892       |
|    value_loss           | 0.956       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36615    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.07e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 65           |
|    time_elapsed         | 36821        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0068515646 |
|    clip_fraction        | 0.11         |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.695        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.75e+03     |
|    n_updates            | 640          |
|    policy_gradient_loss | 0.0052       |
|    std                  | 0.892        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 37027       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.014605882 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.89        |
|    value_loss           | 33.7        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 2.07e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 67           |
|    time_elapsed         | 37233        |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0056840777 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | -0.614       |
|    learning_rate        | 0.0003       |
|    loss                 | 7.11         |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00655     |
|    std                  | 0.89         |
|    value_loss           | 22.7         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 68         |
|    time_elapsed         | 37438      |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.02049405 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.417      |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.00354   |
|    std                  | 0.888      |
|    value_loss           | 3.67       |
----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.80 +/- 0.06
Episode length: 3599.60 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.01178699 |
|    clip_fraction        | 0.0627     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83       |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.00634   |
|    std                  | 0.888      |
|    value_loss           | 9.15       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39447    |
|    total_timesteps | 141312   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 70         |
|    time_elapsed         | 39653      |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.03811929 |
|    clip_fraction        | 0.158      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.00345   |
|    learning_rate        | 0.0003     |
|    loss                 | 430        |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.00383   |
|    std                  | 0.888      |
|    value_loss           | 1.07e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39858       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.034771122 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0807     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.00322     |
|    std                  | 0.886       |
|    value_loss           | 1.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40064       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.021588963 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.0003      |
|    loss                 | 23.7        |
|    n_updates            | 710         |
|    policy_gradient_loss | 0.007       |
|    std                  | 0.886       |
|    value_loss           | 123         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40269       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.002655854 |
|    clip_fraction        | 0.0101      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.16        |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.886       |
|    value_loss           | 33.2        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.81 +/- 0.13
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.025139306 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0284     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.348       |
|    n_updates            | 730         |
|    policy_gradient_loss | 0.000806    |
|    std                  | 0.884       |
|    value_loss           | 0.979       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42278    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42485       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.014745743 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54e+03    |
|    n_updates            | 740         |
|    policy_gradient_loss | 0.00418     |
|    std                  | 0.884       |
|    value_loss           | 1.11e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 76         |
|    time_elapsed         | 42691      |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.03777913 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.00624    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.00653   |
|    std                  | 0.872      |
|    value_loss           | 1.09       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42897       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.019864477 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0364      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.43        |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00763    |
|    std                  | 0.868       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43103       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.019828904 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.022       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.37        |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00624    |
|    std                  | 0.868       |
|    value_loss           | 1.05        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.90 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.023619637 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.04        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.265       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00685    |
|    std                  | 0.862       |
|    value_loss           | 0.745       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45110    |
|    total_timesteps | 161792   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.1e+03      |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 80           |
|    time_elapsed         | 45316        |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0071251364 |
|    clip_fraction        | 0.0529       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.1        |
|    explained_variance   | 0.61         |
|    learning_rate        | 0.0003       |
|    loss                 | 42.5         |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00191     |
|    std                  | 0.862        |
|    value_loss           | 1.08e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45522       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.023805615 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.582      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.539       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00584    |
|    std                  | 0.86        |
|    value_loss           | 1.02        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 82         |
|    time_elapsed         | 45727      |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.03150557 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.00193   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 810        |
|    policy_gradient_loss | 0.000546   |
|    std                  | 0.856      |
|    value_loss           | 0.969      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45933       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.021821344 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.000435    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.46        |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00233    |
|    std                  | 0.852       |
|    value_loss           | 0.927       |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.88 +/- 0.06
Episode length: 3596.60 +/- 6.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.024578135 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.00911     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00662    |
|    std                  | 0.845       |
|    value_loss           | 0.957       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47940    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48146       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.024089403 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -0.000129   |
|    learning_rate        | 0.0003      |
|    loss                 | 838         |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00276    |
|    std                  | 0.844       |
|    value_loss           | 933         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 86         |
|    time_elapsed         | 48352      |
|    total_timesteps      | 176128     |
| train/                  |            |
|    approx_kl            | 0.04166065 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.97      |
|    explained_variance   | -0.292     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.52       |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.00763   |
|    std                  | 0.843      |
|    value_loss           | 14.1       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48557       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.032513537 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.00732     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.385       |
|    n_updates            | 860         |
|    policy_gradient_loss | 0.00166     |
|    std                  | 0.836       |
|    value_loss           | 0.756       |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.77 +/- 0.15
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.011930535 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.24        |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00827    |
|    std                  | 0.835       |
|    value_loss           | 28.8        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50566    |
|    total_timesteps | 180224   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 89         |
|    time_elapsed         | 50773      |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.01836553 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.274      |
|    learning_rate        | 0.0003     |
|    loss                 | 505        |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.836      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 50979      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.03194571 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47       |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.00634   |
|    std                  | 0.838      |
|    value_loss           | 11.7       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 91         |
|    time_elapsed         | 51185      |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.03366233 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | 0.993      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.844      |
|    n_updates            | 900        |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.838      |
|    value_loss           | 1.82       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51391       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.022828635 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.94        |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.00701    |
|    std                  | 0.834       |
|    value_loss           | 9.44        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.89 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.03649109 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.86      |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.92       |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.832      |
|    value_loss           | 14         |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53397    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53604       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.037978794 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.00764    |
|    learning_rate        | 0.0003      |
|    loss                 | 29.7        |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.000524   |
|    std                  | 0.833       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 95         |
|    time_elapsed         | 53809      |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.08333005 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | -0.345     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.381      |
|    n_updates            | 940        |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.83       |
|    value_loss           | 0.834      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 96         |
|    time_elapsed         | 54015      |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.03284484 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.78      |
|    explained_variance   | -0.00175   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.724      |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.00376   |
|    std                  | 0.82       |
|    value_loss           | 1.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 54221      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.02490687 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.76      |
|    explained_variance   | -0.00403   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.00046   |
|    std                  | 0.824      |
|    value_loss           | 0.854      |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.94 +/- 0.02
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.017251644 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.82        |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.823       |
|    value_loss           | 4.95        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56230    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56436       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.020125715 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | 0.164       |
|    learning_rate        | 0.0003      |
|    loss                 | 309         |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.824       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56641       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.034371827 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.00173     |
|    std                  | 0.829       |
|    value_loss           | 0.854       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56847       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.032872934 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -1.23       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.497       |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.000477    |
|    std                  | 0.829       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57052       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.028163549 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | 3.78e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.442       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00291    |
|    std                  | 0.828       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.81 +/- 0.11
Episode length: 3595.00 +/- 8.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.023073502 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -0.00144    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.535       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00801    |
|    std                  | 0.822       |
|    value_loss           | 1.03        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59061    |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 104        |
|    time_elapsed         | 59268      |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.03782786 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | -0.00092   |
|    learning_rate        | 0.0003     |
|    loss                 | 6.67       |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.00245   |
|    std                  | 0.823      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59473       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.034876417 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.528       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00477    |
|    std                  | 0.82        |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 59679       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.028680751 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.415       |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.82        |
|    value_loss           | 0.835       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 59884       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.033039283 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.000158    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.306       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00452    |
|    std                  | 0.814       |
|    value_loss           | 0.783       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.80 +/- 0.07
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.02129186 |
|    clip_fraction        | 0.167      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.68      |
|    explained_variance   | 0.979      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.842      |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.00743   |
|    std                  | 0.814      |
|    value_loss           | 13.5       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61891    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62097       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.016001372 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.131       |
|    learning_rate        | 0.0003      |
|    loss                 | 356         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.815       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 62303       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.034381352 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | -0.0298     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.236       |
|    n_updates            | 1090        |
|    policy_gradient_loss | 0.00125     |
|    std                  | 0.812       |
|    value_loss           | 0.672       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62510       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.020683685 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51        |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.809       |
|    value_loss           | 12.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 62716       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.033063754 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | -2.94       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00151    |
|    std                  | 0.803       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.83 +/- 0.11
Episode length: 3597.80 +/- 6.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.0401274 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.58     |
|    explained_variance   | -0.00234  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.418     |
|    n_updates            | 1120      |
|    policy_gradient_loss | 2.8e-05   |
|    std                  | 0.804     |
|    value_loss           | 0.729     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64724    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64931       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.024400968 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | -0.000652   |
|    learning_rate        | 0.0003      |
|    loss                 | 307         |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00461    |
|    std                  | 0.804       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65137       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.023397554 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | -0.000294   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.327       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00253    |
|    std                  | 0.799       |
|    value_loss           | 0.689       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65342       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.033145327 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -0.106      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.247       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.797       |
|    value_loss           | 0.833       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65548       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.026728667 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.911       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00607    |
|    std                  | 0.798       |
|    value_loss           | 9.79        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.85 +/- 0.10
Episode length: 3599.40 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.036034245 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -0.00495    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.399       |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.00309     |
|    std                  | 0.798       |
|    value_loss           | 0.794       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67557    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67763       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.022301028 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -6.48e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.87        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00181    |
|    std                  | 0.799       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 120        |
|    time_elapsed         | 67969      |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.03863204 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.51      |
|    explained_variance   | 0.00074    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.381      |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.00149   |
|    std                  | 0.796      |
|    value_loss           | 0.804      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68175       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.033644363 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | -0.000385   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.391       |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.00161    |
|    std                  | 0.796       |
|    value_loss           | 0.909       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 122        |
|    time_elapsed         | 68380      |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.02882064 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.48      |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.13       |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.009     |
|    std                  | 0.791      |
|    value_loss           | 6.71       |
----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.81 +/- 0.06
Episode length: 3598.40 +/- 3.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.070020646 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | -2.38e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.235       |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.000856    |
|    std                  | 0.786       |
|    value_loss           | 0.647       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70390    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70596       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.033716287 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+03    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0073     |
|    std                  | 0.788       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70802       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.044373043 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | -0.939      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.237       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.000292   |
|    std                  | 0.788       |
|    value_loss           | 0.68        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 126        |
|    time_elapsed         | 71007      |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.03609637 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 3.16e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.309      |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.00395   |
|    std                  | 0.789      |
|    value_loss           | 0.61       |
----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.74 +/- 0.12
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.03428684 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.44      |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09       |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.79       |
|    value_loss           | 8.12       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.26e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 73016    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 128        |
|    time_elapsed         | 73222      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.02565961 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.0745     |
|    learning_rate        | 0.0003     |
|    loss                 | 4.57       |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.00616   |
|    std                  | 0.788      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 73427       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.040190488 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.785       |
|    value_loss           | 8.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73633       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.033413425 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | -0.015      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 1290        |
|    policy_gradient_loss | 0.00511     |
|    std                  | 0.788       |
|    value_loss           | 0.65        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 73839       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.039855495 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.00142     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.418       |
|    n_updates            | 1300        |
|    policy_gradient_loss | 0.00219     |
|    std                  | 0.788       |
|    value_loss           | 0.783       |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.79 +/- 0.09
Episode length: 3596.20 +/- 9.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.022743806 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.29        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00616    |
|    std                  | 0.789       |
|    value_loss           | 9.04        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75848    |
|    total_timesteps | 270336   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 133        |
|    time_elapsed         | 76055      |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.02709237 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.44      |
|    explained_variance   | -3.06e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 151        |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.000273  |
|    std                  | 0.791      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76261      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.04218266 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.00494    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.00232    |
|    std                  | 0.787      |
|    value_loss           | 0.764      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76466       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.025995275 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00913    |
|    std                  | 0.789       |
|    value_loss           | 6.8         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.29e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 136       |
|    time_elapsed         | 76672     |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0378966 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.39     |
|    explained_variance   | 0.0104    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.538     |
|    n_updates            | 1350      |
|    policy_gradient_loss | 0.00326   |
|    std                  | 0.784     |
|    value_loss           | 0.847     |
---------------------------------------
Eval num_timesteps=280000, episode_reward=-99.78 +/- 0.04
Episode length: 3598.80 +/- 2.86
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.03608486 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.37      |
|    explained_variance   | -0.00167   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.385      |
|    n_updates            | 1360       |
|    policy_gradient_loss | -0.00191   |
|    std                  | 0.784      |
|    value_loss           | 0.851      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78682    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78888       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.040900845 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -0.00209    |
|    learning_rate        | 0.0003      |
|    loss                 | 36.7        |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00609    |
|    std                  | 0.785       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.3e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 139       |
|    time_elapsed         | 79093     |
|    total_timesteps      | 284672    |
| train/                  |           |
|    approx_kl            | 0.0323055 |
|    clip_fraction        | 0.293     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.36     |
|    explained_variance   | 0.00467   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.391     |
|    n_updates            | 1380      |
|    policy_gradient_loss | 0.00182   |
|    std                  | 0.782     |
|    value_loss           | 0.83      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79299       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.039750613 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | -0.102      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.345       |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00137    |
|    std                  | 0.777       |
|    value_loss           | 0.763       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 79504      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.03292142 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | 3.22e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.00263   |
|    std                  | 0.775      |
|    value_loss           | 0.717      |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.80 +/- 0.08
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.03465998 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | 0.00152    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.444      |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.00143   |
|    std                  | 0.772      |
|    value_loss           | 0.81       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81513    |
|    total_timesteps | 290816   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.31e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 143       |
|    time_elapsed         | 81720     |
|    total_timesteps      | 292864    |
| train/                  |           |
|    approx_kl            | 0.0293991 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.24     |
|    explained_variance   | -1.79e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 229       |
|    n_updates            | 1420      |
|    policy_gradient_loss | -0.00229  |
|    std                  | 0.773     |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 81927       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.030791644 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.000549    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.327       |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.000785    |
|    std                  | 0.773       |
|    value_loss           | 0.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82133       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.031004403 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | -1.9        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.54        |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00224    |
|    std                  | 0.774       |
|    value_loss           | 2.7         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82339       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.037529424 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.00817     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 1450        |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.773       |
|    value_loss           | 0.805       |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.82 +/- 0.08
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.03799191 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | -0.234     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.368      |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.000849  |
|    std                  | 0.773      |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84347    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 84553       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.018934209 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.0126      |
|    learning_rate        | 0.0003      |
|    loss                 | 122         |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00664    |
|    std                  | 0.773       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84759       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.033410653 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.00018     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.375       |
|    n_updates            | 1480        |
|    policy_gradient_loss | 0.00243     |
|    std                  | 0.772       |
|    value_loss           | 0.747       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 84964       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.047380198 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.21       |
|    explained_variance   | -0.66       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.379       |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00173    |
|    std                  | 0.769       |
|    value_loss           | 0.968       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 85170       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.037386324 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -0.00293    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.312       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0028     |
|    std                  | 0.77        |
|    value_loss           | 0.643       |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.85 +/- 0.06
Episode length: 3596.00 +/- 7.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.03132104 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | 0.00336    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.397      |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.00163   |
|    std                  | 0.77       |
|    value_loss           | 0.693      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87179    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87387       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.027058922 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.21       |
|    explained_variance   | 0.00436     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.24e+03    |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.00186     |
|    std                  | 0.769       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 87593      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.03432647 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | -0.00233   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.342      |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.00413    |
|    std                  | 0.766      |
|    value_loss           | 0.71       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 155        |
|    time_elapsed         | 87798      |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.03826534 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.17      |
|    explained_variance   | -1.23      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.19       |
|    n_updates            | 1540       |
|    policy_gradient_loss | 0.00306    |
|    std                  | 0.766      |
|    value_loss           | 0.639      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 88004       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.042836536 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.16       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.936       |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00553    |
|    std                  | 0.764       |
|    value_loss           | 2.06        |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.84 +/- 0.06
Episode length: 3598.80 +/- 2.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.036377028 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | -0.00694    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.313       |
|    n_updates            | 1560        |
|    policy_gradient_loss | 0.00262     |
|    std                  | 0.762       |
|    value_loss           | 0.615       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 90013    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90219       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.052972153 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | -8.42e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.02        |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.762       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90425       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.039602004 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | -0.000588   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.348       |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.000363   |
|    std                  | 0.763       |
|    value_loss           | 0.824       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 160        |
|    time_elapsed         | 90630      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.04971042 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.11      |
|    explained_variance   | -0.00138   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.408      |
|    n_updates            | 1590       |
|    policy_gradient_loss | 0.000406   |
|    std                  | 0.76       |
|    value_loss           | 0.816      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 90836       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.029777862 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.97        |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.757       |
|    value_loss           | 3.08        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.82 +/- 0.06
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.039957557 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | -0.00131    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.235       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00599     |
|    std                  | 0.755       |
|    value_loss           | 0.594       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92843    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 163         |
|    time_elapsed         | 93051       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.030891083 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | -0.00166    |
|    learning_rate        | 0.0003      |
|    loss                 | 21.4        |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00692    |
|    std                  | 0.756       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 164        |
|    time_elapsed         | 93256      |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.04341875 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | -0.000489  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.287      |
|    n_updates            | 1630       |
|    policy_gradient_loss | 0.00145    |
|    std                  | 0.758      |
|    value_loss           | 0.767      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93462       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.029488062 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.000358    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.307       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.000115    |
|    std                  | 0.754       |
|    value_loss           | 0.615       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 93668       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.030155115 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | -0.196      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.301       |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.000139   |
|    std                  | 0.754       |
|    value_loss           | 0.771       |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.83 +/- 0.04
Episode length: 3599.40 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.04110899 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | 0.00192    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.383      |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.000986  |
|    std                  | 0.747      |
|    value_loss           | 0.972      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95677    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 95883       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.021379184 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.0548      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.27        |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00432    |
|    std                  | 0.747       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 96089       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.035104197 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | -0.0657     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.0029      |
|    std                  | 0.748       |
|    value_loss           | 0.863       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 96294       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.034346424 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.00122     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.49        |
|    n_updates            | 1690        |
|    policy_gradient_loss | 0.00528     |
|    std                  | 0.743       |
|    value_loss           | 0.678       |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.89 +/- 0.05
Episode length: 3596.40 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.03595988 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.251      |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.00568   |
|    std                  | 0.74       |
|    value_loss           | 2.39       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98304    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98511       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.027892422 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.0185      |
|    learning_rate        | 0.0003      |
|    loss                 | 697         |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00555    |
|    std                  | 0.741       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 173       |
|    time_elapsed         | 98716     |
|    total_timesteps      | 354304    |
| train/                  |           |
|    approx_kl            | 0.0446577 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.83     |
|    explained_variance   | -0.0256   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.51      |
|    n_updates            | 1720      |
|    policy_gradient_loss | 0.00073   |
|    std                  | 0.736     |
|    value_loss           | 0.783     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 98922       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.046687216 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.15        |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.00754    |
|    std                  | 0.735       |
|    value_loss           | 2.68        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 99127       |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.041630182 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | -9.66e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.304       |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.000802    |
|    std                  | 0.73        |
|    value_loss           | 0.854       |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.81 +/- 0.07
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.044038028 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | -0.0228     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.488       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.00547     |
|    std                  | 0.73        |
|    value_loss           | 0.737       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101136   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101342      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.036425702 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | 0.0128      |
|    learning_rate        | 0.0003      |
|    loss                 | 2e+03       |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00612    |
|    std                  | 0.73        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 101549     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.04958015 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | 0.00247    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.00913    |
|    std                  | 0.727      |
|    value_loss           | 0.9        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 101755     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.03727591 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.00283    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.362      |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.724      |
|    value_loss           | 0.737      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 101961      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.041987713 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | 0.00901     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.506       |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.00166     |
|    std                  | 0.725       |
|    value_loss           | 0.76        |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.84 +/- 0.07
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.036314268 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00934    |
|    std                  | 0.722       |
|    value_loss           | 3.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103968   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104175      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.037753217 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | -4.43e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.09e+03    |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00553    |
|    std                  | 0.723       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 183        |
|    time_elapsed         | 104381     |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.05180914 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | -0.000241  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.281      |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.723      |
|    value_loss           | 0.707      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 104586     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.04103396 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | -0.807     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.309      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.00394    |
|    std                  | 0.728      |
|    value_loss           | 0.571      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.49e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 104792     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.04743907 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.68      |
|    explained_variance   | 0.0136     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.434      |
|    n_updates            | 1840       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.724      |
|    value_loss           | 0.846      |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.84 +/- 0.06
Episode length: 3598.60 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.03692462 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5        |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.00434   |
|    std                  | 0.722      |
|    value_loss           | 1.83       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106802   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 107008      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.029413776 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.0585      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.79e+03    |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00898    |
|    std                  | 0.723       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.5e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 107214     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.04781997 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | -0.000667  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.394      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.726      |
|    value_loss           | 0.57       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107419      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.037674434 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.23        |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.00887    |
|    std                  | 0.723       |
|    value_loss           | 5.68        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.51e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 190       |
|    time_elapsed         | 107625    |
|    total_timesteps      | 389120    |
| train/                  |           |
|    approx_kl            | 0.0644836 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.61     |
|    explained_variance   | 0.000902  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.385     |
|    n_updates            | 1890      |
|    policy_gradient_loss | 0.0197    |
|    std                  | 0.718     |
|    value_loss           | 0.598     |
---------------------------------------
Eval num_timesteps=390000, episode_reward=-99.81 +/- 0.04
Episode length: 3596.20 +/- 6.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.04360009 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.288      |
|    n_updates            | 1900       |
|    policy_gradient_loss | 0.000266   |
|    std                  | 0.716      |
|    value_loss           | 2.25       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.51e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109635   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 109842      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.076576814 |
|    clip_fraction        | 0.422       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | -8.93e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 244         |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00204    |
|    std                  | 0.717       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 193        |
|    time_elapsed         | 110047     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.06437601 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.56      |
|    explained_variance   | 0.00572    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.303      |
|    n_updates            | 1920       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.715      |
|    value_loss           | 0.449      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110253      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.045609117 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | -0.682      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.348       |
|    n_updates            | 1930        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.714       |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110458      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.072414085 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.0068      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.324       |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.00895     |
|    std                  | 0.709       |
|    value_loss           | 0.633       |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.83 +/- 0.05
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.06540793 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.00285    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.245      |
|    n_updates            | 1950       |
|    policy_gradient_loss | 0.00835    |
|    std                  | 0.707      |
|    value_loss           | 0.516      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.53e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112467   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112673      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.045224234 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | -0.00149    |
|    learning_rate        | 0.0003      |
|    loss                 | 936         |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00196     |
|    std                  | 0.706       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 112878      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.036132753 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.44       |
|    explained_variance   | 0.00659     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.316       |
|    n_updates            | 1970        |
|    policy_gradient_loss | 0.00641     |
|    std                  | 0.704       |
|    value_loss           | 0.819       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 199         |
|    time_elapsed         | 113084      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.081823036 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | -0.687      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.237       |
|    n_updates            | 1980        |
|    policy_gradient_loss | 0.00473     |
|    std                  | 0.703       |
|    value_loss           | 0.536       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 200         |
|    time_elapsed         | 113291      |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.049282826 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | -0.441      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 1990        |
|    policy_gradient_loss | 0.00514     |
|    std                  | 0.704       |
|    value_loss           | 0.924       |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.83 +/- 0.02
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.041444585 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | -0.0293     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.219       |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.00836     |
|    std                  | 0.7         |
|    value_loss           | 0.541       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.55e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115300   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.57e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 115507     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.05114595 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.000158   |
|    learning_rate        | 0.0003     |
|    loss                 | 6.43       |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.000929  |
|    std                  | 0.701      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 203         |
|    time_elapsed         | 115712      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.045514703 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.36       |
|    explained_variance   | 0.361       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.257       |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00241    |
|    std                  | 0.698       |
|    value_loss           | 0.795       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 115918      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.055930473 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.33       |
|    explained_variance   | 0.00239     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.262       |
|    n_updates            | 2030        |
|    policy_gradient_loss | 0.00889     |
|    std                  | 0.698       |
|    value_loss           | 0.516       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 116123      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.038941827 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | -1.02       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.294       |
|    n_updates            | 2040        |
|    policy_gradient_loss | 0.00925     |
|    std                  | 0.697       |
|    value_loss           | 0.604       |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.83 +/- 0.07
Episode length: 3598.60 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.051932707 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.0146      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.476       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.00773     |
|    std                  | 0.697       |
|    value_loss           | 0.812       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.57e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118133   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118339      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.031257957 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | 0.000214    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.9        |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.697       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118544     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.03740424 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.32      |
|    explained_variance   | 0.0502     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.293      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.00299    |
|    std                  | 0.696      |
|    value_loss           | 0.832      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.59e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 118750     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.05047955 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.31      |
|    explained_variance   | -0.0281    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.288      |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.695      |
|    value_loss           | 0.659      |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.83 +/- 0.06
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.033210367 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.0818      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.262       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.0072      |
|    std                  | 0.692       |
|    value_loss           | 0.621       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120758   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 211        |
|    time_elapsed         | 120965     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.04248018 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.27      |
|    explained_variance   | 0.0098     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.42e+03   |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.00892   |
|    std                  | 0.692      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121172      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.047981262 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | -0.576      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.308       |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.00647     |
|    std                  | 0.689       |
|    value_loss           | 0.65        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121377      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.051317886 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.272       |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.00716    |
|    std                  | 0.69        |
|    value_loss           | 2.2         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 121583     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.03994124 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.25      |
|    explained_variance   | 0.00574    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.286      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.691      |
|    value_loss           | 0.536      |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.79 +/- 0.04
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.046545915 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.00734     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.277       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.69        |
|    value_loss           | 0.633       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123592   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123797      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.026212106 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | -1.51e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 318         |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00815    |
|    std                  | 0.69        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.61e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 217       |
|    time_elapsed         | 124003    |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 0.0477949 |
|    clip_fraction        | 0.351     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.2      |
|    explained_variance   | -0.00174  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.445     |
|    n_updates            | 2160      |
|    policy_gradient_loss | 0.00903   |
|    std                  | 0.685     |
|    value_loss           | 0.536     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 124208     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.04278737 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.18      |
|    explained_variance   | -0.002     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.275      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.00641    |
|    std                  | 0.686      |
|    value_loss           | 0.444      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.62e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 219        |
|    time_elapsed         | 124414     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.04106088 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | 0.00354    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.213      |
|    n_updates            | 2180       |
|    policy_gradient_loss | 0.00892    |
|    std                  | 0.685      |
|    value_loss           | 0.586      |
----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.83 +/- 0.07
Episode length: 3596.80 +/- 6.21
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.04479982 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | -3.14      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.268      |
|    n_updates            | 2190       |
|    policy_gradient_loss | 0.00712    |
|    std                  | 0.684      |
|    value_loss           | 0.657      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126423   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 126630      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.035879314 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | -1.86e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.93        |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0016     |
|    std                  | 0.681       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 126836     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.05062902 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | 0.00108    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.29       |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.00502    |
|    std                  | 0.68       |
|    value_loss           | 0.526      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 127041     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.04090609 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | -0.012     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.194      |
|    n_updates            | 2220       |
|    policy_gradient_loss | 0.00726    |
|    std                  | 0.682      |
|    value_loss           | 0.496      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127247      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.051826507 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.000907    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.243       |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.00241     |
|    std                  | 0.681       |
|    value_loss           | 0.477       |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.82 +/- 0.04
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.056365076 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.266       |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.000899   |
|    std                  | 0.68        |
|    value_loss           | 1.23        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129256   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 129461      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.041695498 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | -3.72e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 868         |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.00105    |
|    std                  | 0.681       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 129667      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.046556167 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.000727    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.315       |
|    n_updates            | 2260        |
|    policy_gradient_loss | 0.00332     |
|    std                  | 0.681       |
|    value_loss           | 0.545       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 129872     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.04355652 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 4.13e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.285      |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.0081     |
|    std                  | 0.677      |
|    value_loss           | 0.386      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 130078     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.04622465 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 5.85e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.22       |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.00939    |
|    std                  | 0.674      |
|    value_loss           | 0.525      |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.89 +/- 0.04
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.039743856 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.173       |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.00107    |
|    std                  | 0.673       |
|    value_loss           | 1.17        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 132086   |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 231        |
|    time_elapsed         | 132292     |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.07195481 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | -0.00127   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+03   |
|    n_updates            | 2300       |
|    policy_gradient_loss | 0.00154    |
|    std                  | 0.673      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 232         |
|    time_elapsed         | 132498      |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.056787938 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.01       |
|    explained_variance   | 3.58e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.292       |
|    n_updates            | 2310        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.671       |
|    value_loss           | 0.416       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 132704      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.042667218 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.99       |
|    explained_variance   | -0.108      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 2320        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.67        |
|    value_loss           | 0.477       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 132910     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.04187328 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.132      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.00633    |
|    std                  | 0.671      |
|    value_loss           | 0.404      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.82 +/- 0.07
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.04361197 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.000321  |
|    std                  | 0.666      |
|    value_loss           | 0.686      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134918   |
|    total_timesteps | 481280   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.69e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 236       |
|    time_elapsed         | 135124    |
|    total_timesteps      | 483328    |
| train/                  |           |
|    approx_kl            | 0.0357814 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.93     |
|    explained_variance   | 0.00345   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.05e+03  |
|    n_updates            | 2350      |
|    policy_gradient_loss | -0.00365  |
|    std                  | 0.666     |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 237         |
|    time_elapsed         | 135330      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.071969375 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | -0.00104    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.228       |
|    n_updates            | 2360        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.669       |
|    value_loss           | 0.456       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 135535     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.03655715 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | -0.0279    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.247      |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.00793    |
|    std                  | 0.664      |
|    value_loss           | 0.492      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135741     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.05048496 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.604      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.00305    |
|    std                  | 0.664      |
|    value_loss           | 0.788      |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.83 +/- 0.05
Episode length: 3597.80 +/- 3.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.067844465 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.9        |
|    explained_variance   | -0.00128    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.22        |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.00906     |
|    std                  | 0.664       |
|    value_loss           | 0.347       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137750   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 241         |
|    time_elapsed         | 137956      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.042512957 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.9        |
|    explained_variance   | -0.000198   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.92        |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0019     |
|    std                  | 0.666       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 242         |
|    time_elapsed         | 138162      |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.076053604 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.88       |
|    explained_variance   | -0.00362    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 2410        |
|    policy_gradient_loss | 0.0119      |
|    std                  | 0.661       |
|    value_loss           | 0.506       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 138368     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.04264631 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.86      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02       |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.00462   |
|    std                  | 0.66       |
|    value_loss           | 1.87       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138573     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.05931137 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.238      |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.000493   |
|    std                  | 0.657      |
|    value_loss           | 0.541      |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.85 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.074954286 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.0106      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.289       |
|    n_updates            | 2440        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.657       |
|    value_loss           | 0.473       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.72e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140581   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 140787      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.032984424 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | -0.000954   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.42        |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00414    |
|    std                  | 0.658       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 140992      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.080111995 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.84       |
|    explained_variance   | -0.0822     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.221       |
|    n_updates            | 2460        |
|    policy_gradient_loss | 0.000542    |
|    std                  | 0.659       |
|    value_loss           | 0.553       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.74e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 248        |
|    time_elapsed         | 141198     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.04452744 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.00432    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.209      |
|    n_updates            | 2470       |
|    policy_gradient_loss | 0.00758    |
|    std                  | 0.665      |
|    value_loss           | 0.45       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141403      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.041522425 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.91       |
|    explained_variance   | 0.00215     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.156       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.666       |
|    value_loss           | 0.37        |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.84 +/- 0.04
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.06595201 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.0017     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.217      |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.664      |
|    value_loss           | 0.475      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.73e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143412   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 143619      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.046966687 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.9        |
|    explained_variance   | 0.00727     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.02        |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00444    |
|    std                  | 0.665       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.74e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 143824     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.05013483 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.567      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.154      |
|    n_updates            | 2510       |
|    policy_gradient_loss | 0.00432    |
|    std                  | 0.664      |
|    value_loss           | 0.527      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 144030     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.05487593 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.000515   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.234      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.00697    |
|    std                  | 0.661      |
|    value_loss           | 0.44       |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.83 +/- 0.05
Episode length: 3599.00 +/- 4.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.04625509 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 2530       |
|    policy_gradient_loss | 0.00914    |
|    std                  | 0.661      |
|    value_loss           | 0.65       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 146039   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146245      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.051215455 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | -0.000297   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.86        |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00172    |
|    std                  | 0.662       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 146451     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.06545532 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | -0.108     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.231      |
|    n_updates            | 2550       |
|    policy_gradient_loss | 0.00635    |
|    std                  | 0.66       |
|    value_loss           | 0.503      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 146656      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.052313082 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.279       |
|    n_updates            | 2560        |
|    policy_gradient_loss | 0.00634     |
|    std                  | 0.658       |
|    value_loss           | 0.649       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 146862      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.051878974 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.000899    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 2570        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.658       |
|    value_loss           | 0.498       |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.80 +/- 0.07
Episode length: 3597.40 +/- 5.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.045874998 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.309       |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.00149     |
|    std                  | 0.656       |
|    value_loss           | 0.472       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148870   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 149077      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.038941227 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | -4.35e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 9.43        |
|    n_updates            | 2590        |
|    policy_gradient_loss | 0.00102     |
|    std                  | 0.657       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 149282      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.051217616 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | -0.0149     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.332       |
|    n_updates            | 2600        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.656       |
|    value_loss           | 0.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 149488      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.058770835 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.77       |
|    explained_variance   | 0.251       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.274       |
|    n_updates            | 2610        |
|    policy_gradient_loss | 0.00804     |
|    std                  | 0.654       |
|    value_loss           | 0.759       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.78e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 263        |
|    time_elapsed         | 149694     |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.06712925 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | 0.00188    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.263      |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.653      |
|    value_loss           | 0.409      |
----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.80 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.057509996 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.74       |
|    explained_variance   | 0.355       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.23        |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.00869     |
|    std                  | 0.652       |
|    value_loss           | 0.489       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.77e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151700   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 151906      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.099008575 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.73       |
|    explained_variance   | -5.08e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 15.8        |
|    n_updates            | 2640        |
|    policy_gradient_loss | 3.13e-05    |
|    std                  | 0.652       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 152112     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.11432442 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 5.84e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.161      |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0287     |
|    std                  | 0.651      |
|    value_loss           | 0.376      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 152318      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.095060736 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | 0.000166    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.233       |
|    n_updates            | 2660        |
|    policy_gradient_loss | 0.00509     |
|    std                  | 0.651       |
|    value_loss           | 0.388       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 152523     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.04536752 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.7       |
|    explained_variance   | 3.67e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.189      |
|    n_updates            | 2670       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.649      |
|    value_loss           | 0.488      |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.85 +/- 0.06
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.04082477 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.123      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.00236    |
|    std                  | 0.65       |
|    value_loss           | 0.44       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.78e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154530   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 154737      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.043778695 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.69       |
|    explained_variance   | -0.0002     |
|    learning_rate        | 0.0003      |
|    loss                 | 52.1        |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00352    |
|    std                  | 0.65        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 154942     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.04199735 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | -0.00222   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.195      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.649      |
|    value_loss           | 0.439      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 155148      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.077239014 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.7        |
|    explained_variance   | 0.000746    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.178       |
|    n_updates            | 2710        |
|    policy_gradient_loss | 0.0189      |
|    std                  | 0.651       |
|    value_loss           | 0.434       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 155353     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.05832667 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.7       |
|    explained_variance   | 0.000104   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.216      |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.649      |
|    value_loss           | 0.463      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.83 +/- 0.04
Episode length: 3599.80 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.06582403 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.68      |
|    explained_variance   | -0.00236   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.174      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.648      |
|    value_loss           | 0.344      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157363   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 157569      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.038913332 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | -8.7e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 393         |
|    n_updates            | 2740        |
|    policy_gradient_loss | 0.00194     |
|    std                  | 0.646       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 157775     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.10700082 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | -3.17e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.213      |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.00678    |
|    std                  | 0.64       |
|    value_loss           | 0.406      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 157980     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.04418038 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | -0.000625  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.211      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.64       |
|    value_loss           | 0.353      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 158186      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.050675116 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | 0.683       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.233       |
|    n_updates            | 2770        |
|    policy_gradient_loss | 0.00327     |
|    std                  | 0.639       |
|    value_loss           | 0.485       |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.88 +/- 0.07
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.057158753 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | 0.0125      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.186       |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.0198      |
|    std                  | 0.639       |
|    value_loss           | 0.365       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160198   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160406      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.050843082 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.59       |
|    explained_variance   | -0.000717   |
|    learning_rate        | 0.0003      |
|    loss                 | 35.6        |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.00261     |
|    std                  | 0.641       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 281         |
|    time_elapsed         | 160611      |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.043049984 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 1.53e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.183       |
|    n_updates            | 2800        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.643       |
|    value_loss           | 0.343       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 160817      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.050609235 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.62       |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 2810        |
|    policy_gradient_loss | 0.00333     |
|    std                  | 0.645       |
|    value_loss           | 0.482       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 283         |
|    time_elapsed         | 161023      |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.034839485 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | -0.234      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 2820        |
|    policy_gradient_loss | 0.0176      |
|    std                  | 0.646       |
|    value_loss           | 0.677       |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.82 +/- 0.04
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.075956404 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.0345      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.441       |
|    n_updates            | 2830        |
|    policy_gradient_loss | 0.00672     |
|    std                  | 0.643       |
|    value_loss           | 0.502       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 163033   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163241      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.062453702 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | -0.00185    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.51e+03    |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.000291    |
|    std                  | 0.643       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 163448     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.06498097 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | -0.263     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.184      |
|    n_updates            | 2850       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.64       |
|    value_loss           | 0.459      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 287         |
|    time_elapsed         | 163654      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.043371707 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | 0.00473     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.215       |
|    n_updates            | 2860        |
|    policy_gradient_loss | 0.00912     |
|    std                  | 0.636       |
|    value_loss           | 0.412       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 288         |
|    time_elapsed         | 163860      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.072792485 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.245       |
|    n_updates            | 2870        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.635       |
|    value_loss           | 0.658       |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.77 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.052947585 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.00422     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.382       |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.00777     |
|    std                  | 0.637       |
|    value_loss           | 0.574       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165866   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 166072     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.04811406 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | 0.00636    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.67e+03   |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.000916  |
|    std                  | 0.635      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166277     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.08207357 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | 0.353      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.13       |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.00344    |
|    std                  | 0.634      |
|    value_loss           | 0.476      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 292         |
|    time_elapsed         | 166483      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.050206564 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.48       |
|    explained_variance   | 0.00034     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.148       |
|    n_updates            | 2910        |
|    policy_gradient_loss | 0.0251      |
|    std                  | 0.632       |
|    value_loss           | 0.39        |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.82 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.060260065 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.47       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.631       |
|    value_loss           | 1.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168497   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168704      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.047478795 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.46       |
|    explained_variance   | -0.000103   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.01        |
|    n_updates            | 2930        |
|    policy_gradient_loss | 0.00262     |
|    std                  | 0.631       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 168910     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.08378094 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.000334   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.323      |
|    n_updates            | 2940       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.633      |
|    value_loss           | 0.468      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 169115     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.23022348 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.49      |
|    explained_variance   | -0.00717   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.298      |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.634      |
|    value_loss           | 0.488      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 169321     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.05757375 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | -0.000242  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.155      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.635      |
|    value_loss           | 0.433      |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.85 +/- 0.07
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.05695375 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.334      |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.00322    |
|    std                  | 0.634      |
|    value_loss           | 0.843      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171328   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 171534     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.10640994 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.49      |
|    explained_variance   | -1.5e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 46.6       |
|    n_updates            | 2980       |
|    policy_gradient_loss | 0.00748    |
|    std                  | 0.634      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171740     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.07640703 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.49      |
|    explained_variance   | 0.000312   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.268      |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.634      |
|    value_loss           | 0.515      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 171945     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.05992025 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.46      |
|    explained_variance   | -0.0137    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.63       |
|    value_loss           | 0.496      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 172151      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.044535406 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.42       |
|    explained_variance   | 0.0125      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.247       |
|    n_updates            | 3010        |
|    policy_gradient_loss | 0.009       |
|    std                  | 0.627       |
|    value_loss           | 0.454       |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.78 +/- 0.08
Episode length: 3596.80 +/- 8.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.06454593 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.138      |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.00445   |
|    std                  | 0.623      |
|    value_loss           | 0.567      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 174162   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 174369      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.051179677 |
|    clip_fraction        | 0.468       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.35       |
|    explained_variance   | -4.42e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 932         |
|    n_updates            | 3030        |
|    policy_gradient_loss | 0.00647     |
|    std                  | 0.622       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.84e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 305      |
|    time_elapsed         | 174574   |
|    total_timesteps      | 624640   |
| train/                  |          |
|    approx_kl            | 0.076064 |
|    clip_fraction        | 0.366    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.35    |
|    explained_variance   | 0.000527 |
|    learning_rate        | 0.0003   |
|    loss                 | 0.188    |
|    n_updates            | 3040     |
|    policy_gradient_loss | 0.0141   |
|    std                  | 0.623    |
|    value_loss           | 0.329    |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 306         |
|    time_elapsed         | 174780      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.053108566 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | 0.00213     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.375       |
|    n_updates            | 3050        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.626       |
|    value_loss           | 0.587       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 174987     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.05726669 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | -0.00257   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.298      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.621      |
|    value_loss           | 0.494      |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.80 +/- 0.07
Episode length: 3595.80 +/- 8.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.07757501 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | -0.428     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.321      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.619      |
|    value_loss           | 0.532      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176997   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 177205      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.048398107 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.0054      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.48        |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.00486    |
|    std                  | 0.619       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 177411     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.06308682 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | -1.45e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.241      |
|    n_updates            | 3090       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.618      |
|    value_loss           | 0.344      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 311        |
|    time_elapsed         | 177616     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.04160622 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | 0.476      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.224      |
|    n_updates            | 3100       |
|    policy_gradient_loss | -0.00402   |
|    std                  | 0.619      |
|    value_loss           | 0.887      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 312        |
|    time_elapsed         | 177822     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.09386665 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | 0.0124     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.215      |
|    n_updates            | 3110       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.619      |
|    value_loss           | 0.421      |
----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.85 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.07490677 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | 0.0731     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.262      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.00547    |
|    std                  | 0.618      |
|    value_loss           | 0.51       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179829   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 180034      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.033314254 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | -0.000433   |
|    learning_rate        | 0.0003      |
|    loss                 | 941         |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00572    |
|    std                  | 0.619       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 315        |
|    time_elapsed         | 180241     |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.07640104 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | -0.00207   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.237      |
|    n_updates            | 3140       |
|    policy_gradient_loss | 0.0084     |
|    std                  | 0.618      |
|    value_loss           | 0.523      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 180449      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.096218735 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.27       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.192       |
|    n_updates            | 3150        |
|    policy_gradient_loss | 0.00757     |
|    std                  | 0.615       |
|    value_loss           | 0.431       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 317         |
|    time_elapsed         | 180655      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.047984853 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.26       |
|    explained_variance   | 0.344       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 3160        |
|    policy_gradient_loss | 0.00823     |
|    std                  | 0.616       |
|    value_loss           | 0.46        |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.04528214 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.26      |
|    explained_variance   | 0.0177     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.201      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.00473    |
|    std                  | 0.614      |
|    value_loss           | 0.439      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182662   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182868      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.038925156 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | -0.000475   |
|    learning_rate        | 0.0003      |
|    loss                 | 63          |
|    n_updates            | 3180        |
|    policy_gradient_loss | 9.48e-05    |
|    std                  | 0.615       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 320        |
|    time_elapsed         | 183073     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.05079649 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.26      |
|    explained_variance   | 0.000102   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.222      |
|    n_updates            | 3190       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.616      |
|    value_loss           | 0.409      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 183279      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.053096954 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.0019      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.264       |
|    n_updates            | 3200        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.613       |
|    value_loss           | 0.583       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 322         |
|    time_elapsed         | 183485      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.058749605 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | -1.54       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.256       |
|    n_updates            | 3210        |
|    policy_gradient_loss | 0.00796     |
|    std                  | 0.613       |
|    value_loss           | 0.579       |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.84 +/- 0.05
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.090749845 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | 0.002       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.306       |
|    n_updates            | 3220        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.611       |
|    value_loss           | 0.503       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185495   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 185704     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.04929661 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -0.000886  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.63e+03   |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.611      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 185911     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.06463695 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.00284    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.176      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.612      |
|    value_loss           | 0.542      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 186117     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.11995414 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.193      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.00771    |
|    std                  | 0.609      |
|    value_loss           | 0.461      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 327         |
|    time_elapsed         | 186322      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.061638027 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.17       |
|    explained_variance   | -0.247      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 3260        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.608       |
|    value_loss           | 0.376       |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.81 +/- 0.07
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.058019478 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | -0.00419    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.188       |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.609       |
|    value_loss           | 0.385       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188329   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 188535     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.08918935 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | -5.48e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.61e+03   |
|    n_updates            | 3280       |
|    policy_gradient_loss | 0.00609    |
|    std                  | 0.609      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 330       |
|    time_elapsed         | 188740    |
|    total_timesteps      | 675840    |
| train/                  |           |
|    approx_kl            | 0.0450152 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.15     |
|    explained_variance   | 1.19e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.125     |
|    n_updates            | 3290      |
|    policy_gradient_loss | 0.0071    |
|    std                  | 0.607     |
|    value_loss           | 0.34      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188946     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.07736409 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 1.19e-07   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.308      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.604      |
|    value_loss           | 0.432      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 332       |
|    time_elapsed         | 189152    |
|    total_timesteps      | 679936    |
| train/                  |           |
|    approx_kl            | 0.0610492 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.09     |
|    explained_variance   | -1.24     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.245     |
|    n_updates            | 3310      |
|    policy_gradient_loss | 0.00883   |
|    std                  | 0.603     |
|    value_loss           | 0.483     |
---------------------------------------
Eval num_timesteps=680000, episode_reward=-99.81 +/- 0.04
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.06150816 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 2.09e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.204      |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.00785    |
|    std                  | 0.6        |
|    value_loss           | 0.409      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 191162   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 334         |
|    time_elapsed         | 191370      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.043162853 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.04       |
|    explained_variance   | -0.000475   |
|    learning_rate        | 0.0003      |
|    loss                 | 56.8        |
|    n_updates            | 3330        |
|    policy_gradient_loss | 0.000321    |
|    std                  | 0.601       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 191577     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.08489293 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.02      |
|    explained_variance   | -0.15      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.162      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.00956    |
|    std                  | 0.598      |
|    value_loss           | 0.39       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 336         |
|    time_elapsed         | 191783      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.082043305 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.04       |
|    explained_variance   | 0.00381     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.167       |
|    n_updates            | 3350        |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.603       |
|    value_loss           | 0.319       |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.85 +/- 0.01
Episode length: 3600.00 +/- 1.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.073408715 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.04       |
|    explained_variance   | 0.000937    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.0161      |
|    std                  | 0.601       |
|    value_loss           | 0.576       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193794   |
|    total_timesteps | 690176   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.86e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 338       |
|    time_elapsed         | 194001    |
|    total_timesteps      | 692224    |
| train/                  |           |
|    approx_kl            | 0.0757698 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.03     |
|    explained_variance   | -0.000471 |
|    learning_rate        | 0.0003    |
|    loss                 | 10.4      |
|    n_updates            | 3370      |
|    policy_gradient_loss | -0.00481  |
|    std                  | 0.6       |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 339         |
|    time_elapsed         | 194207      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.049440205 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.02       |
|    explained_variance   | 0.00189     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.316       |
|    n_updates            | 3380        |
|    policy_gradient_loss | 0.00849     |
|    std                  | 0.598       |
|    value_loss           | 0.465       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 194412      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.050849963 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7          |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.274       |
|    n_updates            | 3390        |
|    policy_gradient_loss | 0.00783     |
|    std                  | 0.597       |
|    value_loss           | 0.556       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 194618      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.059918948 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.0146      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.0197      |
|    std                  | 0.595       |
|    value_loss           | 0.507       |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.82 +/- 0.04
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.06315367 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.96      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.184      |
|    n_updates            | 3410       |
|    policy_gradient_loss | -3.25e-05  |
|    std                  | 0.596      |
|    value_loss           | 0.547      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196626   |
|    total_timesteps | 700416   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 343       |
|    time_elapsed         | 196831    |
|    total_timesteps      | 702464    |
| train/                  |           |
|    approx_kl            | 0.069538  |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.97     |
|    explained_variance   | -0.000783 |
|    learning_rate        | 0.0003    |
|    loss                 | 5.35      |
|    n_updates            | 3420      |
|    policy_gradient_loss | -0.00301  |
|    std                  | 0.596     |
|    value_loss           | 1.04e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 344         |
|    time_elapsed         | 197037      |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.109876364 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.96       |
|    explained_variance   | -0.000942   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.185       |
|    n_updates            | 3430        |
|    policy_gradient_loss | 0.00677     |
|    std                  | 0.595       |
|    value_loss           | 0.491       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 197245     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.12147337 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.307      |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.594      |
|    value_loss           | 0.515      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 197452      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.038114376 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.9        |
|    explained_variance   | -0.000703   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.221       |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.0194      |
|    std                  | 0.592       |
|    value_loss           | 0.454       |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.82 +/- 0.04
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 710000    |
| train/                  |           |
|    approx_kl            | 0.0604404 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.88     |
|    explained_variance   | 0.000568  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.256     |
|    n_updates            | 3460      |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.592     |
|    value_loss           | 0.477     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199461   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 199667      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.054480348 |
|    clip_fraction        | 0.431       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | -0.000142   |
|    learning_rate        | 0.0003      |
|    loss                 | 781         |
|    n_updates            | 3470        |
|    policy_gradient_loss | 0.00584     |
|    std                  | 0.593       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 349         |
|    time_elapsed         | 199872      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.047112662 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.92       |
|    explained_variance   | -0.000457   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.199       |
|    n_updates            | 3480        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.596       |
|    value_loss           | 0.433       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 350         |
|    time_elapsed         | 200078      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.048679605 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 8.86e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.155       |
|    n_updates            | 3490        |
|    policy_gradient_loss | 0.0243      |
|    std                  | 0.596       |
|    value_loss           | 0.44        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 200284     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.07784942 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.00136    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.195      |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.594      |
|    value_loss           | 0.466      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.86 +/- 0.05
Episode length: 3596.00 +/- 6.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.053063348 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | -0.0185     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.212       |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.00114     |
|    std                  | 0.591       |
|    value_loss           | 0.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202292   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 202501      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.041498907 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | 0.00033     |
|    learning_rate        | 0.0003      |
|    loss                 | 50.6        |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00284    |
|    std                  | 0.591       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 202708     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.06359463 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.000526   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.278      |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.592      |
|    value_loss           | 0.39       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 202914     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.09406799 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | 0.000919   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0698     |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.592      |
|    value_loss           | 0.35       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 356         |
|    time_elapsed         | 203119      |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.052261397 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.86       |
|    explained_variance   | 0.00225     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.159       |
|    n_updates            | 3550        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.592       |
|    value_loss           | 0.374       |
-----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.85 +/- 0.05
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.087123886 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.86       |
|    explained_variance   | -0.00786    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.287       |
|    n_updates            | 3560        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.593       |
|    value_loss           | 0.342       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 205128   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205334      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.039563116 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.88       |
|    explained_variance   | -4.72e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.99        |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.000124   |
|    std                  | 0.596       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 359         |
|    time_elapsed         | 205539      |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.044469997 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.9        |
|    explained_variance   | 7.15e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.279       |
|    n_updates            | 3580        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.596       |
|    value_loss           | 0.471       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 205746      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.047224753 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.88       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.34        |
|    n_updates            | 3590        |
|    policy_gradient_loss | -0.00949    |
|    std                  | 0.594       |
|    value_loss           | 0.725       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 205951      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.076974064 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | 0.00144     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.119       |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.0158      |
|    std                  | 0.588       |
|    value_loss           | 0.311       |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.86 +/- 0.04
Episode length: 3598.20 +/- 2.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.08085661 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | -0.00546   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.158      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.589      |
|    value_loss           | 0.312      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207961   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 363        |
|    time_elapsed         | 208168     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.07000847 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.77      |
|    explained_variance   | -0.00164   |
|    learning_rate        | 0.0003     |
|    loss                 | 40.7       |
|    n_updates            | 3620       |
|    policy_gradient_loss | 0.00113    |
|    std                  | 0.586      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 364        |
|    time_elapsed         | 208374     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.07227716 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.72      |
|    explained_variance   | -0.00102   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.247      |
|    n_updates            | 3630       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.584      |
|    value_loss           | 0.382      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 365         |
|    time_elapsed         | 208580      |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.063725136 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.72       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.192       |
|    n_updates            | 3640        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.585       |
|    value_loss           | 0.751       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 208787     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.06228201 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.19       |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.583      |
|    value_loss           | 0.348      |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.83 +/- 0.07
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.06989226 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.00113    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.167      |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.58       |
|    value_loss           | 0.383      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210794   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 368         |
|    time_elapsed         | 211000      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.053129498 |
|    clip_fraction        | 0.422       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.67       |
|    explained_variance   | -0.000827   |
|    learning_rate        | 0.0003      |
|    loss                 | 120         |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.000862   |
|    std                  | 0.581       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 369         |
|    time_elapsed         | 211206      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.064679354 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.69       |
|    explained_variance   | -5.05e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.187       |
|    n_updates            | 3680        |
|    policy_gradient_loss | 0.0227      |
|    std                  | 0.583       |
|    value_loss           | 0.351       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 211413      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.052181803 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 5.59e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 3690        |
|    policy_gradient_loss | 0.0226      |
|    std                  | 0.583       |
|    value_loss           | 0.397       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 211620     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.06766868 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | -0.0156    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.163      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.00615    |
|    std                  | 0.579      |
|    value_loss           | 0.342      |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.82 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.069363184 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.62       |
|    explained_variance   | 0.0018      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.174       |
|    n_updates            | 3710        |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.576       |
|    value_loss           | 0.448       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213628   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 213834     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.04213264 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.62      |
|    explained_variance   | -0.000231  |
|    learning_rate        | 0.0003     |
|    loss                 | 8.85       |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.00424   |
|    std                  | 0.576      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 214042     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.07000736 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | 0.00576    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.162      |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.573      |
|    value_loss           | 0.333      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 214249     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.06864137 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.143      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.00855    |
|    std                  | 0.574      |
|    value_loss           | 0.387      |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.82 +/- 0.07
Episode length: 3596.20 +/- 6.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.051350947 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.573       |
|    value_loss           | 0.704       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 216261   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216468      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.048458923 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | -0.000874   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.75        |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.000536   |
|    std                  | 0.573       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 378         |
|    time_elapsed         | 216674      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.113063976 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.54       |
|    explained_variance   | 7.27e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.792       |
|    n_updates            | 3770        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.569       |
|    value_loss           | 0.354       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 379         |
|    time_elapsed         | 216879      |
|    total_timesteps      | 776192      |
| train/                  |             |
|    approx_kl            | 0.101051934 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.51       |
|    explained_variance   | -1.37       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.174       |
|    n_updates            | 3780        |
|    policy_gradient_loss | 0.00882     |
|    std                  | 0.567       |
|    value_loss           | 0.428       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 380         |
|    time_elapsed         | 217085      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.056254514 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.49       |
|    explained_variance   | 3.05e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.221       |
|    n_updates            | 3790        |
|    policy_gradient_loss | 0.0185      |
|    std                  | 0.566       |
|    value_loss           | 0.402       |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.83 +/- 0.03
Episode length: 3596.40 +/- 7.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.04275297 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.46      |
|    explained_variance   | 0.023      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.129      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.00472    |
|    std                  | 0.563      |
|    value_loss           | 0.395      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 219096   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 219302     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.03908443 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 6.98       |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.00339   |
|    std                  | 0.564      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 383         |
|    time_elapsed         | 219509      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.047810536 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.44       |
|    explained_variance   | 4.94e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.232       |
|    n_updates            | 3820        |
|    policy_gradient_loss | 0.00964     |
|    std                  | 0.562       |
|    value_loss           | 0.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 219715      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.044930782 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.42       |
|    explained_variance   | -0.639      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.141       |
|    n_updates            | 3830        |
|    policy_gradient_loss | 0.0169      |
|    std                  | 0.56        |
|    value_loss           | 0.393       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 385         |
|    time_elapsed         | 219920      |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.079912804 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.41       |
|    explained_variance   | -0.00089    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.232       |
|    n_updates            | 3840        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.561       |
|    value_loss           | 0.399       |
-----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.03764286 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.41      |
|    explained_variance   | -0.00231   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.166      |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.00653    |
|    std                  | 0.56       |
|    value_loss           | 0.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221928   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 222134      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.060096264 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.4        |
|    explained_variance   | -0.000267   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.45        |
|    n_updates            | 3860        |
|    policy_gradient_loss | 0.000484    |
|    std                  | 0.558       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 222340     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.10115747 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 4.17e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.179      |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.56       |
|    value_loss           | 0.437      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 389         |
|    time_elapsed         | 222545      |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.050393127 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.4        |
|    explained_variance   | 0.139       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.209       |
|    n_updates            | 3880        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.558       |
|    value_loss           | 0.358       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 390         |
|    time_elapsed         | 222751      |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.053387795 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.4        |
|    explained_variance   | 0.00722     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.24        |
|    n_updates            | 3890        |
|    policy_gradient_loss | 0.00991     |
|    std                  | 0.56        |
|    value_loss           | 0.404       |
-----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.11540126 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.39      |
|    explained_variance   | -0.392     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.269      |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.558      |
|    value_loss           | 0.457      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224760   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 224965      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.058521748 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.37       |
|    explained_variance   | -0.00157    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+03    |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.000432   |
|    std                  | 0.557       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 225172     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.05923149 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.00311    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.224      |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.00647    |
|    std                  | 0.558      |
|    value_loss           | 0.456      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 225377     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.09146007 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.135      |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.00752    |
|    std                  | 0.554      |
|    value_loss           | 0.49       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 395         |
|    time_elapsed         | 225583      |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.042783637 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.33       |
|    explained_variance   | -0.0032     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.278       |
|    n_updates            | 3940        |
|    policy_gradient_loss | 0.00933     |
|    std                  | 0.553       |
|    value_loss           | 0.442       |
-----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.86 +/- 0.04
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.070431456 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.3        |
|    explained_variance   | -0.0583     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.296       |
|    n_updates            | 3950        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.55        |
|    value_loss           | 0.39        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227592   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 227802     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.04894696 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | -0.000715  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.23e+03   |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.000124  |
|    std                  | 0.547      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 398         |
|    time_elapsed         | 228007      |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.057102997 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.000548    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.152       |
|    n_updates            | 3970        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.547       |
|    value_loss           | 0.347       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 399         |
|    time_elapsed         | 228213      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.118977666 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.23       |
|    explained_variance   | 0.0349      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.122       |
|    n_updates            | 3980        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.544       |
|    value_loss           | 0.412       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 400         |
|    time_elapsed         | 228418      |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.055689737 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.21       |
|    explained_variance   | -0.298      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.23        |
|    n_updates            | 3990        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.543       |
|    value_loss           | 0.709       |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.83 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.041522942 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.22       |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 4000        |
|    policy_gradient_loss | 0.000799    |
|    std                  | 0.546       |
|    value_loss           | 0.511       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230425   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 230630     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.07440582 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.24      |
|    explained_variance   | -7.39e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 17.5       |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.00151    |
|    std                  | 0.546      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 230836     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.08185916 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 1.5e-05    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.229      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.549      |
|    value_loss           | 0.358      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.91e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 404       |
|    time_elapsed         | 231041    |
|    total_timesteps      | 827392    |
| train/                  |           |
|    approx_kl            | 0.0794726 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.29     |
|    explained_variance   | 0.183     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.276     |
|    n_updates            | 4030      |
|    policy_gradient_loss | 0.00811   |
|    std                  | 0.547     |
|    value_loss           | 0.368     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 405         |
|    time_elapsed         | 231248      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.047008865 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.24       |
|    explained_variance   | -0.000825   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.202       |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.543       |
|    value_loss           | 0.328       |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.83 +/- 0.04
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.05982257 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.22      |
|    explained_variance   | 0.000794   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.239      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.544      |
|    value_loss           | 0.402      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 233259   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233465     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.04840044 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.24      |
|    explained_variance   | -0.000246  |
|    learning_rate        | 0.0003     |
|    loss                 | 7.42       |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.000214   |
|    std                  | 0.546      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 233670     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.05415202 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 8.23e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.137      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.548      |
|    value_loss           | 0.341      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 233876     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.11284913 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.156      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.549      |
|    value_loss           | 0.379      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 410         |
|    time_elapsed         | 234082      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.044808574 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.31       |
|    explained_variance   | -0.0141     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 4090        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.553       |
|    value_loss           | 0.345       |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.81 +/- 0.07
Episode length: 3599.60 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.03901197 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.000554   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.206      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.552      |
|    value_loss           | 0.323      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 236091   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 236296     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.04892557 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.3       |
|    explained_variance   | -0.000159  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.97e+03   |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.00642    |
|    std                  | 0.551      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 236503     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.08189632 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.135      |
|    n_updates            | 4120       |
|    policy_gradient_loss | 0.00346    |
|    std                  | 0.55       |
|    value_loss           | 0.389      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 414        |
|    time_elapsed         | 236709     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.05765573 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 0.00323    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.115      |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.548      |
|    value_loss           | 0.262      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 236915     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.06751948 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.24      |
|    explained_variance   | -0.0407    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.091      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.00904    |
|    std                  | 0.548      |
|    value_loss           | 0.408      |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.86 +/- 0.03
Episode length: 3599.40 +/- 1.96
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.044109263 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.26       |
|    explained_variance   | 0.0029      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.185       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.00808     |
|    std                  | 0.55        |
|    value_loss           | 0.443       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238921   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 239131      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.048145637 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | -0.000649   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.16e+03    |
|    n_updates            | 4160        |
|    policy_gradient_loss | -0.000833   |
|    std                  | 0.552       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 418         |
|    time_elapsed         | 239339      |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.059615087 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.29       |
|    explained_variance   | -0.0969     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.102       |
|    n_updates            | 4170        |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.555       |
|    value_loss           | 0.299       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 419         |
|    time_elapsed         | 239544      |
|    total_timesteps      | 858112      |
| train/                  |             |
|    approx_kl            | 0.057351585 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.29       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.173       |
|    n_updates            | 4180        |
|    policy_gradient_loss | 0.00981     |
|    std                  | 0.553       |
|    value_loss           | 0.274       |
-----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.84 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.07597917 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.27      |
|    explained_variance   | 0.035      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.168      |
|    n_updates            | 4190       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.551      |
|    value_loss           | 0.338      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241550   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 241756     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.06504582 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | -0.00015   |
|    learning_rate        | 0.0003     |
|    loss                 | 817        |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.000118  |
|    std                  | 0.551      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 241962     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.10631106 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.23      |
|    explained_variance   | 1.06e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.547      |
|    value_loss           | 0.584      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 242167     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.11247668 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.18      |
|    explained_variance   | -0.0488    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.00932    |
|    std                  | 0.546      |
|    value_loss           | 0.41       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.92e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 424       |
|    time_elapsed         | 242373    |
|    total_timesteps      | 868352    |
| train/                  |           |
|    approx_kl            | 0.1580883 |
|    clip_fraction        | 0.367     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.16     |
|    explained_variance   | 1.79e-07  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.21      |
|    n_updates            | 4230      |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.545     |
|    value_loss           | 0.41      |
---------------------------------------
Eval num_timesteps=870000, episode_reward=-99.85 +/- 0.09
Episode length: 3596.20 +/- 6.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.093788624 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.15       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.146       |
|    n_updates            | 4240        |
|    policy_gradient_loss | 0.0611      |
|    std                  | 0.545       |
|    value_loss           | 0.36        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244385   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 426         |
|    time_elapsed         | 244592      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.060191844 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.15       |
|    explained_variance   | -0.000466   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.01        |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.000275   |
|    std                  | 0.545       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 244798     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.08463407 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.15      |
|    explained_variance   | 0.000287   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.107      |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.545      |
|    value_loss           | 0.285      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 245003     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.10691881 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.14      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.819      |
|    n_updates            | 4270       |
|    policy_gradient_loss | -0.00111   |
|    std                  | 0.544      |
|    value_loss           | 1.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 245209     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.07078008 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.15      |
|    explained_variance   | -0.0171    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.119      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.544      |
|    value_loss           | 0.304      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.83 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.06757967 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.144      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.00671    |
|    std                  | 0.546      |
|    value_loss           | 0.901      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 247215   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 247421      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.049485907 |
|    clip_fraction        | 0.454       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.15       |
|    explained_variance   | -3.68e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.51        |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.000136    |
|    std                  | 0.545       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 432         |
|    time_elapsed         | 247629      |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.105934136 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.11       |
|    explained_variance   | 3.52e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 4310        |
|    policy_gradient_loss | 0.0163      |
|    std                  | 0.541       |
|    value_loss           | 0.367       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 247835      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.095611215 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.09       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.219       |
|    n_updates            | 4320        |
|    policy_gradient_loss | 0.00107     |
|    std                  | 0.541       |
|    value_loss           | 0.422       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 248041     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.07418491 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.000426   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.139      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.541      |
|    value_loss           | 0.246      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.80 +/- 0.08
Episode length: 3595.20 +/- 9.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.10869041 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.07      |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.265      |
|    n_updates            | 4340       |
|    policy_gradient_loss | 0.00426    |
|    std                  | 0.539      |
|    value_loss           | 0.486      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 250051   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 250258      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.061148893 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.06       |
|    explained_variance   | -0.000135   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.28        |
|    n_updates            | 4350        |
|    policy_gradient_loss | 0.00199     |
|    std                  | 0.539       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 250463     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.07202619 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | -0.000345  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.282      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.536      |
|    value_loss           | 0.309      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 438         |
|    time_elapsed         | 250669      |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.089653604 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.656       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.223       |
|    n_updates            | 4370        |
|    policy_gradient_loss | -0.00132    |
|    std                  | 0.536       |
|    value_loss           | 0.456       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 250875     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.04938691 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6         |
|    explained_variance   | -4.64e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.138      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.536      |
|    value_loss           | 0.246      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.88 +/- 0.04
Episode length: 3596.60 +/- 7.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.055013437 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0713      |
|    n_updates            | 4390        |
|    policy_gradient_loss | 0.00279     |
|    std                  | 0.539       |
|    value_loss           | 0.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252886   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 253093     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.06464483 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | 0.000184   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.25e+03   |
|    n_updates            | 4400       |
|    policy_gradient_loss | 7.71e-05   |
|    std                  | 0.539      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 442         |
|    time_elapsed         | 253298      |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.072565675 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.05       |
|    explained_variance   | -0.0099     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.19        |
|    n_updates            | 4410        |
|    policy_gradient_loss | 0.0243      |
|    std                  | 0.54        |
|    value_loss           | 0.326       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 253504     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.12809348 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.255      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.537      |
|    value_loss           | 0.348      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 444         |
|    time_elapsed         | 253710      |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.067401126 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.000327    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.158       |
|    n_updates            | 4430        |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.542       |
|    value_loss           | 0.286       |
-----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.86 +/- 0.07
Episode length: 3596.80 +/- 8.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.05478203 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.06      |
|    explained_variance   | -0.000162  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.162      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.542      |
|    value_loss           | 0.396      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255719   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 255928      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.051887356 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.07       |
|    explained_variance   | -3.99e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 446         |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.000131   |
|    std                  | 0.544       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 447         |
|    time_elapsed         | 256135      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.067386135 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.06       |
|    explained_variance   | 7.15e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.273       |
|    n_updates            | 4460        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.543       |
|    value_loss           | 0.39        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 256341     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.10535851 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.225      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.00874    |
|    std                  | 0.541      |
|    value_loss           | 0.531      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 256546     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.07843458 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.119      |
|    n_updates            | 4480       |
|    policy_gradient_loss | -0.00193   |
|    std                  | 0.542      |
|    value_loss           | 0.443      |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.87 +/- 0.04
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 920000    |
| train/                  |           |
|    approx_kl            | 0.0541991 |
|    clip_fraction        | 0.326     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.03     |
|    explained_variance   | 0.00438   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.244     |
|    n_updates            | 4490      |
|    policy_gradient_loss | 0.0204    |
|    std                  | 0.541     |
|    value_loss           | 0.368     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258553   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 258759      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.047503613 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | -4.55e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 15.6        |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.00338    |
|    std                  | 0.541       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 452        |
|    time_elapsed         | 258965     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.05330634 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.104      |
|    n_updates            | 4510       |
|    policy_gradient_loss | 0.00728    |
|    std                  | 0.537      |
|    value_loss           | 0.236      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 453        |
|    time_elapsed         | 259171     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.04318984 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | -0.000824  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.122      |
|    n_updates            | 4520       |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.538      |
|    value_loss           | 0.276      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 259379     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.08900731 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6         |
|    explained_variance   | 1.14e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.283      |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.00733    |
|    std                  | 0.54       |
|    value_loss           | 0.412      |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.85 +/- 0.01
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.108686194 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.000131    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0913      |
|    n_updates            | 4540        |
|    policy_gradient_loss | 0.0136      |
|    std                  | 0.539       |
|    value_loss           | 0.316       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261389   |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 456        |
|    time_elapsed         | 261595     |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.03991122 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | -0.000162  |
|    learning_rate        | 0.0003     |
|    loss                 | 929        |
|    n_updates            | 4550       |
|    policy_gradient_loss | -0.000261  |
|    std                  | 0.541      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 457         |
|    time_elapsed         | 261801      |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.085101545 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | -0.0145     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.184       |
|    n_updates            | 4560        |
|    policy_gradient_loss | 0.0149      |
|    std                  | 0.541       |
|    value_loss           | 0.335       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 458         |
|    time_elapsed         | 262007      |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.055015936 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 1.19e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.213       |
|    n_updates            | 4570        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.544       |
|    value_loss           | 0.323       |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.87 +/- 0.02
Episode length: 3596.80 +/- 7.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.052410454 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.03       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.245       |
|    n_updates            | 4580        |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.542       |
|    value_loss           | 0.386       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 264016   |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 460         |
|    time_elapsed         | 264223      |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.061772514 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | -9.66e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 769         |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.000904   |
|    std                  | 0.542       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 264428     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.07702124 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 0.135      |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.542      |
|    value_loss           | 0.335      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 462         |
|    time_elapsed         | 264634      |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.048095144 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.05       |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.2         |
|    n_updates            | 4610        |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.543       |
|    value_loss           | 1.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 264839      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.057682395 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.05       |
|    explained_variance   | -5.96e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 4620        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.544       |
|    value_loss           | 0.255       |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.83 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.054058336 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.768       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 4630        |
|    policy_gradient_loss | 0.00235     |
|    std                  | 0.547       |
|    value_loss           | 0.43        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266848   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 267054     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.05030859 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.1       |
|    explained_variance   | -5.85e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.81       |
|    n_updates            | 4640       |
|    policy_gradient_loss | 0.00248    |
|    std                  | 0.547      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 466         |
|    time_elapsed         | 267260      |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.049479935 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.1        |
|    explained_variance   | 1.2e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.117       |
|    n_updates            | 4650        |
|    policy_gradient_loss | 0.0131      |
|    std                  | 0.547       |
|    value_loss           | 0.277       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 467         |
|    time_elapsed         | 267465      |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.063301496 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.282       |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.544       |
|    value_loss           | 0.641       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 468        |
|    time_elapsed         | 267671     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.15308882 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | -0.00178   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.207      |
|    n_updates            | 4670       |
|    policy_gradient_loss | 0.00813    |
|    std                  | 0.542      |
|    value_loss           | 0.287      |
----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.87 +/- 0.04
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.07617589 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | -0.0131    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.261      |
|    n_updates            | 4680       |
|    policy_gradient_loss | 0.0082     |
|    std                  | 0.539      |
|    value_loss           | 0.278      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269683   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 269890      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.064551204 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.99       |
|    explained_variance   | 4.77e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 510         |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.00155     |
|    std                  | 0.54        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.93e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 471       |
|    time_elapsed         | 270095    |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 0.1487953 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.01     |
|    explained_variance   | 1.34e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0932    |
|    n_updates            | 4700      |
|    policy_gradient_loss | 0.031     |
|    std                  | 0.541     |
|    value_loss           | 0.316     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 472         |
|    time_elapsed         | 270301      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.050733484 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.03       |
|    explained_variance   | 4.47e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.22        |
|    n_updates            | 4710        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.544       |
|    value_loss           | 0.341       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 473         |
|    time_elapsed         | 270506      |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.060840916 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | 5.3e-06     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0693      |
|    n_updates            | 4720        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.541       |
|    value_loss           | 0.206       |
-----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.84 +/- 0.03
Episode length: 3595.40 +/- 7.84
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.03599158 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.03       |
|    n_updates            | 4730       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.539      |
|    value_loss           | 2.66       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272517   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 272724     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.04300507 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | 0.00617    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.54e+03   |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.00209   |
|    std                  | 0.539      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 476        |
|    time_elapsed         | 272931     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.06974906 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.00109    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.183      |
|    n_updates            | 4750       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.54       |
|    value_loss           | 0.255      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 273136     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.07362129 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.97      |
|    explained_variance   | -0.000804  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0631     |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.537      |
|    value_loss           | 0.231      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 273342     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.09046306 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | 9.72e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.526      |
|    n_updates            | 4770       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.534      |
|    value_loss           | 0.416      |
----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.81 +/- 0.04
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.038401924 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.341       |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.00664    |
|    std                  | 0.531       |
|    value_loss           | 3.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 275351   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275561      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.066039175 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.87       |
|    explained_variance   | 0.00695     |
|    learning_rate        | 0.0003      |
|    loss                 | 596         |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.00288    |
|    std                  | 0.531       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 275766     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.09753451 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.87      |
|    explained_variance   | -0.155     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.195      |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.532      |
|    value_loss           | 0.269      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275972     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.06186839 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.9       |
|    explained_variance   | -0.0396    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0919     |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.00515    |
|    std                  | 0.534      |
|    value_loss           | 0.284      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 276178     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.04833647 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | 0.00282    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.109      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.00654    |
|    std                  | 0.533      |
|    value_loss           | 0.254      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.85 +/- 0.03
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.050776426 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.93       |
|    explained_variance   | 0.00583     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.154       |
|    n_updates            | 4830        |
|    policy_gradient_loss | 0.00367     |
|    std                  | 0.537       |
|    value_loss           | 0.256       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 278186   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 278393     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.03314572 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | -0.00335   |
|    learning_rate        | 0.0003     |
|    loss                 | 242        |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.00686   |
|    std                  | 0.538      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.94e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 278599     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.08337343 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | -0.00348   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.102      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.538      |
|    value_loss           | 0.265      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.94e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 278805     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.04626646 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18       |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.537      |
|    value_loss           | 1.56       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.94e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 488       |
|    time_elapsed         | 279010    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.0664759 |
|    clip_fraction        | 0.361     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.94     |
|    explained_variance   | -0.00109  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.206     |
|    n_updates            | 4870      |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.536     |
|    value_loss           | 0.323     |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.91 +/- 0.01
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.1385006 |
|    clip_fraction        | 0.351     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.91     |
|    explained_variance   | -0.00202  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0701    |
|    n_updates            | 4880      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.534     |
|    value_loss           | 0.215     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.93e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 281019   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-24_14-30-15_llm_triton_qwen_14b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 3 days, 6:01:00 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.985818  -99.97983   -99.964645  -99.966325 -100.012091]
 [ -99.98229   -99.901787 -100.011218 -100.025126 -100.018155]
 [ -99.895842  -99.976982  -99.992037  -99.897731  -99.98724 ]
 [ -99.985622  -99.870768  -99.942273  -99.830511 -100.008475]
 [ -99.925142  -99.915763  -99.95738   -99.896782  -99.925117]
 [ -99.915542  -99.909225  -99.9184    -99.958196  -99.8759  ]
 [ -99.676459  -99.785419  -99.872589  -99.907794  -99.754704]
 [ -99.713397  -99.829608  -99.728933  -99.865893  -99.850973]
 [ -99.991508  -99.882393  -99.871365  -99.761059  -99.725368]
 [ -99.842891  -99.794576  -99.863815  -99.815642  -99.879532]
 [ -99.806861  -99.718066  -99.937296  -99.713989  -99.892656]
 [ -99.881441  -99.815484  -99.8215    -99.692003  -99.940804]
 [ -99.942621  -99.828101  -99.879377  -99.866185  -99.928271]
 [ -99.753058  -99.724324  -99.891226  -99.820746  -99.795254]
 [ -99.945726  -99.833079  -99.562124  -99.800108  -99.909316]
 [ -99.92329   -99.954401  -99.815499  -99.855656  -99.957084]
 [ -99.946839  -99.853216  -99.851437  -99.800908  -99.963693]
 [ -99.917823  -99.896338  -99.794755  -99.729571  -99.487431]
 [ -99.88238   -99.797355  -99.918833  -99.920671  -99.908999]
 [ -99.926666  -99.926925  -99.977618  -99.942527  -99.929331]
 [ -99.60899   -99.803707  -99.927175  -99.909389  -99.7815  ]
 [ -99.745532  -99.818073  -99.766312  -99.936015  -99.73005 ]
 [ -99.922623  -99.7344    -99.883225  -99.676226  -99.942503]
 [ -99.815616  -99.962473  -99.872223  -99.672828  -99.922491]
 [ -99.925027  -99.786894  -99.746984  -99.805384  -99.792381]
 [ -99.680066  -99.747025  -99.889963  -99.829735  -99.560178]
 [ -99.812972  -99.857745  -99.87664   -99.61896   -99.761389]
 [ -99.818084  -99.75514   -99.826021  -99.760881  -99.734654]
 [ -99.769241  -99.775966  -99.674571  -99.880863  -99.886313]
 [ -99.916161  -99.685716  -99.901868  -99.823188  -99.795863]
 [ -99.757005  -99.850035  -99.92351   -99.821895  -99.898231]
 [ -99.78138   -99.833746  -99.948222  -99.786903  -99.865297]
 [ -99.891163  -99.86815   -99.740399  -99.776445  -99.840017]
 [ -99.791879  -99.864877  -99.804472  -99.895845  -99.813217]
 [ -99.950194  -99.838779  -99.946828  -99.868703  -99.852749]
 [ -99.689858  -99.884388  -99.789355  -99.808175  -99.875579]
 [ -99.831238  -99.76787   -99.767275  -99.921792  -99.922577]
 [ -99.765653  -99.834072  -99.795665  -99.945028  -99.836619]
 [ -99.813166  -99.732235  -99.871113  -99.800437  -99.815943]
 [ -99.838802  -99.818389  -99.92189   -99.791953  -99.77548 ]
 [ -99.859585  -99.822686  -99.818369  -99.839596  -99.798877]
 [ -99.864006  -99.872319  -99.898684  -99.771289  -99.726197]
 [ -99.899825  -99.779866  -99.8835    -99.850902  -99.746657]
 [ -99.828612  -99.780391  -99.771074  -99.730505  -99.853881]
 [ -99.851556  -99.76792   -99.727691  -99.913091  -99.906129]
 [ -99.787888  -99.84102   -99.769466  -99.876882  -99.808914]
 [ -99.950171  -99.847873  -99.853344  -99.888208  -99.894482]
 [ -99.756745  -99.913664  -99.769719  -99.912712  -99.767744]
 [ -99.774046  -99.834615  -99.855661  -99.777242  -99.895443]
 [ -99.93394   -99.922439  -99.784915  -99.75319   -99.855427]
 [ -99.864935  -99.823712  -99.825223  -99.779535  -99.89793 ]
 [ -99.835373  -99.926123  -99.797068  -99.791224  -99.806895]
 [ -99.819849  -99.902965  -99.828955  -99.78482   -99.674768]
 [ -99.785227  -99.73392   -99.813952  -99.836287  -99.837493]
 [ -99.853518  -99.778272  -99.923503  -99.919641  -99.791893]
 [ -99.845802  -99.802369  -99.858321  -99.869097  -99.757175]
 [ -99.832215  -99.864492  -99.780979  -99.980818  -99.930422]
 [ -99.799058  -99.867615  -99.783936  -99.870304  -99.768367]
 [ -99.745239  -99.739983  -99.771068  -99.824773  -99.760653]
 [ -99.857087  -99.817179  -99.809481  -99.865572  -99.746694]
 [ -99.780595  -99.944332  -99.848584  -99.768482  -99.913768]
 [ -99.680262  -99.718512  -99.790116  -99.844963  -99.884071]
 [ -99.88166   -99.831507  -99.835447  -99.779504  -99.665376]
 [ -99.877483  -99.830302  -99.789936  -99.892074  -99.839993]
 [ -99.792586  -99.821708  -99.892086  -99.801912  -99.838229]
 [ -99.812784  -99.813256  -99.859375  -99.921968  -99.795987]
 [ -99.79771   -99.796152  -99.720234  -99.818169  -99.936633]
 [ -99.762851  -99.779964  -99.857854  -99.844597  -99.805456]
 [ -99.837739  -99.850584  -99.835135  -99.844999  -99.875789]
 [ -99.774012  -99.853458  -99.861979  -99.79746   -99.788951]
 [ -99.780714  -99.84494   -99.799011  -99.803918  -99.882729]
 [ -99.86134   -99.832422  -99.917691  -99.789238  -99.900958]
 [ -99.830731  -99.908451  -99.855961  -99.770281  -99.899905]
 [ -99.889663  -99.884087  -99.903901  -99.801886  -99.842462]
 [ -99.787265  -99.83033   -99.947801  -99.841913  -99.728126]
 [ -99.911945  -99.761279  -99.732887  -99.873926  -99.83794 ]
 [ -99.76879   -99.856199  -99.737657  -99.803548  -99.92917 ]
 [ -99.851439  -99.877504  -99.825437  -99.814563  -99.78818 ]
 [ -99.921686  -99.807515  -99.794498  -99.80775   -99.917078]
 [ -99.90961   -99.778213  -99.842064  -99.909759  -99.807629]
 [ -99.839826  -99.798155  -99.918711  -99.84064   -99.884036]
 [ -99.807426  -99.765873  -99.944184  -99.784946  -99.857605]
 [ -99.811614  -99.818151  -99.893832  -99.82503   -99.78243 ]
 [ -99.834919  -99.749333  -99.918699  -99.82141   -99.734852]
 [ -99.822113  -99.892953  -99.902226  -99.828826  -99.864705]
 [ -99.794751  -99.80922   -99.855514  -99.836814  -99.912806]
 [ -99.731302  -99.899107  -99.759543  -99.877399  -99.972349]
 [ -99.845102  -99.883468  -99.808758  -99.816147  -99.813703]
 [ -99.90367   -99.73416   -99.890399  -99.765541  -99.724813]
 [ -99.903175  -99.846613  -99.820083  -99.931063  -99.893142]
 [ -99.7934    -99.790449  -99.973497  -99.865986  -99.865848]
 [ -99.906964  -99.83136   -99.886793  -99.798154  -99.910298]
 [ -99.875685  -99.86234   -99.842246  -99.842578  -99.842849]
 [ -99.826919  -99.875459  -99.895855  -99.87366   -99.872854]
 [ -99.888804  -99.792274  -99.787151  -99.799238  -99.883728]
 [ -99.864849  -99.800086  -99.87729   -99.925819  -99.875527]
 [ -99.852852  -99.812545  -99.808007  -99.885374  -99.865515]
 [ -99.86356   -99.80284   -99.757468  -99.839908  -99.803069]
 [ -99.886325  -99.826231  -99.803553  -99.858841  -99.861233]
 [ -99.920637  -99.919369  -99.892297  -99.900995  -99.923581]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3592 3601 3601]
 [3595 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3582 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3590 3601 3601 3601 3601]
 [3601 3601 3593 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3597 3598]
 [3585 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3585 3601 3595 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3593 3601 3601 3601 3601]
 [3578 3601 3601 3594 3601]
 [3598 3601 3601 3601 3601]
 [3585 3601 3601 3601 3601]
 [3601 3598 3596 3601 3601]
 [3591 3601 3601 3601 3598]
 [3598 3601 3601 3601 3601]
 [3577 3601 3601 3601 3601]
 [3597 3601 3601 3594 3601]
 [3586 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3583 3594 3601 3601 3601]
 [3597 3601 3601 3601 3594]
 [3583 3601 3601 3601 3601]
 [3593 3601 3601 3601 3601]
 [3583 3601 3598 3599 3601]
 [3598 3601 3601 3601 3601]
 [3589 3601 3601 3601 3601]
 [3597 3593 3601 3601 3601]
 [3586 3601 3601 3601 3592]
 [3597 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3597 3601 3593 3601 3601]
 [3592 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3585 3596 3601 3601 3601]
 [3600 3601 3601 3601 3599]
 [3584 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3592 3601 3594 3601 3601]
 [3601 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3591 3601 3601 3601 3601]
 [3587 3601 3601 3597 3601]
 [3601 3601 3601 3601 3601]
 [3592 3601 3601 3601 3601]
 [3601 3597 3599 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3598 3597]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3578 3598]
 [3601 3601 3598 3601 3601]
 [3598 3601 3601 3601 3601]
 [3593 3601 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3601 3597 3600]
 [3601 3596 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3598 3583]
 [3601 3601 3601 3601 3595]
 [3593 3601 3598 3598 3601]
 [3601 3601 3597 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3583 3599 3597 3601]
 [3601 3597 3582 3601 3601]
 [3601 3601 3601 3601 3597]
 [3601 3599 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3597 3601 3598 3601 3601]
 [3597 3601 3601 3597 3601]
 [3601 3601 3601 3601 3601]
 [3599 3583 3601 3597 3601]
 [3601 3601 3601 3601 3601]
 [3576 3601 3601 3601 3597]
 [3601 3582 3601 3598 3601]
 [3601 3601 3601 3601 3580]
 [3601 3601 3598 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3601 3583 3601 3598]
 [3598 3601 3601 3601 3601]
 [3584 3601 3601 3598 3601]
 [3601 3601 3593 3581 3601]
 [3601 3601 3601 3580 3601]
 [3580 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-24_14-30-15_llm_triton_qwen_14b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-24_14-30-15_llm_triton_qwen_14b_binary_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/model
