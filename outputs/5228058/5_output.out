####################
/var/spool/slurmd/job5228058/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_32B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_1_example_explanation.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-02-02_18-32-35_llm_triton_qwen_32b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the movement of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0. You have to output the following calculations:
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 1
 
 Explanation (Do not generate this in your output): The score is 1 since the particle started at (17.25, -160.50) and ended at (16.50, -159.75), while the goal was at (5.75, -57.00). The distance to the goal at starting position was 104.13 while the distance at ending position was 103.31. Since, 103.31 < 104.13, the particle moved closer to the goal. Therefore, the particle moved closer to the goal.
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 7    |
|    iterations      | 1    |
|    time_elapsed    | 270  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.8e+03     |
|    ep_rew_mean          | 854         |
| time/                   |             |
|    fps                  | 7           |
|    iterations           | 2           |
|    time_elapsed         | 534         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.010045636 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0811     |
|    learning_rate        | 0.0003      |
|    loss                 | 10.4        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.998       |
|    value_loss           | 22.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.81e+03    |
|    ep_rew_mean          | 871         |
| time/                   |             |
|    fps                  | 7           |
|    iterations           | 3           |
|    time_elapsed         | 796         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.013012901 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.403      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.67        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.997       |
|    value_loss           | 19.3        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.81e+03     |
|    ep_rew_mean          | 871          |
| time/                   |              |
|    fps                  | 7            |
|    iterations           | 4            |
|    time_elapsed         | 1056         |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0090132095 |
|    clip_fraction        | 0.0942       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.187       |
|    learning_rate        | 0.0003       |
|    loss                 | 4.85         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0197      |
|    std                  | 0.995        |
|    value_loss           | 16.4         |
------------------------------------------
Eval num_timesteps=10000, episode_reward=-99.43 +/- 0.13
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.007509413 |
|    clip_fraction        | 0.0688      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0553     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.42        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.994       |
|    value_loss           | 16.7        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 668      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 3118     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | 668          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 6            |
|    time_elapsed         | 3379         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0015814106 |
|    clip_fraction        | 0.00146      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.000146     |
|    learning_rate        | 0.0003       |
|    loss                 | 18.2         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00427     |
|    std                  | 0.994        |
|    value_loss           | 1.04e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.56e+03     |
|    ep_rew_mean          | 723          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 7            |
|    time_elapsed         | 3639         |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0069437646 |
|    clip_fraction        | 0.0422       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.0602       |
|    learning_rate        | 0.0003       |
|    loss                 | 3.95         |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.0142      |
|    std                  | 0.994        |
|    value_loss           | 13.1         |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.61e+03   |
|    ep_rew_mean          | 761        |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 8          |
|    time_elapsed         | 3900       |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.00822651 |
|    clip_fraction        | 0.0534     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | -0.111     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.92       |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.994      |
|    value_loss           | 11.6       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.61e+03    |
|    ep_rew_mean          | 761         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 9           |
|    time_elapsed         | 4161        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.008886024 |
|    clip_fraction        | 0.0549      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.408      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.38        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.993       |
|    value_loss           | 9.48        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.31 +/- 0.10
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.010605019 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.328      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.994       |
|    value_loss           | 6.07        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 694      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 6223     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | 694          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 6483         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0024131085 |
|    clip_fraction        | 0.00239      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00544     |
|    learning_rate        | 0.0003       |
|    loss                 | 12.8         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00329     |
|    std                  | 0.993        |
|    value_loss           | 1.04e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.54e+03     |
|    ep_rew_mean          | 723          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 12           |
|    time_elapsed         | 6743         |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0111548565 |
|    clip_fraction        | 0.125        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -1.19        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.64         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0211      |
|    std                  | 0.994        |
|    value_loss           | 5.34         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.57e+03    |
|    ep_rew_mean          | 746         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 7003        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.011104725 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.527      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.994       |
|    value_loss           | 4.45        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.59e+03    |
|    ep_rew_mean          | 767         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 7264        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.013644281 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.213      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.77        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.99        |
|    value_loss           | 3.25        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.28 +/- 0.21
Episode length: 3591.60 +/- 18.30
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.017469075 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0996     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.63        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.993       |
|    value_loss           | 3.02        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 707      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 9330     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 707         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 9593        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.006865451 |
|    clip_fraction        | 0.0361      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.00103     |
|    learning_rate        | 0.0003      |
|    loss                 | 299         |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00601    |
|    std                  | 0.992       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 731         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 9854        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.018849272 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -2.08       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.986       |
|    value_loss           | 2.99        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.55e+03    |
|    ep_rew_mean          | 755         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 10115       |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.020624407 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0179     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.29        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0232     |
|    std                  | 0.981       |
|    value_loss           | 2.65        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.56e+03    |
|    ep_rew_mean          | 772         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 10376       |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.018983651 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0231      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.97        |
|    value_loss           | 2.43        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-98.78 +/- 0.37
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.8      |
| time/                   |            |
|    total_timesteps      | 40000      |
| train/                  |            |
|    approx_kl            | 0.01715687 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.00631    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.29       |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.0234    |
|    std                  | 0.964      |
|    value_loss           | 2.76       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 729      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 12437    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.52e+03     |
|    ep_rew_mean          | 748          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 12698        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0071494523 |
|    clip_fraction        | 0.0728       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -7.1e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 756          |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00684     |
|    std                  | 0.963        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 748         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 12959       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.018611267 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -2.04       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.65        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.958       |
|    value_loss           | 3.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | 770         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 13228       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.025667883 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.00611    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0239     |
|    std                  | 0.953       |
|    value_loss           | 2.6         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.55e+03   |
|    ep_rew_mean          | 787        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 24         |
|    time_elapsed         | 13492      |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.02206922 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.00431   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15       |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0297    |
|    std                  | 0.952      |
|    value_loss           | 2.5        |
----------------------------------------
Eval num_timesteps=50000, episode_reward=-98.32 +/- 0.43
Episode length: 3596.40 +/- 6.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.3       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.021667365 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0316     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0261     |
|    std                  | 0.947       |
|    value_loss           | 3.5         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 756      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 15562    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 775         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 15826       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.008427424 |
|    clip_fraction        | 0.0978      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.00182     |
|    learning_rate        | 0.0003      |
|    loss                 | 19.3        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00854    |
|    std                  | 0.947       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 775         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 16087       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.023793608 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -1.04       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.69        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0268     |
|    std                  | 0.942       |
|    value_loss           | 3.62        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 795       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 28        |
|    time_elapsed         | 16348     |
|    total_timesteps      | 57344     |
| train/                  |           |
|    approx_kl            | 0.0224077 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.8     |
|    explained_variance   | -0.00128  |
|    learning_rate        | 0.0003    |
|    loss                 | 1.37      |
|    n_updates            | 270       |
|    policy_gradient_loss | -0.0301   |
|    std                  | 0.938     |
|    value_loss           | 3.18      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.54e+03   |
|    ep_rew_mean          | 816        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 29         |
|    time_elapsed         | 16609      |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 0.03174672 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.0552    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01       |
|    n_updates            | 280        |
|    policy_gradient_loss | -0.034     |
|    std                  | 0.93       |
|    value_loss           | 2.53       |
----------------------------------------
Eval num_timesteps=60000, episode_reward=76.45 +/- 14.36
Episode length: 3598.80 +/- 2.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 76.5        |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.026947815 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.046       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.63        |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0334     |
|    std                  | 0.928       |
|    value_loss           | 2.85        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 792      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 18677    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.46e+03    |
|    ep_rew_mean          | 829         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 18939       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.010645027 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000605   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.1         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.927       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.44e+03    |
|    ep_rew_mean          | 874         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 19201       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.024152935 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.00163     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0265     |
|    std                  | 0.921       |
|    value_loss           | 468         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.46e+03    |
|    ep_rew_mean          | 894         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 19462       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.029192483 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00549    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0225     |
|    std                  | 0.915       |
|    value_loss           | 459         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.47e+03    |
|    ep_rew_mean          | 916         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 19724       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.024286631 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0212     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0297     |
|    std                  | 0.911       |
|    value_loss           | 3.69        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=184.01 +/- 6.37
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 184        |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.02440133 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.0138     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.43       |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0339    |
|    std                  | 0.905      |
|    value_loss           | 5.07       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.31e+03 |
|    ep_rew_mean     | 919      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 21792    |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.31e+03     |
|    ep_rew_mean          | 919          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 36           |
|    time_elapsed         | 22057        |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0066319145 |
|    clip_fraction        | 0.0528       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.5        |
|    explained_variance   | 0.000257     |
|    learning_rate        | 0.0003       |
|    loss                 | 531          |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00411     |
|    std                  | 0.905        |
|    value_loss           | 8.84e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.31e+03    |
|    ep_rew_mean          | 963         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 22319       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.025458168 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.712      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8         |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0319     |
|    std                  | 0.903       |
|    value_loss           | 4.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.31e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 22581       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.011717966 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000172    |
|    learning_rate        | 0.0003      |
|    loss                 | 169         |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.00917    |
|    std                  | 0.903       |
|    value_loss           | 3.88e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.33e+03    |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 22842       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.016539572 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00125     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.69e+03    |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.903       |
|    value_loss           | 3.8e+03     |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=981.61 +/- 331.73
Episode length: 1879.80 +/- 1184.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1.88e+03    |
|    mean_reward          | 982         |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.023303906 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.686      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83        |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.898       |
|    value_loss           | 4.77        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.29e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 24044    |
|    total_timesteps | 81920    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.3e+03    |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 41         |
|    time_elapsed         | 24305      |
|    total_timesteps      | 83968      |
| train/                  |            |
|    approx_kl            | 0.01640835 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.000846   |
|    learning_rate        | 0.0003     |
|    loss                 | 57.4       |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.894      |
|    value_loss           | 289        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.32e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 42         |
|    time_elapsed         | 24566      |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.02308163 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.0167    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.55       |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0324    |
|    std                  | 0.89       |
|    value_loss           | 4.43       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.32e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 43         |
|    time_elapsed         | 24827      |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.02399699 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.015     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.29       |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0341    |
|    std                  | 0.885      |
|    value_loss           | 4.86       |
----------------------------------------
Eval num_timesteps=90000, episode_reward=1264.54 +/- 119.92
Episode length: 1415.20 +/- 669.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1.42e+03    |
|    mean_reward          | 1.26e+03    |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.022813922 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00494     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.61        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0379     |
|    std                  | 0.882       |
|    value_loss           | 5.15        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.31e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25803    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.31e+03    |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 26066       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.011473458 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00219    |
|    learning_rate        | 0.0003      |
|    loss                 | 9.85        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.881       |
|    value_loss           | 3.83e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.29e+03    |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 26326       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.027623702 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0901     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.97        |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0377     |
|    std                  | 0.871       |
|    value_loss           | 5.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.27e+03    |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 26588       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.011688992 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.000265    |
|    learning_rate        | 0.0003      |
|    loss                 | 962         |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00652    |
|    std                  | 0.87        |
|    value_loss           | 3.72e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.23e+03    |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26848       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.012823373 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000805   |
|    learning_rate        | 0.0003      |
|    loss                 | 834         |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.866       |
|    value_loss           | 3.69e+03    |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=1095.11 +/- 30.24
Episode length: 439.80 +/- 184.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 440         |
|    mean_reward          | 1.1e+03     |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.008463503 |
|    clip_fraction        | 0.0777      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00224    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.89e+03    |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00987    |
|    std                  | 0.865       |
|    value_loss           | 7.29e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.21e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 27329    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.16e+03    |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 27589       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.013242399 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000315   |
|    learning_rate        | 0.0003      |
|    loss                 | 50.6        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.864       |
|    value_loss           | 3.63e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.16e+03    |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 27851       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.011017462 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00113     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.17e+03    |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.862       |
|    value_loss           | 7.18e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.08e+03    |
|    ep_rew_mean          | 1.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28112       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.034109622 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.146      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.23        |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0302     |
|    std                  | 0.855       |
|    value_loss           | 5.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | 1.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28373       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.008190403 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.000551    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.26e+03    |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00721    |
|    std                  | 0.854       |
|    value_loss           | 1.06e+04    |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=1044.48 +/- 38.53
Episode length: 164.60 +/- 137.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 165         |
|    mean_reward          | 1.04e+03    |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.022059845 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0125     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.66        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.85        |
|    value_loss           | 781         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.04e+03 |
|    ep_rew_mean     | 1.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 28717    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.96e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 28978       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.010605733 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.000211   |
|    learning_rate        | 0.0003      |
|    loss                 | 17.6        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00892    |
|    std                  | 0.849       |
|    value_loss           | 1.24e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.93e+03   |
|    ep_rew_mean          | 1.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 56         |
|    time_elapsed         | 29239      |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.01211128 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.00175    |
|    learning_rate        | 0.0003     |
|    loss                 | 6.54e+03   |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.849      |
|    value_loss           | 7.4e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.94e+03    |
|    ep_rew_mean          | 1.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 29504       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.008366214 |
|    clip_fraction        | 0.0733      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.001       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.37e+03    |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.849       |
|    value_loss           | 6.92e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.89e+03    |
|    ep_rew_mean          | 1.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 29765       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.010088557 |
|    clip_fraction        | 0.0935      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.00169     |
|    learning_rate        | 0.0003      |
|    loss                 | 118         |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.848       |
|    value_loss           | 3.46e+03    |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=1014.31 +/- 4.84
Episode length: 43.80 +/- 25.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 43.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.009409683 |
|    clip_fraction        | 0.0905      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -8.95e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 9.72e+03    |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.847       |
|    value_loss           | 6.86e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.87e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 59       |
|    time_elapsed    | 30048    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.84e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 60          |
|    time_elapsed         | 30313       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.011944976 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.00261    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.51e+03    |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.846       |
|    value_loss           | 6.81e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.84e+03    |
|    ep_rew_mean          | 1.39e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 61          |
|    time_elapsed         | 30577       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.010164312 |
|    clip_fraction        | 0.0933      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | 0.000495    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.51e+03    |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.844       |
|    value_loss           | 6.72e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.78e+03    |
|    ep_rew_mean          | 1.4e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 62          |
|    time_elapsed         | 30838       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.012978931 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.00428     |
|    learning_rate        | 0.0003      |
|    loss                 | 129         |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.842       |
|    value_loss           | 3.41e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.76e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 63          |
|    time_elapsed         | 31099       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.010038266 |
|    clip_fraction        | 0.0779      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.00115     |
|    learning_rate        | 0.0003      |
|    loss                 | 687         |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.841       |
|    value_loss           | 1.04e+04    |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=1022.82 +/- 11.45
Episode length: 60.20 +/- 32.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 60.2        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.012629724 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.00207     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73e+04    |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.838       |
|    value_loss           | 6.65e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.69e+03 |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 64       |
|    time_elapsed    | 31391    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.6e+03     |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 65          |
|    time_elapsed         | 31661       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.010462118 |
|    clip_fraction        | 0.086       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.00335     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+04     |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.836       |
|    value_loss           | 1.31e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.56e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 66          |
|    time_elapsed         | 31925       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.011652548 |
|    clip_fraction        | 0.0918      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.00225     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.69e+03    |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.835       |
|    value_loss           | 1.92e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.49e+03    |
|    ep_rew_mean          | 1.4e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 67          |
|    time_elapsed         | 32187       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.019860867 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -0.000578   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+03    |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.834       |
|    value_loss           | 6.83e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.47e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 68          |
|    time_elapsed         | 32448       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.011148555 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -0.000398   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.22e+03    |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.832       |
|    value_loss           | 1.87e+04    |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=1013.54 +/- 5.23
Episode length: 31.40 +/- 16.01
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 31.4         |
|    mean_reward          | 1.01e+03     |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0145755485 |
|    clip_fraction        | 0.158        |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.85        |
|    explained_variance   | -0.000572    |
|    learning_rate        | 0.0003       |
|    loss                 | 5.18e+03     |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.0177      |
|    std                  | 0.829        |
|    value_loss           | 6.32e+03     |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.47e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 69       |
|    time_elapsed    | 32726    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.45e+03    |
|    ep_rew_mean          | 1.43e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 70          |
|    time_elapsed         | 32987       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.018521477 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | 0.00142     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.09e+03    |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.827       |
|    value_loss           | 6.32e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.39e+03    |
|    ep_rew_mean          | 1.44e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 71          |
|    time_elapsed         | 33248       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.019214302 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | -0.0015     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04e+04    |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.826       |
|    value_loss           | 6.68e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.34e+03    |
|    ep_rew_mean          | 1.47e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 72          |
|    time_elapsed         | 33511       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.018683149 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -0.00389    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.97e+03    |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.825       |
|    value_loss           | 9.41e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.31e+03    |
|    ep_rew_mean          | 1.49e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 73          |
|    time_elapsed         | 33772       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.016373504 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.00402    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.01e+03    |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.822       |
|    value_loss           | 9.36e+03    |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=1011.15 +/- 1.33
Episode length: 32.60 +/- 13.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 32.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.02202585 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.75      |
|    explained_variance   | 0.00176    |
|    learning_rate        | 0.0003     |
|    loss                 | 883        |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.82       |
|    value_loss           | 6.27e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.25e+03 |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 74       |
|    time_elapsed    | 34050    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.11e+03    |
|    ep_rew_mean          | 1.55e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 75          |
|    time_elapsed         | 34312       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.015321289 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | 0.00412     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24e+03    |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.818       |
|    value_loss           | 9.31e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.02e+03   |
|    ep_rew_mean          | 1.56e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 76         |
|    time_elapsed         | 34574      |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.01822533 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.71      |
|    explained_variance   | 0.00381    |
|    learning_rate        | 0.0003     |
|    loss                 | 7.91e+03   |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.815      |
|    value_loss           | 2.1e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 958        |
|    ep_rew_mean          | 1.58e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 77         |
|    time_elapsed         | 34836      |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.01896187 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.68      |
|    explained_variance   | 0.00112    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.11e+04   |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.812      |
|    value_loss           | 1.19e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 885         |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 78          |
|    time_elapsed         | 35098       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.019711822 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | 0.00276     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.88e+03    |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0189     |
|    std                  | 0.807       |
|    value_loss           | 1.19e+04    |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=1014.32 +/- 3.86
Episode length: 34.00 +/- 10.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.019032001 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | 0.00445     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23e+04    |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.803       |
|    value_loss           | 1.24e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 689      |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 79       |
|    time_elapsed    | 35377    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 619         |
|    ep_rew_mean          | 1.49e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 80          |
|    time_elapsed         | 35645       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.010937225 |
|    clip_fraction        | 0.0912      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.00231     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.47e+04    |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.802       |
|    value_loss           | 2.83e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 588         |
|    ep_rew_mean          | 1.47e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 81          |
|    time_elapsed         | 35910       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.022438057 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 0.00183     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.21e+03    |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0252     |
|    std                  | 0.796       |
|    value_loss           | 1.77e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 557         |
|    ep_rew_mean          | 1.45e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 82          |
|    time_elapsed         | 36172       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.019105125 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | -0.0019     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.33e+03    |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.789       |
|    value_loss           | 1.17e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 534         |
|    ep_rew_mean          | 1.44e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 83          |
|    time_elapsed         | 36435       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.018518299 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -0.000934   |
|    learning_rate        | 0.0003      |
|    loss                 | 8e+03       |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.787       |
|    value_loss           | 1.4e+04     |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=1015.85 +/- 6.82
Episode length: 36.40 +/- 18.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 36.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.023793481 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | -0.00132    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.86e+03    |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.784       |
|    value_loss           | 8.48e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 458      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 84       |
|    time_elapsed    | 36715    |
|    total_timesteps | 172032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 429        |
|    ep_rew_mean          | 1.36e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 85         |
|    time_elapsed         | 36977      |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.02208591 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.37      |
|    explained_variance   | 0.0044     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.51e+04   |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.78       |
|    value_loss           | 2.72e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 422         |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 86          |
|    time_elapsed         | 37239       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.020837834 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | 0.000947    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.26e+03    |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.777       |
|    value_loss           | 2.13e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 409         |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 87          |
|    time_elapsed         | 37503       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.020853918 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | -0.00252    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+04    |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.772       |
|    value_loss           | 1.32e+04    |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=1014.60 +/- 5.93
Episode length: 31.60 +/- 12.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.02148606 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.25      |
|    explained_variance   | -0.0318    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.91e+03   |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.77       |
|    value_loss           | 1.34e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 384      |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 88       |
|    time_elapsed    | 37781    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 325         |
|    ep_rew_mean          | 1.28e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 89          |
|    time_elapsed         | 38043       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.022692185 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.0075      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15e+04    |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.767       |
|    value_loss           | 2.37e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 310         |
|    ep_rew_mean          | 1.27e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 90          |
|    time_elapsed         | 38306       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.022670586 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | 0.00411     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.36e+04    |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.763       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 315         |
|    ep_rew_mean          | 1.28e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 91          |
|    time_elapsed         | 38568       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.041928954 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -0.000817   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28e+04    |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.762       |
|    value_loss           | 1.73e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 290         |
|    ep_rew_mean          | 1.26e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 92          |
|    time_elapsed         | 38830       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.033858187 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.00284     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+04    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.761       |
|    value_loss           | 1.51e+04    |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=1017.32 +/- 5.27
Episode length: 41.60 +/- 7.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.027111944 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | 0.00689     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.44e+03    |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.758       |
|    value_loss           | 2.22e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 284      |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 93       |
|    time_elapsed    | 39113    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 270         |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 94          |
|    time_elapsed         | 39376       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.020286735 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | -0.00304    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57e+04    |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.757       |
|    value_loss           | 2.9e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 246         |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 95          |
|    time_elapsed         | 39642       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.026624681 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -0.0199     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.66e+03    |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00582    |
|    std                  | 0.754       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 246         |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 96          |
|    time_elapsed         | 39907       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.022893663 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.00326     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.63e+03    |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.751       |
|    value_loss           | 1.96e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 240         |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 97          |
|    time_elapsed         | 40170       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.022409884 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | 0.00314     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44e+04    |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0261     |
|    std                  | 0.745       |
|    value_loss           | 2.12e+04    |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=1014.75 +/- 4.60
Episode length: 31.40 +/- 11.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.02702879 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | 0.000744   |
|    learning_rate        | 0.0003     |
|    loss                 | 9.66e+03   |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.743      |
|    value_loss           | 1.65e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 223      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 98       |
|    time_elapsed    | 40449    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 216         |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 99          |
|    time_elapsed         | 40712       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.018507889 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | 0.00881     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17e+04    |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.742       |
|    value_loss           | 3.18e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 200         |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 100         |
|    time_elapsed         | 40975       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.020837326 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.0075      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.58e+04    |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0243     |
|    std                  | 0.738       |
|    value_loss           | 2.68e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 185        |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 101        |
|    time_elapsed         | 41238      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.02153325 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.88      |
|    explained_variance   | 0.0142     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47e+04   |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.735      |
|    value_loss           | 3.07e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 192         |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 102         |
|    time_elapsed         | 41502       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.027394585 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.00679     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.5e+03     |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.733       |
|    value_loss           | 2.59e+04    |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=1019.25 +/- 7.09
Episode length: 50.40 +/- 22.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 50.4       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.02395278 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.83      |
|    explained_variance   | 0.00843    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.91e+04   |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.73       |
|    value_loss           | 2.15e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 184      |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 103      |
|    time_elapsed    | 41791    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 180         |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 104         |
|    time_elapsed         | 42054       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.023231816 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.00548     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+04    |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.727       |
|    value_loss           | 2.73e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 172         |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 105         |
|    time_elapsed         | 42316       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.035309788 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | -0.0259     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.47e+04    |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.725       |
|    value_loss           | 2.5e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 160         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 106         |
|    time_elapsed         | 42578       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.025254313 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | 0.00421     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14e+04    |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.721       |
|    value_loss           | 2.47e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 158         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 107         |
|    time_elapsed         | 42842       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.020570774 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.00729     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32e+04    |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 0.716       |
|    value_loss           | 2.78e+04    |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=1014.16 +/- 3.72
Episode length: 31.80 +/- 7.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.022671731 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.00601     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+04    |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.711       |
|    value_loss           | 2.8e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 164      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 108      |
|    time_elapsed    | 43120    |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 160       |
|    ep_rew_mean          | 1.15e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 109       |
|    time_elapsed         | 43389     |
|    total_timesteps      | 223232    |
| train/                  |           |
|    approx_kl            | 0.0280581 |
|    clip_fraction        | 0.273     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.56     |
|    explained_variance   | 0.00523   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.08e+04  |
|    n_updates            | 1080      |
|    policy_gradient_loss | -0.0223   |
|    std                  | 0.705     |
|    value_loss           | 2.56e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 159         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 110         |
|    time_elapsed         | 43653       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.031227361 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | 0.0072      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17e+04    |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.701       |
|    value_loss           | 2.7e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 151        |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 111        |
|    time_elapsed         | 43917      |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.02415927 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.47      |
|    explained_variance   | 0.00781    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.16e+03   |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.699      |
|    value_loss           | 1.97e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 141         |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 112         |
|    time_elapsed         | 44180       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.018734798 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.44       |
|    explained_variance   | 0.00787     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+04    |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.696       |
|    value_loss           | 3.18e+04    |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=1014.76 +/- 4.97
Episode length: 32.40 +/- 8.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.017608244 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.00489     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04e+04    |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.693       |
|    value_loss           | 3.5e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 113      |
|    time_elapsed    | 44459    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 122         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 114         |
|    time_elapsed         | 44723       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.022094572 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.38       |
|    explained_variance   | 0.0042      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.75e+04    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.692       |
|    value_loss           | 3.65e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 115       |
|    ep_rew_mean          | 1.11e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 115       |
|    time_elapsed         | 44986     |
|    total_timesteps      | 235520    |
| train/                  |           |
|    approx_kl            | 0.0403068 |
|    clip_fraction        | 0.265     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.36     |
|    explained_variance   | -0.000613 |
|    learning_rate        | 0.0003    |
|    loss                 | 2.79e+04  |
|    n_updates            | 1140      |
|    policy_gradient_loss | -0.0192   |
|    std                  | 0.689     |
|    value_loss           | 3.38e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 114         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 116         |
|    time_elapsed         | 45250       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.032241516 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | 0.00299     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.36e+04    |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.684       |
|    value_loss           | 2.67e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 111         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 117         |
|    time_elapsed         | 45514       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.115882605 |
|    clip_fraction        | 0.552       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.00871     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+04    |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.0438      |
|    std                  | 0.684       |
|    value_loss           | 2.78e+04    |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=1010.77 +/- 0.41
Episode length: 24.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.01753749 |
|    clip_fraction        | 0.136      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | 0.0113     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.32e+04   |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.682      |
|    value_loss           | 3.74e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 117      |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 118      |
|    time_elapsed    | 45790    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 119         |
|    time_elapsed         | 46054       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.024196804 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.23       |
|    explained_variance   | 0.0089      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.6e+03     |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.677       |
|    value_loss           | 2.13e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 120         |
|    time_elapsed         | 46317       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.017506294 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.0174      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.9e+03     |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 0.675       |
|    value_loss           | 3.47e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 114         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 121         |
|    time_elapsed         | 46581       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.024012841 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | 0.00413     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.51e+03    |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 0.67        |
|    value_loss           | 2.51e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 111         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 122         |
|    time_elapsed         | 46844       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.022624038 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | 0.000672    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.3e+04     |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.668       |
|    value_loss           | 3.51e+04    |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=1011.49 +/- 1.61
Episode length: 26.80 +/- 5.67
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.02418964 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.0142     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72e+04   |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.665      |
|    value_loss           | 2.87e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 101      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 5        |
|    iterations      | 123      |
|    time_elapsed    | 47121    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 101         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 124         |
|    time_elapsed         | 47391       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.022428446 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | 0.0132      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.45e+04    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.663       |
|    value_loss           | 3.26e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 92.3       |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 125        |
|    time_elapsed         | 47657      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.02613019 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.01      |
|    explained_variance   | 0.0101     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.07e+04   |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.0261    |
|    std                  | 0.659      |
|    value_loss           | 3.47e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 92.6       |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 126        |
|    time_elapsed         | 47921      |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.02576522 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.0169     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36e+04   |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.659      |
|    value_loss           | 3.03e+04   |
----------------------------------------
Eval num_timesteps=260000, episode_reward=1017.21 +/- 11.20
Episode length: 38.60 +/- 24.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 38.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.021352565 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.97       |
|    explained_variance   | 0.00582     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.13e+04    |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.656       |
|    value_loss           | 3.29e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 96.5     |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 5        |
|    iterations      | 127      |
|    time_elapsed    | 48205    |
|    total_timesteps | 260096   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 91.2      |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 128       |
|    time_elapsed         | 48469     |
|    total_timesteps      | 262144    |
| train/                  |           |
|    approx_kl            | 0.0318774 |
|    clip_fraction        | 0.26      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.93     |
|    explained_variance   | 0.00959   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.07e+04  |
|    n_updates            | 1270      |
|    policy_gradient_loss | -0.0247   |
|    std                  | 0.652     |
|    value_loss           | 2.8e+04   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 84.9       |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 129        |
|    time_elapsed         | 48734      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.02662938 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.0242     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.54e+04   |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.648      |
|    value_loss           | 3.85e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 88.7        |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 130         |
|    time_elapsed         | 48997       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.039652552 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | 0.0172      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.64e+04    |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.644       |
|    value_loss           | 3.87e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 79.3        |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 131         |
|    time_elapsed         | 49263       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.048762023 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | 0.0104      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.84e+03    |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.642       |
|    value_loss           | 2.28e+04    |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=1012.84 +/- 3.99
Episode length: 30.20 +/- 5.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.016122453 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | 0.0132      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.87e+04    |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.638       |
|    value_loss           | 3.78e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 84.9     |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 132      |
|    time_elapsed    | 49542    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85.7        |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 133         |
|    time_elapsed         | 49807       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.025321394 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.69       |
|    explained_variance   | 0.0151      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.75e+04    |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.632       |
|    value_loss           | 2.68e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78.8        |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 134         |
|    time_elapsed         | 50071       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.021384526 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.64       |
|    explained_variance   | 0.0398      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.92e+04    |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.024      |
|    std                  | 0.63        |
|    value_loss           | 3.67e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 83        |
|    ep_rew_mean          | 1.08e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 135       |
|    time_elapsed         | 50336     |
|    total_timesteps      | 276480    |
| train/                  |           |
|    approx_kl            | 0.0471625 |
|    clip_fraction        | 0.202     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.62     |
|    explained_variance   | 0.0171    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.61e+04  |
|    n_updates            | 1340      |
|    policy_gradient_loss | -0.0197   |
|    std                  | 0.63      |
|    value_loss           | 3.46e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 79.9        |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 136         |
|    time_elapsed         | 50600       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.022016445 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | 0.017       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11e+04    |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.626       |
|    value_loss           | 2.94e+04    |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=1012.91 +/- 1.41
Episode length: 33.80 +/- 2.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 33.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.022483572 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | 0.0162      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83e+04    |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.622       |
|    value_loss           | 3.03e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 77.3     |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 137      |
|    time_elapsed    | 50881    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 76.4        |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 138         |
|    time_elapsed         | 51152       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.031147778 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | 0.0244      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.63e+04    |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.621       |
|    value_loss           | 4.01e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 70.8       |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 139        |
|    time_elapsed         | 51417      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.02872126 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.48      |
|    explained_variance   | 0.0176     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.16e+04   |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.617      |
|    value_loss           | 3.16e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 66.5        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 140         |
|    time_elapsed         | 51682       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.025587318 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.0256      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+04    |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.616       |
|    value_loss           | 3.54e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 62.4      |
|    ep_rew_mean          | 1.07e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 141       |
|    time_elapsed         | 51949     |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0633672 |
|    clip_fraction        | 0.255     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.42     |
|    explained_variance   | 0.0164    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.34e+04  |
|    n_updates            | 1400      |
|    policy_gradient_loss | -0.0184   |
|    std                  | 0.614     |
|    value_loss           | 3.81e+04  |
---------------------------------------
Eval num_timesteps=290000, episode_reward=1013.79 +/- 3.90
Episode length: 31.60 +/- 10.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.07006501 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.0212     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.612      |
|    value_loss           | 3.7e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 61.1     |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 142      |
|    time_elapsed    | 52229    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 61.7        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 143         |
|    time_elapsed         | 52495       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.031087112 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | 0.0251      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.18e+04    |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0256     |
|    std                  | 0.61        |
|    value_loss           | 3.57e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 65         |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 144        |
|    time_elapsed         | 52760      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.01988791 |
|    clip_fraction        | 0.152      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | 0.0176     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.54e+04   |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.608      |
|    value_loss           | 3.47e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.4        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 145         |
|    time_elapsed         | 53027       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.049086094 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.27e+04    |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.606       |
|    value_loss           | 3.21e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.2        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 146         |
|    time_elapsed         | 53293       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.044434246 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | 0.0244      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.08e+04    |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.602       |
|    value_loss           | 4.05e+04    |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=1015.59 +/- 10.20
Episode length: 31.20 +/- 15.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.06883578 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.22      |
|    explained_variance   | 0.00336    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.33e+04   |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.599      |
|    value_loss           | 3.69e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 56.2     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 147      |
|    time_elapsed    | 53575    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 62.7        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 148         |
|    time_elapsed         | 53840       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.035137102 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | 0.00805     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+04     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.596       |
|    value_loss           | 3e+04       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 67.8        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 149         |
|    time_elapsed         | 54104       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.022896532 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.00816     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.18e+04    |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.595       |
|    value_loss           | 2.98e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 62         |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 150        |
|    time_elapsed         | 54370      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.04637726 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | 0.0156     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+04   |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.59       |
|    value_loss           | 2.65e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 54.4        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 151         |
|    time_elapsed         | 54636       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.031494603 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | 0.0509      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.97e+04    |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 0.587       |
|    value_loss           | 3.7e+04     |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=1017.16 +/- 5.23
Episode length: 39.20 +/- 10.05
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 39.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.04198701 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.04      |
|    explained_variance   | 0.0305     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.91e+04   |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.588      |
|    value_loss           | 3.78e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 49.6     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 152      |
|    time_elapsed    | 54922    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.3        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 153         |
|    time_elapsed         | 55194       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.038349155 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.04       |
|    explained_variance   | 0.0121      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6e+04     |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.586       |
|    value_loss           | 3.46e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.3        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 154         |
|    time_elapsed         | 55462       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.042365424 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.01       |
|    explained_variance   | 0.0214      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.86e+04    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.584       |
|    value_loss           | 3.56e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.3        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 155         |
|    time_elapsed         | 55729       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.040886223 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.00138     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.91e+04    |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.58        |
|    value_loss           | 3.4e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 54.1       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 156        |
|    time_elapsed         | 55995      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.03166166 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.0211     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.39e+03   |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.579      |
|    value_loss           | 3.3e+04    |
----------------------------------------
Eval num_timesteps=320000, episode_reward=1010.82 +/- 0.72
Episode length: 23.20 +/- 2.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.035152096 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.9        |
|    explained_variance   | 0.0101      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.4e+03     |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.576       |
|    value_loss           | 2.66e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 51.2     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 157      |
|    time_elapsed    | 56274    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 46.1        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 158         |
|    time_elapsed         | 56541       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.047919493 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.022       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.54e+04    |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.573       |
|    value_loss           | 3.47e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.9       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 159        |
|    time_elapsed         | 56807      |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.07690231 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | 0.017      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.59e+04   |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.572      |
|    value_loss           | 3.86e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 53.2        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 160         |
|    time_elapsed         | 57073       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.026599636 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.82       |
|    explained_variance   | 0.00199     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88e+04    |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 0.571       |
|    value_loss           | 2.78e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 51.8       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 161        |
|    time_elapsed         | 57340      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.06117484 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.8       |
|    explained_variance   | 0.0112     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+04   |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.57       |
|    value_loss           | 2.57e+04   |
----------------------------------------
Eval num_timesteps=330000, episode_reward=1015.59 +/- 5.30
Episode length: 31.20 +/- 9.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.04083346 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.8       |
|    explained_variance   | 0.0301     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.41e+04   |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.569      |
|    value_loss           | 3.29e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.7     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 162      |
|    time_elapsed    | 57624    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.1        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 163         |
|    time_elapsed         | 57890       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.070947364 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | 0.0158      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88e+04    |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.568       |
|    value_loss           | 3.39e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.6        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 164         |
|    time_elapsed         | 58158       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.039817274 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | 0.00459     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+04    |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.566       |
|    value_loss           | 2.99e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.3       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 165        |
|    time_elapsed         | 58425      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.02887067 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.73      |
|    explained_variance   | 0.0224     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.79e+04   |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.564      |
|    value_loss           | 3.4e+04    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.7        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 166         |
|    time_elapsed         | 58692       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.036039583 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.0174      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79e+04    |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.564       |
|    value_loss           | 3.08e+04    |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=1013.43 +/- 3.34
Episode length: 30.20 +/- 6.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.039309084 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 0.00795     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.14e+04    |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.562       |
|    value_loss           | 2.74e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 45       |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 167      |
|    time_elapsed    | 58979    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46         |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 168        |
|    time_elapsed         | 59247      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.07014174 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.0201     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.78e+04   |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.562      |
|    value_loss           | 3.17e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.6        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 169         |
|    time_elapsed         | 59513       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.028145002 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.67       |
|    explained_variance   | 0.00719     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54e+04    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 0.561       |
|    value_loss           | 2.61e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 40.8      |
|    ep_rew_mean          | 1.05e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 170       |
|    time_elapsed         | 59781     |
|    total_timesteps      | 348160    |
| train/                  |           |
|    approx_kl            | 0.0641679 |
|    clip_fraction        | 0.211     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.67     |
|    explained_variance   | 0.0419    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.28e+04  |
|    n_updates            | 1690      |
|    policy_gradient_loss | -0.0172   |
|    std                  | 0.56      |
|    value_loss           | 3.11e+04  |
---------------------------------------
Eval num_timesteps=350000, episode_reward=1015.42 +/- 8.37
Episode length: 29.60 +/- 13.97
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 29.6       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.04165917 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.67      |
|    explained_variance   | 0.0162     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.49e+04   |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.561      |
|    value_loss           | 2.92e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 41.7     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 171      |
|    time_elapsed    | 60063    |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 43.9       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 172        |
|    time_elapsed         | 60329      |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.06085772 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.67      |
|    explained_variance   | 0.0125     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+04   |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0224    |
|    std                  | 0.56       |
|    value_loss           | 2.78e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 41.3        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 173         |
|    time_elapsed         | 60597       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.040425513 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.65       |
|    explained_variance   | 0.0189      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+04     |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.559       |
|    value_loss           | 2.57e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 174         |
|    time_elapsed         | 60865       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.054087378 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.64       |
|    explained_variance   | 0.0526      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.92e+04    |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.559       |
|    value_loss           | 3.07e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 43.5      |
|    ep_rew_mean          | 1.05e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 175       |
|    time_elapsed         | 61132     |
|    total_timesteps      | 358400    |
| train/                  |           |
|    approx_kl            | 0.1203026 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.61     |
|    explained_variance   | 0.0125    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.4e+04   |
|    n_updates            | 1740      |
|    policy_gradient_loss | -0.016    |
|    std                  | 0.556     |
|    value_loss           | 2.72e+04  |
---------------------------------------
Eval num_timesteps=360000, episode_reward=1012.09 +/- 1.65
Episode length: 27.20 +/- 3.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.039756797 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.59       |
|    explained_variance   | 0.00712     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04e+04    |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.556       |
|    value_loss           | 2.34e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 45.6     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 176      |
|    time_elapsed    | 61413    |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.1        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 177         |
|    time_elapsed         | 61680       |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.032941323 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.59       |
|    explained_variance   | 0.0292      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.9e+03     |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.555       |
|    value_loss           | 2.43e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44          |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 178         |
|    time_elapsed         | 61946       |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.048250537 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.0276      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26e+04    |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.554       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.8       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 179        |
|    time_elapsed         | 62213      |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.03337627 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.035      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+04   |
|    n_updates            | 1780       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.551      |
|    value_loss           | 2.26e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.3       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 180        |
|    time_elapsed         | 62479      |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.04408014 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.52      |
|    explained_variance   | 0.0383     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.69e+04   |
|    n_updates            | 1790       |
|    policy_gradient_loss | -0.0235    |
|    std                  | 0.55       |
|    value_loss           | 2.16e+04   |
----------------------------------------
Eval num_timesteps=370000, episode_reward=1010.81 +/- 0.68
Episode length: 22.80 +/- 3.37
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.05853026 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | 0.0303     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.43e+04   |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.548      |
|    value_loss           | 2.36e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.6     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 181      |
|    time_elapsed    | 62757    |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.7        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 182         |
|    time_elapsed         | 63028       |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.030923005 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.46       |
|    explained_variance   | 0.0386      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28e+04    |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.546       |
|    value_loss           | 2.38e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.7        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 183         |
|    time_elapsed         | 63299       |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.049577408 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.43       |
|    explained_variance   | 0.0201      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+04    |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.543       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.4        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 184         |
|    time_elapsed         | 63567       |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.027730508 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.39       |
|    explained_variance   | 0.0206      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.65e+03    |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0247     |
|    std                  | 0.54        |
|    value_loss           | 1.97e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 185        |
|    time_elapsed         | 63835      |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.03753669 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.0618     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.99e+03   |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.539      |
|    value_loss           | 2.33e+04   |
----------------------------------------
Eval num_timesteps=380000, episode_reward=1015.96 +/- 3.00
Episode length: 31.20 +/- 7.03
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.2        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.047843978 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.32       |
|    explained_variance   | 0.0409      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+04    |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 0.537       |
|    value_loss           | 2.1e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.5     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 186      |
|    time_elapsed    | 64120    |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.9        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 187         |
|    time_elapsed         | 64390       |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.037936255 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.3        |
|    explained_variance   | 0.029       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+04    |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.535       |
|    value_loss           | 1.97e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.5        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 188         |
|    time_elapsed         | 64658       |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.040815316 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.0456      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28e+04    |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.534       |
|    value_loss           | 2.15e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.9        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 189         |
|    time_elapsed         | 64927       |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.027990386 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.26       |
|    explained_variance   | 0.0192      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+04    |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.532       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 190        |
|    time_elapsed         | 65196      |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.06136751 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.23      |
|    explained_variance   | 0.0461     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.87e+03   |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.531      |
|    value_loss           | 1.99e+04   |
----------------------------------------
Eval num_timesteps=390000, episode_reward=1014.07 +/- 2.36
Episode length: 28.00 +/- 5.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.052468695 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.2        |
|    explained_variance   | 0.0437      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.43e+03    |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.528       |
|    value_loss           | 2.03e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 191      |
|    time_elapsed    | 65480    |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 192         |
|    time_elapsed         | 65748       |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.050162237 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.17       |
|    explained_variance   | 0.0507      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.42e+03    |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.526       |
|    value_loss           | 1.95e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 193        |
|    time_elapsed         | 66023      |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.08854748 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.14      |
|    explained_variance   | 0.0349     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.81e+03   |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.524      |
|    value_loss           | 1.86e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.8       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 194        |
|    time_elapsed         | 66294      |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.03351737 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.13      |
|    explained_variance   | 0.0524     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.15e+03   |
|    n_updates            | 1930       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.524      |
|    value_loss           | 1.98e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 195         |
|    time_elapsed         | 66561       |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.090029284 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.1        |
|    explained_variance   | 0.0582      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.12e+03    |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 0.521       |
|    value_loss           | 1.9e+04     |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=1011.76 +/- 1.59
Episode length: 25.80 +/- 4.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.07273801 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.0315     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.81e+03   |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.522      |
|    value_loss           | 1.63e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 196      |
|    time_elapsed    | 66843    |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 197         |
|    time_elapsed         | 67111       |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.050521076 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.0679      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.55e+03    |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.023      |
|    std                  | 0.521       |
|    value_loss           | 1.79e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 198         |
|    time_elapsed         | 67380       |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.035437714 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.06       |
|    explained_variance   | 0.0531      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.75e+03    |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.519       |
|    value_loss           | 1.71e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40         |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 199        |
|    time_elapsed         | 67652      |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07269995 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.0349     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.65e+03   |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.518      |
|    value_loss           | 1.59e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 200         |
|    time_elapsed         | 67923       |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.036881354 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.99       |
|    explained_variance   | 0.0619      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.45e+03    |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.515       |
|    value_loss           | 1.49e+04    |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=1013.97 +/- 4.08
Episode length: 31.60 +/- 6.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.053199477 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.97       |
|    explained_variance   | 0.0627      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.09e+03    |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.515       |
|    value_loss           | 1.51e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 38.4     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 201      |
|    time_elapsed    | 68208    |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 202        |
|    time_elapsed         | 68478      |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.03379203 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.0886     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.93e+03   |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.513      |
|    value_loss           | 1.56e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.5        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 203         |
|    time_elapsed         | 68748       |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.047824275 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.94       |
|    explained_variance   | 0.084       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.22e+03    |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.512       |
|    value_loss           | 1.67e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 204         |
|    time_elapsed         | 69017       |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.031108588 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.92       |
|    explained_variance   | 0.0436      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.47e+03    |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.025      |
|    std                  | 0.511       |
|    value_loss           | 1.48e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 205        |
|    time_elapsed         | 69286      |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.04340781 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.9       |
|    explained_variance   | 0.061      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.14e+03   |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.0248    |
|    std                  | 0.509      |
|    value_loss           | 1.41e+04   |
----------------------------------------
Eval num_timesteps=420000, episode_reward=1013.07 +/- 4.20
Episode length: 28.20 +/- 8.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.03488619 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.88      |
|    explained_variance   | 0.0395     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.22e+03   |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.0243    |
|    std                  | 0.508      |
|    value_loss           | 1.36e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.5     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 206      |
|    time_elapsed    | 69570    |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.8       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 207        |
|    time_elapsed         | 69840      |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.04521251 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.87      |
|    explained_variance   | 0.0836     |
|    learning_rate        | 0.0003     |
|    loss                 | 4.54e+03   |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.507      |
|    value_loss           | 1.32e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 208         |
|    time_elapsed         | 70110       |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.032701716 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.84       |
|    explained_variance   | 0.092       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.56e+03    |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.506       |
|    value_loss           | 1.31e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 209         |
|    time_elapsed         | 70380       |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.024610547 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.82       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.02e+03    |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.505       |
|    value_loss           | 1.3e+04     |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=1014.39 +/- 5.49
Episode length: 29.80 +/- 6.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.065379836 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.81       |
|    explained_variance   | 0.0551      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.93e+03    |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.505       |
|    value_loss           | 1.22e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.6     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 210      |
|    time_elapsed    | 70666    |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 211        |
|    time_elapsed         | 70936      |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.03910948 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.0842     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.63e+03   |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.503      |
|    value_loss           | 1.2e+04    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 36.9      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 212       |
|    time_elapsed         | 71205     |
|    total_timesteps      | 434176    |
| train/                  |           |
|    approx_kl            | 0.0728578 |
|    clip_fraction        | 0.26      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.79     |
|    explained_variance   | 0.115     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.29e+03  |
|    n_updates            | 2110      |
|    policy_gradient_loss | -0.0205   |
|    std                  | 0.502     |
|    value_loss           | 1.16e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 213        |
|    time_elapsed         | 71478      |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.04805626 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.76      |
|    explained_variance   | 0.124      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.27e+03   |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.5        |
|    value_loss           | 9.96e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 214         |
|    time_elapsed         | 71752       |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.044741414 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.73       |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.19e+03    |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 0.499       |
|    value_loss           | 1.08e+04    |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=1012.25 +/- 1.97
Episode length: 29.00 +/- 5.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.045251757 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.7        |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.68e+03    |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 0.497       |
|    value_loss           | 1.01e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.8     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 215      |
|    time_elapsed    | 72034    |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.5        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 216         |
|    time_elapsed         | 72303       |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.029838018 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.113       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.8e+03     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 0.495       |
|    value_loss           | 9.95e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 32.1      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 217       |
|    time_elapsed         | 72577     |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 0.0749124 |
|    clip_fraction        | 0.232     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.64     |
|    explained_variance   | 0.15      |
|    learning_rate        | 0.0003    |
|    loss                 | 4.38e+03  |
|    n_updates            | 2160      |
|    policy_gradient_loss | -0.0209   |
|    std                  | 0.493     |
|    value_loss           | 9.49e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.7        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 218         |
|    time_elapsed         | 72848       |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.090813816 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.61       |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.66e+03    |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.492       |
|    value_loss           | 9.83e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.9       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 219        |
|    time_elapsed         | 73116      |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.06451966 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.6       |
|    explained_variance   | 0.114      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.93e+03   |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.491      |
|    value_loss           | 9.28e+03   |
----------------------------------------
Eval num_timesteps=450000, episode_reward=1010.98 +/- 1.04
Episode length: 23.80 +/- 3.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.19322035 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.6       |
|    explained_variance   | 0.146      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.95e+03   |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.00908   |
|    std                  | 0.492      |
|    value_loss           | 8.85e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.2     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 220      |
|    time_elapsed    | 73398    |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.5        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 221         |
|    time_elapsed         | 73665       |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.029537374 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.6        |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.95e+03    |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.491       |
|    value_loss           | 8.39e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 34.8      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 222       |
|    time_elapsed         | 73934     |
|    total_timesteps      | 454656    |
| train/                  |           |
|    approx_kl            | 0.0579143 |
|    clip_fraction        | 0.232     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.58     |
|    explained_variance   | 0.118     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.44e+03  |
|    n_updates            | 2210      |
|    policy_gradient_loss | -0.0215   |
|    std                  | 0.49      |
|    value_loss           | 8.44e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 223         |
|    time_elapsed         | 74202       |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.037504897 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.56       |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.21e+03    |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0245     |
|    std                  | 0.488       |
|    value_loss           | 8.15e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 224         |
|    time_elapsed         | 74471       |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.047157504 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.54       |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.23e+03    |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 0.488       |
|    value_loss           | 7.98e+03    |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=1017.27 +/- 6.61
Episode length: 35.20 +/- 11.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35.2        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.093023315 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.51       |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.28e+03    |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.485       |
|    value_loss           | 7.21e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.2     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 225      |
|    time_elapsed    | 74759    |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 226         |
|    time_elapsed         | 75028       |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.038356785 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.48       |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.88e+03    |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.485       |
|    value_loss           | 7e+03       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.3      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 227       |
|    time_elapsed         | 75298     |
|    total_timesteps      | 464896    |
| train/                  |           |
|    approx_kl            | 0.1091935 |
|    clip_fraction        | 0.294     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.47     |
|    explained_variance   | 0.224     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.09e+03  |
|    n_updates            | 2260      |
|    policy_gradient_loss | -0.0239   |
|    std                  | 0.483     |
|    value_loss           | 7.2e+03   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 228        |
|    time_elapsed         | 75567      |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.04272364 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.42      |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.65e+03   |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.48       |
|    value_loss           | 6.49e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 229         |
|    time_elapsed         | 75837       |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.043189563 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.39       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.09e+03    |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.0265     |
|    std                  | 0.479       |
|    value_loss           | 6e+03       |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=1010.41 +/- 0.53
Episode length: 21.40 +/- 3.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.032830443 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.39       |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.78e+03    |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.48        |
|    value_loss           | 6.07e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 230      |
|    time_elapsed    | 76119    |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 231         |
|    time_elapsed         | 76394       |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.068239465 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.4        |
|    explained_variance   | 0.224       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.43e+03    |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 0.48        |
|    value_loss           | 5.91e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 232        |
|    time_elapsed         | 76664      |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.10297644 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.217      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.96e+03   |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.478      |
|    value_loss           | 5.15e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 233        |
|    time_elapsed         | 76935      |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.06400736 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | 0.27       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.88e+03   |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.479      |
|    value_loss           | 4.83e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 234        |
|    time_elapsed         | 77206      |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.09121909 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.36      |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.34e+03   |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.478      |
|    value_loss           | 5.03e+03   |
----------------------------------------
Eval num_timesteps=480000, episode_reward=1014.26 +/- 3.91
Episode length: 27.80 +/- 7.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.044670705 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.35       |
|    explained_variance   | 0.273       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79e+03    |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 0.477       |
|    value_loss           | 4.89e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.2     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 235      |
|    time_elapsed    | 77489    |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 236         |
|    time_elapsed         | 77759       |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.046563003 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.33       |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.11e+03    |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.475       |
|    value_loss           | 4.62e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 237        |
|    time_elapsed         | 78028      |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.06649126 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.31      |
|    explained_variance   | 0.227      |
|    learning_rate        | 0.0003     |
|    loss                 | 3e+03      |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.474      |
|    value_loss           | 4.88e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30.3      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 238       |
|    time_elapsed         | 78298     |
|    total_timesteps      | 487424    |
| train/                  |           |
|    approx_kl            | 0.0372663 |
|    clip_fraction        | 0.229     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.3      |
|    explained_variance   | 0.243     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.2e+03   |
|    n_updates            | 2370      |
|    policy_gradient_loss | -0.0202   |
|    std                  | 0.474     |
|    value_loss           | 4.78e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 239         |
|    time_elapsed         | 78569       |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.040718686 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.29       |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.86e+03    |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 0.473       |
|    value_loss           | 4.14e+03    |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=1014.44 +/- 5.82
Episode length: 28.80 +/- 10.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.051942196 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.29       |
|    explained_variance   | 0.313       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.57e+03    |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0283     |
|    std                  | 0.473       |
|    value_loss           | 4.16e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 240      |
|    time_elapsed    | 78853    |
|    total_timesteps | 491520   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 31.6      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 241       |
|    time_elapsed         | 79123     |
|    total_timesteps      | 493568    |
| train/                  |           |
|    approx_kl            | 0.1235336 |
|    clip_fraction        | 0.314     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.29     |
|    explained_variance   | 0.257     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.96e+03  |
|    n_updates            | 2400      |
|    policy_gradient_loss | -0.00992  |
|    std                  | 0.473     |
|    value_loss           | 4.32e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 242         |
|    time_elapsed         | 79390       |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.056633286 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.26       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.86e+03    |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.471       |
|    value_loss           | 3.85e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.3        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 243         |
|    time_elapsed         | 79662       |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.045717433 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.22       |
|    explained_variance   | 0.277       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.02e+03    |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.468       |
|    value_loss           | 4.35e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 244         |
|    time_elapsed         | 79938       |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.025392102 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.17       |
|    explained_variance   | 0.261       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.48e+03    |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 0.465       |
|    value_loss           | 4.4e+03     |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=1011.98 +/- 3.40
Episode length: 22.60 +/- 4.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.05633402 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.14      |
|    explained_variance   | 0.332      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.09e+03   |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 0.463      |
|    value_loss           | 4e+03      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 245      |
|    time_elapsed    | 80222    |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 246        |
|    time_elapsed         | 80492      |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.06641391 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.364      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.41e+03   |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.461      |
|    value_loss           | 3.53e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 247        |
|    time_elapsed         | 80763      |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.05491586 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.09      |
|    explained_variance   | 0.355      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53e+03   |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.462      |
|    value_loss           | 3.35e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 248         |
|    time_elapsed         | 81032       |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.058236837 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.09       |
|    explained_variance   | 0.425       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44e+03    |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.461       |
|    value_loss           | 2.88e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 249        |
|    time_elapsed         | 81302      |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.03847699 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.06      |
|    explained_variance   | 0.365      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.71e+03   |
|    n_updates            | 2480       |
|    policy_gradient_loss | -0.0264    |
|    std                  | 0.459      |
|    value_loss           | 3.22e+03   |
----------------------------------------
Eval num_timesteps=510000, episode_reward=1011.14 +/- 1.02
Episode length: 26.00 +/- 6.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.05680398 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.04      |
|    explained_variance   | 0.377      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.61e+03   |
|    n_updates            | 2490       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.459      |
|    value_loss           | 2.99e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 250      |
|    time_elapsed    | 81588    |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 251         |
|    time_elapsed         | 81858       |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.032183286 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.03       |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.55e+03    |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.458       |
|    value_loss           | 3.85e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 252         |
|    time_elapsed         | 82128       |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.030589119 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.01       |
|    explained_variance   | 0.419       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+03    |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.457       |
|    value_loss           | 2.82e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 253        |
|    time_elapsed         | 82397      |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.04512334 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.01      |
|    explained_variance   | 0.356      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17e+03   |
|    n_updates            | 2520       |
|    policy_gradient_loss | -0.0273    |
|    std                  | 0.457      |
|    value_loss           | 3.1e+03    |
----------------------------------------
Eval num_timesteps=520000, episode_reward=1012.60 +/- 1.86
Episode length: 23.00 +/- 4.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.050628968 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.99       |
|    explained_variance   | 0.265       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.64e+03    |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 0.455       |
|    value_loss           | 3.44e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 254      |
|    time_elapsed    | 82679    |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 255         |
|    time_elapsed         | 82949       |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.035068884 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.98       |
|    explained_variance   | 0.321       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56e+03    |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.456       |
|    value_loss           | 3.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 27.7     |
|    ep_rew_mean          | 1.03e+03 |
| time/                   |          |
|    fps                  | 6        |
|    iterations           | 256      |
|    time_elapsed         | 83220    |
|    total_timesteps      | 524288   |
| train/                  |          |
|    approx_kl            | 0.051524 |
|    clip_fraction        | 0.268    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.97    |
|    explained_variance   | 0.418    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.16e+03 |
|    n_updates            | 2550     |
|    policy_gradient_loss | -0.0245  |
|    std                  | 0.455    |
|    value_loss           | 2.64e+03 |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 257         |
|    time_elapsed         | 83489       |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.044234797 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.95       |
|    explained_variance   | 0.367       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+03    |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.453       |
|    value_loss           | 2.69e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 258        |
|    time_elapsed         | 83762      |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.06411545 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.93      |
|    explained_variance   | 0.393      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.34e+03   |
|    n_updates            | 2570       |
|    policy_gradient_loss | -0.023     |
|    std                  | 0.453      |
|    value_loss           | 2.59e+03   |
----------------------------------------
Eval num_timesteps=530000, episode_reward=1012.59 +/- 2.73
Episode length: 24.00 +/- 4.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.044612907 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.92       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+03    |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.452       |
|    value_loss           | 2.63e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 259      |
|    time_elapsed    | 84047    |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 260        |
|    time_elapsed         | 84317      |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.05932815 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.9       |
|    explained_variance   | 0.426      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+03   |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 0.45       |
|    value_loss           | 2.39e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 261        |
|    time_elapsed         | 84587      |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.11512893 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.89      |
|    explained_variance   | 0.425      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+03   |
|    n_updates            | 2600       |
|    policy_gradient_loss | -0.00784   |
|    std                  | 0.451      |
|    value_loss           | 2.27e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 262         |
|    time_elapsed         | 84857       |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.054179177 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.89       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+03    |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.45        |
|    value_loss           | 2.47e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 263        |
|    time_elapsed         | 85129      |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.06137099 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.88      |
|    explained_variance   | 0.405      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01e+03   |
|    n_updates            | 2620       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.45       |
|    value_loss           | 2.49e+03   |
----------------------------------------
Eval num_timesteps=540000, episode_reward=1010.63 +/- 0.48
Episode length: 20.60 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.053930357 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.86       |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.0003      |
|    loss                 | 890         |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.448       |
|    value_loss           | 2.13e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 264      |
|    time_elapsed    | 85409    |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 265        |
|    time_elapsed         | 85681      |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.04450041 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.84      |
|    explained_variance   | 0.394      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09e+03   |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.447      |
|    value_loss           | 2.51e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 266         |
|    time_elapsed         | 85955       |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.057563476 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.82       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.0003      |
|    loss                 | 898         |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.446       |
|    value_loss           | 1.8e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 267        |
|    time_elapsed         | 86226      |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.07061254 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.79      |
|    explained_variance   | 0.439      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+03   |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.444      |
|    value_loss           | 2.11e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 268        |
|    time_elapsed         | 86497      |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.05516634 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.78      |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.1e+03    |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.444      |
|    value_loss           | 2.72e+03   |
----------------------------------------
Eval num_timesteps=550000, episode_reward=1010.91 +/- 0.39
Episode length: 19.80 +/- 2.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.035251908 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.75       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04e+03    |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.441       |
|    value_loss           | 2.32e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 269      |
|    time_elapsed    | 86777    |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 270         |
|    time_elapsed         | 87048       |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.047678072 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.73       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0003      |
|    loss                 | 933         |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.442       |
|    value_loss           | 1.95e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 271        |
|    time_elapsed         | 87319      |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.03956998 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.72      |
|    explained_variance   | 0.427      |
|    learning_rate        | 0.0003     |
|    loss                 | 892        |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.44       |
|    value_loss           | 2.23e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 272         |
|    time_elapsed         | 87589       |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.047446452 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.69       |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28e+03    |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.439       |
|    value_loss           | 2.41e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 273        |
|    time_elapsed         | 87861      |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.06274865 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.67      |
|    explained_variance   | 0.436      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.0226    |
|    std                  | 0.437      |
|    value_loss           | 2.12e+03   |
----------------------------------------
Eval num_timesteps=560000, episode_reward=1011.39 +/- 1.75
Episode length: 23.40 +/- 4.08
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.11180286 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.64      |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.0003     |
|    loss                 | 954        |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.436      |
|    value_loss           | 1.98e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 274      |
|    time_elapsed    | 88144    |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 275        |
|    time_elapsed         | 88414      |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.11459904 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.63      |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.0003     |
|    loss                 | 947        |
|    n_updates            | 2740       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.436      |
|    value_loss           | 1.67e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 276        |
|    time_elapsed         | 88685      |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.05090161 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.61      |
|    explained_variance   | 0.461      |
|    learning_rate        | 0.0003     |
|    loss                 | 964        |
|    n_updates            | 2750       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.434      |
|    value_loss           | 1.9e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 277         |
|    time_elapsed         | 88955       |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.044952128 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.59       |
|    explained_variance   | 0.492       |
|    learning_rate        | 0.0003      |
|    loss                 | 813         |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 0.434       |
|    value_loss           | 1.73e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 278         |
|    time_elapsed         | 89225       |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.046771422 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.6        |
|    explained_variance   | 0.388       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+03    |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 0.434       |
|    value_loss           | 2.29e+03    |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=1013.30 +/- 2.93
Episode length: 27.00 +/- 5.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.08707934 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.59      |
|    explained_variance   | 0.404      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18e+03   |
|    n_updates            | 2780       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.433      |
|    value_loss           | 2.16e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 279      |
|    time_elapsed    | 89509    |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 280         |
|    time_elapsed         | 89786       |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.050488185 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.57       |
|    explained_variance   | 0.461       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+03    |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.432       |
|    value_loss           | 2.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 281        |
|    time_elapsed         | 90060      |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.07717778 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.54      |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0003     |
|    loss                 | 678        |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.431      |
|    value_loss           | 1.5e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 282        |
|    time_elapsed         | 90331      |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.09764099 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.52      |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.0003     |
|    loss                 | 793        |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.429      |
|    value_loss           | 1.72e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 283         |
|    time_elapsed         | 90603       |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.056033894 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.5        |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 838         |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.429       |
|    value_loss           | 1.83e+03    |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=1011.49 +/- 1.30
Episode length: 20.60 +/- 1.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.038738452 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.51       |
|    explained_variance   | 0.456       |
|    learning_rate        | 0.0003      |
|    loss                 | 850         |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 0.429       |
|    value_loss           | 1.9e+03     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 284      |
|    time_elapsed    | 90883    |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 285        |
|    time_elapsed         | 91153      |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.04833028 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.49      |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+03   |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.428      |
|    value_loss           | 2.43e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 286         |
|    time_elapsed         | 91423       |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.050381817 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.49       |
|    explained_variance   | 0.444       |
|    learning_rate        | 0.0003      |
|    loss                 | 995         |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.428       |
|    value_loss           | 2.19e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 287         |
|    time_elapsed         | 91693       |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.044337038 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.48       |
|    explained_variance   | 0.484       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+03     |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.427       |
|    value_loss           | 2e+03       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 288         |
|    time_elapsed         | 91964       |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.038880747 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.46       |
|    explained_variance   | 0.373       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.31e+03    |
|    n_updates            | 2870        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.427       |
|    value_loss           | 2.49e+03    |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=1011.76 +/- 2.49
Episode length: 24.00 +/- 5.51
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.14528024 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.46      |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.0003     |
|    loss                 | 837        |
|    n_updates            | 2880       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.426      |
|    value_loss           | 1.93e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 289      |
|    time_elapsed    | 92247    |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 290        |
|    time_elapsed         | 92518      |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.04335893 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.44      |
|    explained_variance   | 0.439      |
|    learning_rate        | 0.0003     |
|    loss                 | 885        |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.425      |
|    value_loss           | 2.19e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 291        |
|    time_elapsed         | 92789      |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.04989232 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.43      |
|    explained_variance   | 0.441      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09e+03   |
|    n_updates            | 2900       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.425      |
|    value_loss           | 2.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 292         |
|    time_elapsed         | 93060       |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.044504113 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.43       |
|    explained_variance   | 0.397       |
|    learning_rate        | 0.0003      |
|    loss                 | 950         |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 0.424       |
|    value_loss           | 2.35e+03    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=1010.85 +/- 0.72
Episode length: 22.00 +/- 2.45
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 22        |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 600000    |
| train/                  |           |
|    approx_kl            | 0.0793408 |
|    clip_fraction        | 0.335     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.41     |
|    explained_variance   | 0.494     |
|    learning_rate        | 0.0003    |
|    loss                 | 847       |
|    n_updates            | 2920      |
|    policy_gradient_loss | -0.0171   |
|    std                  | 0.423     |
|    value_loss           | 1.88e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 293      |
|    time_elapsed    | 93342    |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 294         |
|    time_elapsed         | 93619       |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.056905605 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.39       |
|    explained_variance   | 0.498       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.422       |
|    value_loss           | 1.82e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 295         |
|    time_elapsed         | 93892       |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.058050245 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.37       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0003      |
|    loss                 | 830         |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.0284     |
|    std                  | 0.422       |
|    value_loss           | 1.44e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 296        |
|    time_elapsed         | 94163      |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.07312125 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.36      |
|    explained_variance   | 0.559      |
|    learning_rate        | 0.0003     |
|    loss                 | 970        |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.421      |
|    value_loss           | 1.39e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 297        |
|    time_elapsed         | 94435      |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.07445806 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.35      |
|    explained_variance   | 0.49       |
|    learning_rate        | 0.0003     |
|    loss                 | 810        |
|    n_updates            | 2960       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.42       |
|    value_loss           | 1.57e+03   |
----------------------------------------
Eval num_timesteps=610000, episode_reward=1012.93 +/- 2.60
Episode length: 24.20 +/- 3.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.06118361 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.33      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 741        |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.419      |
|    value_loss           | 1.59e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 298      |
|    time_elapsed    | 94718    |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 299         |
|    time_elapsed         | 94990       |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.054628022 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.32       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 763         |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.419       |
|    value_loss           | 1.75e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 300        |
|    time_elapsed         | 95262      |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.12279326 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.33      |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.0003     |
|    loss                 | 779        |
|    n_updates            | 2990       |
|    policy_gradient_loss | -0.00928   |
|    std                  | 0.42       |
|    value_loss           | 1.36e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 301        |
|    time_elapsed         | 95534      |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.05234673 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.32      |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.0003     |
|    loss                 | 969        |
|    n_updates            | 3000       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.418      |
|    value_loss           | 1.62e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 302         |
|    time_elapsed         | 95805       |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.053475842 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.29       |
|    explained_variance   | 0.523       |
|    learning_rate        | 0.0003      |
|    loss                 | 959         |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.0272     |
|    std                  | 0.418       |
|    value_loss           | 1.56e+03    |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=1013.56 +/- 5.53
Episode length: 25.40 +/- 8.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.08571952 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.29      |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.0003     |
|    loss                 | 671        |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.417      |
|    value_loss           | 1.64e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 303      |
|    time_elapsed    | 96089    |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 304        |
|    time_elapsed         | 96360      |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.05603369 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.29      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.0003     |
|    loss                 | 1e+03      |
|    n_updates            | 3030       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.417      |
|    value_loss           | 1.93e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 305        |
|    time_elapsed         | 96630      |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.09125291 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.27      |
|    explained_variance   | 0.558      |
|    learning_rate        | 0.0003     |
|    loss                 | 543        |
|    n_updates            | 3040       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.416      |
|    value_loss           | 1.5e+03    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 306       |
|    time_elapsed         | 96901     |
|    total_timesteps      | 626688    |
| train/                  |           |
|    approx_kl            | 0.0819819 |
|    clip_fraction        | 0.335     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.25     |
|    explained_variance   | 0.503     |
|    learning_rate        | 0.0003    |
|    loss                 | 850       |
|    n_updates            | 3050      |
|    policy_gradient_loss | -0.0196   |
|    std                  | 0.415     |
|    value_loss           | 1.58e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 307        |
|    time_elapsed         | 97171      |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.05895245 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0.523      |
|    learning_rate        | 0.0003     |
|    loss                 | 686        |
|    n_updates            | 3060       |
|    policy_gradient_loss | -0.0273    |
|    std                  | 0.414      |
|    value_loss           | 1.58e+03   |
----------------------------------------
Eval num_timesteps=630000, episode_reward=1010.84 +/- 0.41
Episode length: 21.20 +/- 1.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.09463863 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.22      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 897        |
|    n_updates            | 3070       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.414      |
|    value_loss           | 1.69e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 308      |
|    time_elapsed    | 97452    |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 309        |
|    time_elapsed         | 97726      |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.11893027 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.19      |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.0003     |
|    loss                 | 594        |
|    n_updates            | 3080       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.412      |
|    value_loss           | 1.48e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 310        |
|    time_elapsed         | 98000      |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.04668139 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.441      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18e+03   |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.022     |
|    std                  | 0.412      |
|    value_loss           | 2.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 311         |
|    time_elapsed         | 98272       |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.040834315 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.17       |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.0003      |
|    loss                 | 755         |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.411       |
|    value_loss           | 1.68e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 312         |
|    time_elapsed         | 98544       |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.060973134 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.17       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.0003      |
|    loss                 | 584         |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.411       |
|    value_loss           | 1.19e+03    |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=1010.63 +/- 0.78
Episode length: 21.00 +/- 1.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.052838944 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.15       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.0003      |
|    loss                 | 721         |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.409       |
|    value_loss           | 1.38e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 313      |
|    time_elapsed    | 98826    |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 314        |
|    time_elapsed         | 99098      |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.07142725 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.11      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0003     |
|    loss                 | 778        |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.407      |
|    value_loss           | 1.74e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 315         |
|    time_elapsed         | 99370       |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.120910384 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.1        |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.0003      |
|    loss                 | 982         |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.00804    |
|    std                  | 0.408       |
|    value_loss           | 1.37e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 316        |
|    time_elapsed         | 99642      |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.09121553 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.1       |
|    explained_variance   | 0.542      |
|    learning_rate        | 0.0003     |
|    loss                 | 474        |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.028     |
|    std                  | 0.408      |
|    value_loss           | 1.43e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 317        |
|    time_elapsed         | 99913      |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.10108167 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.08      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0003     |
|    loss                 | 683        |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.406      |
|    value_loss           | 1.08e+03   |
----------------------------------------
Eval num_timesteps=650000, episode_reward=1010.78 +/- 0.75
Episode length: 23.60 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.10712758 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.06      |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 853        |
|    n_updates            | 3170       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.406      |
|    value_loss           | 1.49e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 318      |
|    time_elapsed    | 100196   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 319        |
|    time_elapsed         | 100468     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.05572553 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.05      |
|    explained_variance   | 0.58       |
|    learning_rate        | 0.0003     |
|    loss                 | 497        |
|    n_updates            | 3180       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.405      |
|    value_loss           | 1.28e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 320         |
|    time_elapsed         | 100740      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.073161304 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.03       |
|    explained_variance   | 0.619       |
|    learning_rate        | 0.0003      |
|    loss                 | 459         |
|    n_updates            | 3190        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.404       |
|    value_loss           | 1.13e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 321        |
|    time_elapsed         | 101011     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.06208542 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.02      |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0003     |
|    loss                 | 808        |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.404      |
|    value_loss           | 1.33e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.5      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 322       |
|    time_elapsed         | 101285    |
|    total_timesteps      | 659456    |
| train/                  |           |
|    approx_kl            | 0.0393006 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.02     |
|    explained_variance   | 0.502     |
|    learning_rate        | 0.0003    |
|    loss                 | 789       |
|    n_updates            | 3210      |
|    policy_gradient_loss | -0.0169   |
|    std                  | 0.404     |
|    value_loss           | 1.54e+03  |
---------------------------------------
Eval num_timesteps=660000, episode_reward=1013.37 +/- 3.04
Episode length: 22.40 +/- 7.14
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 22.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 660000    |
| train/                  |           |
|    approx_kl            | 0.0669873 |
|    clip_fraction        | 0.299     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.98     |
|    explained_variance   | 0.54      |
|    learning_rate        | 0.0003    |
|    loss                 | 793       |
|    n_updates            | 3220      |
|    policy_gradient_loss | -0.0272   |
|    std                  | 0.401     |
|    value_loss           | 1.5e+03   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 323      |
|    time_elapsed    | 101572   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 324        |
|    time_elapsed         | 101846     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.07355726 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.95      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 667        |
|    n_updates            | 3230       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.4        |
|    value_loss           | 1.19e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 325        |
|    time_elapsed         | 102117     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.07919255 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.92      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 593        |
|    n_updates            | 3240       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.398      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 326        |
|    time_elapsed         | 102389     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.05256625 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.89      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | 639        |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.398      |
|    value_loss           | 1.15e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 327        |
|    time_elapsed         | 102661     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.08083318 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.89      |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.0003     |
|    loss                 | 707        |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.398      |
|    value_loss           | 1.26e+03   |
----------------------------------------
Eval num_timesteps=670000, episode_reward=1011.39 +/- 2.23
Episode length: 22.60 +/- 4.22
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.18385068 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.87      |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.0003     |
|    loss                 | 893        |
|    n_updates            | 3270       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.397      |
|    value_loss           | 1.18e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 328      |
|    time_elapsed    | 102944   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 329        |
|    time_elapsed         | 103215     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.09976882 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.87      |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.0003     |
|    loss                 | 651        |
|    n_updates            | 3280       |
|    policy_gradient_loss | 2.99e-05   |
|    std                  | 0.397      |
|    value_loss           | 1.27e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 330         |
|    time_elapsed         | 103487      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.050746657 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.86       |
|    explained_variance   | 0.588       |
|    learning_rate        | 0.0003      |
|    loss                 | 524         |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.396       |
|    value_loss           | 1.26e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 331        |
|    time_elapsed         | 103757     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.07367226 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.85      |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.0003     |
|    loss                 | 599        |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.395      |
|    value_loss           | 1.25e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 332        |
|    time_elapsed         | 104028     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.11187707 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.84      |
|    explained_variance   | 0.567      |
|    learning_rate        | 0.0003     |
|    loss                 | 727        |
|    n_updates            | 3310       |
|    policy_gradient_loss | -0.00794   |
|    std                  | 0.396      |
|    value_loss           | 1.33e+03   |
----------------------------------------
Eval num_timesteps=680000, episode_reward=1010.97 +/- 0.60
Episode length: 23.20 +/- 3.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.09932882 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.85      |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | 783        |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.395      |
|    value_loss           | 1.15e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 333      |
|    time_elapsed    | 104310   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 334         |
|    time_elapsed         | 104582      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.052285265 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.83       |
|    explained_variance   | 0.501       |
|    learning_rate        | 0.0003      |
|    loss                 | 884         |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 0.394       |
|    value_loss           | 1.56e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 335         |
|    time_elapsed         | 104852      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.100930795 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.8        |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.0003      |
|    loss                 | 671         |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.393       |
|    value_loss           | 1.13e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 336       |
|    time_elapsed         | 105126    |
|    total_timesteps      | 688128    |
| train/                  |           |
|    approx_kl            | 0.0521906 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.78     |
|    explained_variance   | 0.568     |
|    learning_rate        | 0.0003    |
|    loss                 | 531       |
|    n_updates            | 3350      |
|    policy_gradient_loss | -0.0173   |
|    std                  | 0.392     |
|    value_loss           | 1.37e+03  |
---------------------------------------
Eval num_timesteps=690000, episode_reward=1011.99 +/- 2.53
Episode length: 23.40 +/- 2.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.21216547 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.77      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 500        |
|    n_updates            | 3360       |
|    policy_gradient_loss | -0.00585   |
|    std                  | 0.392      |
|    value_loss           | 1.32e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 337      |
|    time_elapsed    | 105412   |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 338        |
|    time_elapsed         | 105685     |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.08226828 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.76      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 648        |
|    n_updates            | 3370       |
|    policy_gradient_loss | -0.0124    |
|    std                  | 0.391      |
|    value_loss           | 1.4e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 339        |
|    time_elapsed         | 105957     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.08140527 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.76      |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.0003     |
|    loss                 | 656        |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.392      |
|    value_loss           | 1.33e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 340        |
|    time_elapsed         | 106228     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.12871328 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.75      |
|    explained_variance   | 0.554      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02e+03   |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.391      |
|    value_loss           | 1.4e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 341        |
|    time_elapsed         | 106500     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.05722781 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.73      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 573        |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.39       |
|    value_loss           | 1.18e+03   |
----------------------------------------
Eval num_timesteps=700000, episode_reward=1010.29 +/- 0.36
Episode length: 19.80 +/- 1.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.07729466 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.72      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 580        |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.01      |
|    std                  | 0.389      |
|    value_loss           | 1.23e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 342      |
|    time_elapsed    | 106782   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 343         |
|    time_elapsed         | 107054      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.076897755 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.7        |
|    explained_variance   | 0.562       |
|    learning_rate        | 0.0003      |
|    loss                 | 752         |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.389       |
|    value_loss           | 1.3e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 344        |
|    time_elapsed         | 107326     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.13517785 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.69      |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.0003     |
|    loss                 | 712        |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.389      |
|    value_loss           | 1.27e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 345         |
|    time_elapsed         | 107597      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.041786015 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.69       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.0003      |
|    loss                 | 718         |
|    n_updates            | 3440        |
|    policy_gradient_loss | -0.0271     |
|    std                  | 0.388       |
|    value_loss           | 1.3e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 346        |
|    time_elapsed         | 107869     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.15157601 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.67      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.0003     |
|    loss                 | 703        |
|    n_updates            | 3450       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.387      |
|    value_loss           | 1.28e+03   |
----------------------------------------
Eval num_timesteps=710000, episode_reward=1010.81 +/- 0.68
Episode length: 22.60 +/- 2.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.08284108 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 634        |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.00231   |
|    std                  | 0.387      |
|    value_loss           | 1.09e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 347      |
|    time_elapsed    | 108152   |
|    total_timesteps | 710656   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 348       |
|    time_elapsed         | 108429    |
|    total_timesteps      | 712704    |
| train/                  |           |
|    approx_kl            | 0.0707635 |
|    clip_fraction        | 0.358     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.64     |
|    explained_variance   | 0.584     |
|    learning_rate        | 0.0003    |
|    loss                 | 661       |
|    n_updates            | 3470      |
|    policy_gradient_loss | -0.0214   |
|    std                  | 0.386     |
|    value_loss           | 1.2e+03   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 349        |
|    time_elapsed         | 108700     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.06689591 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.63      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 529        |
|    n_updates            | 3480       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.386      |
|    value_loss           | 1.03e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 350         |
|    time_elapsed         | 108971      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.052518796 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.63       |
|    explained_variance   | 0.523       |
|    learning_rate        | 0.0003      |
|    loss                 | 946         |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.387       |
|    value_loss           | 1.45e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.2      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 351       |
|    time_elapsed         | 109244    |
|    total_timesteps      | 718848    |
| train/                  |           |
|    approx_kl            | 0.0695269 |
|    clip_fraction        | 0.361     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.62     |
|    explained_variance   | 0.613     |
|    learning_rate        | 0.0003    |
|    loss                 | 531       |
|    n_updates            | 3500      |
|    policy_gradient_loss | -0.0236   |
|    std                  | 0.386     |
|    value_loss           | 1.14e+03  |
---------------------------------------
Eval num_timesteps=720000, episode_reward=1011.21 +/- 0.94
Episode length: 22.40 +/- 1.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.07861097 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.6       |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.0003     |
|    loss                 | 324        |
|    n_updates            | 3510       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.385      |
|    value_loss           | 930        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 352      |
|    time_elapsed    | 109526   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 353        |
|    time_elapsed         | 109799     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.04126139 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.59      |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | 570        |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.384      |
|    value_loss           | 1.24e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 354        |
|    time_elapsed         | 110069     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.10294995 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.57      |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0003     |
|    loss                 | 452        |
|    n_updates            | 3530       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.383      |
|    value_loss           | 1.18e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 355        |
|    time_elapsed         | 110340     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.07572903 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.56      |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | 731        |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.383      |
|    value_loss           | 1.54e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 356        |
|    time_elapsed         | 110612     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.05329841 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.54      |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 510        |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.382      |
|    value_loss           | 1.5e+03    |
----------------------------------------
Eval num_timesteps=730000, episode_reward=1010.86 +/- 0.35
Episode length: 21.20 +/- 1.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.19063792 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 562        |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.382      |
|    value_loss           | 940        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 357      |
|    time_elapsed    | 110895   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 358        |
|    time_elapsed         | 111167     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.06331915 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 436        |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.382      |
|    value_loss           | 1.11e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 359        |
|    time_elapsed         | 111438     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.13757294 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | 527        |
|    n_updates            | 3580       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.382      |
|    value_loss           | 1.09e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 360       |
|    time_elapsed         | 111709    |
|    total_timesteps      | 737280    |
| train/                  |           |
|    approx_kl            | 0.6110337 |
|    clip_fraction        | 0.55      |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.53     |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.0003    |
|    loss                 | 428       |
|    n_updates            | 3590      |
|    policy_gradient_loss | 0.0358    |
|    std                  | 0.382     |
|    value_loss           | 870       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 361         |
|    time_elapsed         | 111980      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.076380804 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.52       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 475         |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.381       |
|    value_loss           | 1.34e+03    |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=1011.19 +/- 0.91
Episode length: 23.80 +/- 4.45
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.10667127 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.49      |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.0003     |
|    loss                 | 407        |
|    n_updates            | 3610       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.379      |
|    value_loss           | 891        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 362      |
|    time_elapsed    | 112264   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 363        |
|    time_elapsed         | 112541     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.06545772 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.48      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 570        |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.379      |
|    value_loss           | 892        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 364         |
|    time_elapsed         | 112815      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.082062945 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.47       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.0003      |
|    loss                 | 404         |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.378       |
|    value_loss           | 723         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 365        |
|    time_elapsed         | 113088     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.07152615 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.46      |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 260        |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.0134    |
|    std                  | 0.378      |
|    value_loss           | 713        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 366        |
|    time_elapsed         | 113360     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.08642745 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.46      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | 441        |
|    n_updates            | 3650       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.377      |
|    value_loss           | 886        |
----------------------------------------
Eval num_timesteps=750000, episode_reward=1011.48 +/- 1.29
Episode length: 22.40 +/- 2.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.06090921 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.46      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 521        |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.378      |
|    value_loss           | 958        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 367      |
|    time_elapsed    | 113643   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 368        |
|    time_elapsed         | 113914     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.07942941 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.45      |
|    explained_variance   | 0.472      |
|    learning_rate        | 0.0003     |
|    loss                 | 843        |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.377      |
|    value_loss           | 1.55e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 369        |
|    time_elapsed         | 114185     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.25721258 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.42      |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.0003     |
|    loss                 | 508        |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.376      |
|    value_loss           | 1.08e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 370        |
|    time_elapsed         | 114457     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.04421723 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.4       |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.0003     |
|    loss                 | 733        |
|    n_updates            | 3690       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.375      |
|    value_loss           | 1.5e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 371         |
|    time_elapsed         | 114728      |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.085946605 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.39       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.0003      |
|    loss                 | 360         |
|    n_updates            | 3700        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.374       |
|    value_loss           | 812         |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=1010.89 +/- 0.38
Episode length: 20.80 +/- 0.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.055407517 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.37       |
|    explained_variance   | 0.59        |
|    learning_rate        | 0.0003      |
|    loss                 | 643         |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 0.374       |
|    value_loss           | 1.1e+03     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 372      |
|    time_elapsed    | 115010   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 373        |
|    time_elapsed         | 115282     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.18455996 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.35      |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | 377        |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.372      |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.3      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 374       |
|    time_elapsed         | 115554    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 0.1104238 |
|    clip_fraction        | 0.359     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.32     |
|    explained_variance   | 0.639     |
|    learning_rate        | 0.0003    |
|    loss                 | 617       |
|    n_updates            | 3730      |
|    policy_gradient_loss | -0.0192   |
|    std                  | 0.371     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 375        |
|    time_elapsed         | 115825     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.08924638 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.3       |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.0003     |
|    loss                 | 531        |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.369      |
|    value_loss           | 1.14e+03   |
----------------------------------------
Eval num_timesteps=770000, episode_reward=1010.43 +/- 0.45
Episode length: 22.40 +/- 2.73
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 22.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.085661404 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.28       |
|    explained_variance   | 0.676       |
|    learning_rate        | 0.0003      |
|    loss                 | 448         |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.369       |
|    value_loss           | 881         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 376      |
|    time_elapsed    | 116108   |
|    total_timesteps | 770048   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.3      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 377       |
|    time_elapsed         | 116385    |
|    total_timesteps      | 772096    |
| train/                  |           |
|    approx_kl            | 0.0703764 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.27     |
|    explained_variance   | 0.65      |
|    learning_rate        | 0.0003    |
|    loss                 | 349       |
|    n_updates            | 3760      |
|    policy_gradient_loss | -0.0175   |
|    std                  | 0.368     |
|    value_loss           | 1.04e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 378         |
|    time_elapsed         | 116660      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.045825876 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.25       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.0003      |
|    loss                 | 413         |
|    n_updates            | 3770        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.367       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 379        |
|    time_elapsed         | 116934     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.23490474 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.25      |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.0003     |
|    loss                 | 554        |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.00616   |
|    std                  | 0.368      |
|    value_loss           | 938        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 380         |
|    time_elapsed         | 117206      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.108904876 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.25       |
|    explained_variance   | 0.626       |
|    learning_rate        | 0.0003      |
|    loss                 | 751         |
|    n_updates            | 3790        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.367       |
|    value_loss           | 997         |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=1011.26 +/- 0.68
Episode length: 20.80 +/- 4.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.07975797 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.22      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 710        |
|    n_updates            | 3800       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.366      |
|    value_loss           | 869        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 381      |
|    time_elapsed    | 117490   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 382        |
|    time_elapsed         | 117762     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.05119659 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.2       |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.0003     |
|    loss                 | 479        |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0223    |
|    std                  | 0.365      |
|    value_loss           | 1.23e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 383        |
|    time_elapsed         | 118034     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.05723204 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.18      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 500        |
|    n_updates            | 3820       |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.364      |
|    value_loss           | 1.03e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 384        |
|    time_elapsed         | 118306     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.13626823 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.16      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.0003     |
|    loss                 | 399        |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.024     |
|    std                  | 0.363      |
|    value_loss           | 787        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.7      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 385       |
|    time_elapsed         | 118579    |
|    total_timesteps      | 788480    |
| train/                  |           |
|    approx_kl            | 0.0519284 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.14     |
|    explained_variance   | 0.58      |
|    learning_rate        | 0.0003    |
|    loss                 | 587       |
|    n_updates            | 3840      |
|    policy_gradient_loss | -0.0223   |
|    std                  | 0.362     |
|    value_loss           | 1.21e+03  |
---------------------------------------
Eval num_timesteps=790000, episode_reward=1010.46 +/- 0.51
Episode length: 21.40 +/- 1.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.09065862 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.13      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.0003     |
|    loss                 | 309        |
|    n_updates            | 3850       |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.362      |
|    value_loss           | 749        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 386      |
|    time_elapsed    | 118862   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 387        |
|    time_elapsed         | 119135     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.07326843 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.11      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 381        |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.0211    |
|    std                  | 0.361      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 388        |
|    time_elapsed         | 119408     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.11541171 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.11      |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | 473        |
|    n_updates            | 3870       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.361      |
|    value_loss           | 1.16e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21.5      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 389       |
|    time_elapsed         | 119681    |
|    total_timesteps      | 796672    |
| train/                  |           |
|    approx_kl            | 0.1048899 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.1      |
|    explained_variance   | 0.704     |
|    learning_rate        | 0.0003    |
|    loss                 | 309       |
|    n_updates            | 3880      |
|    policy_gradient_loss | -0.0217   |
|    std                  | 0.361     |
|    value_loss           | 799       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 390        |
|    time_elapsed         | 119953     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.19237792 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.09      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.0003     |
|    loss                 | 216        |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.00285   |
|    std                  | 0.361      |
|    value_loss           | 761        |
----------------------------------------
Eval num_timesteps=800000, episode_reward=1010.80 +/- 0.70
Episode length: 21.40 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.050715856 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.07       |
|    explained_variance   | 0.663       |
|    learning_rate        | 0.0003      |
|    loss                 | 415         |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0244     |
|    std                  | 0.359       |
|    value_loss           | 885         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 391      |
|    time_elapsed    | 120241   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 392        |
|    time_elapsed         | 120515     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.05974006 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.04      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.0003     |
|    loss                 | 401        |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.023     |
|    std                  | 0.358      |
|    value_loss           | 1.03e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 393       |
|    time_elapsed         | 120788    |
|    total_timesteps      | 804864    |
| train/                  |           |
|    approx_kl            | 0.1358719 |
|    clip_fraction        | 0.404     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.04     |
|    explained_variance   | 0.594     |
|    learning_rate        | 0.0003    |
|    loss                 | 775       |
|    n_updates            | 3920      |
|    policy_gradient_loss | -0.0139   |
|    std                  | 0.358     |
|    value_loss           | 1.13e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 394        |
|    time_elapsed         | 121060     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.20868687 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.04      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.0003     |
|    loss                 | 214        |
|    n_updates            | 3930       |
|    policy_gradient_loss | -0.00221   |
|    std                  | 0.358      |
|    value_loss           | 715        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 395        |
|    time_elapsed         | 121332     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.06115205 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.02      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.0003     |
|    loss                 | 228        |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.024     |
|    std                  | 0.357      |
|    value_loss           | 689        |
----------------------------------------
Eval num_timesteps=810000, episode_reward=1011.63 +/- 1.19
Episode length: 22.40 +/- 3.14
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 22.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.082771465 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3          |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.0003      |
|    loss                 | 290         |
|    n_updates            | 3950        |
|    policy_gradient_loss | -0.00903    |
|    std                  | 0.356       |
|    value_loss           | 760         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 396      |
|    time_elapsed    | 121616   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 397        |
|    time_elapsed         | 121888     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.11413023 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.98      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 358        |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.355      |
|    value_loss           | 677        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 398        |
|    time_elapsed         | 122160     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.16118874 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.97      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.0003     |
|    loss                 | 505        |
|    n_updates            | 3970       |
|    policy_gradient_loss | -0.00373   |
|    std                  | 0.355      |
|    value_loss           | 763        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 399        |
|    time_elapsed         | 122432     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.08488037 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.96      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | 556        |
|    n_updates            | 3980       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.354      |
|    value_loss           | 834        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 400        |
|    time_elapsed         | 122703     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.09024396 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.94      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0003     |
|    loss                 | 520        |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0204    |
|    std                  | 0.353      |
|    value_loss           | 966        |
----------------------------------------
Eval num_timesteps=820000, episode_reward=1010.67 +/- 0.49
Episode length: 21.20 +/- 2.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.10244033 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.94      |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 691        |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.353      |
|    value_loss           | 1.01e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 401      |
|    time_elapsed    | 122986   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 402        |
|    time_elapsed         | 123259     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.08267082 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.93      |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.0003     |
|    loss                 | 566        |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.353      |
|    value_loss           | 817        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 403        |
|    time_elapsed         | 123530     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.11319754 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.91      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 498        |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.352      |
|    value_loss           | 914        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 404        |
|    time_elapsed         | 123801     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.07002498 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.88      |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.0003     |
|    loss                 | 507        |
|    n_updates            | 4030       |
|    policy_gradient_loss | -0.0243    |
|    std                  | 0.35       |
|    value_loss           | 873        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 405         |
|    time_elapsed         | 124078      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.082922965 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.0003      |
|    loss                 | 347         |
|    n_updates            | 4040        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.35        |
|    value_loss           | 1.09e+03    |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=1012.25 +/- 3.29
Episode length: 21.60 +/- 5.39
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.10591975 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.85      |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.0003     |
|    loss                 | 453        |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.349      |
|    value_loss           | 783        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 406      |
|    time_elapsed    | 124362   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 407        |
|    time_elapsed         | 124636     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.15132114 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.84      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0003     |
|    loss                 | 617        |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.00392   |
|    std                  | 0.349      |
|    value_loss           | 1.03e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 408        |
|    time_elapsed         | 124908     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.14340764 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.82      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 470        |
|    n_updates            | 4070       |
|    policy_gradient_loss | -0.00874   |
|    std                  | 0.348      |
|    value_loss           | 719        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 409        |
|    time_elapsed         | 125180     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.07725321 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.81      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.0003     |
|    loss                 | 360        |
|    n_updates            | 4080       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.348      |
|    value_loss           | 722        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 410        |
|    time_elapsed         | 125453     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.14060524 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.79      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 371        |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.347      |
|    value_loss           | 962        |
----------------------------------------
Eval num_timesteps=840000, episode_reward=1010.92 +/- 0.39
Episode length: 19.40 +/- 1.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.18330753 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.75      |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | 317        |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.00813   |
|    std                  | 0.345      |
|    value_loss           | 794        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 411      |
|    time_elapsed    | 125735   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 412        |
|    time_elapsed         | 126007     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.07072433 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.73      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.0003     |
|    loss                 | 246        |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.344      |
|    value_loss           | 701        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 413        |
|    time_elapsed         | 126279     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.09309174 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.73      |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0003     |
|    loss                 | 237        |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.00754   |
|    std                  | 0.345      |
|    value_loss           | 688        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 414        |
|    time_elapsed         | 126551     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.08449227 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.73      |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.0003     |
|    loss                 | 404        |
|    n_updates            | 4130       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.344      |
|    value_loss           | 786        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 415        |
|    time_elapsed         | 126823     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.19980067 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.71      |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0003     |
|    loss                 | 471        |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.343      |
|    value_loss           | 679        |
----------------------------------------
Eval num_timesteps=850000, episode_reward=1010.66 +/- 0.48
Episode length: 20.00 +/- 1.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.10773519 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.69      |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.0003     |
|    loss                 | 435        |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.343      |
|    value_loss           | 738        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 416      |
|    time_elapsed    | 127105   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 417        |
|    time_elapsed         | 127379     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.10553005 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.69      |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.0003     |
|    loss                 | 349        |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.00118   |
|    std                  | 0.343      |
|    value_loss           | 687        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 418        |
|    time_elapsed         | 127651     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.06720472 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 381        |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.342      |
|    value_loss           | 720        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 419         |
|    time_elapsed         | 127923      |
|    total_timesteps      | 858112      |
| train/                  |             |
|    approx_kl            | 0.078636914 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.0003      |
|    loss                 | 466         |
|    n_updates            | 4180        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.342       |
|    value_loss           | 984         |
-----------------------------------------
Eval num_timesteps=860000, episode_reward=1012.02 +/- 2.94
Episode length: 22.40 +/- 3.88
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.09781468 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.66      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.0003     |
|    loss                 | 467        |
|    n_updates            | 4190       |
|    policy_gradient_loss | -0.0124    |
|    std                  | 0.342      |
|    value_loss           | 889        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 420      |
|    time_elapsed    | 128213   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 421        |
|    time_elapsed         | 128487     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.24208802 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.66      |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.0003     |
|    loss                 | 370        |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.341      |
|    value_loss           | 746        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 422        |
|    time_elapsed         | 128762     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.13952534 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.63      |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.0003     |
|    loss                 | 402        |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.34       |
|    value_loss           | 612        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 423         |
|    time_elapsed         | 129035      |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.103896774 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.61       |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.0003      |
|    loss                 | 299         |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.339       |
|    value_loss           | 676         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 424        |
|    time_elapsed         | 129308     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.10100707 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.61      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.0003     |
|    loss                 | 285        |
|    n_updates            | 4230       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.339      |
|    value_loss           | 635        |
----------------------------------------
Eval num_timesteps=870000, episode_reward=1010.82 +/- 0.42
Episode length: 20.80 +/- 2.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.08047988 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.61      |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.0003     |
|    loss                 | 514        |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.0134    |
|    std                  | 0.339      |
|    value_loss           | 809        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 425      |
|    time_elapsed    | 129591   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 426        |
|    time_elapsed         | 129863     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.12328443 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.59      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 437        |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.338      |
|    value_loss           | 899        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 427        |
|    time_elapsed         | 130136     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.18473461 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.59      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.0003     |
|    loss                 | 412        |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.00392   |
|    std                  | 0.339      |
|    value_loss           | 683        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 428        |
|    time_elapsed         | 130408     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.11408544 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.61      |
|    explained_variance   | 0.782      |
|    learning_rate        | 0.0003     |
|    loss                 | 232        |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.00738    |
|    std                  | 0.339      |
|    value_loss           | 504        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 429        |
|    time_elapsed         | 130681     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.11163444 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.6       |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.0003     |
|    loss                 | 175        |
|    n_updates            | 4280       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.338      |
|    value_loss           | 583        |
----------------------------------------
Eval num_timesteps=880000, episode_reward=1010.89 +/- 0.38
Episode length: 20.60 +/- 1.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.114356525 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.677       |
|    learning_rate        | 0.0003      |
|    loss                 | 415         |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.336       |
|    value_loss           | 807         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 430      |
|    time_elapsed    | 130963   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 431        |
|    time_elapsed         | 131235     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.06786389 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 491        |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.336      |
|    value_loss           | 922        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 432        |
|    time_elapsed         | 131508     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.20462543 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 406        |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.00663   |
|    std                  | 0.336      |
|    value_loss           | 850        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 433        |
|    time_elapsed         | 131781     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.09878349 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 428        |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.336      |
|    value_loss           | 922        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 434        |
|    time_elapsed         | 132059     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.15653762 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.54      |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.0003     |
|    loss                 | 213        |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.00559   |
|    std                  | 0.336      |
|    value_loss           | 817        |
----------------------------------------
Eval num_timesteps=890000, episode_reward=1010.70 +/- 0.49
Episode length: 19.60 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.07833174 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.0003     |
|    loss                 | 317        |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.336      |
|    value_loss           | 954        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 435      |
|    time_elapsed    | 132344   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 436        |
|    time_elapsed         | 132618     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.09786989 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.0003     |
|    loss                 | 301        |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.335      |
|    value_loss           | 656        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 437        |
|    time_elapsed         | 132891     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.09075531 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.5       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | 403        |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.0252    |
|    std                  | 0.335      |
|    value_loss           | 881        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 438        |
|    time_elapsed         | 133164     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.10509587 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.0003     |
|    loss                 | 232        |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.00748   |
|    std                  | 0.336      |
|    value_loss           | 508        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 21        |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 439       |
|    time_elapsed         | 133437    |
|    total_timesteps      | 899072    |
| train/                  |           |
|    approx_kl            | 0.0809482 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.53     |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.0003    |
|    loss                 | 277       |
|    n_updates            | 4380      |
|    policy_gradient_loss | -0.0113   |
|    std                  | 0.336     |
|    value_loss           | 599       |
---------------------------------------
Eval num_timesteps=900000, episode_reward=1011.96 +/- 2.48
Episode length: 24.00 +/- 5.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.11300534 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 397        |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.335      |
|    value_loss           | 692        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 440      |
|    time_elapsed    | 133721   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 441        |
|    time_elapsed         | 133993     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.10186994 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.51      |
|    explained_variance   | 0.621      |
|    learning_rate        | 0.0003     |
|    loss                 | 600        |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.335      |
|    value_loss           | 1.02e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 442        |
|    time_elapsed         | 134266     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.15739673 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.51      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 302        |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.00905   |
|    std                  | 0.335      |
|    value_loss           | 663        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 443        |
|    time_elapsed         | 134539     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.06740153 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.0003     |
|    loss                 | 260        |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.336      |
|    value_loss           | 671        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 444        |
|    time_elapsed         | 134812     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.14558034 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.0003     |
|    loss                 | 324        |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.335      |
|    value_loss           | 734        |
----------------------------------------
Eval num_timesteps=910000, episode_reward=1012.79 +/- 4.43
Episode length: 23.20 +/- 7.11
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 23.2      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 910000    |
| train/                  |           |
|    approx_kl            | 0.1445924 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.5      |
|    explained_variance   | 0.73      |
|    learning_rate        | 0.0003    |
|    loss                 | 252       |
|    n_updates            | 4440      |
|    policy_gradient_loss | -0.00374  |
|    std                  | 0.335     |
|    value_loss           | 602       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 445      |
|    time_elapsed    | 135096   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 446        |
|    time_elapsed         | 135368     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.11150571 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.5       |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | 287        |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.0067    |
|    std                  | 0.335      |
|    value_loss           | 900        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 447         |
|    time_elapsed         | 135642      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.099819876 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.51       |
|    explained_variance   | 0.682       |
|    learning_rate        | 0.0003      |
|    loss                 | 358         |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.336       |
|    value_loss           | 706         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 448        |
|    time_elapsed         | 135921     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.09266035 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.0003     |
|    loss                 | 459        |
|    n_updates            | 4470       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.336      |
|    value_loss           | 873        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 449        |
|    time_elapsed         | 136196     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.12488434 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | 317        |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.00228    |
|    std                  | 0.336      |
|    value_loss           | 740        |
----------------------------------------
Eval num_timesteps=920000, episode_reward=1010.68 +/- 0.46
Episode length: 20.40 +/- 1.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.16722643 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.0003     |
|    loss                 | 334        |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.00254    |
|    std                  | 0.337      |
|    value_loss           | 767        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 450      |
|    time_elapsed    | 136482   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 451        |
|    time_elapsed         | 136755     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.13849281 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.51      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.0003     |
|    loss                 | 246        |
|    n_updates            | 4500       |
|    policy_gradient_loss | -0.00056   |
|    std                  | 0.335      |
|    value_loss           | 575        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20        |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 452       |
|    time_elapsed         | 137029    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 0.1023263 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.48     |
|    explained_variance   | 0.765     |
|    learning_rate        | 0.0003    |
|    loss                 | 173       |
|    n_updates            | 4510      |
|    policy_gradient_loss | -0.0187   |
|    std                  | 0.335     |
|    value_loss           | 500       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 453        |
|    time_elapsed         | 137303     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.16285565 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.46      |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.0003     |
|    loss                 | 294        |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.00384   |
|    std                  | 0.333      |
|    value_loss           | 454        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 454         |
|    time_elapsed         | 137576      |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.092941634 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.0003      |
|    loss                 | 206         |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.332       |
|    value_loss           | 618         |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=1010.85 +/- 0.36
Episode length: 21.00 +/- 2.83
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 21        |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 930000    |
| train/                  |           |
|    approx_kl            | 0.1524626 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.41     |
|    explained_variance   | 0.722     |
|    learning_rate        | 0.0003    |
|    loss                 | 343       |
|    n_updates            | 4540      |
|    policy_gradient_loss | -0.0117   |
|    std                  | 0.332     |
|    value_loss           | 635       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 455      |
|    time_elapsed    | 137860   |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 456        |
|    time_elapsed         | 138134     |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.13542713 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.4       |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.0003     |
|    loss                 | 326        |
|    n_updates            | 4550       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.331      |
|    value_loss           | 562        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 457        |
|    time_elapsed         | 138407     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.24499351 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.39      |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.0003     |
|    loss                 | 271        |
|    n_updates            | 4560       |
|    policy_gradient_loss | -0.01      |
|    std                  | 0.331      |
|    value_loss           | 483        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 458        |
|    time_elapsed         | 138680     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.07725501 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.39      |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.0003     |
|    loss                 | 302        |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.00981   |
|    std                  | 0.331      |
|    value_loss           | 680        |
----------------------------------------
Eval num_timesteps=940000, episode_reward=1011.82 +/- 2.57
Episode length: 22.40 +/- 3.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.08248796 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.36      |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.0003     |
|    loss                 | 351        |
|    n_updates            | 4580       |
|    policy_gradient_loss | -0.00969   |
|    std                  | 0.33       |
|    value_loss           | 721        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 459      |
|    time_elapsed    | 138964   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 460        |
|    time_elapsed         | 139237     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.10215774 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.34      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 416        |
|    n_updates            | 4590       |
|    policy_gradient_loss | -0.00659   |
|    std                  | 0.329      |
|    value_loss           | 721        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 461        |
|    time_elapsed         | 139511     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.08013539 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.32      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 343        |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.328      |
|    value_loss           | 715        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 462       |
|    time_elapsed         | 139787    |
|    total_timesteps      | 946176    |
| train/                  |           |
|    approx_kl            | 0.5967761 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.31     |
|    explained_variance   | 0.74      |
|    learning_rate        | 0.0003    |
|    loss                 | 241       |
|    n_updates            | 4610      |
|    policy_gradient_loss | 0.0305    |
|    std                  | 0.328     |
|    value_loss           | 614       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 463        |
|    time_elapsed         | 140063     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.10255566 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.29      |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.0003     |
|    loss                 | 263        |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.327      |
|    value_loss           | 563        |
----------------------------------------
Eval num_timesteps=950000, episode_reward=1010.60 +/- 0.54
Episode length: 22.00 +/- 3.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 22          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.083995946 |
|    clip_fraction        | 0.422       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.0003      |
|    loss                 | 297         |
|    n_updates            | 4630        |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.327       |
|    value_loss           | 541         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 464      |
|    time_elapsed    | 140349   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 465        |
|    time_elapsed         | 140622     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.13065664 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.27      |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.0003     |
|    loss                 | 231        |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.326      |
|    value_loss           | 613        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 466        |
|    time_elapsed         | 140896     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.30538014 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.25      |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.0003     |
|    loss                 | 174        |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.325      |
|    value_loss           | 384        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 467        |
|    time_elapsed         | 141170     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.08855646 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.24      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.0003     |
|    loss                 | 163        |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.00754   |
|    std                  | 0.325      |
|    value_loss           | 514        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 468        |
|    time_elapsed         | 141443     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.07227795 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.24      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | 353        |
|    n_updates            | 4670       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.325      |
|    value_loss           | 738        |
----------------------------------------
Eval num_timesteps=960000, episode_reward=1010.63 +/- 0.76
Episode length: 20.60 +/- 1.74
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.11481269 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.24      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 322        |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.00805   |
|    std                  | 0.324      |
|    value_loss           | 592        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 469      |
|    time_elapsed    | 141726   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 470        |
|    time_elapsed         | 141999     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.14420535 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.21      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | 257        |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.00298   |
|    std                  | 0.324      |
|    value_loss           | 733        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 471        |
|    time_elapsed         | 142272     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.19532745 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.2       |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.0003     |
|    loss                 | 280        |
|    n_updates            | 4700       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.324      |
|    value_loss           | 535        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.8      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 472       |
|    time_elapsed         | 142545    |
|    total_timesteps      | 966656    |
| train/                  |           |
|    approx_kl            | 0.6333862 |
|    clip_fraction        | 0.52      |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.2      |
|    explained_variance   | 0.73      |
|    learning_rate        | 0.0003    |
|    loss                 | 241       |
|    n_updates            | 4710      |
|    policy_gradient_loss | 0.026     |
|    std                  | 0.323     |
|    value_loss           | 625       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 473        |
|    time_elapsed         | 142818     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.10048795 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.18      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.0003     |
|    loss                 | 282        |
|    n_updates            | 4720       |
|    policy_gradient_loss | -0.00894   |
|    std                  | 0.322      |
|    value_loss           | 619        |
----------------------------------------
Eval num_timesteps=970000, episode_reward=1010.34 +/- 0.40
Episode length: 19.40 +/- 1.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.116947934 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 193         |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.323       |
|    value_loss           | 463         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 474      |
|    time_elapsed    | 143101   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 475        |
|    time_elapsed         | 143374     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.11017144 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.17      |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.0003     |
|    loss                 | 262        |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.322      |
|    value_loss           | 523        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 476        |
|    time_elapsed         | 143650     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.15061182 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.14      |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.0003     |
|    loss                 | 254        |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.00789   |
|    std                  | 0.321      |
|    value_loss           | 503        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 477       |
|    time_elapsed         | 143924    |
|    total_timesteps      | 976896    |
| train/                  |           |
|    approx_kl            | 0.2717661 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.1      |
|    explained_variance   | 0.777     |
|    learning_rate        | 0.0003    |
|    loss                 | 206       |
|    n_updates            | 4760      |
|    policy_gradient_loss | 0.00529   |
|    std                  | 0.319     |
|    value_loss           | 475       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 478        |
|    time_elapsed         | 144199     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.13261075 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.09      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 498        |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.00758   |
|    std                  | 0.32       |
|    value_loss           | 739        |
----------------------------------------
Eval num_timesteps=980000, episode_reward=1010.62 +/- 0.77
Episode length: 21.60 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.12779354 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.1       |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.0003     |
|    loss                 | 257        |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.32       |
|    value_loss           | 491        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 479      |
|    time_elapsed    | 144482   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 480        |
|    time_elapsed         | 144755     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.14706883 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.11      |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.0003     |
|    loss                 | 267        |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.0054    |
|    std                  | 0.32       |
|    value_loss           | 630        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 481        |
|    time_elapsed         | 145028     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.10021227 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.11      |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.0003     |
|    loss                 | 263        |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.32       |
|    value_loss           | 542        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 482        |
|    time_elapsed         | 145300     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.11254424 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.1       |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.0003     |
|    loss                 | 359        |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.00889   |
|    std                  | 0.319      |
|    value_loss           | 496        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 483        |
|    time_elapsed         | 145572     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.31302497 |
|    clip_fraction        | 0.521      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.1       |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.0003     |
|    loss                 | 401        |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.319      |
|    value_loss           | 537        |
----------------------------------------
Eval num_timesteps=990000, episode_reward=1011.43 +/- 2.68
Episode length: 20.20 +/- 4.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.13624272 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.1       |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0003     |
|    loss                 | 550        |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0014     |
|    std                  | 0.319      |
|    value_loss           | 673        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 484      |
|    time_elapsed    | 145854   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 485        |
|    time_elapsed         | 146126     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.16067414 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.09      |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.0003     |
|    loss                 | 224        |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.319      |
|    value_loss           | 541        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 486        |
|    time_elapsed         | 146398     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.10198845 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.08      |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.0003     |
|    loss                 | 325        |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.000928   |
|    std                  | 0.318      |
|    value_loss           | 548        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 487        |
|    time_elapsed         | 146669     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.12824152 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.07      |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.0003     |
|    loss                 | 483        |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.318      |
|    value_loss           | 656        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.5      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 488       |
|    time_elapsed         | 146942    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.0833501 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.07     |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.0003    |
|    loss                 | 252       |
|    n_updates            | 4870      |
|    policy_gradient_loss | -0.0112   |
|    std                  | 0.318     |
|    value_loss           | 598       |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=1010.67 +/- 0.51
Episode length: 19.80 +/- 1.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.18375096 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.06      |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0003     |
|    loss                 | 391        |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.318      |
|    value_loss           | 544        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 6        |
|    iterations      | 489      |
|    time_elapsed    | 147224   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-02-02_18-32-35_llm_triton_qwen_32b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 1 day, 16:50:19 < 0:00:00 , 7 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.373617  -99.289338  -99.333832  -99.518051  -99.631532]
 [ -99.150024  -99.284887  -99.461101  -99.270299  -99.370821]
 [ -98.998895  -99.380143  -99.589564  -99.117776  -99.331328]
 [ -98.955202  -98.876698  -98.110739  -98.740722  -99.229437]
 [ -97.562494  -98.718908  -98.364449  -98.731827  -98.237185]
 [  58.059885   81.592567   63.798369   98.622061   80.195757]
 [ 177.450605  182.725625  188.157661  194.042132  177.652227]
 [1103.466493  341.939055 1119.760946 1303.777824 1039.114568]
 [1302.882864 1071.986303 1252.139802 1446.140162 1249.526105]
 [1077.621778 1149.894645 1104.267722 1064.70166  1079.065457]
 [1109.03517  1016.14477  1009.998627 1068.712211 1018.496591]
 [1023.423344 1010.968278 1011.04142  1015.187312 1010.940169]
 [1040.210147 1011.87772  1010.006896 1021.037116 1030.94519 ]
 [1023.941172 1010.049082 1010.944233 1011.80214  1010.974355]
 [1010.868173 1010.101899 1011.059583 1013.674523 1010.044298]
 [1019.643088 1018.35946  1011.064167 1010.89476  1011.613986]
 [1011.094338 1016.422691 1012.947141 1010.016129 1028.791681]
 [1011.829436 1013.819233 1026.205479 1010.089429 1011.043551]
 [1011.629759 1018.537275 1022.343271 1023.341851 1010.726967]
 [1011.018278 1010.916254 1011.036722 1020.513748 1020.248693]
 [1011.657846 1012.748764 1018.667491 1021.910382 1031.244527]
 [1011.944275 1010.065435 1011.59884  1019.506456 1017.703266]
 [1013.778549 1024.400876 1013.627176 1010.926767 1011.049881]
 [1010.94426  1011.026675 1010.972854 1009.947863 1010.962791]
 [1010.982479 1010.93806  1010.873028 1010.036862 1014.628555]
 [1039.366505 1010.764998 1011.063539 1014.786296 1010.087191]
 [1011.901543 1009.897704 1009.918481 1011.857374 1020.620289]
 [1014.72664  1011.81033  1013.54203  1013.666336 1010.787941]
 [1019.464103 1010.082882 1017.53783  1010.836154 1011.045652]
 [1011.024    1010.093826 1009.857973 1011.00533  1035.964037]
 [1025.340144 1021.153142 1011.882604 1012.68353  1014.729494]
 [1011.056642 1011.921503 1009.956388 1010.105876 1011.049626]
 [1010.050338 1014.780458 1019.521685 1010.06029  1023.541015]
 [1010.010834 1010.042355 1015.851544 1018.547353 1012.679113]
 [1010.994829 1011.86003  1032.13605  1010.98645  1011.097729]
 [1011.840686 1011.001736 1010.018598 1012.766827 1014.844907]
 [1010.971052 1010.026099 1010.114205 1011.058648 1011.858296]
 [1015.82789  1015.734212 1020.394425 1016.838609 1011.006916]
 [1016.670337 1013.901857 1011.947453 1011.044729 1016.79822 ]
 [1011.055067 1014.717074 1011.919365 1011.040636 1010.056812]
 [1009.87639  1010.999036 1020.57308  1016.815326 1011.566496]
 [1021.475826 1010.986915 1011.03328  1010.989412 1010.872469]
 [1011.768867 1009.961436 1024.52185  1015.762478 1009.954076]
 [1015.727897 1012.821233 1010.938127 1011.733472 1010.014774]
 [1010.056773 1010.110313 1012.929498 1010.878521 1010.904522]
 [1028.396526 1011.037999 1018.602354 1018.312335 1010.010393]
 [1009.990438 1009.982802 1011.12397  1011.001029 1009.960095]
 [1013.851756 1010.032999 1019.567311 1010.062598 1017.787366]
 [1017.726543 1009.995054 1024.434743 1009.983154 1010.082806]
 [1011.051433 1010.0947   1010.009896 1018.731895 1010.022208]
 [1011.893427 1011.022756 1010.04716  1010.101661 1012.659266]
 [1011.058551 1014.795359 1014.963064 1011.05402  1011.139073]
 [1010.077532 1011.095736 1014.858067 1010.140828 1016.774488]
 [1010.054932 1011.062734 1010.039749 1011.026974 1010.956203]
 [1011.125462 1011.162981 1010.142805 1010.988212 1011.106513]
 [1010.056606 1014.763618 1011.125921 1010.036487 1010.981032]
 [1017.788479 1011.00292  1010.106104 1011.959032 1015.655915]
 [1011.180612 1010.161479 1013.980069 1011.075215 1011.073315]
 [1010.994098 1011.005639 1010.070303 1010.054816 1016.666318]
 [1010.037291 1011.967959 1011.109536 1010.095621 1011.047499]
 [1009.985497 1013.95682  1016.782991 1010.042888 1013.873481]
 [1011.002709 1024.589442 1011.078748 1010.087627 1011.064261]
 [1010.011701 1011.004615 1011.093672 1011.044645 1011.034407]
 [1009.985904 1012.030021 1010.114634 1010.09215  1010.938552]
 [1009.945463 1011.994768 1010.032842 1010.934735 1011.002712]
 [1010.015486 1018.105334 1010.130233 1013.826409 1014.755927]
 [1011.015896 1015.789179 1010.079789 1009.999057 1010.085423]
 [1011.084304 1010.914248 1011.904242 1010.895401 1010.027641]
 [1011.977359 1011.049189 1010.048163 1016.840204 1010.030809]
 [1010.133426 1010.06145  1011.007208 1010.07855  1010.161555]
 [1010.086739 1010.942168 1011.886395 1011.04878  1010.0618  ]
 [1011.053479 1011.034648 1010.06284  1012.935057 1010.939263]
 [1011.057883 1011.051699 1010.896392 1010.165768 1011.125345]
 [1011.799184 1010.069113 1010.079675 1011.921017 1012.062189]
 [1011.01343  1011.164653 1011.106145 1013.952779 1010.154603]
 [1011.098405 1011.078743 1011.106268 1010.137453 1011.013935]
 [1010.11193  1010.974677 1010.139158 1009.948677 1010.978983]
 [1011.102917 1010.102567 1011.933889 1011.969565 1011.166239]
 [1011.066183 1011.099085 1009.958288 1010.036911 1010.143971]
 [1010.08585  1011.958884 1011.042883 1010.055706 1010.843055]
 [1010.924081 1011.138211 1011.059665 1011.029513 1014.00545 ]
 [1010.030177 1010.09247  1011.10478  1011.022024 1011.080293]
 [1011.063199 1010.104657 1018.767496 1010.205882 1011.100094]
 [1011.053462 1011.120627 1011.09048  1010.148407 1011.201699]
 [1010.094097 1010.068333 1011.041786 1011.009958 1011.109968]
 [1011.028785 1017.840852 1010.084166 1011.082364 1010.062516]
 [1011.117443 1010.870287 1011.065236 1011.072081 1009.990792]
 [1011.090172 1011.088858 1011.088438 1011.036369 1010.132981]
 [1010.042304 1011.104156 1010.162553 1010.998235 1011.168831]
 [1011.923331 1011.078957 1010.093447 1010.005576 1016.714192]
 [1011.070145 1010.10427  1010.155383 1021.606846 1011.00967 ]
 [1010.112818 1011.055756 1010.113183 1011.097101 1011.007293]
 [1010.122384 1011.09048  1011.000854 1010.963025 1011.056382]
 [1016.873306 1010.001275 1011.092278 1011.11877  1010.03416 ]
 [1011.096195 1009.844658 1010.949775 1010.052666 1011.041557]
 [1010.04077  1010.007978 1011.93955  1010.092025 1011.047092]
 [1011.135761 1010.135336 1010.18024  1010.170818 1010.065515]
 [1011.927159 1010.046409 1011.074514 1010.073048 1009.9976  ]
 [1016.792321 1010.10579  1010.124346 1010.056474 1010.077696]
 [1011.064622 1010.055083 1011.063997 1010.028985 1011.117336]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3587 3601 3601]
 [3599 3601 3601 3601 3601]
 [3600 3601 3601 3601 3555]
 [3601 3601 3601 3601 3601]
 [3596 3583 3601 3601 3601]
 [3601 3601 3601 3597 3594]
 [3601 3601 3601 3601 3601]
 [1135 3601 1505 2839  319]
 [1564  332 1393 2434 1353]
 [ 343  753  545  267  291]
 [ 407   96   21  221   78]
 [  90   25   24   54   26]
 [  95   27   22   58   99]
 [  63   20   23   28   23]
 [  28   58   22   33   22]
 [  38   48   21   24   39]
 [  22   43   26   22   69]
 [  29   31   55   22   21]
 [  35   38   51   50   34]
 [  20   26   21   40   50]
 [  34   30   36   63   89]
 [  24   22   40   40   33]
 [  33   46   35   26   22]
 [  25   23   23   26   25]
 [  22   23   29   23   37]
 [  86   32   22   31   22]
 [  26   28   27   30   40]
 [  36   30   38   33   32]
 [  45   21   43   29   20]
 [  24   20   29   21   62]
 [  49   52   25   37   33]
 [  24   28   22   19   23]
 [  23   30   42   20   41]
 [  24   23   30   41   33]
 [  24   27   57   21   19]
 [  29   23   23   30   31]
 [  23   21   19   22   29]
 [  28   32   44   29   23]
 [  36   29   24   20   31]
 [  21   33   29   24   22]
 [  28   22   40   29   39]
 [  44   23   20   24   30]
 [  29   25   42   30   23]
 [  33   30   26   35   21]
 [  21   18   29   25   26]
 [  45   22   39   49   21]
 [  23   21   17   20   26]
 [  29   20   39   18   33]
 [  35   21   47   21   20]
 [  20   18   20   32   23]
 [  26   24   21   21   38]
 [  18   30   24   23   20]
 [  20   21   30   19   30]
 [  19   19   19   24   22]
 [  20   18   17   23   21]
 [  23   31   19   21   23]
 [  29   22   22   25   37]
 [  19   19   24   21   20]
 [  21   21   22   21   35]
 [  23   26   19   20   22]
 [  23   22   29   20   27]
 [  21   42   21   22   21]
 [  22   24   18   21   21]
 [  21   20   21   19   24]
 [  23   25   23   26   21]
 [  21   11   20   29   31]
 [  20   31   20   21   21]
 [  18   25   25   27   21]
 [  24   21   22   27   23]
 [  20   18   20   22   19]
 [  19   23   27   22   22]
 [  20   21   22   25   24]
 [  22   21   24   18   21]
 [  31   18   21   26   23]
 [  24   19   22   27   20]
 [  20   22   21   20   21]
 [  21   26   18   24   23]
 [  17   16   28   23   20]
 [  21   21   25   20   20]
 [  20   25   22   21   19]
 [  28   19   20   22   23]
 [  22   23   19   24   18]
 [  20   17   32   18   21]
 [  19   20   21   19   18]
 [  18   20   20   21   21]
 [  21   30   19   21   21]
 [  19   26   19   19   21]
 [  23   20   19   21   20]
 [  22   18   18   22   18]
 [  27   20   18   22   33]
 [  21   17   19   37   22]
 [  21   22   19   18   22]
 [  18   20   22   26   19]
 [  29   20   19   21   23]
 [  18   27   26   20   19]
 [  20   20   24   20   19]
 [  21   19   18   19   20]
 [  25   19   21   21   22]
 [  29   18   16   18   20]
 [  22   20   19   21   17]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-02-02_18-32-35_llm_triton_qwen_32b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-02-02_18-32-35_llm_triton_qwen_32b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/model
