####################
/var/spool/slurmd/job5228068/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_3B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_1_example_explanation.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-20_12-13-39_llm_triton_qwen_3b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 1
 
 Explanation (Do not generate this in your output): The particle started at (17.25, -160.50) and ended at (16.50, -159.75), while the goal was at (5.75, -57.00). The distance to the goal at starting position was 104.13 while the distance at ending position was 103.31. Since, 103.31 < 104.13, the particle moved closer to the goal the score should be positive. But the magnitude of reduction in distance isn't very high so the magnitude should be low. Therfore, a score of 1 seems appropriate.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 8    |
|    iterations      | 1    |
|    time_elapsed    | 239  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.12e+03    |
|    ep_rew_mean          | -122        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 2           |
|    time_elapsed         | 475         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.013610652 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0606     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0274     |
|    std                  | 0.995       |
|    value_loss           | 2.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.12e+03    |
|    ep_rew_mean          | -122        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 3           |
|    time_elapsed         | 707         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.012109185 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.843       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0256     |
|    std                  | 0.996       |
|    value_loss           | 1.91        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.14e+03  |
|    ep_rew_mean          | -73.3     |
| time/                   |           |
|    fps                  | 8         |
|    iterations           | 4         |
|    time_elapsed         | 937       |
|    total_timesteps      | 8192      |
| train/                  |           |
|    approx_kl            | 0.0129856 |
|    clip_fraction        | 0.178     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.3     |
|    explained_variance   | 0.202     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.804     |
|    n_updates            | 30        |
|    policy_gradient_loss | -0.0286   |
|    std                  | 0.995     |
|    value_loss           | 2.21      |
---------------------------------------
Eval num_timesteps=10000, episode_reward=-99.93 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.013602243 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0196      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.636       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0237     |
|    std                  | 0.996       |
|    value_loss           | 2.15        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -124     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2967     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -124         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 6            |
|    time_elapsed         | 3192         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0032331431 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00231     |
|    learning_rate        | 0.0003       |
|    loss                 | 2.92         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00387     |
|    std                  | 0.997        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.65e+03    |
|    ep_rew_mean          | -72         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3417        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.016036106 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -1.17       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.791       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.995       |
|    value_loss           | 1.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.65e+03    |
|    ep_rew_mean          | -72         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3640        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.013897799 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0546     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.989       |
|    value_loss           | 1.21        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.76e+03   |
|    ep_rew_mean          | -32.4      |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 9          |
|    time_elapsed         | 3863       |
|    total_timesteps      | 18432      |
| train/                  |            |
|    approx_kl            | 0.01463189 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.067      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.654      |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.984      |
|    value_loss           | 1.47       |
----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.81 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.016678022 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0949     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.447       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.983       |
|    value_loss           | 1.32        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -54.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5892     |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -54.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 6117        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.012974953 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.000105   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.02        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00548    |
|    std                  | 0.982       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.59e+03  |
|    ep_rew_mean          | -18.4     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 12        |
|    time_elapsed         | 6338      |
|    total_timesteps      | 24576     |
| train/                  |           |
|    approx_kl            | 0.0190534 |
|    clip_fraction        | 0.241     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.2     |
|    explained_variance   | -0.278    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.341     |
|    n_updates            | 110       |
|    policy_gradient_loss | -0.0112   |
|    std                  | 0.984     |
|    value_loss           | 0.954     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.59e+03    |
|    ep_rew_mean          | -18.4       |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6557        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.019019175 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.165      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.977       |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.66e+03    |
|    ep_rew_mean          | 17.4        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6778        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.015760798 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00367     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.391       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.977       |
|    value_loss           | 0.834       |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.75 +/- 0.06
Episode length: 3595.60 +/- 10.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.8        |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0144301485 |
|    clip_fraction        | 0.169        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.255        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.577        |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.0158      |
|    std                  | 0.971        |
|    value_loss           | 1.21         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -1.19    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8803     |
|    total_timesteps | 30720    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -1.19      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 16         |
|    time_elapsed         | 9022       |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.01797233 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.0398     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+03   |
|    n_updates            | 150        |
|    policy_gradient_loss | -0.00901   |
|    std                  | 0.967      |
|    value_loss           | 781        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.57e+03    |
|    ep_rew_mean          | 30.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 9239        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.016353337 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.0587     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.964       |
|    value_loss           | 0.697       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.63e+03   |
|    ep_rew_mean          | 59.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 18         |
|    time_elapsed         | 9457       |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.01759659 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 1          |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.955      |
|    value_loss           | 1.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.63e+03    |
|    ep_rew_mean          | 59.4        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9674        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.019062439 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.084      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.314       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.95        |
|    value_loss           | 0.652       |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.79 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 40000      |
| train/                  |            |
|    approx_kl            | 0.01556652 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.00893   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.197      |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.948      |
|    value_loss           | 0.431      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.67e+03 |
|    ep_rew_mean     | 52.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11691    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.67e+03    |
|    ep_rew_mean          | 52.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 11910       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.019751266 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -5.81e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 43.2        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00415    |
|    std                  | 0.95        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.71e+03    |
|    ep_rew_mean          | 79.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 12127       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.022280306 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.181      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00864    |
|    std                  | 0.949       |
|    value_loss           | 0.692       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.75e+03   |
|    ep_rew_mean          | 103        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 23         |
|    time_elapsed         | 12344      |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.01753069 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.291      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.946      |
|    value_loss           | 1.33       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.75e+03  |
|    ep_rew_mean          | 103       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 24        |
|    time_elapsed         | 12561     |
|    total_timesteps      | 49152     |
| train/                  |           |
|    approx_kl            | 0.0180965 |
|    clip_fraction        | 0.227     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.9     |
|    explained_variance   | -1.31     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.303     |
|    n_updates            | 230       |
|    policy_gradient_loss | -0.0128   |
|    std                  | 0.945     |
|    value_loss           | 1.64      |
---------------------------------------
Eval num_timesteps=50000, episode_reward=-99.76 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.015395863 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0124     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.258       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00564    |
|    std                  | 0.947       |
|    value_loss           | 0.545       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.78e+03 |
|    ep_rew_mean     | 94.6     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14582    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.78e+03    |
|    ep_rew_mean          | 94.6        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 14801       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.013327282 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00179    |
|    learning_rate        | 0.0003      |
|    loss                 | 46.9        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00263    |
|    std                  | 0.948       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.81e+03    |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 15019       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.023273509 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0788     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00822    |
|    std                  | 0.949       |
|    value_loss           | 0.579       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.84e+03    |
|    ep_rew_mean          | 137         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 15235       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.020635279 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.204      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00627    |
|    std                  | 0.944       |
|    value_loss           | 0.815       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.84e+03    |
|    ep_rew_mean          | 137         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 15451       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.016902246 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -1.25       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.229       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00624    |
|    std                  | 0.945       |
|    value_loss           | 0.639       |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.73 +/- 0.01
Episode length: 3597.00 +/- 6.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.01719065 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.00312   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.256      |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.00798   |
|    std                  | 0.94       |
|    value_loss           | 0.552      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.86e+03 |
|    ep_rew_mean     | 130      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 17473    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.88e+03    |
|    ep_rew_mean          | 148         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17693       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.020829901 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.00139    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.35        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00871    |
|    std                  | 0.939       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.88e+03    |
|    ep_rew_mean          | 148         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17909       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.025968298 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.049      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.21        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00483    |
|    std                  | 0.94        |
|    value_loss           | 0.488       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.9e+03      |
|    ep_rew_mean          | 165          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 33           |
|    time_elapsed         | 18127        |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0148327425 |
|    clip_fraction        | 0.192        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | 0.000201     |
|    learning_rate        | 0.0003       |
|    loss                 | 0.178        |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00101     |
|    std                  | 0.943        |
|    value_loss           | 0.501        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.9e+03      |
|    ep_rew_mean          | 165          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 34           |
|    time_elapsed         | 18343        |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0149272075 |
|    clip_fraction        | 0.206        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.04         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00837     |
|    std                  | 0.941        |
|    value_loss           | 1.57         |
------------------------------------------
Eval num_timesteps=70000, episode_reward=-99.73 +/- 0.10
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.017977986 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0275     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.177       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00792    |
|    std                  | 0.938       |
|    value_loss           | 0.405       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.92e+03 |
|    ep_rew_mean     | 158      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 20361    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.94e+03    |
|    ep_rew_mean          | 173         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20577       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.022806652 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.000767   |
|    learning_rate        | 0.0003      |
|    loss                 | 22.9        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00709    |
|    std                  | 0.935       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.94e+03    |
|    ep_rew_mean          | 173         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20794       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.021942358 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0178     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.208       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00355    |
|    std                  | 0.936       |
|    value_loss           | 0.476       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.96e+03    |
|    ep_rew_mean          | 188         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 21011       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.018396009 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00041     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.174       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.00362    |
|    std                  | 0.937       |
|    value_loss           | 0.493       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.96e+03    |
|    ep_rew_mean          | 188         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 21233       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.021356385 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.302       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00889    |
|    std                  | 0.935       |
|    value_loss           | 1.48        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.71 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.019010182 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0294     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0661      |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.936       |
|    value_loss           | 0.33        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.96e+03 |
|    ep_rew_mean     | 181      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 23251    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.98e+03    |
|    ep_rew_mean          | 194         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 23469       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.021081215 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.000181   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.935       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.98e+03    |
|    ep_rew_mean          | 194         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23685       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.017719856 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.895      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.247       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00792    |
|    std                  | 0.933       |
|    value_loss           | 0.791       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.99e+03    |
|    ep_rew_mean          | 206         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23901       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.016824797 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0166     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00654    |
|    std                  | 0.93        |
|    value_loss           | 0.384       |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.77 +/- 0.10
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.022579456 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 1.86e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.215       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00311    |
|    std                  | 0.932       |
|    value_loss           | 0.428       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3e+03    |
|    ep_rew_mean     | 200      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25921    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | 200         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 26136       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.026107365 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -2.11e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.01        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0059     |
|    std                  | 0.936       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.01e+03    |
|    ep_rew_mean          | 212         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 26351       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.026758384 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0132     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.235       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00544    |
|    std                  | 0.933       |
|    value_loss           | 0.439       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.01e+03    |
|    ep_rew_mean          | 212         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 26565       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.020017687 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.211      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.204       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00409    |
|    std                  | 0.928       |
|    value_loss           | 0.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.03e+03    |
|    ep_rew_mean          | 223         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26780       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.019301629 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0081     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.162       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00432    |
|    std                  | 0.927       |
|    value_loss           | 0.374       |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.74 +/- 0.12
Episode length: 3598.80 +/- 3.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.016011495 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000976   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00172    |
|    std                  | 0.926       |
|    value_loss           | 0.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.03e+03 |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28798    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.03e+03    |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 29012       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.028082192 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.000158    |
|    learning_rate        | 0.0003      |
|    loss                 | 445         |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00626    |
|    std                  | 0.926       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.04e+03    |
|    ep_rew_mean          | 228         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 29227       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.022818152 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0471     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.197       |
|    n_updates            | 500         |
|    policy_gradient_loss | 0.000801    |
|    std                  | 0.925       |
|    value_loss           | 0.418       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.04e+03    |
|    ep_rew_mean          | 228         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 29442       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.023407396 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -1.65       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.000745   |
|    std                  | 0.922       |
|    value_loss           | 0.45        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.05e+03    |
|    ep_rew_mean          | 239         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 29657       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.021988746 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000437   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.143       |
|    n_updates            | 520         |
|    policy_gradient_loss | 0.00181     |
|    std                  | 0.924       |
|    value_loss           | 0.348       |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.82 +/- 0.10
Episode length: 3596.00 +/- 7.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.031147074 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.485       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.554       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.922       |
|    value_loss           | 1.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.06e+03 |
|    ep_rew_mean     | 233      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 31677    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.06e+03    |
|    ep_rew_mean          | 233         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31893       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.021033265 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -4.63e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 414         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00475    |
|    std                  | 0.922       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.07e+03    |
|    ep_rew_mean          | 242         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 32108       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.025666174 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.841      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.21        |
|    n_updates            | 550         |
|    policy_gradient_loss | 0.002       |
|    std                  | 0.918       |
|    value_loss           | 0.351       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.07e+03   |
|    ep_rew_mean          | 242        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 57         |
|    time_elapsed         | 32322      |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.02569313 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -2.75      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.00712   |
|    std                  | 0.915      |
|    value_loss           | 0.567      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.08e+03    |
|    ep_rew_mean          | 251         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 32543       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.023097124 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -4.39e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.184       |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.00429     |
|    std                  | 0.915       |
|    value_loss           | 0.385       |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.77 +/- 0.12
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.024755565 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.355       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00822    |
|    std                  | 0.916       |
|    value_loss           | 2.4         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.08e+03 |
|    ep_rew_mean     | 242      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 34559    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.08e+03    |
|    ep_rew_mean          | 242         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 34773       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.034994606 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000994   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.53e+03    |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.000142   |
|    std                  | 0.915       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.09e+03    |
|    ep_rew_mean          | 251         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34986       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.017273856 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00815    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.144       |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.00435     |
|    std                  | 0.915       |
|    value_loss           | 0.399       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.09e+03    |
|    ep_rew_mean          | 260         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 35202       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.027630031 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.000314    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.156       |
|    n_updates            | 610         |
|    policy_gradient_loss | 0.00413     |
|    std                  | 0.915       |
|    value_loss           | 0.343       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.09e+03    |
|    ep_rew_mean          | 260         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 35417       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.022899438 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.516       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.385       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0057     |
|    std                  | 0.915       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.70 +/- 0.08
Episode length: 3597.00 +/- 8.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.021017186 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.215      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.176       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00234    |
|    std                  | 0.918       |
|    value_loss           | 0.396       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.1e+03  |
|    ep_rew_mean     | 255      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 37435    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.1e+03     |
|    ep_rew_mean          | 255         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 37652       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.030345473 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -9.89e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 127         |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00154    |
|    std                  | 0.923       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.1e+03     |
|    ep_rew_mean          | 264         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 37867       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.017278904 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00224    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.144       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.000855   |
|    std                  | 0.921       |
|    value_loss           | 0.338       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.11e+03   |
|    ep_rew_mean          | 271        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 67         |
|    time_elapsed         | 38085      |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.03542304 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.0132    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.101      |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.00168   |
|    std                  | 0.916      |
|    value_loss           | 0.312      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.11e+03    |
|    ep_rew_mean          | 271         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 38300       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.026331998 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.797       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00863    |
|    std                  | 0.918       |
|    value_loss           | 1.9         |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.75 +/- 0.11
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.025370311 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00456    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.15        |
|    n_updates            | 680         |
|    policy_gradient_loss | -3.76e-05   |
|    std                  | 0.92        |
|    value_loss           | 0.332       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.11e+03 |
|    ep_rew_mean     | 265      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 40316    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.11e+03    |
|    ep_rew_mean          | 265         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 40531       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.026991958 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000417   |
|    learning_rate        | 0.0003      |
|    loss                 | 928         |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.922       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.12e+03    |
|    ep_rew_mean          | 272         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 40746       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.023125399 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000139   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.219       |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.0031      |
|    std                  | 0.925       |
|    value_loss           | 0.461       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | 279         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40960       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.021142323 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00259    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.159       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.000632   |
|    std                  | 0.924       |
|    value_loss           | 0.441       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | 279         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 41175       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.024469858 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0364     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.155       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00244    |
|    std                  | 0.925       |
|    value_loss           | 0.281       |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.70 +/- 0.08
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.02278103 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.00115   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.218      |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00177   |
|    std                  | 0.926      |
|    value_loss           | 0.499      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.13e+03 |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 43197    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | 281         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 43413       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.035564546 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -2.74e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 65.5        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00229    |
|    std                  | 0.925       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | 281         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 43628       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.025053836 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000116   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 750         |
|    policy_gradient_loss | 0.00204     |
|    std                  | 0.929       |
|    value_loss           | 0.378       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.14e+03    |
|    ep_rew_mean          | 287         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 43841       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.020786816 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00152    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 760         |
|    policy_gradient_loss | 0.000915    |
|    std                  | 0.932       |
|    value_loss           | 0.386       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.14e+03   |
|    ep_rew_mean          | 287        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 78         |
|    time_elapsed         | 44057      |
|    total_timesteps      | 159744     |
| train/                  |            |
|    approx_kl            | 0.01830874 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.00268   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.171      |
|    n_updates            | 770        |
|    policy_gradient_loss | 0.00494    |
|    std                  | 0.928      |
|    value_loss           | 0.404      |
----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.70 +/- 0.09
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.023040188 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 3.65e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.194       |
|    n_updates            | 780         |
|    policy_gradient_loss | 0.000271    |
|    std                  | 0.927       |
|    value_loss           | 0.527       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.14e+03 |
|    ep_rew_mean     | 282      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 46079    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.14e+03    |
|    ep_rew_mean          | 289         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 46300       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.030350706 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 13.1        |
|    n_updates            | 790         |
|    policy_gradient_loss | 3.34e-06    |
|    std                  | 0.929       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.14e+03    |
|    ep_rew_mean          | 289         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 46515       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.027895031 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.224       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00642    |
|    std                  | 0.928       |
|    value_loss           | 1.34        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.15e+03   |
|    ep_rew_mean          | 293        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 82         |
|    time_elapsed         | 46734      |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.02018444 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.00693   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 810        |
|    policy_gradient_loss | 0.00127    |
|    std                  | 0.924      |
|    value_loss           | 0.335      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.15e+03    |
|    ep_rew_mean          | 293         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 46952       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.029696384 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.406       |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00621    |
|    std                  | 0.924       |
|    value_loss           | 2.84        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.58 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.038361005 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00915    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.12        |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00289    |
|    std                  | 0.921       |
|    value_loss           | 0.36        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.15e+03 |
|    ep_rew_mean     | 287      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 48969    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.15e+03    |
|    ep_rew_mean          | 293         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 49183       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.037320253 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 2.19e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56        |
|    n_updates            | 840         |
|    policy_gradient_loss | 0.00772     |
|    std                  | 0.922       |
|    value_loss           | 923         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.15e+03    |
|    ep_rew_mean          | 293         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 49397       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.048200503 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0222     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.179       |
|    n_updates            | 850         |
|    policy_gradient_loss | 0.000677    |
|    std                  | 0.922       |
|    value_loss           | 0.321       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | 299         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 49611       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.031525716 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00182    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.242       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.918       |
|    value_loss           | 0.394       |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.61 +/- 0.04
Episode length: 3599.40 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.03193875 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -2.65      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.142      |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.00193   |
|    std                  | 0.919      |
|    value_loss           | 1.05       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | 294      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 51630    |
|    total_timesteps | 180224   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | 294        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 89         |
|    time_elapsed         | 51845      |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.03403285 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.00129   |
|    learning_rate        | 0.0003     |
|    loss                 | 81.7       |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.00461   |
|    std                  | 0.918      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | 300        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 52059      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.03341284 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.00372   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.22       |
|    n_updates            | 890        |
|    policy_gradient_loss | 0.00792    |
|    std                  | 0.92       |
|    value_loss           | 0.347      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | 300        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 91         |
|    time_elapsed         | 52273      |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.02866095 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.62      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.103      |
|    n_updates            | 900        |
|    policy_gradient_loss | 0.000271   |
|    std                  | 0.92       |
|    value_loss           | 0.33       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | 306        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 92         |
|    time_elapsed         | 52487      |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.01897353 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.00189    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.214      |
|    n_updates            | 910        |
|    policy_gradient_loss | 0.00447    |
|    std                  | 0.917      |
|    value_loss           | 0.384      |
----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.59 +/- 0.03
Episode length: 3597.20 +/- 6.21
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.031276673 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.771      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.246       |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.000145   |
|    std                  | 0.914       |
|    value_loss           | 0.571       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.17e+03 |
|    ep_rew_mean     | 302      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 54505    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | 302        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 94         |
|    time_elapsed         | 54723      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.03611256 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -9.19e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.11e+03   |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.00277   |
|    std                  | 0.913      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | 307         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 54937       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.024792215 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.046      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.00297     |
|    std                  | 0.916       |
|    value_loss           | 0.377       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | 307         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 55152       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.020428125 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.273      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 950         |
|    policy_gradient_loss | 0.00445     |
|    std                  | 0.919       |
|    value_loss           | 0.317       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | 312        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 55368      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.03030948 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.000641   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.181      |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.00338   |
|    std                  | 0.913      |
|    value_loss           | 0.328      |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.55 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.024662994 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.283       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00735    |
|    std                  | 0.914       |
|    value_loss           | 0.537       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.17e+03 |
|    ep_rew_mean     | 309      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 57381    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | 309         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 57595       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.037022986 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00136    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54e+03    |
|    n_updates            | 980         |
|    policy_gradient_loss | 0.00135     |
|    std                  | 0.915       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | 314         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 57811       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.027763944 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00045    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.121       |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.00791     |
|    std                  | 0.913       |
|    value_loss           | 0.392       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | 314         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 58026       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.026471525 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.781      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 1000        |
|    policy_gradient_loss | 4.76e-05    |
|    std                  | 0.911       |
|    value_loss           | 0.546       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | 319         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 58240       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.027173748 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0841     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.186       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.000949   |
|    std                  | 0.91        |
|    value_loss           | 0.361       |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.58 +/- 0.03
Episode length: 3596.00 +/- 10.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.029139113 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -1.29       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00151    |
|    std                  | 0.906       |
|    value_loss           | 0.498       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.18e+03 |
|    ep_rew_mean     | 315      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 60261    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | 315         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 60478       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.035919614 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000327   |
|    learning_rate        | 0.0003      |
|    loss                 | 16.4        |
|    n_updates            | 1030        |
|    policy_gradient_loss | 0.000655    |
|    std                  | 0.909       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.19e+03    |
|    ep_rew_mean          | 320         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 60694       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.029866394 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00167    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 1040        |
|    policy_gradient_loss | 0.00223     |
|    std                  | 0.905       |
|    value_loss           | 0.303       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.19e+03   |
|    ep_rew_mean          | 325        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 60909      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.02789573 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.354      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.134      |
|    n_updates            | 1050       |
|    policy_gradient_loss | 0.000111   |
|    std                  | 0.912      |
|    value_loss           | 0.31       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.19e+03    |
|    ep_rew_mean          | 325         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 61125       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.019569322 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.318      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.134       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00162    |
|    std                  | 0.913       |
|    value_loss           | 0.358       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.54 +/- 0.04
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.028393477 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.000944    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.146       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00229    |
|    std                  | 0.91        |
|    value_loss           | 0.347       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.19e+03 |
|    ep_rew_mean     | 322      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 63144    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.19e+03    |
|    ep_rew_mean          | 322         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 63360       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.029164627 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00102    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.11e+03    |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00353    |
|    std                  | 0.912       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.19e+03    |
|    ep_rew_mean          | 326         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 63575       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.030191148 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0168     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.143       |
|    n_updates            | 1090        |
|    policy_gradient_loss | 0.00426     |
|    std                  | 0.91        |
|    value_loss           | 0.337       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 331         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 63790       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.035253573 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.8        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.103       |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00223    |
|    std                  | 0.913       |
|    value_loss           | 0.318       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 331         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 64006       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.024631087 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.11       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.132       |
|    n_updates            | 1110        |
|    policy_gradient_loss | 0.00078     |
|    std                  | 0.915       |
|    value_loss           | 0.332       |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.57 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.018753942 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00235     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.117       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00134     |
|    std                  | 0.912       |
|    value_loss           | 0.269       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.19e+03 |
|    ep_rew_mean     | 328      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 66025    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 332         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 66239       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.035443086 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -8.36e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.16        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0016     |
|    std                  | 0.914       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.2e+03    |
|    ep_rew_mean          | 332        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 115        |
|    time_elapsed         | 66456      |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.03170302 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.0102    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.101      |
|    n_updates            | 1140       |
|    policy_gradient_loss | 0.00189    |
|    std                  | 0.913      |
|    value_loss           | 0.356      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 336         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 66668       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.021480419 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000199   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.00176     |
|    std                  | 0.91        |
|    value_loss           | 0.311       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 336         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 66881       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.020375364 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00234     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.131       |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.0048      |
|    std                  | 0.912       |
|    value_loss           | 0.276       |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.56 +/- 0.04
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.03132794 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.000586  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.114      |
|    n_updates            | 1170       |
|    policy_gradient_loss | 0.00426    |
|    std                  | 0.918      |
|    value_loss           | 0.28       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.2e+03  |
|    ep_rew_mean     | 333      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 68900    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 338         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 69117       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.022254836 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00128    |
|    learning_rate        | 0.0003      |
|    loss                 | 54.7        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00145    |
|    std                  | 0.92        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | 338         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 69331       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.036460534 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.198      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.000572   |
|    std                  | 0.918       |
|    value_loss           | 0.382       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 342         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 69546       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.029039644 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00137    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.168       |
|    n_updates            | 1200        |
|    policy_gradient_loss | 0.00928     |
|    std                  | 0.917       |
|    value_loss           | 0.345       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.21e+03   |
|    ep_rew_mean          | 342        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 122        |
|    time_elapsed         | 69763      |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.03123982 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.0209    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 1210       |
|    policy_gradient_loss | 0.000203   |
|    std                  | 0.919      |
|    value_loss           | 0.291      |
----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.53 +/- 0.05
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.033738077 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0124     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.206       |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.000682    |
|    std                  | 0.92        |
|    value_loss           | 0.322       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.21e+03 |
|    ep_rew_mean     | 339      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 71780    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 343         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 71994       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.025410123 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000799   |
|    learning_rate        | 0.0003      |
|    loss                 | 389         |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00507    |
|    std                  | 0.92        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 343         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 72209       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.024756052 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.401      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.121       |
|    n_updates            | 1240        |
|    policy_gradient_loss | 0.00378     |
|    std                  | 0.917       |
|    value_loss           | 0.455       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 346         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 72424       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.019781288 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0387     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0985      |
|    n_updates            | 1250        |
|    policy_gradient_loss | 0.005       |
|    std                  | 0.911       |
|    value_loss           | 0.279       |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.56 +/- 0.04
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.026792955 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0396      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.00413    |
|    std                  | 0.912       |
|    value_loss           | 0.281       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.21e+03 |
|    ep_rew_mean     | 343      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 74448    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.21e+03   |
|    ep_rew_mean          | 343        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 128        |
|    time_elapsed         | 74666      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.03845261 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.0013    |
|    learning_rate        | 0.0003     |
|    loss                 | 273        |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.00318   |
|    std                  | 0.913      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 347         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 74881       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.032973446 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 5.66e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.124       |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.00658     |
|    std                  | 0.914       |
|    value_loss           | 0.35        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.21e+03   |
|    ep_rew_mean          | 347        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 130        |
|    time_elapsed         | 75095      |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.02427579 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.371     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.081      |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.00215   |
|    std                  | 0.911      |
|    value_loss           | 0.373      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 351         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 75310       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.025087185 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00411     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.131       |
|    n_updates            | 1300        |
|    policy_gradient_loss | 0.00182     |
|    std                  | 0.907       |
|    value_loss           | 0.252       |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.68 +/- 0.12
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.03235073 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -1.17      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.705      |
|    n_updates            | 1310       |
|    policy_gradient_loss | 0.00192    |
|    std                  | 0.904      |
|    value_loss           | 0.37       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.21e+03 |
|    ep_rew_mean     | 348      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 77330    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | 348         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 77544       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.037980363 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000571   |
|    learning_rate        | 0.0003      |
|    loss                 | 21.4        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00162    |
|    std                  | 0.906       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | 351         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 134         |
|    time_elapsed         | 77757       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.029482514 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.057      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.127       |
|    n_updates            | 1330        |
|    policy_gradient_loss | 0.00566     |
|    std                  | 0.907       |
|    value_loss           | 0.333       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.22e+03   |
|    ep_rew_mean          | 351        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 77971      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.04046156 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.606     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.133      |
|    n_updates            | 1340       |
|    policy_gradient_loss | -0.000664  |
|    std                  | 0.904      |
|    value_loss           | 0.425      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | 355         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 78186       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.026149027 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00364     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0955      |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.000978   |
|    std                  | 0.902       |
|    value_loss           | 0.267       |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.57 +/- 0.03
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 280000    |
| train/                  |           |
|    approx_kl            | 0.0308107 |
|    clip_fraction        | 0.248     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | 0.00205   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.151     |
|    n_updates            | 1360      |
|    policy_gradient_loss | 0.000465  |
|    std                  | 0.903     |
|    value_loss           | 0.38      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.22e+03 |
|    ep_rew_mean     | 352      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 80202    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | 352         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 80415       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.025890484 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000308   |
|    learning_rate        | 0.0003      |
|    loss                 | 19.2        |
|    n_updates            | 1370        |
|    policy_gradient_loss | 0.00424     |
|    std                  | 0.905       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.22e+03   |
|    ep_rew_mean          | 355        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 139        |
|    time_elapsed         | 80628      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.04642899 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.000314   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.187      |
|    n_updates            | 1380       |
|    policy_gradient_loss | 0.00653    |
|    std                  | 0.907      |
|    value_loss           | 0.346      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | 355         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 80841       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.028806504 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0012     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.251       |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.000511   |
|    std                  | 0.903       |
|    value_loss           | 0.475       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.22e+03   |
|    ep_rew_mean          | 359        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 81054      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.05063612 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.00739   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.196      |
|    n_updates            | 1400       |
|    policy_gradient_loss | 0.00575    |
|    std                  | 0.9        |
|    value_loss           | 0.312      |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.54 +/- 0.05
Episode length: 3595.00 +/- 9.30
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.044068884 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.601      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.227       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.000842   |
|    std                  | 0.903       |
|    value_loss           | 0.416       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.22e+03 |
|    ep_rew_mean     | 356      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 83074    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | 356         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 83290       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.031733245 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000378   |
|    learning_rate        | 0.0003      |
|    loss                 | 130         |
|    n_updates            | 1420        |
|    policy_gradient_loss | 0.00115     |
|    std                  | 0.906       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 83505       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.040841054 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000792    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.906       |
|    value_loss           | 0.304       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.23e+03   |
|    ep_rew_mean          | 363        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 145        |
|    time_elapsed         | 83719      |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.03307545 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.128     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.14       |
|    n_updates            | 1440       |
|    policy_gradient_loss | 0.00211    |
|    std                  | 0.908      |
|    value_loss           | 0.31       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | 363         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 83933       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.038674004 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0101     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.146       |
|    n_updates            | 1450        |
|    policy_gradient_loss | 0.00192     |
|    std                  | 0.906       |
|    value_loss           | 0.341       |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.61 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.028378423 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0038     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.00356     |
|    std                  | 0.904       |
|    value_loss           | 0.342       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | 360      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 85950    |
|    total_timesteps | 301056   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.23e+03  |
|    ep_rew_mean          | 360       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 148       |
|    time_elapsed         | 86164     |
|    total_timesteps      | 303104    |
| train/                  |           |
|    approx_kl            | 0.0299895 |
|    clip_fraction        | 0.322     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | -0.000214 |
|    learning_rate        | 0.0003    |
|    loss                 | 453       |
|    n_updates            | 1470      |
|    policy_gradient_loss | -0.0028   |
|    std                  | 0.909     |
|    value_loss           | 1.04e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | 363         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 86377       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.028740691 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 8.89e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.13        |
|    n_updates            | 1480        |
|    policy_gradient_loss | 0.00192     |
|    std                  | 0.902       |
|    value_loss           | 0.347       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | 366         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 86592       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.031180961 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.998      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.11        |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00157    |
|    std                  | 0.901       |
|    value_loss           | 0.387       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.23e+03   |
|    ep_rew_mean          | 366        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 86805      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.03246666 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.207     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.135      |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.00257   |
|    std                  | 0.902      |
|    value_loss           | 0.34       |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.56 +/- 0.05
Episode length: 3596.60 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.035498045 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00499     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0965      |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.0037      |
|    std                  | 0.902       |
|    value_loss           | 0.243       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | 364      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 88823    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.23e+03   |
|    ep_rew_mean          | 364        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 153        |
|    time_elapsed         | 89038      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.04949041 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 1.36e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.76e+03   |
|    n_updates            | 1520       |
|    policy_gradient_loss | 0.005      |
|    std                  | 0.901      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | 367         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 89251       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.024241755 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.000305    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.202       |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.000273   |
|    std                  | 0.901       |
|    value_loss           | 0.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | 370         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 89464       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.030511443 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.294      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.12        |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00322    |
|    std                  | 0.902       |
|    value_loss           | 0.289       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.23e+03   |
|    ep_rew_mean          | 370        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 89677      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.03468932 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -1.13      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0819     |
|    n_updates            | 1550       |
|    policy_gradient_loss | 0.00216    |
|    std                  | 0.901      |
|    value_loss           | 0.258      |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.56 +/- 0.04
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.028675811 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00205    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0798      |
|    n_updates            | 1560        |
|    policy_gradient_loss | 0.000255    |
|    std                  | 0.902       |
|    value_loss           | 0.274       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | 368      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 91690    |
|    total_timesteps | 321536   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.23e+03  |
|    ep_rew_mean          | 371       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 158       |
|    time_elapsed         | 91905     |
|    total_timesteps      | 323584    |
| train/                  |           |
|    approx_kl            | 0.0418085 |
|    clip_fraction        | 0.313     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.4     |
|    explained_variance   | -0.000628 |
|    learning_rate        | 0.0003    |
|    loss                 | 270       |
|    n_updates            | 1570      |
|    policy_gradient_loss | 1.02e-05  |
|    std                  | 0.904     |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.23e+03  |
|    ep_rew_mean          | 371       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 159       |
|    time_elapsed         | 92119     |
|    total_timesteps      | 325632    |
| train/                  |           |
|    approx_kl            | 0.0232085 |
|    clip_fraction        | 0.285     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | 0.000134  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.104     |
|    n_updates            | 1580      |
|    policy_gradient_loss | 0.000517  |
|    std                  | 0.907     |
|    value_loss           | 0.32      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | 379         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 92332       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.040878255 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00109     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 1590        |
|    policy_gradient_loss | 0.00105     |
|    std                  | 0.905       |
|    value_loss           | 0.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | 379         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 92546       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.042488847 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00966     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 1600        |
|    policy_gradient_loss | 0.00281     |
|    std                  | 0.899       |
|    value_loss           | 0.298       |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.74 +/- 0.02
Episode length: 3596.20 +/- 6.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.025069209 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00224     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.176       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00469     |
|    std                  | 0.899       |
|    value_loss           | 0.355       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.24e+03 |
|    ep_rew_mean     | 380      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 94565    |
|    total_timesteps | 331776   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.24e+03  |
|    ep_rew_mean          | 385       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 163       |
|    time_elapsed         | 94781     |
|    total_timesteps      | 333824    |
| train/                  |           |
|    approx_kl            | 0.0338842 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.4     |
|    explained_variance   | -0.000107 |
|    learning_rate        | 0.0003    |
|    loss                 | 613       |
|    n_updates            | 1620      |
|    policy_gradient_loss | -0.00151  |
|    std                  | 0.898     |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | 385         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 94995       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.027337214 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.785      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0782      |
|    n_updates            | 1630        |
|    policy_gradient_loss | 0.000436    |
|    std                  | 0.896       |
|    value_loss           | 0.328       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | 396         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 95208       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.031772308 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 6.29e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0594      |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.00221     |
|    std                  | 0.898       |
|    value_loss           | 0.252       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | 396         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 95423       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.023855664 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 8.33e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.228       |
|    n_updates            | 1650        |
|    policy_gradient_loss | 0.00415     |
|    std                  | 0.904       |
|    value_loss           | 0.35        |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.57 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.025800992 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.152       |
|    n_updates            | 1660        |
|    policy_gradient_loss | 0.00131     |
|    std                  | 0.906       |
|    value_loss           | 0.284       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.27e+03 |
|    ep_rew_mean     | 396      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 97437    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | 401         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 97651       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.029479217 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.36        |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00045    |
|    std                  | 0.909       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | 401         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 97864       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.029092515 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.39       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.218       |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.00121     |
|    std                  | 0.912       |
|    value_loss           | 0.385       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | 405         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 98078       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.021330934 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00456     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0891      |
|    n_updates            | 1690        |
|    policy_gradient_loss | 0.000215    |
|    std                  | 0.909       |
|    value_loss           | 0.275       |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.64 +/- 0.03
Episode length: 3596.20 +/- 9.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.017479561 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00635     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.16        |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.00154     |
|    std                  | 0.906       |
|    value_loss           | 0.361       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | 411      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 100097   |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | 411        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 172        |
|    time_elapsed         | 100310     |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.03280449 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -5.72e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 943        |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.000325  |
|    std                  | 0.906      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | 415         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 100523      |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.035908505 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 4.05e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0931      |
|    n_updates            | 1720        |
|    policy_gradient_loss | 0.00201     |
|    std                  | 0.902       |
|    value_loss           | 0.281       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | 415         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 100735      |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.047236092 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 1.03e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.167       |
|    n_updates            | 1730        |
|    policy_gradient_loss | 0.00589     |
|    std                  | 0.902       |
|    value_loss           | 0.417       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | 419         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 100949      |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.026510596 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -5.88e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0931      |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.00555     |
|    std                  | 0.902       |
|    value_loss           | 0.27        |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.59 +/- 0.02
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.03031727 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -2.21      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.114      |
|    n_updates            | 1750       |
|    policy_gradient_loss | 0.00227    |
|    std                  | 0.903      |
|    value_loss           | 0.554      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | 417      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 102963   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | 417         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 103176      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.056087453 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 7.51e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.98e+03    |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.00423     |
|    std                  | 0.905       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 429         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 103388      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.021370087 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00885    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.117       |
|    n_updates            | 1770        |
|    policy_gradient_loss | 0.00607     |
|    std                  | 0.903       |
|    value_loss           | 0.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 429         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 103602      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.028710933 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -1.38       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.136       |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.00082    |
|    std                  | 0.904       |
|    value_loss           | 0.359       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 432         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 103814      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.029329646 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0134     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.082       |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.00338     |
|    std                  | 0.905       |
|    value_loss           | 0.321       |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.61 +/- 0.04
Episode length: 3594.60 +/- 10.07
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.021234471 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0343     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00272    |
|    std                  | 0.905       |
|    value_loss           | 0.267       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 429      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 105834   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 429         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 106049      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.032199763 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000141   |
|    learning_rate        | 0.0003      |
|    loss                 | 444         |
|    n_updates            | 1810        |
|    policy_gradient_loss | 0.00303     |
|    std                  | 0.911       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 436         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 106263      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.028258953 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -3.1e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.131       |
|    n_updates            | 1820        |
|    policy_gradient_loss | -9.03e-05   |
|    std                  | 0.915       |
|    value_loss           | 0.335       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 436         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 106475      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.028029263 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.136      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.119       |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.000117   |
|    std                  | 0.913       |
|    value_loss           | 0.281       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 438        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 106688     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.03167637 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.000272   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.106      |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.00116   |
|    std                  | 0.914      |
|    value_loss           | 0.271      |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.62 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.032835472 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00108     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.151       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.00239    |
|    std                  | 0.915       |
|    value_loss           | 0.3         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 434      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 108703   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 434         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 108918      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.029114064 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -1.07e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.3        |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00228    |
|    std                  | 0.921       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 441         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 188         |
|    time_elapsed         | 109132      |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.024378968 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 6.5e-06     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 1870        |
|    policy_gradient_loss | 0.00115     |
|    std                  | 0.922       |
|    value_loss           | 0.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 443         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 109346      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.028884953 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 4.77e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.178       |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.925       |
|    value_loss           | 0.281       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 443        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 109561     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.03235472 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -1.27      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0744     |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.00478   |
|    std                  | 0.929      |
|    value_loss           | 0.288      |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.65 +/- 0.04
Episode length: 3596.40 +/- 9.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.027943494 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0112     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.159       |
|    n_updates            | 1900        |
|    policy_gradient_loss | 0.00578     |
|    std                  | 0.928       |
|    value_loss           | 0.291       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 439      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 111579   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 439         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 111792      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.035536323 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -3.86e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 10.4        |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00299    |
|    std                  | 0.932       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 445        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 193        |
|    time_elapsed         | 112005     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.03397448 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.000191  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.108      |
|    n_updates            | 1920       |
|    policy_gradient_loss | 0.00027    |
|    std                  | 0.928      |
|    value_loss           | 0.333      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 447       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 194       |
|    time_elapsed         | 112217    |
|    total_timesteps      | 397312    |
| train/                  |           |
|    approx_kl            | 0.0363333 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.7     |
|    explained_variance   | -2.8      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0733    |
|    n_updates            | 1930      |
|    policy_gradient_loss | -0.000506 |
|    std                  | 0.927     |
|    value_loss           | 0.511     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 447         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 112429      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.030319944 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.392      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.152       |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.000662    |
|    std                  | 0.929       |
|    value_loss           | 0.265       |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.62 +/- 0.04
Episode length: 3599.40 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.02114543 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 1.8e-05    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0851     |
|    n_updates            | 1950       |
|    policy_gradient_loss | 0.00192    |
|    std                  | 0.929      |
|    value_loss           | 0.257      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 443      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 114443   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 443         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 114655      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.030655488 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -2.26e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 23.9        |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.00471    |
|    std                  | 0.928       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 450         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 114866      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.032864537 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -1.12e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.147       |
|    n_updates            | 1970        |
|    policy_gradient_loss | 0.01        |
|    std                  | 0.931       |
|    value_loss           | 0.32        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 452        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 115079     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.03889178 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.000179   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.119      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.00536    |
|    std                  | 0.923      |
|    value_loss           | 0.304      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 452        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 115291     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.03263694 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -1.55      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.131      |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.000141  |
|    std                  | 0.921      |
|    value_loss           | 0.391      |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.61 +/- 0.05
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.029608037 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00296     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.186       |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.00469     |
|    std                  | 0.917       |
|    value_loss           | 0.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 447      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 117309   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 454         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 117524      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.044542667 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -1.04e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 210         |
|    n_updates            | 2010        |
|    policy_gradient_loss | 0.00636     |
|    std                  | 0.918       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 454         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 203         |
|    time_elapsed         | 117736      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.037589643 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000291   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.091       |
|    n_updates            | 2020        |
|    policy_gradient_loss | 0.00675     |
|    std                  | 0.913       |
|    value_loss           | 0.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 455         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 117949      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.023769433 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000149   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 2030        |
|    policy_gradient_loss | 0.00229     |
|    std                  | 0.911       |
|    value_loss           | 0.283       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 455        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 118162     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.02917756 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -1.24      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0876     |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.00107    |
|    std                  | 0.91       |
|    value_loss           | 0.311      |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.56 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.029847536 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0147     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.00855     |
|    std                  | 0.908       |
|    value_loss           | 0.238       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 451      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 120175   |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 458        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 207        |
|    time_elapsed         | 120386     |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.03272606 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.00011   |
|    learning_rate        | 0.0003     |
|    loss                 | 393        |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.000466  |
|    std                  | 0.91       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 458         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 208         |
|    time_elapsed         | 120597      |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.022558413 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00365    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0427      |
|    n_updates            | 2070        |
|    policy_gradient_loss | 0.00429     |
|    std                  | 0.908       |
|    value_loss           | 0.27        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 459        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 120808     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.04806429 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.00708   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0591     |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.00359    |
|    std                  | 0.906      |
|    value_loss           | 0.257      |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.55 +/- 0.04
Episode length: 3595.40 +/- 11.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.03873138 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.0858    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.167      |
|    n_updates            | 2090       |
|    policy_gradient_loss | 0.00747    |
|    std                  | 0.907      |
|    value_loss           | 0.306      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 455      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 122825   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 455         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 123037      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.040727638 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000104   |
|    learning_rate        | 0.0003      |
|    loss                 | 45.2        |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0051     |
|    std                  | 0.912       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 461         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 123250      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.033832062 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 7.51e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.102       |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.00273     |
|    std                  | 0.911       |
|    value_loss           | 0.302       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 461         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 123462      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.032899305 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 8.57e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0972      |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.0047      |
|    std                  | 0.906       |
|    value_loss           | 0.245       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 463         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 123674      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.025054079 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -6.02e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0732      |
|    n_updates            | 2130        |
|    policy_gradient_loss | 0.00422     |
|    std                  | 0.905       |
|    value_loss           | 0.229       |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.54 +/- 0.04
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.021909254 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00342    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.146       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.000203    |
|    std                  | 0.908       |
|    value_loss           | 0.208       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 458      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 125690   |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 458        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 216        |
|    time_elapsed         | 125902     |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.03819325 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.000108  |
|    learning_rate        | 0.0003     |
|    loss                 | 728        |
|    n_updates            | 2150       |
|    policy_gradient_loss | 0.00339    |
|    std                  | 0.913      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 465         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 217         |
|    time_elapsed         | 126115      |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.028857317 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00712    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 2160        |
|    policy_gradient_loss | 0.00459     |
|    std                  | 0.913       |
|    value_loss           | 0.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 465         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 218         |
|    time_elapsed         | 126327      |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.028316338 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.448      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.105       |
|    n_updates            | 2170        |
|    policy_gradient_loss | 0.003       |
|    std                  | 0.91        |
|    value_loss           | 0.258       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 467        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 219        |
|    time_elapsed         | 126539     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.03226666 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.00214    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.125      |
|    n_updates            | 2180       |
|    policy_gradient_loss | 0.00466    |
|    std                  | 0.91       |
|    value_loss           | 0.246      |
----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.51 +/- 0.03
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.04786838 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -3.08      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.191      |
|    n_updates            | 2190       |
|    policy_gradient_loss | 0.0013     |
|    std                  | 0.91       |
|    value_loss           | 0.285      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 462      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 128558   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 462         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 128772      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.035509482 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0012     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+03    |
|    n_updates            | 2200        |
|    policy_gradient_loss | 0.000525    |
|    std                  | 0.91        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 470         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 128987      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.030281821 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00423    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.127       |
|    n_updates            | 2210        |
|    policy_gradient_loss | 0.00474     |
|    std                  | 0.91        |
|    value_loss           | 0.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 470         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 129199      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.028553221 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0147      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.215       |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.00931     |
|    std                  | 0.907       |
|    value_loss           | 0.268       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 471         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 129413      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.031406865 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0019     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0688      |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.00173     |
|    std                  | 0.902       |
|    value_loss           | 0.207       |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.58 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.041016772 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.6        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0521      |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.00591     |
|    std                  | 0.901       |
|    value_loss           | 0.275       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 467      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 131425   |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 467        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 226        |
|    time_elapsed         | 131637     |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.03996708 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.000111   |
|    learning_rate        | 0.0003     |
|    loss                 | 34.4       |
|    n_updates            | 2250       |
|    policy_gradient_loss | 0.00414    |
|    std                  | 0.903      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 473         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 131849      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.024411717 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.12e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0791      |
|    n_updates            | 2260        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.901       |
|    value_loss           | 0.233       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 473         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 132061      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.025717728 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 5.36e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.133       |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.00516     |
|    std                  | 0.903       |
|    value_loss           | 0.259       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 475         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 132274      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.053590305 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 1.37e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.166       |
|    n_updates            | 2280        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.9         |
|    value_loss           | 0.221       |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.56 +/- 0.05
Episode length: 3595.80 +/- 7.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.046204243 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.58       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0894      |
|    n_updates            | 2290        |
|    policy_gradient_loss | 0.00389     |
|    std                  | 0.896       |
|    value_loss           | 0.275       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 470      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 134293   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 470         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 134507      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.043550737 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.000792   |
|    learning_rate        | 0.0003      |
|    loss                 | 39.3        |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.00122    |
|    std                  | 0.902       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 477         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 232         |
|    time_elapsed         | 134721      |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.034273066 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 1.96e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0965      |
|    n_updates            | 2310        |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.905       |
|    value_loss           | 0.258       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 479         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 134934      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.038849674 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000298    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.1         |
|    n_updates            | 2320        |
|    policy_gradient_loss | 0.00713     |
|    std                  | 0.904       |
|    value_loss           | 0.275       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 479         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 234         |
|    time_elapsed         | 135147      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.042575922 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -2.63       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.153       |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.000461   |
|    std                  | 0.908       |
|    value_loss           | 0.284       |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.57 +/- 0.05
Episode length: 3599.80 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.024016097 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00235    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.00781     |
|    std                  | 0.906       |
|    value_loss           | 0.282       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 474      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 137163   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 474         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 137377      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.034944616 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -8.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 2350        |
|    policy_gradient_loss | 0.00172     |
|    std                  | 0.913       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 480        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 137590     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.02707702 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -2.03e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.126      |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.0043     |
|    std                  | 0.909      |
|    value_loss           | 0.318      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 482        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 137804     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.03514902 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.224     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.108      |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.000515   |
|    std                  | 0.901      |
|    value_loss           | 0.288      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 482         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 239         |
|    time_elapsed         | 138017      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.031818014 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0422     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0987      |
|    n_updates            | 2380        |
|    policy_gradient_loss | 0.00249     |
|    std                  | 0.905       |
|    value_loss           | 0.27        |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.53 +/- 0.04
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.026364602 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -3.61e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.065       |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.00285     |
|    std                  | 0.903       |
|    value_loss           | 0.214       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 477      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 140035   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 484         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 241         |
|    time_elapsed         | 140249      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.060065873 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -3.85e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.06        |
|    n_updates            | 2400        |
|    policy_gradient_loss | 0.00408     |
|    std                  | 0.904       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 484        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 140464     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.02669363 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.132     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.124      |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.00456    |
|    std                  | 0.9        |
|    value_loss           | 0.253      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 485        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 140678     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.05853492 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.000944   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.119      |
|    n_updates            | 2420       |
|    policy_gradient_loss | 0.0031     |
|    std                  | 0.899      |
|    value_loss           | 0.271      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 485         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 140890      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.023987561 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0293     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.098       |
|    n_updates            | 2430        |
|    policy_gradient_loss | 0.0098      |
|    std                  | 0.896       |
|    value_loss           | 0.22        |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.53 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.022743601 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.000156    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0873      |
|    n_updates            | 2440        |
|    policy_gradient_loss | 0.005       |
|    std                  | 0.901       |
|    value_loss           | 0.199       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 482      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 142903   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 490        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 143115     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.03346923 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -1.31e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.000426  |
|    std                  | 0.905      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 490         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 143329      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.039682135 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.000243    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0675      |
|    n_updates            | 2460        |
|    policy_gradient_loss | 0.00473     |
|    std                  | 0.905       |
|    value_loss           | 0.251       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 491         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 143541      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.034317728 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 4.17e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0858      |
|    n_updates            | 2470        |
|    policy_gradient_loss | 0.0079      |
|    std                  | 0.908       |
|    value_loss           | 0.261       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 491         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 143755      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.039227676 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00605    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.132       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.00829     |
|    std                  | 0.905       |
|    value_loss           | 0.243       |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.55 +/- 0.03
Episode length: 3597.00 +/- 5.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.035584275 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 2.38e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.14        |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.00344     |
|    std                  | 0.896       |
|    value_loss           | 0.22        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 486      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 145774   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 493         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 145987      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.038512185 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.19e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 20.2        |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.00262     |
|    std                  | 0.898       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 493         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 146199      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.032046452 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00526     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.125       |
|    n_updates            | 2510        |
|    policy_gradient_loss | 0.00686     |
|    std                  | 0.895       |
|    value_loss           | 0.255       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 494        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 146409     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.02745254 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 1.37e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0776     |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.00756    |
|    std                  | 0.896      |
|    value_loss           | 0.258      |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.53 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.043782964 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -1.81       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0618      |
|    n_updates            | 2530        |
|    policy_gradient_loss | 0.00474     |
|    std                  | 0.89        |
|    value_loss           | 0.305       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 490      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 148423   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 490         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 148635      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.031624172 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.000138   |
|    learning_rate        | 0.0003      |
|    loss                 | 272         |
|    n_updates            | 2540        |
|    policy_gradient_loss | 0.0052      |
|    std                  | 0.89        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 497         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 256         |
|    time_elapsed         | 148847      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.037730534 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.000211   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.151       |
|    n_updates            | 2550        |
|    policy_gradient_loss | 0.00559     |
|    std                  | 0.886       |
|    value_loss           | 0.255       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 497         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 149059      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.035628192 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.114      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.164       |
|    n_updates            | 2560        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.886       |
|    value_loss           | 0.266       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 498         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 149272      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.037933946 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00345    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0504      |
|    n_updates            | 2570        |
|    policy_gradient_loss | 0.00937     |
|    std                  | 0.887       |
|    value_loss           | 0.176       |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.50 +/- 0.03
Episode length: 3596.60 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.028895292 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.162      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0979      |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.00328     |
|    std                  | 0.882       |
|    value_loss           | 0.196       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 493      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 151288   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 493        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 151500     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.05413719 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -3.14e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.18       |
|    n_updates            | 2590       |
|    policy_gradient_loss | 0.00648    |
|    std                  | 0.885      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 500         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 151713      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.034818716 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0853      |
|    n_updates            | 2600        |
|    policy_gradient_loss | 0.00932     |
|    std                  | 0.887       |
|    value_loss           | 0.247       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 500         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 151925      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.027788736 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00014     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0966      |
|    n_updates            | 2610        |
|    policy_gradient_loss | 0.00766     |
|    std                  | 0.887       |
|    value_loss           | 0.206       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 501         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 152138      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.023435034 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 2.92e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0817      |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.00554     |
|    std                  | 0.884       |
|    value_loss           | 0.243       |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.51 +/- 0.03
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.048518844 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -1.51       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.129       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.008       |
|    std                  | 0.884       |
|    value_loss           | 0.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 496      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 154151   |
|    total_timesteps | 540672   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 496       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 265       |
|    time_elapsed         | 154365    |
|    total_timesteps      | 542720    |
| train/                  |           |
|    approx_kl            | 0.0505407 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | -4.18e-05 |
|    learning_rate        | 0.0003    |
|    loss                 | 614       |
|    n_updates            | 2640      |
|    policy_gradient_loss | 0.00671   |
|    std                  | 0.885     |
|    value_loss           | 1.04e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 502         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 266         |
|    time_elapsed         | 154579      |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.043749027 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 1.29e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0798      |
|    n_updates            | 2650        |
|    policy_gradient_loss | 0.00152     |
|    std                  | 0.889       |
|    value_loss           | 0.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 502         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 154793      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.032549724 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -2.76       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.12        |
|    n_updates            | 2660        |
|    policy_gradient_loss | 0.00307     |
|    std                  | 0.89        |
|    value_loss           | 0.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 503         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 155008      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.031371888 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0011      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.106       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0163      |
|    std                  | 0.885       |
|    value_loss           | 0.293       |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.51 +/- 0.03
Episode length: 3595.40 +/- 7.91
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.036345415 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.0162     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 2680        |
|    policy_gradient_loss | 0.00259     |
|    std                  | 0.884       |
|    value_loss           | 0.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 497      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 157026   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 497        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 270        |
|    time_elapsed         | 157240     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.04073941 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.000491  |
|    learning_rate        | 0.0003     |
|    loss                 | 13         |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.00308   |
|    std                  | 0.889      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 503         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 271         |
|    time_elapsed         | 157454      |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.041875917 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.000188    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0755      |
|    n_updates            | 2700        |
|    policy_gradient_loss | 0.00666     |
|    std                  | 0.881       |
|    value_loss           | 0.283       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 504        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 157668     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.04309724 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.0852    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.114      |
|    n_updates            | 2710       |
|    policy_gradient_loss | 0.00889    |
|    std                  | 0.881      |
|    value_loss           | 0.252      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 504        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 157881     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.06711954 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.0856     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.171      |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.00133   |
|    std                  | 0.881      |
|    value_loss           | 0.229      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.55 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.04247687 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.000399  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.128      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.00604    |
|    std                  | 0.876      |
|    value_loss           | 0.256      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 499      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 159896   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 499        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 160111     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.03580859 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -1.96e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 82.9       |
|    n_updates            | 2740       |
|    policy_gradient_loss | 0.00623    |
|    std                  | 0.874      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 505         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 276         |
|    time_elapsed         | 160326      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.037070476 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -3.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0625      |
|    n_updates            | 2750        |
|    policy_gradient_loss | 0.00353     |
|    std                  | 0.873       |
|    value_loss           | 0.225       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 506         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 160540      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.057654366 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.48       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.123       |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.00617     |
|    std                  | 0.869       |
|    value_loss           | 0.283       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 506         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 160753      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.056530833 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.637      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.098       |
|    n_updates            | 2770        |
|    policy_gradient_loss | 0.0084      |
|    std                  | 0.874       |
|    value_loss           | 0.245       |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.55 +/- 0.03
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.040858973 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.00149    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0774      |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.873       |
|    value_loss           | 0.244       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 501      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 162771   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 501         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 162985      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.054078914 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -2.63e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 263         |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.00224    |
|    std                  | 0.873       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 507        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 163198     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.04509775 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 6.97e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 2800       |
|    policy_gradient_loss | 0.00667    |
|    std                  | 0.868      |
|    value_loss           | 0.364      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 508         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 163410      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.032434713 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.145      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.126       |
|    n_updates            | 2810        |
|    policy_gradient_loss | 0.00586     |
|    std                  | 0.868       |
|    value_loss           | 0.263       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 508        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 163623     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.03742239 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.273     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0736     |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.000162   |
|    std                  | 0.866      |
|    value_loss           | 0.228      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.53 +/- 0.04
Episode length: 3600.20 +/- 1.60
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.5    |
| time/                   |          |
|    total_timesteps      | 580000   |
| train/                  |          |
|    approx_kl            | 0.025594 |
|    clip_fraction        | 0.313    |
|    clip_range           | 0.2      |
|    entropy_loss         | -10.1    |
|    explained_variance   | 0.000131 |
|    learning_rate        | 0.0003   |
|    loss                 | 0.126    |
|    n_updates            | 2830     |
|    policy_gradient_loss | 0.0113   |
|    std                  | 0.866    |
|    value_loss           | 0.229    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 502      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 165638   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 509        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 285        |
|    time_elapsed         | 165851     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.02318052 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.00119   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 2840       |
|    policy_gradient_loss | 0.0026     |
|    std                  | 0.868      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 509         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 286         |
|    time_elapsed         | 166063      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.041453056 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.14       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0923      |
|    n_updates            | 2850        |
|    policy_gradient_loss | 0.00113     |
|    std                  | 0.864       |
|    value_loss           | 0.221       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 510         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 287         |
|    time_elapsed         | 166276      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.037044503 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.0519     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.181       |
|    n_updates            | 2860        |
|    policy_gradient_loss | 0.0075      |
|    std                  | 0.854       |
|    value_loss           | 0.289       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 510        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 166488     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.03312698 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.94      |
|    explained_variance   | 5.89e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.119      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.00868    |
|    std                  | 0.855      |
|    value_loss           | 0.172      |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.54 +/- 0.04
Episode length: 3595.40 +/- 8.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.031405427 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 4.55e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0964      |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.00507     |
|    std                  | 0.85        |
|    value_loss           | 0.184       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 505      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 168507   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 511         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 168723      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.049434897 |
|    clip_fraction        | 0.431       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.000102   |
|    learning_rate        | 0.0003      |
|    loss                 | 188         |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.00675     |
|    std                  | 0.849       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 511         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 291         |
|    time_elapsed         | 168935      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.037420537 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 5.79e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0891      |
|    n_updates            | 2900        |
|    policy_gradient_loss | 0.00949     |
|    std                  | 0.853       |
|    value_loss           | 0.376       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 512        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 169149     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.03677203 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | -7.27e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.174      |
|    n_updates            | 2910       |
|    policy_gradient_loss | 0.00749    |
|    std                  | 0.855      |
|    value_loss           | 0.33       |
----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.51 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.06506717 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | -0.23      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.179      |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.00244   |
|    std                  | 0.852      |
|    value_loss           | 0.428      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 507      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 171163   |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 507        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 294        |
|    time_elapsed         | 171376     |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.05001828 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | -0.000466  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.29       |
|    n_updates            | 2930       |
|    policy_gradient_loss | 0.00793    |
|    std                  | 0.855      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 513         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 295         |
|    time_elapsed         | 171588      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.019058933 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -0.000645   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.09        |
|    n_updates            | 2940        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.853       |
|    value_loss           | 0.315       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 513         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 296         |
|    time_elapsed         | 171801      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.041639134 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.154       |
|    n_updates            | 2950        |
|    policy_gradient_loss | 0.00485     |
|    std                  | 0.846       |
|    value_loss           | 0.254       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 514         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 297         |
|    time_elapsed         | 172015      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.032476947 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.000577    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.123       |
|    n_updates            | 2960        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.848       |
|    value_loss           | 0.272       |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.62 +/- 0.12
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.031637643 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -0.278      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0294      |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.00379     |
|    std                  | 0.844       |
|    value_loss           | 0.179       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 509      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 174033   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 509        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 174248     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.03385931 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | -3.04e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 12.1       |
|    n_updates            | 2980       |
|    policy_gradient_loss | 0.00209    |
|    std                  | 0.847      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 516         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 300         |
|    time_elapsed         | 174461      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.023665924 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 1.03e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0855      |
|    n_updates            | 2990        |
|    policy_gradient_loss | 0.00751     |
|    std                  | 0.851       |
|    value_loss           | 0.208       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 516         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 174674      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.040052123 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.384      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.081       |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.0073      |
|    std                  | 0.849       |
|    value_loss           | 0.269       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 517         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 174887      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.042624198 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | -1.79e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.103       |
|    n_updates            | 3010        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.845       |
|    value_loss           | 0.184       |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.55 +/- 0.04
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.056801643 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.00231    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0675      |
|    n_updates            | 3020        |
|    policy_gradient_loss | 0.00598     |
|    std                  | 0.847       |
|    value_loss           | 0.193       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 512      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 176902   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 512        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 177114     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.04941751 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.89      |
|    explained_variance   | -1.6e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 201        |
|    n_updates            | 3030       |
|    policy_gradient_loss | 0.00294    |
|    std                  | 0.852      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 518        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 305        |
|    time_elapsed         | 177328     |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.03592903 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | 3.93e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0883     |
|    n_updates            | 3040       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.847      |
|    value_loss           | 0.306      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 518         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 306         |
|    time_elapsed         | 177540      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.029567624 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -0.263      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.171       |
|    n_updates            | 3050        |
|    policy_gradient_loss | 0.00905     |
|    std                  | 0.843       |
|    value_loss           | 0.241       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 519        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 177753     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.03609483 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | -1.07e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.113      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.00864    |
|    std                  | 0.843      |
|    value_loss           | 0.253      |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.55 +/- 0.05
Episode length: 3595.60 +/- 7.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.04636628 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | 0.0619     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0867     |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.0027     |
|    std                  | 0.839      |
|    value_loss           | 0.272      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 514      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 179772   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 514        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 179985     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.04123879 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.8       |
|    explained_variance   | -0.000895  |
|    learning_rate        | 0.0003     |
|    loss                 | 104        |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00805    |
|    std                  | 0.84       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 520         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 310         |
|    time_elapsed         | 180197      |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.049552526 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 0.000281    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0526      |
|    n_updates            | 3090        |
|    policy_gradient_loss | 0.00752     |
|    std                  | 0.839       |
|    value_loss           | 0.242       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 520         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 180410      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.039136462 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -0.207      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0633      |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.00572     |
|    std                  | 0.84        |
|    value_loss           | 0.257       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 521         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 180622      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.045046024 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -3.34e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.127       |
|    n_updates            | 3110        |
|    policy_gradient_loss | 0.00874     |
|    std                  | 0.84        |
|    value_loss           | 0.194       |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.62 +/- 0.09
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.035567593 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | 0.000459    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0934      |
|    n_updates            | 3120        |
|    policy_gradient_loss | 0.00553     |
|    std                  | 0.837       |
|    value_loss           | 0.213       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 516      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 182635   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 516         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 182847      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.021411825 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.000821   |
|    learning_rate        | 0.0003      |
|    loss                 | 211         |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.838       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 523        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 315        |
|    time_elapsed         | 183059     |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.02956331 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | -0.052     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.15       |
|    n_updates            | 3140       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.844      |
|    value_loss           | 0.186      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 523         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 183271      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.031158391 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -3.93e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0996      |
|    n_updates            | 3150        |
|    policy_gradient_loss | 0.0119      |
|    std                  | 0.844       |
|    value_loss           | 0.159       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 523        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 183484     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.04307981 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | 0.326      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.086      |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.00397   |
|    std                  | 0.846      |
|    value_loss           | 0.189      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.71 +/- 0.05
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.041579265 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.000124    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0722      |
|    n_updates            | 3170        |
|    policy_gradient_loss | 0.0099      |
|    std                  | 0.848       |
|    value_loss           | 0.145       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 518      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 185502   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 518         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 185716      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.047217418 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -1.31e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.003       |
|    std                  | 0.849       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 525         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 320         |
|    time_elapsed         | 185928      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.039671082 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.000105    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0633      |
|    n_updates            | 3190        |
|    policy_gradient_loss | 0.00197     |
|    std                  | 0.846       |
|    value_loss           | 0.268       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 525         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 186141      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.029194543 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 6.2e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0983      |
|    n_updates            | 3200        |
|    policy_gradient_loss | 0.00567     |
|    std                  | 0.845       |
|    value_loss           | 0.227       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 525         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 322         |
|    time_elapsed         | 186352      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.032273043 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 1.61e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.18        |
|    n_updates            | 3210        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.846       |
|    value_loss           | 0.239       |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.62 +/- 0.15
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.031333707 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 7.3e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.152       |
|    n_updates            | 3220        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.844       |
|    value_loss           | 0.175       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 521      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 188366   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 528        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 188579     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.03909684 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.86      |
|    explained_variance   | -3.6e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 18.3       |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.0016     |
|    std                  | 0.848      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 528         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 325         |
|    time_elapsed         | 188790      |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.034538046 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -3.65       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0719      |
|    n_updates            | 3240        |
|    policy_gradient_loss | 0.00562     |
|    std                  | 0.851       |
|    value_loss           | 0.293       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 529        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 189004     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.04962482 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | 0.000771   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0861     |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.00805    |
|    std                  | 0.85       |
|    value_loss           | 0.259      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 529        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 189215     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.04193368 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | -0.0858    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.156      |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.00943    |
|    std                  | 0.853      |
|    value_loss           | 0.174      |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.65 +/- 0.12
Episode length: 3596.60 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.030603789 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.00205     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0686      |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.00728     |
|    std                  | 0.852       |
|    value_loss           | 0.198       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 524      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 191232   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 530        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 191451     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.07690764 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | -0.00187   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.71       |
|    n_updates            | 3280       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.853      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 530        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 191661     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.24140239 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.489      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.102      |
|    n_updates            | 3290       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.855      |
|    value_loss           | 0.763      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 530         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 331         |
|    time_elapsed         | 191874      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.049011864 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -0.188      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0657      |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.0087      |
|    std                  | 0.862       |
|    value_loss           | 0.206       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 530         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 332         |
|    time_elapsed         | 192085      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.027835622 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.000136    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.15        |
|    n_updates            | 3310        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.861       |
|    value_loss           | 0.181       |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.55 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.035822522 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.000233   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.123       |
|    n_updates            | 3320        |
|    policy_gradient_loss | 0.00538     |
|    std                  | 0.857       |
|    value_loss           | 0.229       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 526      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 194099   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 532         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 334         |
|    time_elapsed         | 194311      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.042897508 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.000231   |
|    learning_rate        | 0.0003      |
|    loss                 | 347         |
|    n_updates            | 3330        |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.859       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 532         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 335         |
|    time_elapsed         | 194524      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.034675144 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.00481    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0374      |
|    n_updates            | 3340        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.858       |
|    value_loss           | 0.166       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 533         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 336         |
|    time_elapsed         | 194735      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.030401941 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | -0.00058    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 3350        |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.855       |
|    value_loss           | 0.165       |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.52 +/- 0.04
Episode length: 3596.80 +/- 8.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.04286343 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | -1.94      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.087      |
|    n_updates            | 3360       |
|    policy_gradient_loss | 0.0077     |
|    std                  | 0.853      |
|    value_loss           | 0.198      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 528      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 196751   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 528         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 196964      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.039682023 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 274         |
|    n_updates            | 3370        |
|    policy_gradient_loss | 1.75e-06    |
|    std                  | 0.855       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 534         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 339         |
|    time_elapsed         | 197177      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.041783616 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.00368    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 3380        |
|    policy_gradient_loss | 0.00979     |
|    std                  | 0.851       |
|    value_loss           | 0.276       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 534         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 197390      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.047485672 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -0.00155    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0407      |
|    n_updates            | 3390        |
|    policy_gradient_loss | 0.00993     |
|    std                  | 0.848       |
|    value_loss           | 0.231       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 535         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 197603      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.053111546 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -5.84e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.00715     |
|    std                  | 0.842       |
|    value_loss           | 0.234       |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.53 +/- 0.05
Episode length: 3600.00 +/- 2.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 700000    |
| train/                  |           |
|    approx_kl            | 0.0393868 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.82     |
|    explained_variance   | 0.325     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0915    |
|    n_updates            | 3410      |
|    policy_gradient_loss | 0.00329   |
|    std                  | 0.846     |
|    value_loss           | 0.322     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 530      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 199616   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 530        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 199829     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.03301289 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | -0.000237  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 3420       |
|    policy_gradient_loss | 0.00185    |
|    std                  | 0.846      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 536        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 200041     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.04341326 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | -0.00342   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0679     |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.843      |
|    value_loss           | 0.194      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 536         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 345         |
|    time_elapsed         | 200254      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.042127445 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | -0.0712     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0996      |
|    n_updates            | 3440        |
|    policy_gradient_loss | 0.00649     |
|    std                  | 0.843       |
|    value_loss           | 0.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 537         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 200467      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.040757015 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -0.00077    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0604      |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.00731     |
|    std                  | 0.844       |
|    value_loss           | 0.176       |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.57 +/- 0.03
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.05743889 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | 0.0179     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.017      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.844      |
|    value_loss           | 0.209      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 532      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 202485   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 532         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 202698      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.061276216 |
|    clip_fraction        | 0.444       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -7.58e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.8        |
|    n_updates            | 3470        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.845       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 538         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 349         |
|    time_elapsed         | 202910      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.042176783 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -9.31e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0804      |
|    n_updates            | 3480        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.842       |
|    value_loss           | 0.182       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 538         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 350         |
|    time_elapsed         | 203123      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.025255468 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | -0.000889   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0764      |
|    n_updates            | 3490        |
|    policy_gradient_loss | 0.00636     |
|    std                  | 0.836       |
|    value_loss           | 0.219       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 540        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 203337     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.03395684 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | -0.000155  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0957     |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.00853    |
|    std                  | 0.837      |
|    value_loss           | 0.164      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.51 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.051708832 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | -1.86       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0569      |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.833       |
|    value_loss           | 0.235       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 535      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 205351   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 535        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 205564     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.04192704 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.72      |
|    explained_variance   | -3.11e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 50.9       |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.000734  |
|    std                  | 0.835      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 541         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 354         |
|    time_elapsed         | 205777      |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.025622487 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.000221    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.07        |
|    n_updates            | 3530        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.834       |
|    value_loss           | 0.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 542         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 355         |
|    time_elapsed         | 205989      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.051420905 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -0.484      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.111       |
|    n_updates            | 3540        |
|    policy_gradient_loss | 0.00658     |
|    std                  | 0.841       |
|    value_loss           | 0.204       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 542        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 206203     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.09419043 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | -2.61      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.187      |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.843      |
|    value_loss           | 0.184      |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.52 +/- 0.03
Episode length: 3598.00 +/- 4.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.02853631 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | -0.00374   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0273     |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.843      |
|    value_loss           | 0.138      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 537      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 208219   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 537        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 358        |
|    time_elapsed         | 208432     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.07936166 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.8       |
|    explained_variance   | -0.000592  |
|    learning_rate        | 0.0003     |
|    loss                 | 214        |
|    n_updates            | 3570       |
|    policy_gradient_loss | 0.00564    |
|    std                  | 0.844      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 543         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 359         |
|    time_elapsed         | 208644      |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.032603152 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | -0.000474   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0858      |
|    n_updates            | 3580        |
|    policy_gradient_loss | 0.00494     |
|    std                  | 0.846       |
|    value_loss           | 0.196       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 544         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 208856      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.034521952 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | -0.0417     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.00687     |
|    std                  | 0.845       |
|    value_loss           | 0.177       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 544         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 209068      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.029380871 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.00154     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0864      |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00547     |
|    std                  | 0.842       |
|    value_loss           | 0.267       |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.56 +/- 0.04
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.048645005 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | -0.000322   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0887      |
|    n_updates            | 3610        |
|    policy_gradient_loss | 0.00749     |
|    std                  | 0.84        |
|    value_loss           | 0.179       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 538      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 211080   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 538         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 211291      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.045946293 |
|    clip_fraction        | 0.452       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | -3.7e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 241         |
|    n_updates            | 3620        |
|    policy_gradient_loss | 0.00512     |
|    std                  | 0.839       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 545        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 364        |
|    time_elapsed         | 211503     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.05744891 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | -4.37e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.132      |
|    n_updates            | 3630       |
|    policy_gradient_loss | 0.00756    |
|    std                  | 0.837      |
|    value_loss           | 0.227      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 546        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 211714     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.06400454 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.72      |
|    explained_variance   | -0.852     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.112      |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.00791    |
|    std                  | 0.833      |
|    value_loss           | 0.2        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 546         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 211926      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.027485201 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | -0.00506    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.106       |
|    n_updates            | 3650        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.831       |
|    value_loss           | 0.154       |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.50 +/- 0.04
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.061775967 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.000594   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.0174      |
|    std                  | 0.836       |
|    value_loss           | 0.255       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 541      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 213943   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 547         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 368         |
|    time_elapsed         | 214155      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.043072358 |
|    clip_fraction        | 0.44        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | -5.48e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 19.2        |
|    n_updates            | 3670        |
|    policy_gradient_loss | 0.00652     |
|    std                  | 0.841       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 547        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 214367     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.03752602 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | -0.0972    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.179      |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.00925    |
|    std                  | 0.841      |
|    value_loss           | 0.262      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 548         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 214580      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.040047564 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | -0.000165   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.118       |
|    n_updates            | 3690        |
|    policy_gradient_loss | 0.00621     |
|    std                  | 0.84        |
|    value_loss           | 0.235       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 548         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 371         |
|    time_elapsed         | 214792      |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.030469043 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | 6.26e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0932      |
|    n_updates            | 3700        |
|    policy_gradient_loss | 0.00681     |
|    std                  | 0.837       |
|    value_loss           | 0.252       |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.49 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.029311307 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | 0.000157    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0468      |
|    n_updates            | 3710        |
|    policy_gradient_loss | 0.00878     |
|    std                  | 0.836       |
|    value_loss           | 0.207       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 542      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 216807   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 549        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 217020     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.04104356 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.71      |
|    explained_variance   | -2.86e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 6          |
|    n_updates            | 3720       |
|    policy_gradient_loss | 0.00449    |
|    std                  | 0.833      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 549         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 374         |
|    time_elapsed         | 217231      |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.035660245 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | -0.0403     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0561      |
|    n_updates            | 3730        |
|    policy_gradient_loss | 0.00839     |
|    std                  | 0.834       |
|    value_loss           | 0.203       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 549         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 375         |
|    time_elapsed         | 217443      |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.035674773 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.00512     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0917      |
|    n_updates            | 3740        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.834       |
|    value_loss           | 0.24        |
-----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.50 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.023201322 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.002      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0989      |
|    n_updates            | 3750        |
|    policy_gradient_loss | 0.00705     |
|    std                  | 0.834       |
|    value_loss           | 0.185       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 544      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 219458   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 544         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 219672      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.039556693 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | -0.000697   |
|    learning_rate        | 0.0003      |
|    loss                 | 81.4        |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00653     |
|    std                  | 0.837       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 550         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 378         |
|    time_elapsed         | 219886      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.051049333 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.00145     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0967      |
|    n_updates            | 3770        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.835       |
|    value_loss           | 0.202       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 550         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 379         |
|    time_elapsed         | 220102      |
|    total_timesteps      | 776192      |
| train/                  |             |
|    approx_kl            | 0.026261358 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | -0.00324    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.161       |
|    n_updates            | 3780        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.833       |
|    value_loss           | 0.169       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 551         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 380         |
|    time_elapsed         | 220318      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.051871262 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | -0.000531   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0346      |
|    n_updates            | 3790        |
|    policy_gradient_loss | 0.000516    |
|    std                  | 0.83        |
|    value_loss           | 0.158       |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.47 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.039446853 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0665      |
|    n_updates            | 3800        |
|    policy_gradient_loss | 0.00341     |
|    std                  | 0.833       |
|    value_loss           | 0.202       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 546      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 222333   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 546         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 222545      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.045652255 |
|    clip_fraction        | 0.44        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -5.82e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+03    |
|    n_updates            | 3810        |
|    policy_gradient_loss | -5.41e-05   |
|    std                  | 0.835       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 552         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 383         |
|    time_elapsed         | 222758      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.051399015 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 5.51e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0571      |
|    n_updates            | 3820        |
|    policy_gradient_loss | 0.0233      |
|    std                  | 0.834       |
|    value_loss           | 0.187       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 552        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 222972     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.03933859 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.73      |
|    explained_variance   | -0.13      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0633     |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.00914    |
|    std                  | 0.834      |
|    value_loss           | 0.224      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 553         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 385         |
|    time_elapsed         | 223186      |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.060858093 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | -0.00343    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0726      |
|    n_updates            | 3840        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.833       |
|    value_loss           | 0.162       |
-----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.54 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.03981042 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.72      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0711     |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.00103    |
|    std                  | 0.832      |
|    value_loss           | 0.284      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 547      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 225200   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 547        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 387        |
|    time_elapsed         | 225414     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.03730862 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.71      |
|    explained_variance   | -0.00044   |
|    learning_rate        | 0.0003     |
|    loss                 | 19.7       |
|    n_updates            | 3860       |
|    policy_gradient_loss | 0.00252    |
|    std                  | 0.834      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 554        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 225627     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.04007129 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.73      |
|    explained_variance   | 0.000288   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0619     |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.00827    |
|    std                  | 0.835      |
|    value_loss           | 0.176      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 554         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 389         |
|    time_elapsed         | 225840      |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.063678786 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | -1.77       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0972      |
|    n_updates            | 3880        |
|    policy_gradient_loss | 0.00409     |
|    std                  | 0.837       |
|    value_loss           | 0.153       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 554         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 390         |
|    time_elapsed         | 226052      |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.028491084 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | -0.0261     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0617      |
|    n_updates            | 3890        |
|    policy_gradient_loss | 0.0169      |
|    std                  | 0.833       |
|    value_loss           | 0.141       |
-----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.49 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.037038133 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0797      |
|    n_updates            | 3900        |
|    policy_gradient_loss | 0.00875     |
|    std                  | 0.835       |
|    value_loss           | 0.128       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 549      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 228067   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 549        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 228280     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.07996768 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | -0.000422  |
|    learning_rate        | 0.0003     |
|    loss                 | 569        |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.00178    |
|    std                  | 0.837      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 555         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 393         |
|    time_elapsed         | 228490      |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.030223865 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | -0.0014     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 3920        |
|    policy_gradient_loss | 0.0091      |
|    std                  | 0.835       |
|    value_loss           | 0.183       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 555         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 228702      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.037470907 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.00692    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0626      |
|    n_updates            | 3930        |
|    policy_gradient_loss | 0.00601     |
|    std                  | 0.834       |
|    value_loss           | 0.153       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 556         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 395         |
|    time_elapsed         | 228915      |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.049762882 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | 1.79e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00963     |
|    n_updates            | 3940        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.829       |
|    value_loss           | 0.134       |
-----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.50 +/- 0.04
Episode length: 3596.00 +/- 10.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.06748174 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.62      |
|    explained_variance   | 0.00119    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0924     |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.824      |
|    value_loss           | 0.138      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 551      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 230932   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 551        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 231145     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.06274939 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.62      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 3.42e+03   |
|    n_updates            | 3960       |
|    policy_gradient_loss | 0.000366   |
|    std                  | 0.828      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 557         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 398         |
|    time_elapsed         | 231357      |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.025676074 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 3.46e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0575      |
|    n_updates            | 3970        |
|    policy_gradient_loss | 0.016       |
|    std                  | 0.829       |
|    value_loss           | 0.152       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 558         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 399         |
|    time_elapsed         | 231568      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.050241135 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0655      |
|    n_updates            | 3980        |
|    policy_gradient_loss | 0.00213     |
|    std                  | 0.821       |
|    value_loss           | 0.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 558         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 400         |
|    time_elapsed         | 231779      |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.048384503 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.0156      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 3990        |
|    policy_gradient_loss | 0.0065      |
|    std                  | 0.821       |
|    value_loss           | 0.192       |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.27 +/- 0.42
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.026377358 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | 0.000203    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0949      |
|    n_updates            | 4000        |
|    policy_gradient_loss | 0.018       |
|    std                  | 0.816       |
|    value_loss           | 0.211       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 553      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 233797   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 553         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 234010      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.050741926 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | -8.18e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.45e+03    |
|    n_updates            | 4010        |
|    policy_gradient_loss | 0.00727     |
|    std                  | 0.821       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 559        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 234222     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.03528554 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.57      |
|    explained_variance   | 3.82e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.154      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.00158    |
|    std                  | 0.821      |
|    value_loss           | 0.197      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 559        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 234435     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.05074463 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.57      |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0605     |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.00106    |
|    std                  | 0.821      |
|    value_loss           | 0.232      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 559         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 405         |
|    time_elapsed         | 234646      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.029722475 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.0455      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.116       |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.82        |
|    value_loss           | 0.168       |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.50 +/- 0.02
Episode length: 3598.60 +/- 4.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.037967518 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | -0.00923    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0175      |
|    n_updates            | 4050        |
|    policy_gradient_loss | 0.00832     |
|    std                  | 0.82        |
|    value_loss           | 0.159       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 554      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 236662   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 560         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 407         |
|    time_elapsed         | 236878      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.055223294 |
|    clip_fraction        | 0.464       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -0.000168   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 4060        |
|    policy_gradient_loss | 0.00524     |
|    std                  | 0.822       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 560        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 237090     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.04606068 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.57      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0455     |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.00109    |
|    std                  | 0.82       |
|    value_loss           | 0.238      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 409         |
|    time_elapsed         | 237303      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.026097238 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | -5.11e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.11        |
|    n_updates            | 4080        |
|    policy_gradient_loss | 0.0092      |
|    std                  | 0.816       |
|    value_loss           | 0.172       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 410         |
|    time_elapsed         | 237514      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.041304357 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.48       |
|    explained_variance   | 0.0929      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0393      |
|    n_updates            | 4090        |
|    policy_gradient_loss | 0.0058      |
|    std                  | 0.809       |
|    value_loss           | 0.26        |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.54 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.037116975 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | 0.000978    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0108      |
|    n_updates            | 4100        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.812       |
|    value_loss           | 0.128       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 555      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 239530   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 561        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 239744     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.05602401 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | -0.000427  |
|    learning_rate        | 0.0003     |
|    loss                 | 391        |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.0039     |
|    std                  | 0.816      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 413         |
|    time_elapsed         | 239956      |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.044674844 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.172       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0409      |
|    n_updates            | 4120        |
|    policy_gradient_loss | 0.0183      |
|    std                  | 0.812       |
|    value_loss           | 0.247       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 562         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 414         |
|    time_elapsed         | 240168      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.035464756 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.000325    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.27        |
|    n_updates            | 4130        |
|    policy_gradient_loss | 0.0152      |
|    std                  | 0.815       |
|    value_loss           | 0.197       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 562         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 415         |
|    time_elapsed         | 240383      |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.040371016 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 0.000208    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.111       |
|    n_updates            | 4140        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.818       |
|    value_loss           | 0.194       |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.61 +/- 0.05
Episode length: 3599.80 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.04349532 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.52      |
|    explained_variance   | -0.000454  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0645     |
|    n_updates            | 4150       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.818      |
|    value_loss           | 0.153      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 556      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 242399   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 563         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 242610      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.040430672 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -1.47e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 6           |
|    n_updates            | 4160        |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.819       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 563         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 418         |
|    time_elapsed         | 242821      |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.046796076 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | -5.84e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0736      |
|    n_updates            | 4170        |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.825       |
|    value_loss           | 0.188       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 563         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 419         |
|    time_elapsed         | 243033      |
|    total_timesteps      | 858112      |
| train/                  |             |
|    approx_kl            | 0.057080865 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.000981    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0678      |
|    n_updates            | 4180        |
|    policy_gradient_loss | 0.0176      |
|    std                  | 0.824       |
|    value_loss           | 0.197       |
-----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.56 +/- 0.04
Episode length: 3595.80 +/- 6.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.04560656 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.6       |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0806     |
|    n_updates            | 4190       |
|    policy_gradient_loss | 0.00392    |
|    std                  | 0.828      |
|    value_loss           | 0.14       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 557      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 245047   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 557        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 245259     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.05934512 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.63      |
|    explained_variance   | -1.31e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 11.2       |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.00584    |
|    std                  | 0.829      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 564        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 245470     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.04664354 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | -5.19e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.102      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.83       |
|    value_loss           | 0.187      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 564         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 423         |
|    time_elapsed         | 245683      |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.077212416 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.188       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0581      |
|    n_updates            | 4220        |
|    policy_gradient_loss | 0.00753     |
|    std                  | 0.829       |
|    value_loss           | 0.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 564        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 245895     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.04076474 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.66      |
|    explained_variance   | -0.000145  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.214      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.832      |
|    value_loss           | 0.174      |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.50 +/- 0.03
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.04407079 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.68      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.185      |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.000307  |
|    std                  | 0.834      |
|    value_loss           | 0.223      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 558      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 247909   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 558        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 248123     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.07543923 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.69      |
|    explained_variance   | -2.38e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 8.08       |
|    n_updates            | 4250       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.834      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 565         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 427         |
|    time_elapsed         | 248335      |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.028613986 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | -9.54e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0711      |
|    n_updates            | 4260        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.835       |
|    value_loss           | 0.247       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 565         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 428         |
|    time_elapsed         | 248547      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.042193636 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.13        |
|    n_updates            | 4270        |
|    policy_gradient_loss | 0.00114     |
|    std                  | 0.829       |
|    value_loss           | 0.284       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 565         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 429         |
|    time_elapsed         | 248761      |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.048851013 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | -0.00198    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0523      |
|    n_updates            | 4280        |
|    policy_gradient_loss | 0.0167      |
|    std                  | 0.823       |
|    value_loss           | 0.182       |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.52 +/- 0.05
Episode length: 3597.20 +/- 6.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.050744344 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -0.000536   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0993      |
|    n_updates            | 4290        |
|    policy_gradient_loss | 0.0178      |
|    std                  | 0.821       |
|    value_loss           | 0.225       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 561      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 250779   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 250991      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.055777147 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | -7.33e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.35        |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.0149      |
|    std                  | 0.819       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 567         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 432         |
|    time_elapsed         | 251204      |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.042888805 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 9.12e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 4310        |
|    policy_gradient_loss | 0.0191      |
|    std                  | 0.818       |
|    value_loss           | 0.247       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 567        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 251414     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.03418555 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | -0.136     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0271     |
|    n_updates            | 4320       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.813      |
|    value_loss           | 0.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 568        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 251625     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.10090275 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.49      |
|    explained_variance   | -0.00135   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.116      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.814      |
|    value_loss           | 0.207      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.52 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.035883743 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | -0.0269     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0504      |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.0159      |
|    std                  | 0.817       |
|    value_loss           | 0.146       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 563      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 253638   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 563         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 253851      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.061008245 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | -0.000109   |
|    learning_rate        | 0.0003      |
|    loss                 | 22.3        |
|    n_updates            | 4350        |
|    policy_gradient_loss | 0.00477     |
|    std                  | 0.818       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 569         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 437         |
|    time_elapsed         | 254063      |
|    total_timesteps      | 894976      |
| train/                  |             |
|    approx_kl            | 0.042077724 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | -2.6e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.157       |
|    n_updates            | 4360        |
|    policy_gradient_loss | 0.0199      |
|    std                  | 0.821       |
|    value_loss           | 0.205       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 570         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 438         |
|    time_elapsed         | 254275      |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.052704375 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | -0.0626     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0559      |
|    n_updates            | 4370        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.817       |
|    value_loss           | 0.221       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 570        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 254487     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.03720632 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.55      |
|    explained_variance   | -0.164     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0609     |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0049     |
|    std                  | 0.82       |
|    value_loss           | 0.159      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.52 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.03612102 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.52      |
|    explained_variance   | -0.00133   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0938     |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.813      |
|    value_loss           | 0.164      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 565      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 256499   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 565         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 256710      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.070819795 |
|    clip_fraction        | 0.463       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | -2.86e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+03    |
|    n_updates            | 4400        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.813       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 571        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 256920     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.04969365 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.49      |
|    explained_variance   | -7.25e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0489     |
|    n_updates            | 4410       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.813      |
|    value_loss           | 0.161      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 572         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 443         |
|    time_elapsed         | 257132      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.061061926 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | -0.229      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 4420        |
|    policy_gradient_loss | 0.0218      |
|    std                  | 0.809       |
|    value_loss           | 0.183       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 572        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 257342     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.06432884 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.0507     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0771     |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.00503    |
|    std                  | 0.808      |
|    value_loss           | 0.15       |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.60 +/- 0.03
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.035709243 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.000543    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0344      |
|    n_updates            | 4440        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.806       |
|    value_loss           | 0.131       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 567      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 259355   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 567         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 259567      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.057522394 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | -0.000259   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.31e+03    |
|    n_updates            | 4450        |
|    policy_gradient_loss | 0.00434     |
|    std                  | 0.805       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 573         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 447         |
|    time_elapsed         | 259780      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.064910784 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.000353    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0916      |
|    n_updates            | 4460        |
|    policy_gradient_loss | 0.0166      |
|    std                  | 0.805       |
|    value_loss           | 0.147       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 574         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 448         |
|    time_elapsed         | 259990      |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.033953305 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.201       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.07        |
|    n_updates            | 4470        |
|    policy_gradient_loss | 0.00761     |
|    std                  | 0.805       |
|    value_loss           | 0.165       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 574         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 449         |
|    time_elapsed         | 260201      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.056923337 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | 7.36e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.131       |
|    n_updates            | 4480        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.802       |
|    value_loss           | 0.17        |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.58 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.050818972 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 3.18e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0737      |
|    n_updates            | 4490        |
|    policy_gradient_loss | 0.0172      |
|    std                  | 0.801       |
|    value_loss           | 0.146       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 568      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 262213   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 574         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 262423      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.054682024 |
|    clip_fraction        | 0.454       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | -0.000726   |
|    learning_rate        | 0.0003      |
|    loss                 | 14.1        |
|    n_updates            | 4500        |
|    policy_gradient_loss | 0.0052      |
|    std                  | 0.799       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 574         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 262633      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.030625612 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | -0.0455     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0232      |
|    n_updates            | 4510        |
|    policy_gradient_loss | 0.0192      |
|    std                  | 0.796       |
|    value_loss           | 0.157       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 576         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 453         |
|    time_elapsed         | 262843      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.045920566 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 2.81e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0833      |
|    n_updates            | 4520        |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.795       |
|    value_loss           | 0.156       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 576        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 263053     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.04195199 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | -5.83      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0178     |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.00914    |
|    std                  | 0.793      |
|    value_loss           | 0.184      |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.59 +/- 0.02
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.06636272 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.000117   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0261     |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.794      |
|    value_loss           | 0.137      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 570      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 265065   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 577         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 265277      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.079011664 |
|    clip_fraction        | 0.495       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | -0.000208   |
|    learning_rate        | 0.0003      |
|    loss                 | 929         |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.00806     |
|    std                  | 0.795       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 577        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 265487     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.06835732 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.29      |
|    explained_variance   | -0.126     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0361     |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.00257    |
|    std                  | 0.79       |
|    value_loss           | 0.313      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 578         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 458         |
|    time_elapsed         | 265699      |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.041503504 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | -0.00235    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0847      |
|    n_updates            | 4570        |
|    policy_gradient_loss | 0.0158      |
|    std                  | 0.784       |
|    value_loss           | 0.156       |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.58 +/- 0.04
Episode length: 3597.40 +/- 4.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.03360767 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.2       |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0408     |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.783      |
|    value_loss           | 0.187      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 572      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 267710   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 572        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 267921     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.10398617 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | -4.92e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 35.1       |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.784      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 578        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 268132     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.04255262 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | -0.00171   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0373     |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.779      |
|    value_loss           | 0.172      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 578         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 462         |
|    time_elapsed         | 268341      |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.102094315 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | -1.1        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0795      |
|    n_updates            | 4610        |
|    policy_gradient_loss | 0.025       |
|    std                  | 0.776       |
|    value_loss           | 0.188       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 579         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 268551      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.039535657 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | -0.00072    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0866      |
|    n_updates            | 4620        |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.776       |
|    value_loss           | 0.175       |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.54 +/- 0.03
Episode length: 3599.00 +/- 3.52
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.039160017 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | -0.0277     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0769      |
|    n_updates            | 4630        |
|    policy_gradient_loss | 0.016       |
|    std                  | 0.775       |
|    value_loss           | 0.109       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 574      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 270562   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 574        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 270777     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.08888286 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.14      |
|    explained_variance   | -0.00152   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.94e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.779      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 580        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 270989     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.04941953 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | 0.00184    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.027      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0307     |
|    std                  | 0.778      |
|    value_loss           | 0.228      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 580        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 271200     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.05077312 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.16      |
|    explained_variance   | 0.31       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0898     |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.777      |
|    value_loss           | 0.172      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 580         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 271412      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.044740845 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -7.45e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0371      |
|    n_updates            | 4670        |
|    policy_gradient_loss | 0.00879     |
|    std                  | 0.78        |
|    value_loss           | 0.127       |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.53 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.062179547 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.21       |
|    explained_variance   | -0.0773     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.103       |
|    n_updates            | 4680        |
|    policy_gradient_loss | 0.0151      |
|    std                  | 0.785       |
|    value_loss           | 0.119       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 575      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 273426   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 575         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 273639      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.047537852 |
|    clip_fraction        | 0.492       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | -0.000277   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.61e+03    |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.00869     |
|    std                  | 0.787       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 581         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 273850      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.046457235 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | -0.00693    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0713      |
|    n_updates            | 4700        |
|    policy_gradient_loss | 0.0199      |
|    std                  | 0.785       |
|    value_loss           | 0.197       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 581         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 472         |
|    time_elapsed         | 274062      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.121610716 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | -0.00817    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.154       |
|    n_updates            | 4710        |
|    policy_gradient_loss | 0.0275      |
|    std                  | 0.783       |
|    value_loss           | 0.165       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 582        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 274275     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.03266203 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.22      |
|    explained_variance   | -0.001     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0827     |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.783      |
|    value_loss           | 0.166      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.53 +/- 0.03
Episode length: 3600.00 +/- 1.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.057438225 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | -1.88       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0258      |
|    n_updates            | 4730        |
|    policy_gradient_loss | 0.00712     |
|    std                  | 0.785       |
|    value_loss           | 0.186       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 576      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 276286   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 576        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 276498     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.05239805 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.23      |
|    explained_variance   | -0.000155  |
|    learning_rate        | 0.0003     |
|    loss                 | 33.4       |
|    n_updates            | 4740       |
|    policy_gradient_loss | 0.00172    |
|    std                  | 0.782      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 583        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 476        |
|    time_elapsed         | 276710     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.04112504 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.22      |
|    explained_variance   | 5.6e-05    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0846     |
|    n_updates            | 4750       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.781      |
|    value_loss           | 0.164      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 583         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 477         |
|    time_elapsed         | 276922      |
|    total_timesteps      | 976896      |
| train/                  |             |
|    approx_kl            | 0.040519275 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | -0.0259     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0437      |
|    n_updates            | 4760        |
|    policy_gradient_loss | 0.00878     |
|    std                  | 0.781       |
|    value_loss           | 0.179       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 583         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 478         |
|    time_elapsed         | 277133      |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.048693173 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.21       |
|    explained_variance   | 0.000172    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0229      |
|    n_updates            | 4770        |
|    policy_gradient_loss | 0.023       |
|    std                  | 0.781       |
|    value_loss           | 0.154       |
-----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.53 +/- 0.03
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.049404033 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0251      |
|    n_updates            | 4780        |
|    policy_gradient_loss | 0.00791     |
|    std                  | 0.782       |
|    value_loss           | 0.206       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 578      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 279145   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 578        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 279357     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.08914794 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | -3.19e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05e+03   |
|    n_updates            | 4790       |
|    policy_gradient_loss | 0.00817    |
|    std                  | 0.783      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 584        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 279568     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.04532727 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | -0.0198    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0438     |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.783      |
|    value_loss           | 0.137      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 584         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 482         |
|    time_elapsed         | 279779      |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.057233945 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0377      |
|    n_updates            | 4810        |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.784       |
|    value_loss           | 0.178       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 584         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 483         |
|    time_elapsed         | 279990      |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.056621715 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | 1.87e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.129       |
|    n_updates            | 4820        |
|    policy_gradient_loss | 0.0181      |
|    std                  | 0.784       |
|    value_loss           | 0.114       |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.56 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.03137678 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.26      |
|    explained_variance   | -0.00793   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0708     |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.00938    |
|    std                  | 0.787      |
|    value_loss           | 0.182      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 579      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 282005   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 579         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 282218      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.055470597 |
|    clip_fraction        | 0.447       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | -7.33e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 10.6        |
|    n_updates            | 4840        |
|    policy_gradient_loss | 0.00805     |
|    std                  | 0.786       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 585        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 282428     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.03342245 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.29      |
|    explained_variance   | -3.22e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0866     |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.79       |
|    value_loss           | 0.163      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 585         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 487         |
|    time_elapsed         | 282638      |
|    total_timesteps      | 997376      |
| train/                  |             |
|    approx_kl            | 0.029611602 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.26       |
|    explained_variance   | 0.00211     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0569      |
|    n_updates            | 4860        |
|    policy_gradient_loss | 0.0161      |
|    std                  | 0.783       |
|    value_loss           | 0.162       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 585        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 282847     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.06093885 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.22      |
|    explained_variance   | -1.31      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0464     |
|    n_updates            | 4870       |
|    policy_gradient_loss | 0.00863    |
|    std                  | 0.783      |
|    value_loss           | 0.13       |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.59 +/- 0.04
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.0374449 |
|    clip_fraction        | 0.287     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.22     |
|    explained_variance   | 0.000991  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.028     |
|    n_updates            | 4880      |
|    policy_gradient_loss | 0.00844   |
|    std                  | 0.782     |
|    value_loss           | 0.117     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 580      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 284859   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-20_12-13-39_llm_triton_qwen_3b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 7:05:04 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-99.952026 -99.940698 -99.915101 -99.923293 -99.929836]
 [-99.826854 -99.798241 -99.81969  -99.807058 -99.821769]
 [-99.816026 -99.755926 -99.8062   -99.694302 -99.682071]
 [-99.834257 -99.78629  -99.818853 -99.691895 -99.809541]
 [-99.726653 -99.746898 -99.783283 -99.795357 -99.749861]
 [-99.718199 -99.723076 -99.733052 -99.747688 -99.742122]
 [-99.68579  -99.910022 -99.743295 -99.677183 -99.628015]
 [-99.754096 -99.693864 -99.737125 -99.647974 -99.692264]
 [-99.844524 -99.618117 -99.861955 -99.842185 -99.679591]
 [-99.704441 -99.884979 -99.626662 -99.856888 -99.602407]
 [-99.898748 -99.875074 -99.882287 -99.822468 -99.615045]
 [-99.856074 -99.86536  -99.60027  -99.657393 -99.889847]
 [-99.596904 -99.742536 -99.704059 -99.616877 -99.82033 ]
 [-99.621205 -99.872951 -99.614409 -99.817442 -99.828777]
 [-99.691005 -99.696078 -99.68345  -99.606433 -99.839736]
 [-99.643771 -99.585587 -99.787298 -99.821398 -99.645551]
 [-99.610452 -99.578205 -99.56034  -99.559256 -99.608154]
 [-99.562485 -99.588012 -99.598907 -99.655128 -99.668065]
 [-99.556908 -99.593784 -99.571428 -99.625181 -99.615033]
 [-99.546456 -99.636933 -99.539472 -99.530215 -99.514278]
 [-99.619407 -99.601167 -99.549073 -99.550779 -99.587409]
 [-99.621275 -99.528759 -99.485873 -99.528284 -99.560568]
 [-99.611635 -99.593636 -99.625111 -99.528548 -99.506901]
 [-99.495282 -99.593217 -99.521283 -99.564494 -99.611988]
 [-99.472207 -99.518689 -99.612577 -99.512561 -99.520616]
 [-99.537093 -99.496381 -99.556064 -99.605588 -99.613443]
 [-99.633172 -99.908744 -99.651697 -99.58902  -99.598644]
 [-99.595858 -99.530792 -99.563237 -99.607599 -99.531806]
 [-99.553578 -99.481327 -99.557617 -99.488303 -99.615592]
 [-99.646302 -99.631382 -99.580071 -99.572544 -99.630067]
 [-99.575382 -99.509877 -99.588144 -99.624782 -99.495093]
 [-99.622976 -99.588786 -99.513284 -99.536225 -99.523623]
 [-99.728941 -99.775552 -99.730917 -99.7373   -99.733509]
 [-99.543604 -99.571729 -99.575756 -99.568642 -99.585221]
 [-99.587698 -99.620704 -99.671114 -99.646374 -99.681621]
 [-99.556542 -99.610688 -99.57204  -99.606579 -99.621129]
 [-99.651658 -99.537875 -99.583735 -99.626579 -99.632693]
 [-99.575267 -99.549592 -99.685657 -99.647277 -99.647787]
 [-99.716771 -99.645332 -99.67007  -99.623192 -99.58276 ]
 [-99.63913  -99.674737 -99.574859 -99.571238 -99.619796]
 [-99.672109 -99.600653 -99.534381 -99.571983 -99.662996]
 [-99.589067 -99.522993 -99.615549 -99.595064 -99.498662]
 [-99.526362 -99.582037 -99.610539 -99.539071 -99.485751]
 [-99.50385  -99.567687 -99.565936 -99.577623 -99.493868]
 [-99.53164  -99.502403 -99.543213 -99.520602 -99.4667  ]
 [-99.519659 -99.624234 -99.557262 -99.614703 -99.565304]
 [-99.610375 -99.469973 -99.552888 -99.571146 -99.596819]
 [-99.555638 -99.510778 -99.627828 -99.62031  -99.521232]
 [-99.536357 -99.460473 -99.527117 -99.569972 -99.563929]
 [-99.560976 -99.456438 -99.547085 -99.536686 -99.546859]
 [-99.535222 -99.61118  -99.532002 -99.536568 -99.518913]
 [-99.564736 -99.500273 -99.45596  -99.531195 -99.585066]
 [-99.517537 -99.461693 -99.467348 -99.539269 -99.502884]
 [-99.564707 -99.511333 -99.466527 -99.506208 -99.510852]
 [-99.573987 -99.506753 -99.477667 -99.496989 -99.515972]
 [-99.46157  -99.556355 -99.592343 -99.558132 -99.563931]
 [-99.528872 -99.586791 -99.555694 -99.494185 -99.568502]
 [-99.474111 -99.524696 -99.490038 -99.574793 -99.562906]
 [-99.535876 -99.567962 -99.549934 -99.476636 -99.578927]
 [-99.48859  -99.464769 -99.536373 -99.529217 -99.531039]
 [-99.557684 -99.520057 -99.626716 -99.540998 -99.856625]
 [-99.548345 -99.557566 -99.582371 -99.558717 -99.478455]
 [-99.547171 -99.490014 -99.52342  -99.564401 -99.645541]
 [-99.481647 -99.603484 -99.59006  -99.686214 -99.757679]
 [-99.655863 -99.64571  -99.731609 -99.775643 -99.73314 ]
 [-99.532115 -99.456396 -99.836012 -99.498308 -99.758343]
 [-99.6037   -99.560346 -99.859459 -99.705535 -99.52703 ]
 [-99.597986 -99.515436 -99.540845 -99.531601 -99.580177]
 [-99.52213  -99.470397 -99.590143 -99.490322 -99.5399  ]
 [-99.571261 -99.467656 -99.478369 -99.579172 -99.561291]
 [-99.608692 -99.591417 -99.539452 -99.576704 -99.544161]
 [-99.535391 -99.572219 -99.478738 -99.487367 -99.461089]
 [-99.488288 -99.539679 -99.502628 -99.585217 -99.505488]
 [-99.517225 -99.51255  -99.58963  -99.550852 -99.608805]
 [-99.527235 -99.4685   -99.545951 -99.528042 -99.447404]
 [-99.509571 -99.49093  -99.449225 -99.498423 -99.49125 ]
 [-99.517722 -99.491827 -99.501822 -99.512299 -99.490011]
 [-99.43792  -99.469758 -99.43332  -99.470891 -99.520682]
 [-99.539938 -99.555078 -99.463654 -99.608154 -99.553121]
 [-99.461951 -99.499605 -99.502732 -99.497834 -99.46832 ]
 [-99.51325  -99.451465 -99.521872 -99.54167  -99.453777]
 [-99.506564 -99.462266 -99.468018 -98.428496 -99.497867]
 [-99.471399 -99.494318 -99.541863 -99.489562 -99.488637]
 [-99.493784 -99.565686 -99.606248 -99.564853 -99.486806]
 [-99.534694 -99.649842 -99.577765 -99.648212 -99.642371]
 [-99.495734 -99.586618 -99.521439 -99.599193 -99.573714]
 [-99.489126 -99.466935 -99.490599 -99.506084 -99.563762]
 [-99.513089 -99.484565 -99.545564 -99.472943 -99.598079]
 [-99.495076 -99.47471  -99.551306 -99.533051 -99.562866]
 [-99.5159   -99.472274 -99.611498 -99.525451 -99.462934]
 [-99.629376 -99.633217 -99.571909 -99.605113 -99.541914]
 [-99.613941 -99.552679 -99.645859 -99.565836 -99.513759]
 [-99.597089 -99.576117 -99.566235 -99.610373 -99.610344]
 [-99.519525 -99.549693 -99.61583  -99.588152 -99.644829]
 [-99.478887 -99.567717 -99.534314 -99.537466 -99.572403]
 [-99.597281 -99.518512 -99.525488 -99.493721 -99.504622]
 [-99.549371 -99.587409 -99.51791  -99.490155 -99.513688]
 [-99.514759 -99.498037 -99.492209 -99.533518 -99.587926]
 [-99.541933 -99.591943 -99.565836 -99.538338 -99.56391 ]
 [-99.583549 -99.634152 -99.51872  -99.607262 -99.602783]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3574 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3585 3601 3601]
 [3601 3601 3601 3593 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3589 3601 3601]
 [3598 3593 3601 3601 3601]
 [3583 3601 3601 3594 3601]
 [3600 3601 3601 3601 3601]
 [3581 3601 3601 3601 3601]
 [3601 3595 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3580 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3593 3601 3601]
 [3598 3601 3585 3601 3601]
 [3601 3601 3601 3601 3601]
 [3576 3601 3601 3601 3601]
 [3601 3601 3601 3591 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3594 3601 3601 3601]
 [3601 3601 3601 3601 3593]
 [3601 3601 3582 3601 3601]
 [3601 3601 3601 3601 3601]
 [3577 3601 3595 3601 3601]
 [3601 3601 3601 3601 3601]
 [3579 3601 3601 3601 3601]
 [3594 3601 3601 3601 3601]
 [3584 3601 3601 3594 3601]
 [3601 3601 3601 3601 3601]
 [3577 3601 3601 3601 3601]
 [3601 3596 3601 3601 3601]
 [3575 3601 3601 3601 3595]
 [3601 3601 3601 3601 3601]
 [3578 3601 3601 3601 3601]
 [3601 3601 3593 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3573 3601 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3594 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3582 3594 3601 3601 3601]
 [3601 3601 3601 3597 3599]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3586 3598 3599 3601 3601]
 [3601 3601 3601 3601 3599]
 [3579 3601 3601 3601 3601]
 [3596 3601 3601 3601 3601]
 [3580 3601 3596 3599 3601]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3579 3601 3601 3595 3601]
 [3601 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3601 3594 3601 3601 3601]
 [3582 3601 3601 3601 3593]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3593 3601 3601]
 [3579 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3596 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3590 3597 3601 3601 3601]
 [3601 3601 3601 3601 3597]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3576 3601 3601 3601 3601]
 [3601 3601 3601 3582 3601]
 [3600 3601 3601 3601 3590]
 [3601 3601 3601 3601 3601]
 [3601 3595 3601 3601 3601]
 [3601 3601 3584 3601 3592]
 [3601 3601 3601 3601 3584]
 [3601 3601 3601 3584 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3594]
 [3601 3601 3601 3601 3601]
 [3601 3596 3601 3601 3601]
 [3590 3597 3598 3601 3601]
 [3601 3601 3601 3592 3600]
 [3601 3601 3601 3601 3601]
 [3600 3601 3597 3601 3601]
 [3601 3601 3580 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-20_12-13-39_llm_triton_qwen_3b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-20_12-13-39_llm_triton_qwen_3b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/model
