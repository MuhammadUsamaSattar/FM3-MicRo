####################
/var/spool/slurmd/job5534534/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_32B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-02-04_22-27-54_llm_triton_qwen_32b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and +9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.82e+03 |
|    ep_rew_mean     | -227     |
| time/              |          |
|    fps             | 5        |
|    iterations      | 1        |
|    time_elapsed    | 406      |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.82e+03    |
|    ep_rew_mean          | -227        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 2           |
|    time_elapsed         | 813         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012341654 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.04        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.96        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0202     |
|    std                  | 1           |
|    value_loss           | 4.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.82e+03    |
|    ep_rew_mean          | -228        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 3           |
|    time_elapsed         | 1216        |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010590563 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.376       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0218     |
|    std                  | 1           |
|    value_loss           | 4.7         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.82e+03     |
|    ep_rew_mean          | -212         |
| time/                   |              |
|    fps                  | 5            |
|    iterations           | 4            |
|    time_elapsed         | 1622         |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0093316985 |
|    clip_fraction        | 0.104        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.451        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.23         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0194      |
|    std                  | 0.999        |
|    value_loss           | 2.84         |
------------------------------------------
Eval num_timesteps=10000, episode_reward=-99.96 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.011331229 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.999       |
|    value_loss           | 1.85        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -262     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 5        |
|    time_elapsed    | 3829     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.69e+03     |
|    ep_rew_mean          | -250         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 6            |
|    time_elapsed         | 4230         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0012138461 |
|    clip_fraction        | 0.000928     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.0115       |
|    learning_rate        | 0.0003       |
|    loss                 | 124          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00209     |
|    std                  | 0.999        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.71e+03    |
|    ep_rew_mean          | -235        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 7           |
|    time_elapsed         | 4627        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.010533926 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.999       |
|    value_loss           | 4.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.73e+03    |
|    ep_rew_mean          | -223        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 8           |
|    time_elapsed         | 5025        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.010212736 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.484       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.912       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.998       |
|    value_loss           | 2.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.74e+03    |
|    ep_rew_mean          | -212        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 9           |
|    time_elapsed         | 5421        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.009729992 |
|    clip_fraction        | 0.095       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.588       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.997       |
|    value_loss           | 1.5         |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.99 +/- 0.06
Episode length: 3594.20 +/- 13.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.013329878 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.426       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.995       |
|    value_loss           | 1.27        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -232     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 10       |
|    time_elapsed    | 7620     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.68e+03     |
|    ep_rew_mean          | -223         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 11           |
|    time_elapsed         | 8018         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0020289652 |
|    clip_fraction        | 0.00215      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00838     |
|    learning_rate        | 0.0003       |
|    loss                 | 478          |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00264     |
|    std                  | 0.995        |
|    value_loss           | 1.04e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.69e+03     |
|    ep_rew_mean          | -213         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 12           |
|    time_elapsed         | 8415         |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0140194725 |
|    clip_fraction        | 0.149        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.74        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.987        |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0221      |
|    std                  | 0.994        |
|    value_loss           | 1.94         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.7e+03     |
|    ep_rew_mean          | -207        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 8812        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.010624012 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.549       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.994       |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.71e+03    |
|    ep_rew_mean          | -199        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 9207        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.017811667 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.573       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.99        |
|    value_loss           | 1.38        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.91 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.015233539 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.339       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.991       |
|    value_loss           | 0.752       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -210     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 15       |
|    time_elapsed    | 11410    |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.68e+03     |
|    ep_rew_mean          | -202         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 16           |
|    time_elapsed         | 11805        |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0076832795 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00544     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.35e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.003       |
|    std                  | 0.992        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.69e+03    |
|    ep_rew_mean          | -195        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 17          |
|    time_elapsed         | 12201       |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.017199598 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -1.49       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.364       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.991       |
|    value_loss           | 0.976       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.69e+03    |
|    ep_rew_mean          | -189        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 18          |
|    time_elapsed         | 12595       |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.019248474 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.236       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.993       |
|    value_loss           | 0.624       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.7e+03     |
|    ep_rew_mean          | -183        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 19          |
|    time_elapsed         | 12990       |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.018715378 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.325       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.989       |
|    value_loss           | 0.578       |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.98 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.012555296 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.594       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.223       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.986       |
|    value_loss           | 0.587       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -191     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 20       |
|    time_elapsed    | 15186    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -185        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 21          |
|    time_elapsed         | 15585       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.010415534 |
|    clip_fraction        | 0.0897      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00358     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.36e+03    |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.986       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -180       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 22         |
|    time_elapsed         | 15981      |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.02052822 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.354      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.285      |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.982      |
|    value_loss           | 0.61       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.69e+03    |
|    ep_rew_mean          | -174        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 23          |
|    time_elapsed         | 16376       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.019603398 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.526       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.336       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.976       |
|    value_loss           | 0.497       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.69e+03   |
|    ep_rew_mean          | -170       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 24         |
|    time_elapsed         | 16770      |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.02427068 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.116      |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.976      |
|    value_loss           | 0.514      |
----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.96 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.02015222 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.216      |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0096    |
|    std                  | 0.97       |
|    value_loss           | 0.394      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -177     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 25       |
|    time_elapsed    | 18964    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -173        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 26          |
|    time_elapsed         | 19363       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.019191444 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.00418     |
|    learning_rate        | 0.0003      |
|    loss                 | 649         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00137    |
|    std                  | 0.971       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -168        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 27          |
|    time_elapsed         | 19759       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.024335394 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.271       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0091     |
|    std                  | 0.965       |
|    value_loss           | 0.647       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.68e+03     |
|    ep_rew_mean          | -164         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 28           |
|    time_elapsed         | 20152        |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0138252415 |
|    clip_fraction        | 0.173        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.704        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.268        |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.013       |
|    std                  | 0.96         |
|    value_loss           | 0.609        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.7e+03     |
|    ep_rew_mean          | -156        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 29          |
|    time_elapsed         | 20545       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.014808368 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.648       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.299       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00911    |
|    std                  | 0.958       |
|    value_loss           | 0.576       |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.88 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.021450244 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.254       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00721    |
|    std                  | 0.955       |
|    value_loss           | 0.488       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -166     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 30       |
|    time_elapsed    | 22739    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -162        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 31          |
|    time_elapsed         | 23136       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.018280894 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00762     |
|    learning_rate        | 0.0003      |
|    loss                 | 650         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0057     |
|    std                  | 0.955       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -158       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 32         |
|    time_elapsed         | 23528      |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.02883146 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.507      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.00701   |
|    std                  | 0.952      |
|    value_loss           | 1.01       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.69e+03    |
|    ep_rew_mean          | -151        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 33          |
|    time_elapsed         | 23920       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.020083545 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.465       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.242       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.961       |
|    value_loss           | 0.802       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.69e+03    |
|    ep_rew_mean          | -147        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 34          |
|    time_elapsed         | 24311       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.021595383 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.35        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.172       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.96        |
|    value_loss           | 0.666       |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.86 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.017152658 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.255       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00909    |
|    std                  | 0.958       |
|    value_loss           | 0.493       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -156     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 35       |
|    time_elapsed    | 26504    |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | -153       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 36         |
|    time_elapsed         | 26894      |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.00306979 |
|    clip_fraction        | 0.0128     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.00338   |
|    learning_rate        | 0.0003     |
|    loss                 | 133        |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.00149   |
|    std                  | 0.958      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -146        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 37          |
|    time_elapsed         | 27290       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.012488445 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.174      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.957       |
|    value_loss           | 1.04        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.69e+03     |
|    ep_rew_mean          | -143         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 38           |
|    time_elapsed         | 27681        |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0148544125 |
|    clip_fraction        | 0.122        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.269        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.382        |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00971     |
|    std                  | 0.955        |
|    value_loss           | 0.619        |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.69e+03   |
|    ep_rew_mean          | -140       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 39         |
|    time_elapsed         | 28071      |
|    total_timesteps      | 79872      |
| train/                  |            |
|    approx_kl            | 0.01753631 |
|    clip_fraction        | 0.15       |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.233      |
|    n_updates            | 380        |
|    policy_gradient_loss | -0.00982   |
|    std                  | 0.955      |
|    value_loss           | 0.622      |
----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.74 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.013740655 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.306       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.953       |
|    value_loss           | 0.645       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -145     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 40       |
|    time_elapsed    | 30264    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -142        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 41          |
|    time_elapsed         | 30655       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.009607565 |
|    clip_fraction        | 0.0765      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00514     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00642    |
|    std                  | 0.953       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -140       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 42         |
|    time_elapsed         | 31053      |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.01885565 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.0251     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.25       |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.00943   |
|    std                  | 0.951      |
|    value_loss           | 0.584      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -137       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 43         |
|    time_elapsed         | 31445      |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.01547446 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.26       |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0092    |
|    std                  | 0.949      |
|    value_loss           | 0.569      |
----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.92 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.025960058 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.476       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.24        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00925    |
|    std                  | 0.947       |
|    value_loss           | 0.595       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -141     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 44       |
|    time_elapsed    | 33636    |
|    total_timesteps | 90112    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | -139       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 45         |
|    time_elapsed         | 34028      |
|    total_timesteps      | 92160      |
| train/                  |            |
|    approx_kl            | 0.03260534 |
|    clip_fraction        | 0.0821     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.000421  |
|    learning_rate        | 0.0003     |
|    loss                 | 250        |
|    n_updates            | 440        |
|    policy_gradient_loss | -0.00343   |
|    std                  | 0.947      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | -136       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 46         |
|    time_elapsed         | 34419      |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.02917401 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.602     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.224      |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.00401   |
|    std                  | 0.946      |
|    value_loss           | 0.54       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -133        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 47          |
|    time_elapsed         | 34815       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.017797636 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.266       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00639    |
|    std                  | 0.946       |
|    value_loss           | 0.554       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -131        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 48          |
|    time_elapsed         | 35208       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.013918907 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.407       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00855    |
|    std                  | 0.947       |
|    value_loss           | 0.492       |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.93 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.017777734 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00816    |
|    std                  | 0.941       |
|    value_loss           | 0.629       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -135     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 49       |
|    time_elapsed    | 37398    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 50          |
|    time_elapsed         | 37789       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.010561086 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000558   |
|    learning_rate        | 0.0003      |
|    loss                 | 906         |
|    n_updates            | 490         |
|    policy_gradient_loss | 0.000169    |
|    std                  | 0.941       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -130        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 51          |
|    time_elapsed         | 38179       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.023169609 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.212       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.946       |
|    value_loss           | 0.56        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -128       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 52         |
|    time_elapsed         | 38568      |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.01668032 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.173      |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.00411   |
|    std                  | 0.946      |
|    value_loss           | 0.551      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -126        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 53          |
|    time_elapsed         | 38963       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.020510819 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.457       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.254       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0051     |
|    std                  | 0.946       |
|    value_loss           | 0.586       |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.67 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.015745807 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.498       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.288       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00338    |
|    std                  | 0.942       |
|    value_loss           | 0.652       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -129     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 54       |
|    time_elapsed    | 41156    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -127        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 55          |
|    time_elapsed         | 41546       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.005595484 |
|    clip_fraction        | 0.0862      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000896   |
|    learning_rate        | 0.0003      |
|    loss                 | 314         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.942       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -126        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 56          |
|    time_elapsed         | 41935       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.030784443 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.745      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.175       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00578    |
|    std                  | 0.94        |
|    value_loss           | 0.582       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -124        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 57          |
|    time_elapsed         | 42325       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.023650354 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.362       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.288       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.000339   |
|    std                  | 0.94        |
|    value_loss           | 0.568       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -122        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 58          |
|    time_elapsed         | 42720       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.019448683 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.424       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.291       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00239    |
|    std                  | 0.938       |
|    value_loss           | 0.631       |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.73 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.026304489 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.492       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.26        |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00584    |
|    std                  | 0.936       |
|    value_loss           | 0.563       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -125     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 59       |
|    time_elapsed    | 44912    |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | -123       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 60         |
|    time_elapsed         | 45300      |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.00996829 |
|    clip_fraction        | 0.12       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.00287   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.89e+03   |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.00523   |
|    std                  | 0.937      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -121        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 61          |
|    time_elapsed         | 45688       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.029268194 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.843      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.202       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00824    |
|    std                  | 0.938       |
|    value_loss           | 0.762       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -120       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 62         |
|    time_elapsed         | 46074      |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.02249623 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.238      |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.00741   |
|    std                  | 0.941      |
|    value_loss           | 0.596      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -118        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 63          |
|    time_elapsed         | 46466       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.018916905 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.406       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.253       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00847    |
|    std                  | 0.945       |
|    value_loss           | 0.523       |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.75 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.023395076 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.499       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.393       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.000954   |
|    std                  | 0.944       |
|    value_loss           | 0.723       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -121     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 64       |
|    time_elapsed    | 48659    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -119        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 65          |
|    time_elapsed         | 49048       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.008270079 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00193    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.84        |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0043     |
|    std                  | 0.944       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -118        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 66          |
|    time_elapsed         | 49437       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.024303772 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.109      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.255       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00402    |
|    std                  | 0.944       |
|    value_loss           | 0.691       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -116        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 67          |
|    time_elapsed         | 49825       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.033081807 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.213       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00539    |
|    std                  | 0.941       |
|    value_loss           | 0.518       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -115        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 68          |
|    time_elapsed         | 50214       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.020173457 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.211       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0032     |
|    std                  | 0.939       |
|    value_loss           | 0.587       |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.77 +/- 0.04
Episode length: 3597.20 +/- 4.66
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.02848541 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.434      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.276      |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.00891   |
|    std                  | 0.939      |
|    value_loss           | 0.597      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -118     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 69       |
|    time_elapsed    | 52404    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -116        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 70          |
|    time_elapsed         | 52793       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.013615157 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0012     |
|    learning_rate        | 0.0003      |
|    loss                 | 71          |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.939       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -115        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 71          |
|    time_elapsed         | 53181       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.027852468 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0685     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.000182   |
|    std                  | 0.939       |
|    value_loss           | 0.717       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -113        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 72          |
|    time_elapsed         | 53569       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.041057765 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.22        |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.938       |
|    value_loss           | 0.456       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -111        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 73          |
|    time_elapsed         | 53955       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.023323977 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.246       |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.00299     |
|    std                  | 0.939       |
|    value_loss           | 0.556       |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.77 +/- 0.06
Episode length: 3599.00 +/- 4.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.03391523 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.417      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.271      |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00214   |
|    std                  | 0.936      |
|    value_loss           | 0.526      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -114     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 74       |
|    time_elapsed    | 56150    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -112        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 75          |
|    time_elapsed         | 56541       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.010685548 |
|    clip_fraction        | 0.0871      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00187     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.1         |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00157    |
|    std                  | 0.936       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -111        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 76          |
|    time_elapsed         | 56929       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.021230005 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.288       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00248    |
|    std                  | 0.934       |
|    value_loss           | 0.622       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -108        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 77          |
|    time_elapsed         | 57315       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.028683998 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.372       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.359       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.934       |
|    value_loss           | 0.504       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 78          |
|    time_elapsed         | 57702       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.020742357 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.306       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.204       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.000771   |
|    std                  | 0.937       |
|    value_loss           | 0.602       |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.81 +/- 0.02
Episode length: 3598.60 +/- 3.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.019753518 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.432       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00482    |
|    std                  | 0.939       |
|    value_loss           | 0.595       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | -110     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 79       |
|    time_elapsed    | 59895    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -107        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 80          |
|    time_elapsed         | 60285       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.005401413 |
|    clip_fraction        | 0.0569      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.000498    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.08        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00149    |
|    std                  | 0.939       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | -106       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 81         |
|    time_elapsed         | 60672      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.01645815 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.25      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.224      |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.004     |
|    std                  | 0.942      |
|    value_loss           | 0.691      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -104        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 82          |
|    time_elapsed         | 61061       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.037287038 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.465       |
|    n_updates            | 810         |
|    policy_gradient_loss | 0.00298     |
|    std                  | 0.944       |
|    value_loss           | 0.644       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -102       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 83         |
|    time_elapsed         | 61450      |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.04613453 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.321      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.327      |
|    n_updates            | 820        |
|    policy_gradient_loss | -0.00113   |
|    std                  | 0.944      |
|    value_loss           | 0.57       |
----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.84 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.024039602 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.55        |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00638    |
|    std                  | 0.943       |
|    value_loss           | 0.728       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -103     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 84       |
|    time_elapsed    | 64063    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -101        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 85          |
|    time_elapsed         | 64451       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.029981073 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.00305     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.59e+03    |
|    n_updates            | 840         |
|    policy_gradient_loss | 0.00707     |
|    std                  | 0.941       |
|    value_loss           | 1.42e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.67e+03    |
|    ep_rew_mean          | -98.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 86          |
|    time_elapsed         | 64838       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.032920115 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.311       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.37        |
|    n_updates            | 850         |
|    policy_gradient_loss | 0.0011      |
|    std                  | 0.939       |
|    value_loss           | 0.67        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -92.5      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 87         |
|    time_elapsed         | 65225      |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.01663514 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.342      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.271      |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.000158  |
|    std                  | 0.938      |
|    value_loss           | 0.612      |
----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.82 +/- 0.05
Episode length: 3507.40 +/- 187.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.51e+03   |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.03686066 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.223      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.277      |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.00485   |
|    std                  | 0.937      |
|    value_loss           | 0.674      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -93.9    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 88       |
|    time_elapsed    | 67413    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -92.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 89          |
|    time_elapsed         | 67799       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.010656139 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 9.91e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 93.4        |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00308    |
|    std                  | 0.937       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -90.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 90          |
|    time_elapsed         | 68186       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.035688892 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.255       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00523    |
|    std                  | 0.937       |
|    value_loss           | 0.583       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -89.2       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 91          |
|    time_elapsed         | 68573       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.025277017 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.371       |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.938       |
|    value_loss           | 0.601       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -83.1      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 92         |
|    time_elapsed         | 68958      |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.02649185 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.429      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.277      |
|    n_updates            | 910        |
|    policy_gradient_loss | 0.00172    |
|    std                  | 0.931      |
|    value_loss           | 0.479      |
----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.77 +/- 0.06
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.024360238 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.356       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.189       |
|    n_updates            | 920         |
|    policy_gradient_loss | 0.000332    |
|    std                  | 0.933       |
|    value_loss           | 0.507       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -85.3    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 93       |
|    time_elapsed    | 71152    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -83.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 94          |
|    time_elapsed         | 71541       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.011699673 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00597     |
|    learning_rate        | 0.0003      |
|    loss                 | 56.7        |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00541    |
|    std                  | 0.933       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -82.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 95          |
|    time_elapsed         | 71928       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.031248674 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.59       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.311       |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0012     |
|    std                  | 0.932       |
|    value_loss           | 0.675       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -81         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 96          |
|    time_elapsed         | 72314       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.018573314 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00401    |
|    std                  | 0.931       |
|    value_loss           | 0.48        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -75.1      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 97         |
|    time_elapsed         | 72699      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.03140379 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 960        |
|    policy_gradient_loss | 0.00218    |
|    std                  | 0.931      |
|    value_loss           | 0.485      |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.79 +/- 0.04
Episode length: 3600.00 +/- 1.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.025806563 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.334       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.275       |
|    n_updates            | 970         |
|    policy_gradient_loss | 0.00129     |
|    std                  | 0.929       |
|    value_loss           | 0.531       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -78.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 98       |
|    time_elapsed    | 74886    |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -76.9      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 99         |
|    time_elapsed         | 75274      |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.02729778 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.000469   |
|    learning_rate        | 0.0003     |
|    loss                 | 505        |
|    n_updates            | 980        |
|    policy_gradient_loss | 0.00408    |
|    std                  | 0.931      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -75.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 100         |
|    time_elapsed         | 75663       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.030573793 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.139      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.215       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.000195   |
|    std                  | 0.93        |
|    value_loss           | 0.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -74.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 101         |
|    time_elapsed         | 76048       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.023431469 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.402       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.162       |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.00201     |
|    std                  | 0.93        |
|    value_loss           | 0.578       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -68.6      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 102        |
|    time_elapsed         | 76433      |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.02895175 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.353      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.304      |
|    n_updates            | 1010       |
|    policy_gradient_loss | 0.00185    |
|    std                  | 0.93       |
|    value_loss           | 0.508      |
----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.80 +/- 0.06
Episode length: 3599.60 +/- 1.96
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.025244739 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.279       |
|    n_updates            | 1020        |
|    policy_gradient_loss | 0.000191    |
|    std                  | 0.927       |
|    value_loss           | 0.636       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -71.7    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 103      |
|    time_elapsed    | 78620    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -71         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 104         |
|    time_elapsed         | 79010       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.036306124 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000914   |
|    learning_rate        | 0.0003      |
|    loss                 | 97.4        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.927       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -69.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 105         |
|    time_elapsed         | 79398       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.029913887 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00752    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.342       |
|    n_updates            | 1040        |
|    policy_gradient_loss | 0.00692     |
|    std                  | 0.926       |
|    value_loss           | 0.72        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -68.4      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 106        |
|    time_elapsed         | 79782      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.02730559 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.308      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.304      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.00334   |
|    std                  | 0.922      |
|    value_loss           | 0.718      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -62.5       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 107         |
|    time_elapsed         | 80168       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.028499665 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0841      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.273       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00521    |
|    std                  | 0.915       |
|    value_loss           | 0.658       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.79 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.026249664 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0495      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.399       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00757    |
|    std                  | 0.917       |
|    value_loss           | 0.599       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -66      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 108      |
|    time_elapsed    | 82355    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -64.9       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 109         |
|    time_elapsed         | 82741       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.016997064 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000582   |
|    learning_rate        | 0.0003      |
|    loss                 | 13.7        |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00799    |
|    std                  | 0.916       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -64         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 110         |
|    time_elapsed         | 83129       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.024605986 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.114      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.301       |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.00596    |
|    std                  | 0.915       |
|    value_loss           | 0.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -63         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 111         |
|    time_elapsed         | 83516       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.024571963 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0441      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.296       |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.917       |
|    value_loss           | 0.728       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -57         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 112         |
|    time_elapsed         | 83901       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.020990238 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0628      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00551    |
|    std                  | 0.911       |
|    value_loss           | 0.657       |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.48 +/- 0.45
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.029890416 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0631      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0068     |
|    std                  | 0.91        |
|    value_loss           | 0.791       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -60.9    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 113      |
|    time_elapsed    | 86088    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -59.9       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 114         |
|    time_elapsed         | 86475       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.019147705 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000973   |
|    learning_rate        | 0.0003      |
|    loss                 | 22.1        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00691    |
|    std                  | 0.911       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -59.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 115         |
|    time_elapsed         | 86863       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.029436238 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0193     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.441       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00451    |
|    std                  | 0.91        |
|    value_loss           | 0.774       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -58.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 116         |
|    time_elapsed         | 87251       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.022587346 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0302      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.313       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00667    |
|    std                  | 0.907       |
|    value_loss           | 0.794       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -51.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 117         |
|    time_elapsed         | 87637       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.027421601 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.516       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00283    |
|    std                  | 0.904       |
|    value_loss           | 0.814       |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.85 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.045710213 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.435       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00891    |
|    std                  | 0.898       |
|    value_loss           | 0.864       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -56.6    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 118      |
|    time_elapsed    | 89823    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -55.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 119         |
|    time_elapsed         | 90209       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.017038751 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000333   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57e+03    |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00598    |
|    std                  | 0.898       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -54.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 120         |
|    time_elapsed         | 90596       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.027832586 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.047      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.285       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00333    |
|    std                  | 0.901       |
|    value_loss           | 0.791       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -48.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 121         |
|    time_elapsed         | 90983       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.024123937 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.255       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.329       |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0098     |
|    std                  | 0.903       |
|    value_loss           | 0.842       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -47.5       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 122         |
|    time_elapsed         | 91368       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.034730017 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0929      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.254       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00996    |
|    std                  | 0.901       |
|    value_loss           | 0.682       |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.73 +/- 0.03
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.03337125 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.0827     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.00951   |
|    std                  | 0.903      |
|    value_loss           | 0.785      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -52      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 123      |
|    time_elapsed    | 93553    |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -50.3      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 124        |
|    time_elapsed         | 93941      |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.02798369 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.00129   |
|    learning_rate        | 0.0003     |
|    loss                 | 654        |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.00676   |
|    std                  | 0.901      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -49.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 125         |
|    time_elapsed         | 94326       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.028152138 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0328     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.326       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.00581    |
|    std                  | 0.892       |
|    value_loss           | 0.76        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -43.9       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 126         |
|    time_elapsed         | 94715       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.027338535 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0875      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00924    |
|    std                  | 0.892       |
|    value_loss           | 0.819       |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.62 +/- 0.07
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.028877303 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.149       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0044     |
|    std                  | 0.889       |
|    value_loss           | 0.802       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -48      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 127      |
|    time_elapsed    | 96901    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -47.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 128         |
|    time_elapsed         | 97286       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.020931523 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.000697   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.2        |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.889       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -46.6      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 129        |
|    time_elapsed         | 97670      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.03518995 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.259     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.363      |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.884      |
|    value_loss           | 0.768      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -46.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 130         |
|    time_elapsed         | 98057       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.031832602 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.361       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00646    |
|    std                  | 0.88        |
|    value_loss           | 0.922       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -40.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 131         |
|    time_elapsed         | 98442       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.027993493 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00904    |
|    std                  | 0.878       |
|    value_loss           | 0.926       |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.53 +/- 0.09
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.030561354 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00922    |
|    std                  | 0.877       |
|    value_loss           | 0.917       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -44.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 132      |
|    time_elapsed    | 100631   |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.66e+03  |
|    ep_rew_mean          | -43.8     |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 133       |
|    time_elapsed         | 101019    |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0246091 |
|    clip_fraction        | 0.202     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.3     |
|    explained_variance   | -0.000932 |
|    learning_rate        | 0.0003    |
|    loss                 | 18.4      |
|    n_updates            | 1320      |
|    policy_gradient_loss | -0.00598  |
|    std                  | 0.875     |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -43.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 134         |
|    time_elapsed         | 101403      |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.028997738 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.171      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.535       |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.874       |
|    value_loss           | 1.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -42.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 135         |
|    time_elapsed         | 101792      |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.021956861 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.253       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.411       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00625    |
|    std                  | 0.874       |
|    value_loss           | 0.77        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -37         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 136         |
|    time_elapsed         | 102175      |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.031769566 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.441       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.41        |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.871       |
|    value_loss           | 0.961       |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.08 +/- 0.48
Episode length: 3598.40 +/- 5.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.1       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.026605166 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.321       |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.00407    |
|    std                  | 0.868       |
|    value_loss           | 0.695       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -41.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 137      |
|    time_elapsed    | 104363   |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -40.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 138         |
|    time_elapsed         | 104751      |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.016368886 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.0014     |
|    learning_rate        | 0.0003      |
|    loss                 | 457         |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0072     |
|    std                  | 0.868       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -40         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 139         |
|    time_elapsed         | 105135      |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.027163144 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0488      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.692       |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.869       |
|    value_loss           | 1.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -39.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 140         |
|    time_elapsed         | 105520      |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.024446975 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.138       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.316       |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00986    |
|    std                  | 0.869       |
|    value_loss           | 0.839       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -33.3      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 141        |
|    time_elapsed         | 105904     |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.02030576 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.257      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.223      |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.00636   |
|    std                  | 0.873      |
|    value_loss           | 0.646      |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.54 +/- 0.08
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.021267436 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.266       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.169       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00454    |
|    std                  | 0.865       |
|    value_loss           | 0.604       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -37.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 142      |
|    time_elapsed    | 108088   |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -36.2       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 143         |
|    time_elapsed         | 108474      |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.029257286 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00209    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.9        |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.865       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -35.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 144         |
|    time_elapsed         | 108859      |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.039222036 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0186     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.388       |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.00385     |
|    std                  | 0.858       |
|    value_loss           | 0.826       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -35.2      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 145        |
|    time_elapsed         | 109244     |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.03238134 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.155      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.422      |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.00613   |
|    std                  | 0.855      |
|    value_loss           | 0.95       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -29.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 146         |
|    time_elapsed         | 109634      |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.023613255 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.324       |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.00138    |
|    std                  | 0.848       |
|    value_loss           | 0.68        |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.55 +/- 0.10
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 0.0282738 |
|    clip_fraction        | 0.289     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.99     |
|    explained_variance   | 0.404     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.395     |
|    n_updates            | 1460      |
|    policy_gradient_loss | -0.00809  |
|    std                  | 0.848     |
|    value_loss           | 0.835     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -33.4    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 147      |
|    time_elapsed    | 111821   |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -32.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 148         |
|    time_elapsed         | 112207      |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.019111287 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | -0.000985   |
|    learning_rate        | 0.0003      |
|    loss                 | 64          |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.847       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -31.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 149         |
|    time_elapsed         | 112591      |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.026911568 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | -0.0348     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.432       |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.00516    |
|    std                  | 0.847       |
|    value_loss           | 0.761       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -30.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 150         |
|    time_elapsed         | 112974      |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.035907127 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.25        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.329       |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00227    |
|    std                  | 0.84        |
|    value_loss           | 0.777       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -24.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 151         |
|    time_elapsed         | 113361      |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.031142203 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.331       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.84        |
|    value_loss           | 0.671       |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.38 +/- 0.50
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.036342435 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.541       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.252       |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.836       |
|    value_loss           | 0.754       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -29.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 152      |
|    time_elapsed    | 115550   |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -28.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 153         |
|    time_elapsed         | 115935      |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.019202359 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -0.000264   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.91        |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00633    |
|    std                  | 0.836       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -27.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 154         |
|    time_elapsed         | 116319      |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.034844607 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.298      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.451       |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.832       |
|    value_loss           | 0.777       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -27        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 155        |
|    time_elapsed         | 116702     |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.02672588 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.265      |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.00815   |
|    std                  | 0.827      |
|    value_loss           | 0.705      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.68e+03  |
|    ep_rew_mean          | -21.1     |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 156       |
|    time_elapsed         | 117086    |
|    total_timesteps      | 319488    |
| train/                  |           |
|    approx_kl            | 0.0257552 |
|    clip_fraction        | 0.291     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.77     |
|    explained_variance   | 0.339     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.47      |
|    n_updates            | 1550      |
|    policy_gradient_loss | -0.0109   |
|    std                  | 0.823     |
|    value_loss           | 0.838     |
---------------------------------------
Eval num_timesteps=320000, episode_reward=-99.12 +/- 0.84
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.1       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.034884717 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.422       |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.822       |
|    value_loss           | 0.904       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -25.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 157      |
|    time_elapsed    | 119271   |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -24.7      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 158        |
|    time_elapsed         | 119656     |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.03071111 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | 0.00305    |
|    learning_rate        | 0.0003     |
|    loss                 | 67.2       |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.00656   |
|    std                  | 0.821      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -24.2       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 159         |
|    time_elapsed         | 120039      |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.038168766 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | 0.111       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.26        |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00414    |
|    std                  | 0.821       |
|    value_loss           | 0.849       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -23.3      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 160        |
|    time_elapsed         | 120423     |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.02998003 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.73      |
|    explained_variance   | 0.299      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.293      |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.00436   |
|    std                  | 0.821      |
|    value_loss           | 0.659      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -16.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 161         |
|    time_elapsed         | 120807      |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.029025687 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.276       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.741       |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00888    |
|    std                  | 0.816       |
|    value_loss           | 1.06        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.18 +/- 0.83
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.2      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.04274407 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.65      |
|    explained_variance   | 0.236      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.307      |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.811      |
|    value_loss           | 0.856      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -21.7    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 162      |
|    time_elapsed    | 122995   |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -20.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 163         |
|    time_elapsed         | 123381      |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.022839138 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.63       |
|    explained_variance   | -1.23e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67e+03    |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00541    |
|    std                  | 0.812       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -19.5      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 164        |
|    time_elapsed         | 123765     |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.03185294 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | -0.155     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.259      |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.00408   |
|    std                  | 0.813      |
|    value_loss           | 0.847      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -12.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 165         |
|    time_elapsed         | 124148      |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.035246458 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | 0.273       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.366       |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.00166    |
|    std                  | 0.813       |
|    value_loss           | 0.779       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.68e+03  |
|    ep_rew_mean          | -11.5     |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 166       |
|    time_elapsed         | 124532    |
|    total_timesteps      | 339968    |
| train/                  |           |
|    approx_kl            | 0.0363295 |
|    clip_fraction        | 0.314     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.63     |
|    explained_variance   | 0.325     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.23      |
|    n_updates            | 1650      |
|    policy_gradient_loss | -0.00435  |
|    std                  | 0.811     |
|    value_loss           | 0.6       |
---------------------------------------
Eval num_timesteps=340000, episode_reward=-99.10 +/- 0.85
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.03499701 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.63      |
|    explained_variance   | 0.404      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.00661   |
|    std                  | 0.813      |
|    value_loss           | 0.976      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -15.9    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 167      |
|    time_elapsed    | 126716   |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -15.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 168         |
|    time_elapsed         | 127103      |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.014167981 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | -0.000585   |
|    learning_rate        | 0.0003      |
|    loss                 | 569         |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00533    |
|    std                  | 0.813       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -14.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 169         |
|    time_elapsed         | 127486      |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.035817206 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.811       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.811       |
|    value_loss           | 1.19        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | -8.12       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 170         |
|    time_elapsed         | 127871      |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.029651333 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.292       |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.00693    |
|    std                  | 0.804       |
|    value_loss           | 0.713       |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.39 +/- 0.52
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.034044445 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.178       |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0085     |
|    std                  | 0.802       |
|    value_loss           | 0.833       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 171      |
|    time_elapsed    | 130055   |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -11.5      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 172        |
|    time_elapsed         | 130439     |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.03668268 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.53      |
|    explained_variance   | -0.000469  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.3e+03    |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.00182   |
|    std                  | 0.802      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -10.8      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 173        |
|    time_elapsed         | 130825     |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.03648391 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | 0.162      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.271      |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.00844   |
|    std                  | 0.799      |
|    value_loss           | 0.741      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | -9.9       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 174        |
|    time_elapsed         | 131210     |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.04639969 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.49      |
|    explained_variance   | 0.312      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.33       |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.00434   |
|    std                  | 0.8        |
|    value_loss           | 0.774      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | -4.03      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 175        |
|    time_elapsed         | 131594     |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.03620241 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.47      |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.442      |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.00768   |
|    std                  | 0.795      |
|    value_loss           | 0.785      |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-96.63 +/- 1.54
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.6       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.029389648 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.304       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.423       |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.791       |
|    value_loss           | 0.993       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -8.56    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 176      |
|    time_elapsed    | 133779   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -7.6        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 177         |
|    time_elapsed         | 134162      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.021867372 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.000813    |
|    learning_rate        | 0.0003      |
|    loss                 | 958         |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0095     |
|    std                  | 0.791       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -6.79       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 178         |
|    time_elapsed         | 134545      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.031409077 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | 0.0523      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.329       |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.787       |
|    value_loss           | 1.11        |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 1.66e+03 |
|    ep_rew_mean          | -6.01    |
| time/                   |          |
|    fps                  | 2        |
|    iterations           | 179      |
|    time_elapsed         | 134928   |
|    total_timesteps      | 366592   |
| train/                  |          |
|    approx_kl            | 0.036313 |
|    clip_fraction        | 0.311    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.35    |
|    explained_variance   | 0.285    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.456    |
|    n_updates            | 1780     |
|    policy_gradient_loss | -0.0102  |
|    std                  | 0.784    |
|    value_loss           | 1.08     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 0.358       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 180         |
|    time_elapsed         | 135313      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.033404205 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.366       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.305       |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00217    |
|    std                  | 0.782       |
|    value_loss           | 0.684       |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-96.84 +/- 1.73
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.8       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.029548243 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | 0.419       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.59        |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00652    |
|    std                  | 0.778       |
|    value_loss           | 1.03        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -4.28    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 181      |
|    time_elapsed    | 137496   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -3.54       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 182         |
|    time_elapsed         | 137878      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.032215927 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.00215     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54        |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00662    |
|    std                  | 0.777       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -2.62       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 183         |
|    time_elapsed         | 138259      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.042333003 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | -0.0395     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0012     |
|    std                  | 0.771       |
|    value_loss           | 0.935       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | -1.83       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 184         |
|    time_elapsed         | 138643      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.040626857 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 1830        |
|    policy_gradient_loss | 0.000219    |
|    std                  | 0.769       |
|    value_loss           | 0.846       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 4.36        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 185         |
|    time_elapsed         | 139026      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.039076474 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.443       |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.00626    |
|    std                  | 0.765       |
|    value_loss           | 0.902       |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-97.39 +/- 2.03
Episode length: 3599.80 +/- 1.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -97.4       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.044383526 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.555       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.00179    |
|    std                  | 0.76        |
|    value_loss           | 0.707       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | -0.063   |
| time/              |          |
|    fps             | 2        |
|    iterations      | 186      |
|    time_elapsed    | 141207   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 0.799       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 187         |
|    time_elapsed         | 141588      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.028659131 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.00102     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.34        |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00222    |
|    std                  | 0.761       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 1.68       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 188        |
|    time_elapsed         | 141968     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.05013121 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | -0.194     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.341      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.00996    |
|    std                  | 0.756      |
|    value_loss           | 0.778      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 2.65        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 189         |
|    time_elapsed         | 142349      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.039980024 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.386       |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.00519    |
|    std                  | 0.749       |
|    value_loss           | 0.778       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 9.08        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 190         |
|    time_elapsed         | 142731      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.058502816 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.308       |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.00526    |
|    std                  | 0.748       |
|    value_loss           | 0.964       |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-98.07 +/- 1.02
Episode length: 3599.80 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.1       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.038698412 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.242       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.343       |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00533    |
|    std                  | 0.744       |
|    value_loss           | 0.859       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 4.67     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 191      |
|    time_elapsed    | 144915   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 5.5         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 192         |
|    time_elapsed         | 145296      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.030890435 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.000915    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.99        |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00525    |
|    std                  | 0.745       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 6.11       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 193        |
|    time_elapsed         | 145678     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.04460987 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | -0.0717    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.475      |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.00808   |
|    std                  | 0.743      |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 7           |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 194         |
|    time_elapsed         | 146058      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.037064653 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.447       |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.00277    |
|    std                  | 0.744       |
|    value_loss           | 0.896       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 13.7        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 195         |
|    time_elapsed         | 146441      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.028871426 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.333       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00608    |
|    std                  | 0.741       |
|    value_loss           | 0.851       |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-97.22 +/- 1.88
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -97.2       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.031983785 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.85       |
|    explained_variance   | 0.351       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.592       |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.739       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 9.29     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 196      |
|    time_elapsed    | 148628   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 10.2       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 197        |
|    time_elapsed         | 149009     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.02439608 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.000167   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.11       |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.00329   |
|    std                  | 0.739      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 11.3        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 198         |
|    time_elapsed         | 149391      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.044215422 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.0321      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.669       |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.00786    |
|    std                  | 0.737       |
|    value_loss           | 1.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 12.3        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 199         |
|    time_elapsed         | 149772      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.048810367 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.81       |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.55        |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.735       |
|    value_loss           | 1.3         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | 19.1       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 200        |
|    time_elapsed         | 150154     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.05105807 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.78      |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.526      |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.732      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.13 +/- 0.84
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.1       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.032355234 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.351       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.476       |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00832    |
|    std                  | 0.729       |
|    value_loss           | 0.904       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 14.7     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 201      |
|    time_elapsed    | 152339   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 15.6        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 202         |
|    time_elapsed         | 152726      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.024844265 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | -0.000327   |
|    learning_rate        | 0.0003      |
|    loss                 | 91.3        |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00688    |
|    std                  | 0.728       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 16.7        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 203         |
|    time_elapsed         | 153107      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.043952353 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | 0.0421      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.613       |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.729       |
|    value_loss           | 1.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 24.8        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 204         |
|    time_elapsed         | 153492      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.044098206 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.69       |
|    explained_variance   | 0.273       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.413       |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.723       |
|    value_loss           | 1.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 26          |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 205         |
|    time_elapsed         | 153875      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.059765883 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00764    |
|    std                  | 0.722       |
|    value_loss           | 0.973       |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-91.71 +/- 3.62
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -91.7       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.044545986 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | 0.224       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.724       |
|    value_loss           | 1.38        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 20.6     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 206      |
|    time_elapsed    | 156063   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 22.8        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 207         |
|    time_elapsed         | 156447      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.020580852 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.000823    |
|    learning_rate        | 0.0003      |
|    loss                 | 400         |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00353    |
|    std                  | 0.724       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 24          |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 208         |
|    time_elapsed         | 156829      |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.047270816 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.0725      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.33        |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.00998    |
|    std                  | 0.726       |
|    value_loss           | 1.02        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.68e+03    |
|    ep_rew_mean          | 30.9        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 209         |
|    time_elapsed         | 157211      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.048092674 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.722       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-63.71 +/- 8.16
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -63.7       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.042365104 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.281       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.718       |
|    value_loss           | 1.28        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.66e+03 |
|    ep_rew_mean     | 27       |
| time/              |          |
|    fps             | 2        |
|    iterations      | 210      |
|    time_elapsed    | 159394   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 28.1       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 211        |
|    time_elapsed         | 159783     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.02002912 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.00376    |
|    learning_rate        | 0.0003     |
|    loss                 | 276        |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.00694   |
|    std                  | 0.719      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.65e+03    |
|    ep_rew_mean          | 39.5        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 212         |
|    time_elapsed         | 160168      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.044044036 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.667       |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.717       |
|    value_loss           | 1.69        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 46.5        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 213         |
|    time_elapsed         | 160551      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.042850964 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.00156     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.447       |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.714       |
|    value_loss           | 513         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 47.2       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 214        |
|    time_elapsed         | 160934     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.03510362 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.54      |
|    explained_variance   | 0.229      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.726      |
|    n_updates            | 2130       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.713      |
|    value_loss           | 1.68       |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-73.54 +/- 2.71
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -73.5       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.042502686 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | 0.356       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.541       |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.709       |
|    value_loss           | 1.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 43.3     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 215      |
|    time_elapsed    | 163117   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 44.8        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 216         |
|    time_elapsed         | 163501      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.026047802 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | 0.00544     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.18        |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00608    |
|    std                  | 0.708       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 46.5       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 217        |
|    time_elapsed         | 163890     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.04318037 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.46      |
|    explained_variance   | -0.524     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.835      |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.705      |
|    value_loss           | 2.21       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 54          |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 218         |
|    time_elapsed         | 164274      |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.057299387 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.0552      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15        |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.701       |
|    value_loss           | 5.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 56.1        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 219         |
|    time_elapsed         | 164657      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.055230178 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.713       |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.701       |
|    value_loss           | 1.74        |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-75.19 +/- 2.51
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -75.2      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.04254096 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.4       |
|    explained_variance   | 0.285      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.737      |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.701      |
|    value_loss           | 1.7        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 52.7     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 220      |
|    time_elapsed    | 166839   |
|    total_timesteps | 450560   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.64e+03     |
|    ep_rew_mean          | 53.7         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 221          |
|    time_elapsed         | 167224       |
|    total_timesteps      | 452608       |
| train/                  |              |
|    approx_kl            | 0.0155856935 |
|    clip_fraction        | 0.267        |
|    clip_range           | 0.2          |
|    entropy_loss         | -8.39        |
|    explained_variance   | 0.00336      |
|    learning_rate        | 0.0003       |
|    loss                 | 149          |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.00443     |
|    std                  | 0.7          |
|    value_loss           | 1.05e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 54.7       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 222        |
|    time_elapsed         | 167612     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.05194671 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | -0.0605    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.986      |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.695      |
|    value_loss           | 1.78       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 61.7       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 223        |
|    time_elapsed         | 167998     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.05717875 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.34      |
|    explained_variance   | 0.3        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.659      |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.696      |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 63.1       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 224        |
|    time_elapsed         | 168380     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.04682658 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.33      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.636      |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.695      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.31 +/- 0.77
Episode length: 3600.80 +/- 0.40
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.3    |
| time/                   |          |
|    total_timesteps      | 460000   |
| train/                  |          |
|    approx_kl            | 0.050205 |
|    clip_fraction        | 0.373    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.32    |
|    explained_variance   | 0.331    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.687    |
|    n_updates            | 2240     |
|    policy_gradient_loss | -0.0166  |
|    std                  | 0.695    |
|    value_loss           | 1.63     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.64e+03 |
|    ep_rew_mean     | 59.6     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 225      |
|    time_elapsed    | 170563   |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 60.9       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 226        |
|    time_elapsed         | 170946     |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.04553752 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.31      |
|    explained_variance   | 0.00184    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.34e+03   |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.00716   |
|    std                  | 0.695      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.65e+03    |
|    ep_rew_mean          | 78.5        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 227         |
|    time_elapsed         | 171329      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.050264746 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | -0.393      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.696       |
|    value_loss           | 2           |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.63e+03    |
|    ep_rew_mean          | 89.8        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 228         |
|    time_elapsed         | 171719      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.020831719 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | -0.00048    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.85e+03    |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0087     |
|    std                  | 0.696       |
|    value_loss           | 4.2e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.63e+03    |
|    ep_rew_mean          | 91.4        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 229         |
|    time_elapsed         | 172104      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.052243926 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | -0.00131    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76        |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.00279    |
|    std                  | 0.694       |
|    value_loss           | 3.75e+03    |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-51.91 +/- 12.17
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -51.9       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.049991958 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | 0.0253      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.854       |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.692       |
|    value_loss           | 2.4         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 87.1     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 230      |
|    time_elapsed    | 174289   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 89.4        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 231         |
|    time_elapsed         | 174672      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.036873113 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | -0.000809   |
|    learning_rate        | 0.0003      |
|    loss                 | 372         |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0081     |
|    std                  | 0.692       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.64e+03  |
|    ep_rew_mean          | 96.7      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 232       |
|    time_elapsed         | 175056    |
|    total_timesteps      | 475136    |
| train/                  |           |
|    approx_kl            | 0.0606585 |
|    clip_fraction        | 0.415     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.28     |
|    explained_variance   | -0.264    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.12      |
|    n_updates            | 2310      |
|    policy_gradient_loss | -0.0148   |
|    std                  | 0.693     |
|    value_loss           | 2.52      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 98.7        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 233         |
|    time_elapsed         | 175445      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.037980802 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55        |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.686       |
|    value_loss           | 2.89        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 100         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 234         |
|    time_elapsed         | 175829      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.044093333 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | 0.211       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.45        |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.687       |
|    value_loss           | 2.74        |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-81.41 +/- 6.19
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -81.4       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.033679046 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.963       |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.684       |
|    value_loss           | 2.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 96.6     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 235      |
|    time_elapsed    | 178015   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 98.3        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 236         |
|    time_elapsed         | 178398      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.029090121 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | -0.00162    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.32        |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0091     |
|    std                  | 0.685       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 237         |
|    time_elapsed         | 178780      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.043584734 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.0914      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.684       |
|    value_loss           | 1.7         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.64e+03  |
|    ep_rew_mean          | 107       |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 238       |
|    time_elapsed         | 179171    |
|    total_timesteps      | 487424    |
| train/                  |           |
|    approx_kl            | 0.0336121 |
|    clip_fraction        | 0.325     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.18     |
|    explained_variance   | 0.173     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.42      |
|    n_updates            | 2370      |
|    policy_gradient_loss | -0.0141   |
|    std                  | 0.683     |
|    value_loss           | 2.93      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 109         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 239         |
|    time_elapsed         | 179555      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.044318534 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.53        |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.681       |
|    value_loss           | 1.7         |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-83.11 +/- 2.72
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -83.1       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.042251345 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.678       |
|    value_loss           | 2.6         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 105      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 240      |
|    time_elapsed    | 181748   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 106         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 241         |
|    time_elapsed         | 182132      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.029227775 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | -8.82e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55e+03    |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.00642    |
|    std                  | 0.677       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 114        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 242        |
|    time_elapsed         | 182515     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.06183638 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | 0.0309     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.839      |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.68       |
|    value_loss           | 2.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 118         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 243         |
|    time_elapsed         | 182899      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.055825524 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84        |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.679       |
|    value_loss           | 2.72        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 120         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 244         |
|    time_elapsed         | 183284      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.043145932 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.09       |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.675       |
|    value_loss           | 2.81        |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=36.86 +/- 12.61
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 36.9        |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.064526364 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | 0.22        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.674       |
|    value_loss           | 2.59        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 115      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 245      |
|    time_elapsed    | 185477   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 125         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 246         |
|    time_elapsed         | 185865      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.025078475 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.00479     |
|    learning_rate        | 0.0003      |
|    loss                 | 504         |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00897    |
|    std                  | 0.673       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 127        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 247        |
|    time_elapsed         | 186248     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.04686178 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | 0.0415     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.57       |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0242    |
|    std                  | 0.671      |
|    value_loss           | 4.3        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 130        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 248        |
|    time_elapsed         | 186634     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.06526983 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | 0.231      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.48       |
|    n_updates            | 2470       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.67       |
|    value_loss           | 2.63       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.64e+03  |
|    ep_rew_mean          | 131       |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 249       |
|    time_elapsed         | 187019    |
|    total_timesteps      | 509952    |
| train/                  |           |
|    approx_kl            | 0.0466024 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.97     |
|    explained_variance   | 0.13      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.82      |
|    n_updates            | 2480      |
|    policy_gradient_loss | -0.0121   |
|    std                  | 0.667     |
|    value_loss           | 4.62      |
---------------------------------------
Eval num_timesteps=510000, episode_reward=-64.02 +/- 24.62
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -64         |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.051423587 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | 0.19        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.47        |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.664       |
|    value_loss           | 3.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.62e+03 |
|    ep_rew_mean     | 128      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 250      |
|    time_elapsed    | 189207   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 251         |
|    time_elapsed         | 189601      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.015183464 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | 0.00934     |
|    learning_rate        | 0.0003      |
|    loss                 | 123         |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.663       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.64e+03   |
|    ep_rew_mean          | 138        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 252        |
|    time_elapsed         | 189990     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.05321127 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | -0.296     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.66       |
|    n_updates            | 2510       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.66       |
|    value_loss           | 4.51       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 159         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 253         |
|    time_elapsed         | 190378      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.044681147 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.03        |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.656       |
|    value_loss           | 3.75        |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=177.32 +/- 29.74
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 177        |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.01130246 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.000687   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.4e+03    |
|    n_updates            | 2530       |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.656      |
|    value_loss           | 8.21e+03   |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.6e+03  |
|    ep_rew_mean     | 347      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 254      |
|    time_elapsed    | 192569   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 356         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 255         |
|    time_elapsed         | 192957      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.012040066 |
|    clip_fraction        | 0.0438      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | 9.01e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 104         |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00313    |
|    std                  | 0.656       |
|    value_loss           | 1.45e+06    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 358         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 256         |
|    time_elapsed         | 193352      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.054977022 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | -2.47       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.42        |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 0.655       |
|    value_loss           | 9.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.62e+03    |
|    ep_rew_mean          | 360         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 257         |
|    time_elapsed         | 193743      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.045171045 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | -0.0828     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.23        |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.65        |
|    value_loss           | 8.75        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.62e+03   |
|    ep_rew_mean          | 362        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 258        |
|    time_elapsed         | 194133     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.05275758 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.0312     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.16       |
|    n_updates            | 2570       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.649      |
|    value_loss           | 6.02       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=281.68 +/- 14.77
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 282         |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.057038203 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | 0.077       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.88        |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.648       |
|    value_loss           | 4.98        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.6e+03  |
|    ep_rew_mean     | 360      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 259      |
|    time_elapsed    | 196323   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.62e+03   |
|    ep_rew_mean          | 369        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 260        |
|    time_elapsed         | 196715     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.03082936 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.00289    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.53       |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.00794   |
|    std                  | 0.646      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.61e+03    |
|    ep_rew_mean          | 380         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 261         |
|    time_elapsed         | 197107      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.052630726 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | -0.0804     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.64        |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 0.644       |
|    value_loss           | 7.68        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.61e+03    |
|    ep_rew_mean          | 393         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 262         |
|    time_elapsed         | 197504      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.020892765 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.7        |
|    explained_variance   | 0.000681    |
|    learning_rate        | 0.0003      |
|    loss                 | 59.5        |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.643       |
|    value_loss           | 4.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.61e+03  |
|    ep_rew_mean          | 400       |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 263       |
|    time_elapsed         | 197898    |
|    total_timesteps      | 538624    |
| train/                  |           |
|    approx_kl            | 0.0156578 |
|    clip_fraction        | 0.18      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.69     |
|    explained_variance   | 0.00346   |
|    learning_rate        | 0.0003    |
|    loss                 | 196       |
|    n_updates            | 2620      |
|    policy_gradient_loss | -0.0132   |
|    std                  | 0.642     |
|    value_loss           | 4.1e+03   |
---------------------------------------
Eval num_timesteps=540000, episode_reward=542.10 +/- 341.09
Episode length: 3230.20 +/- 739.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.23e+03   |
|    mean_reward          | 542        |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.07175246 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | -0.623     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.91       |
|    n_updates            | 2630       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.638      |
|    value_loss           | 7.76       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.6e+03  |
|    ep_rew_mean     | 413      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 264      |
|    time_elapsed    | 199906   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.58e+03    |
|    ep_rew_mean          | 434         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 265         |
|    time_elapsed         | 200296      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.021434776 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.64       |
|    explained_variance   | 0.000464    |
|    learning_rate        | 0.0003      |
|    loss                 | 698         |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.638       |
|    value_loss           | 4.9e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.58e+03    |
|    ep_rew_mean          | 438         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 266         |
|    time_elapsed         | 200688      |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.012672601 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | -0.000492   |
|    learning_rate        | 0.0003      |
|    loss                 | 573         |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.637       |
|    value_loss           | 7.95e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 1.58e+03  |
|    ep_rew_mean          | 442       |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 267       |
|    time_elapsed         | 201086    |
|    total_timesteps      | 546816    |
| train/                  |           |
|    approx_kl            | 0.0348148 |
|    clip_fraction        | 0.279     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.61     |
|    explained_variance   | -0.632    |
|    learning_rate        | 0.0003    |
|    loss                 | 5.66      |
|    n_updates            | 2660      |
|    policy_gradient_loss | -0.0279   |
|    std                  | 0.635     |
|    value_loss           | 15        |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.51e+03    |
|    ep_rew_mean          | 506         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 268         |
|    time_elapsed         | 201481      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.055945106 |
|    clip_fraction        | 0.433       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | -0.308      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.49        |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.631       |
|    value_loss           | 9.17        |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=641.33 +/- 372.02
Episode length: 3515.60 +/- 169.30
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.52e+03    |
|    mean_reward          | 641         |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.011910154 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | 0.00148     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.04e+04    |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.00749    |
|    std                  | 0.63        |
|    value_loss           | 2.32e+04    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.5e+03  |
|    ep_rew_mean     | 503      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 269      |
|    time_elapsed    | 203632   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.5e+03    |
|    ep_rew_mean          | 533        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 270        |
|    time_elapsed         | 204023     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.03468435 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.54      |
|    explained_variance   | -0.00555   |
|    learning_rate        | 0.0003     |
|    loss                 | 863        |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.629      |
|    value_loss           | 986        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.47e+03   |
|    ep_rew_mean          | 555        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 271        |
|    time_elapsed         | 204414     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.01719112 |
|    clip_fraction        | 0.19       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | 0.00474    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+04   |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.629      |
|    value_loss           | 7.76e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.47e+03    |
|    ep_rew_mean          | 558         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 272         |
|    time_elapsed         | 204805      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.016737929 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | 0.00284     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.12e+03    |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.628       |
|    value_loss           | 7.68e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.48e+03    |
|    ep_rew_mean          | 574         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 273         |
|    time_elapsed         | 205200      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.072045624 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | -0.5        |
|    learning_rate        | 0.0003      |
|    loss                 | 4.87        |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.63        |
|    value_loss           | 18.5        |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=934.11 +/- 344.27
Episode length: 2246.80 +/- 1451.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.25e+03    |
|    mean_reward          | 934         |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.027330954 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | 0.00274     |
|    learning_rate        | 0.0003      |
|    loss                 | 297         |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.629       |
|    value_loss           | 3.88e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.44e+03 |
|    ep_rew_mean     | 593      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 274      |
|    time_elapsed    | 206725   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.43e+03    |
|    ep_rew_mean          | 632         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 275         |
|    time_elapsed         | 207119      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.014132686 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.00578     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.36e+03    |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.628       |
|    value_loss           | 8.16e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.41e+03    |
|    ep_rew_mean          | 656         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 276         |
|    time_elapsed         | 207513      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.015820011 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.5        |
|    explained_variance   | 0.00908     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.37e+03    |
|    n_updates            | 2750        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.627       |
|    value_loss           | 1.11e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.41e+03   |
|    ep_rew_mean          | 660        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 277        |
|    time_elapsed         | 207907     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.01691249 |
|    clip_fraction        | 0.165      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.48      |
|    explained_variance   | 0.0109     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.52e+03   |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.626      |
|    value_loss           | 7.52e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.39e+03    |
|    ep_rew_mean          | 681         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 278         |
|    time_elapsed         | 208300      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.043516893 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.49       |
|    explained_variance   | -0.495      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.28        |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 0.628       |
|    value_loss           | 33.1        |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=1046.51 +/- 320.18
Episode length: 1763.80 +/- 1510.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1.76e+03    |
|    mean_reward          | 1.05e+03    |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.025883965 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.5        |
|    explained_variance   | 0.000878    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3e+03     |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.627       |
|    value_loss           | 7.49e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.39e+03 |
|    ep_rew_mean     | 699      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 279      |
|    time_elapsed    | 209583   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.38e+03    |
|    ep_rew_mean          | 708         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 280         |
|    time_elapsed         | 209978      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.015417814 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.49       |
|    explained_variance   | 0.00791     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.69e+03    |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.626       |
|    value_loss           | 7.82e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.35e+03   |
|    ep_rew_mean          | 750        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 281        |
|    time_elapsed         | 210373     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.03097945 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.48      |
|    explained_variance   | -0.000973  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.45e+03   |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.625      |
|    value_loss           | 3.77e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.33e+03    |
|    ep_rew_mean          | 771         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 282         |
|    time_elapsed         | 210769      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.017760478 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.47       |
|    explained_variance   | 0.00696     |
|    learning_rate        | 0.0003      |
|    loss                 | 922         |
|    n_updates            | 2810        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.625       |
|    value_loss           | 1.11e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.33e+03   |
|    ep_rew_mean          | 774        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 283        |
|    time_elapsed         | 211163     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.02805195 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.00596    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.98e+03   |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.622      |
|    value_loss           | 7.36e+03   |
----------------------------------------
Eval num_timesteps=580000, episode_reward=1191.47 +/- 112.98
Episode length: 1240.00 +/- 793.38
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.24e+03   |
|    mean_reward          | 1.19e+03   |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.07955412 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | -0.888     |
|    learning_rate        | 0.0003     |
|    loss                 | 11.2       |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.00954   |
|    std                  | 0.618      |
|    value_loss           | 32.2       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.32e+03 |
|    ep_rew_mean     | 846      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 284      |
|    time_elapsed    | 212179   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.31e+03   |
|    ep_rew_mean          | 875        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 285        |
|    time_elapsed         | 212572     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.02025411 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | 0.000529   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.12e+05   |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.00511   |
|    std                  | 0.618      |
|    value_loss           | 2.05e+05   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.28e+03    |
|    ep_rew_mean          | 908         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 286         |
|    time_elapsed         | 212970      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.018349584 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.35       |
|    explained_variance   | 0.0062      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.47e+03    |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.616       |
|    value_loss           | 7.33e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.28e+03    |
|    ep_rew_mean          | 928         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 287         |
|    time_elapsed         | 213369      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.017917408 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.33       |
|    explained_variance   | -0.00599    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+04    |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.614       |
|    value_loss           | 1.1e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.25e+03   |
|    ep_rew_mean          | 947        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 288        |
|    time_elapsed         | 213766     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.12820956 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.28      |
|    explained_variance   | -0.0381    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.69       |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.0071    |
|    std                  | 0.609      |
|    value_loss           | 464        |
----------------------------------------
Eval num_timesteps=590000, episode_reward=959.85 +/- 342.30
Episode length: 2344.40 +/- 1184.96
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.34e+03    |
|    mean_reward          | 960         |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.029692806 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | 0.00216     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32e+03    |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.607       |
|    value_loss           | 7.22e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.22e+03 |
|    ep_rew_mean     | 955      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 289      |
|    time_elapsed    | 215341   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.2e+03     |
|    ep_rew_mean          | 995         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 290         |
|    time_elapsed         | 215739      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.017546177 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.00489     |
|    learning_rate        | 0.0003      |
|    loss                 | 319         |
|    n_updates            | 2890        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.607       |
|    value_loss           | 1.13e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.18e+03    |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 291         |
|    time_elapsed         | 216133      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.020090617 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 0.00319     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.13e+03    |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.606       |
|    value_loss           | 1.07e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.16e+03    |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 292         |
|    time_elapsed         | 216529      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.022637922 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | -0.00211    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.16e+03    |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.605       |
|    value_loss           | 7.06e+03    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=1014.46 +/- 210.92
Episode length: 1243.20 +/- 1222.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1.24e+03    |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.022133602 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | 0.000925    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.72e+03    |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.604       |
|    value_loss           | 1.05e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.06e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 293      |
|    time_elapsed    | 217545   |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.05e+03   |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 294        |
|    time_elapsed         | 217940     |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.02388201 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.002      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.15e+03   |
|    n_updates            | 2930       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.602      |
|    value_loss           | 1.77e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.05e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 295        |
|    time_elapsed         | 218336     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.03744034 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.00125    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.99e+03   |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.601      |
|    value_loss           | 3.47e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 982        |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 296        |
|    time_elapsed         | 218730     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.08206573 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | -0.724     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.53       |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.6        |
|    value_loss           | 47.7       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 960         |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 297         |
|    time_elapsed         | 219132      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.017580532 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.11       |
|    explained_variance   | 0.00693     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.59e+03    |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.598       |
|    value_loss           | 1.72e+04    |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=1037.79 +/- 365.48
Episode length: 2443.00 +/- 1287.34
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.44e+03   |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.03582687 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | -0.0004    |
|    learning_rate        | 0.0003     |
|    loss                 | 6.3e+03    |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.596      |
|    value_loss           | 6.89e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 925      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 298      |
|    time_elapsed    | 220751   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 898         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 299         |
|    time_elapsed         | 221148      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.017886236 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | 0.00355     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.26e+03    |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.594       |
|    value_loss           | 1.08e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 842         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 300         |
|    time_elapsed         | 221543      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.022333156 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.04       |
|    explained_variance   | 0.00735     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.07e+03    |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 0.592       |
|    value_loss           | 1.02e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 797         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 301         |
|    time_elapsed         | 221939      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.019348782 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.01       |
|    explained_variance   | 0.00428     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41e+04    |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.59        |
|    value_loss           | 1.33e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 781         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 302         |
|    time_elapsed         | 222335      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.024300788 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.99       |
|    explained_variance   | 0.00643     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.06e+03    |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.023      |
|    std                  | 0.59        |
|    value_loss           | 1.64e+04    |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=1213.68 +/- 339.69
Episode length: 2222.40 +/- 1077.98
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.22e+03    |
|    mean_reward          | 1.21e+03    |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.036259986 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.96       |
|    explained_variance   | 0.0063      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.16e+03    |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.587       |
|    value_loss           | 6.63e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 720      |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 303      |
|    time_elapsed    | 223851   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 717         |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 304         |
|    time_elapsed         | 224250      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.023995914 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 0.0115      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.79e+03    |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 0.585       |
|    value_loss           | 1.98e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 677        |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 305        |
|    time_elapsed         | 224647     |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.03147536 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | -0.00143   |
|    learning_rate        | 0.0003     |
|    loss                 | 5.68e+03   |
|    n_updates            | 3040       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.586      |
|    value_loss           | 1.32e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 652         |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 306         |
|    time_elapsed         | 225044      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.034957238 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.92       |
|    explained_variance   | 0.00545     |
|    learning_rate        | 0.0003      |
|    loss                 | 3e+03       |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.585       |
|    value_loss           | 1.89e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 639        |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 307        |
|    time_elapsed         | 225440     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.03695967 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.94      |
|    explained_variance   | 0.00624    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.71e+03   |
|    n_updates            | 3060       |
|    policy_gradient_loss | -0.024     |
|    std                  | 0.587      |
|    value_loss           | 1.59e+04   |
----------------------------------------
Eval num_timesteps=630000, episode_reward=1131.91 +/- 160.06
Episode length: 622.60 +/- 751.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 623         |
|    mean_reward          | 1.13e+03    |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.043629393 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 0.00326     |
|    learning_rate        | 0.0003      |
|    loss                 | 337         |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.584       |
|    value_loss           | 6.35e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 569      |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 308      |
|    time_elapsed    | 226149   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 479         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 309         |
|    time_elapsed         | 226547      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.029710572 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.9        |
|    explained_variance   | 0.0142      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.4e+03     |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.0243     |
|    std                  | 0.583       |
|    value_loss           | 2.46e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 445        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 310        |
|    time_elapsed         | 226950     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.03177114 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | 0.00594    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.64e+04   |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0226    |
|    std                  | 0.582      |
|    value_loss           | 3.57e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 403         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 311         |
|    time_elapsed         | 227346      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.031673122 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.84       |
|    explained_variance   | 0.00138     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+04    |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.577       |
|    value_loss           | 2.66e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 366        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 312        |
|    time_elapsed         | 227743     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.05236829 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.79      |
|    explained_variance   | 0.00505    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.77e+03   |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.575      |
|    value_loss           | 1.75e+04   |
----------------------------------------
Eval num_timesteps=640000, episode_reward=1181.89 +/- 57.09
Episode length: 760.00 +/- 272.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 760         |
|    mean_reward          | 1.18e+03    |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.036979213 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | 0.00646     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.73e+03    |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.572       |
|    value_loss           | 2.94e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 348      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 313      |
|    time_elapsed    | 228520   |
|    total_timesteps | 641024   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 329       |
|    ep_rew_mean          | 1.13e+03  |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 314       |
|    time_elapsed         | 228916    |
|    total_timesteps      | 643072    |
| train/                  |           |
|    approx_kl            | 0.0386364 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.75     |
|    explained_variance   | 0.00209   |
|    learning_rate        | 0.0003    |
|    loss                 | 6.82e+03  |
|    n_updates            | 3130      |
|    policy_gradient_loss | -0.0162   |
|    std                  | 0.573     |
|    value_loss           | 1.17e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 324         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 315         |
|    time_elapsed         | 229312      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.042571936 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.73       |
|    explained_variance   | 0.0124      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.86e+03    |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.023      |
|    std                  | 0.57        |
|    value_loss           | 2.25e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 308         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 316         |
|    time_elapsed         | 229707      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.036672004 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 0.00343     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+04    |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.567       |
|    value_loss           | 1.15e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 288         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 317         |
|    time_elapsed         | 230105      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.034112822 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.66       |
|    explained_variance   | 0.00494     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 0.565       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=1032.84 +/- 17.51
Episode length: 146.60 +/- 44.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 147         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.044168122 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.61       |
|    explained_variance   | 0.0115      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.83e+03    |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 0.56        |
|    value_loss           | 2.2e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 266      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 318      |
|    time_elapsed    | 230575   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 263         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 319         |
|    time_elapsed         | 230979      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.028298452 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | 0.0101      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.27e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.56        |
|    value_loss           | 2.98e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 249        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 320        |
|    time_elapsed         | 231378     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.06833574 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.00205    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 3190       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.56       |
|    value_loss           | 1.88e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 251         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 321         |
|    time_elapsed         | 231775      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.034856636 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.55       |
|    explained_variance   | 0.0068      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.27e+03    |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.556       |
|    value_loss           | 2.62e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 245        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 322        |
|    time_elapsed         | 232172     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.04537245 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | 0.0077     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.46e+03   |
|    n_updates            | 3210       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.552      |
|    value_loss           | 2e+04      |
----------------------------------------
Eval num_timesteps=660000, episode_reward=1027.29 +/- 15.90
Episode length: 107.60 +/- 73.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 108         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.041782033 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.44       |
|    explained_variance   | 0.0107      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.2e+04     |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0266     |
|    std                  | 0.548       |
|    value_loss           | 2.83e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 236      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 323      |
|    time_elapsed    | 232624   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 235         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 324         |
|    time_elapsed         | 233022      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.045337908 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.39       |
|    explained_variance   | 0.00902     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.68e+04    |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.546       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 325         |
|    time_elapsed         | 233417      |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.029483989 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.38       |
|    explained_variance   | 0.00971     |
|    learning_rate        | 0.0003      |
|    loss                 | 9.24e+03    |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.545       |
|    value_loss           | 2.49e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 208         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 326         |
|    time_elapsed         | 233814      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.058759697 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.00528     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.65e+03    |
|    n_updates            | 3250        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.542       |
|    value_loss           | 1.98e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 202         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 327         |
|    time_elapsed         | 234212      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.100644276 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.34       |
|    explained_variance   | 0.00757     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.74e+03    |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.544       |
|    value_loss           | 2.46e+04    |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=1068.55 +/- 59.31
Episode length: 243.60 +/- 213.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 244         |
|    mean_reward          | 1.07e+03    |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.025054162 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.011       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+04    |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.0251     |
|    std                  | 0.543       |
|    value_loss           | 2.86e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 208      |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 328      |
|    time_elapsed    | 234738   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 200        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 329        |
|    time_elapsed         | 235138     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.05533298 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.35      |
|    explained_variance   | 0.009      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 3280       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.544      |
|    value_loss           | 2.37e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 203        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 330        |
|    time_elapsed         | 235535     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.03812314 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.34      |
|    explained_variance   | 0.00727    |
|    learning_rate        | 0.0003     |
|    loss                 | 5e+03      |
|    n_updates            | 3290       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.542      |
|    value_loss           | 2.38e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 190        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 331        |
|    time_elapsed         | 235932     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.03900315 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.00805    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+04   |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.54       |
|    value_loss           | 2.32e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 332         |
|    time_elapsed         | 236328      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.111067645 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.3        |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | 1e+04       |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.00185    |
|    std                  | 0.54        |
|    value_loss           | 3.16e+04    |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=1118.52 +/- 84.63
Episode length: 429.40 +/- 286.48
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 429        |
|    mean_reward          | 1.12e+03   |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.12784049 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.27      |
|    explained_variance   | 0.0108     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.84e+03   |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.00758   |
|    std                  | 0.537      |
|    value_loss           | 2.9e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 182      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 333      |
|    time_elapsed    | 236941   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 171         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 334         |
|    time_elapsed         | 237337      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.043443516 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.26       |
|    explained_variance   | 0.0023      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.45e+03    |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.538       |
|    value_loss           | 2.67e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 165         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 335         |
|    time_elapsed         | 237732      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.030149484 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.26       |
|    explained_variance   | 0.00218     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+04    |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.537       |
|    value_loss           | 3.04e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 163         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 336         |
|    time_elapsed         | 238131      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.030414201 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | 0.00392     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.82e+04    |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.538       |
|    value_loss           | 3.41e+04    |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=1071.54 +/- 56.60
Episode length: 369.80 +/- 184.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 370         |
|    mean_reward          | 1.07e+03    |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.055533357 |
|    clip_fraction        | 0.496       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.00169     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.62e+03    |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.00581    |
|    std                  | 0.539       |
|    value_loss           | 2.16e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 155      |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 337      |
|    time_elapsed    | 238720   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 159         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 338         |
|    time_elapsed         | 239120      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.038432375 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | 0.00743     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.29e+04    |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.537       |
|    value_loss           | 2.76e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 146        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 339        |
|    time_elapsed         | 239518     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.05408319 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.25      |
|    explained_variance   | -0.0022    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.43e+04   |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.536      |
|    value_loss           | 2.5e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 136        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 340        |
|    time_elapsed         | 239914     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.02591141 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.24      |
|    explained_variance   | 0.0168     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.51e+04   |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.0272    |
|    std                  | 0.536      |
|    value_loss           | 4.22e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 121        |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 341        |
|    time_elapsed         | 240312     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.03801421 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.23      |
|    explained_variance   | 0.00559    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.79e+04   |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.536      |
|    value_loss           | 3.58e+04   |
----------------------------------------
Eval num_timesteps=700000, episode_reward=1068.45 +/- 52.60
Episode length: 222.60 +/- 187.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 223        |
|    mean_reward          | 1.07e+03   |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.03806317 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.22      |
|    explained_variance   | 0.0144     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.88e+04   |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.534      |
|    value_loss           | 4.7e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 104      |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 342      |
|    time_elapsed    | 240820   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 91.6       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 343        |
|    time_elapsed         | 241216     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.03731089 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.19      |
|    explained_variance   | 0.00403    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.42e+04   |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.0268    |
|    std                  | 0.531      |
|    value_loss           | 4.17e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 89.8       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 344        |
|    time_elapsed         | 241615     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.03653863 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.15      |
|    explained_variance   | 0.0207     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.33e+04   |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.0264    |
|    std                  | 0.529      |
|    value_loss           | 4.5e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 95.5       |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 345        |
|    time_elapsed         | 242013     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.04244022 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.11      |
|    explained_variance   | 0.0101     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.58e+04   |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.526      |
|    value_loss           | 4.25e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 90.5        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 346         |
|    time_elapsed         | 242414      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.044410046 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.00242     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.49e+04    |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.525       |
|    value_loss           | 3.14e+04    |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=1087.59 +/- 76.80
Episode length: 226.80 +/- 199.29
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 227        |
|    mean_reward          | 1.09e+03   |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.03995934 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.06      |
|    explained_variance   | 0.00725    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.86e+04   |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.524      |
|    value_loss           | 4.09e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 89       |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 347      |
|    time_elapsed    | 242926   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 91.2       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 348        |
|    time_elapsed         | 243325     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.04694748 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.00481    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.11e+04   |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.522      |
|    value_loss           | 4.41e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 88.5        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 349         |
|    time_elapsed         | 243729      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.040412247 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6          |
|    explained_variance   | 0.00773     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.16e+04    |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 0.52        |
|    value_loss           | 4.3e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 83.9        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 350         |
|    time_elapsed         | 244130      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.073456034 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.97       |
|    explained_variance   | 0.00329     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.518       |
|    value_loss           | 3.12e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 89.6        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 351         |
|    time_elapsed         | 244527      |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.029254004 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.95       |
|    explained_variance   | 0.0206      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57e+04    |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.517       |
|    value_loss           | 4.69e+04    |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=1061.99 +/- 31.82
Episode length: 194.40 +/- 95.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 194         |
|    mean_reward          | 1.06e+03    |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.041096613 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.93       |
|    explained_variance   | 0.00782     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.42e+04    |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.024      |
|    std                  | 0.516       |
|    value_loss           | 3.81e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 85.4     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 352      |
|    time_elapsed    | 245021   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 81.7       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 353        |
|    time_elapsed         | 245417     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.04954454 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.88      |
|    explained_variance   | 0.0087     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.13e+04   |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0273    |
|    std                  | 0.512      |
|    value_loss           | 3.94e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 86.1      |
|    ep_rew_mean          | 1.06e+03  |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 354       |
|    time_elapsed         | 245814    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.0836886 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.84     |
|    explained_variance   | 0.0121    |
|    learning_rate        | 0.0003    |
|    loss                 | 3.1e+04   |
|    n_updates            | 3530      |
|    policy_gradient_loss | -0.00761  |
|    std                  | 0.509     |
|    value_loss           | 4.03e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.7        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 355         |
|    time_elapsed         | 246212      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.029412143 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.81       |
|    explained_variance   | 0.00692     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.87e+04    |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.026      |
|    std                  | 0.507       |
|    value_loss           | 3.37e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85          |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 356         |
|    time_elapsed         | 246612      |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.042992823 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.76       |
|    explained_variance   | 0.0152      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.27e+04    |
|    n_updates            | 3550        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 0.504       |
|    value_loss           | 3.99e+04    |
-----------------------------------------
Eval num_timesteps=730000, episode_reward=1100.80 +/- 74.85
Episode length: 269.60 +/- 182.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 270         |
|    mean_reward          | 1.1e+03     |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.048578963 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.72       |
|    explained_variance   | 0.0186      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.9e+04     |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.503       |
|    value_loss           | 4.01e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.3     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 357      |
|    time_elapsed    | 247146   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.4        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 358         |
|    time_elapsed         | 247549      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.073370315 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.71       |
|    explained_variance   | 0.0119      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.83e+04    |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.502       |
|    value_loss           | 3.79e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.2        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 359         |
|    time_elapsed         | 247950      |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.086290956 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.7        |
|    explained_variance   | 0.00808     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67e+04    |
|    n_updates            | 3580        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.503       |
|    value_loss           | 3.74e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 82.3       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 360        |
|    time_elapsed         | 248349     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.04643005 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.69      |
|    explained_variance   | 0.00878    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+04   |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.501      |
|    value_loss           | 3.13e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.3        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 361         |
|    time_elapsed         | 248746      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.034505457 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.0361      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.44e+04    |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 0.5         |
|    value_loss           | 4.17e+04    |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=1079.79 +/- 49.22
Episode length: 202.40 +/- 113.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 202        |
|    mean_reward          | 1.08e+03   |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.04630296 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.62      |
|    explained_variance   | 0.00731    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.57e+03   |
|    n_updates            | 3610       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.496      |
|    value_loss           | 2.65e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 86.3     |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 362      |
|    time_elapsed    | 249245   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 81.7       |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 363        |
|    time_elapsed         | 249641     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.06314886 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.59      |
|    explained_variance   | 0.0333     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.91e+04   |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.495      |
|    value_loss           | 4.64e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 75.2        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 364         |
|    time_elapsed         | 250036      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.053064786 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.59       |
|    explained_variance   | 0.0197      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.43e+04    |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.0235     |
|    std                  | 0.495       |
|    value_loss           | 3.76e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 65.3       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 365        |
|    time_elapsed         | 250435     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.03631574 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.56      |
|    explained_variance   | 0.0183     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.37e+04   |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.025     |
|    std                  | 0.493      |
|    value_loss           | 4.45e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 63.7       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 366        |
|    time_elapsed         | 250830     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.07429898 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.53      |
|    explained_variance   | 0.0168     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.6e+04    |
|    n_updates            | 3650       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.491      |
|    value_loss           | 4.46e+04   |
----------------------------------------
Eval num_timesteps=750000, episode_reward=1055.51 +/- 39.14
Episode length: 146.00 +/- 101.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 146         |
|    mean_reward          | 1.06e+03    |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.055310775 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.52       |
|    explained_variance   | 0.00706     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.23e+04    |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.491       |
|    value_loss           | 3.89e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 59.5     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 367      |
|    time_elapsed    | 251299   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59.4        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 368         |
|    time_elapsed         | 251703      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.079328775 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.49       |
|    explained_variance   | 0.0168      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.76e+04    |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.488       |
|    value_loss           | 4.73e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 369         |
|    time_elapsed         | 252103      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.085055485 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.47       |
|    explained_variance   | 0.0107      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.14e+04    |
|    n_updates            | 3680        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 0.488       |
|    value_loss           | 4.28e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59.5        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 252502      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.056634076 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.0181      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.3e+04     |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.486       |
|    value_loss           | 4.09e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 60.8       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 252899     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.22192737 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | 0.0162     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+04   |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.483      |
|    value_loss           | 3.7e+04    |
----------------------------------------
Eval num_timesteps=760000, episode_reward=1035.85 +/- 26.96
Episode length: 86.80 +/- 53.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 86.8        |
|    mean_reward          | 1.04e+03    |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.047458235 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.38       |
|    explained_variance   | 0.0381      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.06e+04    |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.0275     |
|    std                  | 0.483       |
|    value_loss           | 4.08e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.6     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 253340   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 55.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 253740     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.06842263 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | 0.0263     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.38e+04   |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.481      |
|    value_loss           | 4.12e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 55.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 254141     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.07487461 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.34      |
|    explained_variance   | 0.0295     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.6e+04    |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.48       |
|    value_loss           | 4.26e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 56.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 254539     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.07331044 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.33      |
|    explained_variance   | 0.00841    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.6e+04    |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.479      |
|    value_loss           | 3.86e+04   |
----------------------------------------
Eval num_timesteps=770000, episode_reward=1038.37 +/- 28.50
Episode length: 97.80 +/- 67.66
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 97.8       |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.06210126 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.31      |
|    explained_variance   | 0.0216     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.72e+04   |
|    n_updates            | 3750       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.478      |
|    value_loss           | 4.01e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.3     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 254986   |
|    total_timesteps | 770048   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 59.8       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 377        |
|    time_elapsed         | 255391     |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.24580726 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.29      |
|    explained_variance   | 0.0105     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.77e+04   |
|    n_updates            | 3760       |
|    policy_gradient_loss | -0.00958   |
|    std                  | 0.476      |
|    value_loss           | 3.15e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 56.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 255788     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.11898617 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.28      |
|    explained_variance   | 0.0424     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+04   |
|    n_updates            | 3770       |
|    policy_gradient_loss | -0.023     |
|    std                  | 0.476      |
|    value_loss           | 3.76e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 55.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 256187     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.07187249 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.27      |
|    explained_variance   | 0.0773     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.73e+04   |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.475      |
|    value_loss           | 3.98e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 54.5      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 380       |
|    time_elapsed         | 256586    |
|    total_timesteps      | 778240    |
| train/                  |           |
|    approx_kl            | 0.0350359 |
|    clip_fraction        | 0.269     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.26     |
|    explained_variance   | 0.043     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.21e+04  |
|    n_updates            | 3790      |
|    policy_gradient_loss | -0.0213   |
|    std                  | 0.475     |
|    value_loss           | 3.58e+04  |
---------------------------------------
Eval num_timesteps=780000, episode_reward=1031.22 +/- 12.23
Episode length: 153.60 +/- 83.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 154         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.054293096 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.24       |
|    explained_variance   | 0.0306      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.68e+04    |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.473       |
|    value_loss           | 4.05e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 49.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 257061   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.3        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 257460      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.059473827 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.2        |
|    explained_variance   | 0.0264      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79e+04    |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.471       |
|    value_loss           | 4.05e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 57.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 383         |
|    time_elapsed         | 257858      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.061354488 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.19       |
|    explained_variance   | 0.00539     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+04    |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.0252     |
|    std                  | 0.471       |
|    value_loss           | 3.44e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 58.3        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 258258      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.047499962 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.18       |
|    explained_variance   | 0.0244      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83e+04    |
|    n_updates            | 3830        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 0.469       |
|    value_loss           | 3.08e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 57.8       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 258656     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.05135736 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.15      |
|    explained_variance   | 0.0302     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+04   |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.0272    |
|    std                  | 0.467      |
|    value_loss           | 3.15e+04   |
----------------------------------------
Eval num_timesteps=790000, episode_reward=1030.24 +/- 27.90
Episode length: 74.00 +/- 67.19
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 74          |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.045917604 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.13       |
|    explained_variance   | 0.0365      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+04    |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.0247     |
|    std                  | 0.466       |
|    value_loss           | 3.4e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 53.6     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 259089   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.5        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 259494      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.058886237 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.11       |
|    explained_variance   | 0.0454      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.49e+04    |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.466       |
|    value_loss           | 3.9e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 388         |
|    time_elapsed         | 259895      |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.093240425 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.08       |
|    explained_variance   | 0.0234      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42e+04    |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.463       |
|    value_loss           | 3.44e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 260294     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.07311541 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.06      |
|    explained_variance   | 0.021      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.17e+04   |
|    n_updates            | 3880       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.463      |
|    value_loss           | 3.51e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 47.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 260692     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.07640837 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.06      |
|    explained_variance   | 0.0345     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.21e+04   |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.0282    |
|    std                  | 0.463      |
|    value_loss           | 3.29e+04   |
----------------------------------------
Eval num_timesteps=800000, episode_reward=1025.44 +/- 10.87
Episode length: 65.80 +/- 25.22
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 65.8       |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.20745587 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.03      |
|    explained_variance   | 0.0328     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.95e+04   |
|    n_updates            | 3900       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.46       |
|    value_loss           | 3.48e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 261124   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 261523      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.075911306 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5          |
|    explained_variance   | 0.0288      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76e+04    |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.46        |
|    value_loss           | 3.39e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 261924     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.12741823 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.98      |
|    explained_variance   | 0.0389     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.66e+04   |
|    n_updates            | 3920       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.457      |
|    value_loss           | 3.48e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 47.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 262320     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.10987292 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.95      |
|    explained_variance   | 0.0241     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.75e+04   |
|    n_updates            | 3930       |
|    policy_gradient_loss | -0.03      |
|    std                  | 0.457      |
|    value_loss           | 3.17e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 395         |
|    time_elapsed         | 262719      |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.062313467 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.92       |
|    explained_variance   | 0.0433      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6e+04     |
|    n_updates            | 3940        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.454       |
|    value_loss           | 3.03e+04    |
-----------------------------------------
Eval num_timesteps=810000, episode_reward=1020.94 +/- 14.00
Episode length: 46.40 +/- 25.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 46.4       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.22597526 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.88      |
|    explained_variance   | 0.0354     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.37e+04   |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.0278    |
|    std                  | 0.452      |
|    value_loss           | 3.17e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47.4     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 263149   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 263550     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.13892394 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.86      |
|    explained_variance   | 0.0385     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.45e+04   |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.00939   |
|    std                  | 0.451      |
|    value_loss           | 3.17e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 398         |
|    time_elapsed         | 263948      |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.049531728 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.85       |
|    explained_variance   | 0.0244      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15e+04    |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.451       |
|    value_loss           | 2.85e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 264348     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.10139014 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.84      |
|    explained_variance   | 0.0264     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.82e+04   |
|    n_updates            | 3980       |
|    policy_gradient_loss | -0.0257    |
|    std                  | 0.45       |
|    value_loss           | 3.01e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 264747     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.27762562 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.84      |
|    explained_variance   | 0.0261     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+04   |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.00193    |
|    std                  | 0.451      |
|    value_loss           | 2.96e+04   |
----------------------------------------
Eval num_timesteps=820000, episode_reward=1027.81 +/- 15.00
Episode length: 73.40 +/- 32.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 73.4       |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.23901758 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.83      |
|    explained_variance   | 0.0363     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.64e+04   |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.449      |
|    value_loss           | 2.69e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 48       |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 265184   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 265583      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.055679295 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.8        |
|    explained_variance   | 0.0346      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+04    |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.0278     |
|    std                  | 0.447       |
|    value_loss           | 2.58e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 42.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 403       |
|    time_elapsed         | 265983    |
|    total_timesteps      | 825344    |
| train/                  |           |
|    approx_kl            | 0.0859997 |
|    clip_fraction        | 0.251     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.76     |
|    explained_variance   | 0.0942    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.43e+04  |
|    n_updates            | 4020      |
|    policy_gradient_loss | -0.0233   |
|    std                  | 0.445     |
|    value_loss           | 2.8e+04   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 41         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 266383     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.10427031 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.74      |
|    explained_variance   | 0.063      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.16e+03   |
|    n_updates            | 4030       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.444      |
|    value_loss           | 2.94e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 405         |
|    time_elapsed         | 266780      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.088543236 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.72       |
|    explained_variance   | 0.0401      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42e+04    |
|    n_updates            | 4040        |
|    policy_gradient_loss | -0.0202     |
|    std                  | 0.442       |
|    value_loss           | 2.85e+04    |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=1019.43 +/- 11.47
Episode length: 57.20 +/- 29.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 57.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.19994995 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.67      |
|    explained_variance   | 0.0715     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.51e+04   |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.44       |
|    value_loss           | 2.85e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 267215   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 407         |
|    time_elapsed         | 267615      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.046905994 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.64       |
|    explained_variance   | 0.0443      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55e+04    |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.438       |
|    value_loss           | 2.36e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 268014     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.06080447 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.62      |
|    explained_variance   | 0.0874     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17e+04   |
|    n_updates            | 4070       |
|    policy_gradient_loss | -0.0294    |
|    std                  | 0.438      |
|    value_loss           | 2.61e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 41.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 409       |
|    time_elapsed         | 268414    |
|    total_timesteps      | 837632    |
| train/                  |           |
|    approx_kl            | 0.1344267 |
|    clip_fraction        | 0.308     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.61     |
|    explained_variance   | 0.0479    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.21e+04  |
|    n_updates            | 4080      |
|    policy_gradient_loss | -0.0142   |
|    std                  | 0.437     |
|    value_loss           | 2.44e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 268815     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.21309108 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.59      |
|    explained_variance   | 0.0745     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.78e+03   |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.436      |
|    value_loss           | 2.55e+04   |
----------------------------------------
Eval num_timesteps=840000, episode_reward=1013.77 +/- 4.00
Episode length: 52.40 +/- 22.78
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 52.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.15261179 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.56      |
|    explained_variance   | 0.0581     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+04   |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.00974   |
|    std                  | 0.434      |
|    value_loss           | 2.76e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 269239   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 269639     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.08638903 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.53      |
|    explained_variance   | 0.0269     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.432      |
|    value_loss           | 2.47e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 270040     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.06310078 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.49      |
|    explained_variance   | 0.0574     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.31e+04   |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0291    |
|    std                  | 0.43       |
|    value_loss           | 2.4e+04    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 414         |
|    time_elapsed         | 270437      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.067159995 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.47       |
|    explained_variance   | 0.0563      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.429       |
|    value_loss           | 2.4e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 270835     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.09678754 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.44      |
|    explained_variance   | 0.0681     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+04   |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.428      |
|    value_loss           | 2.32e+04   |
----------------------------------------
Eval num_timesteps=850000, episode_reward=1034.16 +/- 15.80
Episode length: 77.00 +/- 30.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 77         |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.08100913 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.42      |
|    explained_variance   | 0.042      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.2e+04    |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.426      |
|    value_loss           | 2.05e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 43       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 271281   |
|    total_timesteps | 851968   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 41.7      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 417       |
|    time_elapsed         | 271684    |
|    total_timesteps      | 854016    |
| train/                  |           |
|    approx_kl            | 0.1626072 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.42     |
|    explained_variance   | 0.05      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.12e+04  |
|    n_updates            | 4160      |
|    policy_gradient_loss | -0.0159   |
|    std                  | 0.427     |
|    value_loss           | 2.02e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 418        |
|    time_elapsed         | 272082     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.05364787 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.42      |
|    explained_variance   | 0.0922     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.33e+04   |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.427      |
|    value_loss           | 2.15e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 272482     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.15355672 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.42      |
|    explained_variance   | 0.0819     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.11e+04   |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.427      |
|    value_loss           | 2.24e+04   |
----------------------------------------
Eval num_timesteps=860000, episode_reward=1040.15 +/- 21.83
Episode length: 91.60 +/- 38.75
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 91.6       |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.19803476 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.39      |
|    explained_variance   | 0.0309     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.16e+04   |
|    n_updates            | 4190       |
|    policy_gradient_loss | -0.0242    |
|    std                  | 0.425      |
|    value_loss           | 1.93e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 39.9     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 272929   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39         |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 273329     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.19314975 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.37      |
|    explained_variance   | 0.0418     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.38e+03   |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.424      |
|    value_loss           | 2.19e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 38.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 422       |
|    time_elapsed         | 273731    |
|    total_timesteps      | 864256    |
| train/                  |           |
|    approx_kl            | 0.5701028 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.36     |
|    explained_variance   | 0.0644    |
|    learning_rate        | 0.0003    |
|    loss                 | 7.35e+03  |
|    n_updates            | 4210      |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.424     |
|    value_loss           | 1.89e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 274131     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.07952006 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.35      |
|    explained_variance   | 0.0781     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18e+04   |
|    n_updates            | 4220       |
|    policy_gradient_loss | -0.0244    |
|    std                  | 0.422      |
|    value_loss           | 1.91e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 274531     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.13336344 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.32      |
|    explained_variance   | 0.0935     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.61e+03   |
|    n_updates            | 4230       |
|    policy_gradient_loss | -0.0267    |
|    std                  | 0.422      |
|    value_loss           | 1.76e+04   |
----------------------------------------
Eval num_timesteps=870000, episode_reward=1023.02 +/- 6.17
Episode length: 50.60 +/- 17.86
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 50.6       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.12835757 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.29      |
|    explained_variance   | 0.0599     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.78e+03   |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.419      |
|    value_loss           | 1.79e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 274964   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 275366     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.48954242 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.27      |
|    explained_variance   | 0.061      |
|    learning_rate        | 0.0003     |
|    loss                 | 8.82e+03   |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.00614   |
|    std                  | 0.419      |
|    value_loss           | 1.92e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 275766     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.08760582 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.26      |
|    explained_variance   | 0.0688     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.19e+03   |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.0244    |
|    std                  | 0.418      |
|    value_loss           | 1.76e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 276165     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.17374796 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.25      |
|    explained_variance   | 0.0488     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.3e+03    |
|    n_updates            | 4270       |
|    policy_gradient_loss | -0.00659   |
|    std                  | 0.418      |
|    value_loss           | 1.69e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 429         |
|    time_elapsed         | 276564      |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.062786914 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.0279      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.34e+03    |
|    n_updates            | 4280        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.418       |
|    value_loss           | 1.53e+04    |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=1033.46 +/- 20.94
Episode length: 73.00 +/- 35.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 73          |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.057658285 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.0839      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.17e+03    |
|    n_updates            | 4290        |
|    policy_gradient_loss | -0.0271     |
|    std                  | 0.417       |
|    value_loss           | 1.48e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 39.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 277001   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 277399     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.09109922 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.23      |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.62e+03   |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.0224    |
|    std                  | 0.417      |
|    value_loss           | 1.41e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 432        |
|    time_elapsed         | 277799     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.31416738 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.23      |
|    explained_variance   | 0.129      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.39e+03   |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.00778   |
|    std                  | 0.418      |
|    value_loss           | 1.56e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 278197      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.119749114 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.22       |
|    explained_variance   | 0.0773      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.29e+03    |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0261     |
|    std                  | 0.417       |
|    value_loss           | 1.38e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 39.2      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 434       |
|    time_elapsed         | 278596    |
|    total_timesteps      | 888832    |
| train/                  |           |
|    approx_kl            | 0.0810875 |
|    clip_fraction        | 0.311     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.2      |
|    explained_variance   | 0.0948    |
|    learning_rate        | 0.0003    |
|    loss                 | 7.99e+03  |
|    n_updates            | 4330      |
|    policy_gradient_loss | -0.0185   |
|    std                  | 0.416     |
|    value_loss           | 1.31e+04  |
---------------------------------------
Eval num_timesteps=890000, episode_reward=1021.83 +/- 11.80
Episode length: 51.60 +/- 25.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 51.6       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.34475106 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.158      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.65e+03   |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.414      |
|    value_loss           | 1.31e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 38.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 279028   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 279430     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.05627506 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.16      |
|    explained_variance   | 0.147      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.13e+03   |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.0258    |
|    std                  | 0.414      |
|    value_loss           | 1.26e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 279831     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.10986555 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.14      |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.68e+03   |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.413      |
|    value_loss           | 1.28e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 280232     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.07791194 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.12      |
|    explained_variance   | 0.286      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.85e+03   |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.411      |
|    value_loss           | 1.12e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 439         |
|    time_elapsed         | 280636      |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.047965985 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.11       |
|    explained_variance   | 0.319       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.71e+03    |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.411       |
|    value_loss           | 1.1e+04     |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=1032.15 +/- 11.40
Episode length: 89.20 +/- 39.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 89.2        |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.056902234 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.1        |
|    explained_variance   | 0.286       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.43e+03    |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.411       |
|    value_loss           | 1.04e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 47.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 281080   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 281483     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.08242149 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.08      |
|    explained_variance   | 0.328      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.09e+03   |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.409      |
|    value_loss           | 9.85e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 281883     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.07312568 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.06      |
|    explained_variance   | 0.264      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.72e+03   |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.0219    |
|    std                  | 0.409      |
|    value_loss           | 1.09e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 443         |
|    time_elapsed         | 282282      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.033415604 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.06       |
|    explained_variance   | 0.295       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.6e+03     |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.409       |
|    value_loss           | 9.88e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 444         |
|    time_elapsed         | 282689      |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.063647896 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.05       |
|    explained_variance   | 0.267       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.63e+03    |
|    n_updates            | 4430        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.408       |
|    value_loss           | 1.01e+04    |
-----------------------------------------
Eval num_timesteps=910000, episode_reward=576.58 +/- 552.42
Episode length: 1479.40 +/- 1732.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.48e+03   |
|    mean_reward          | 577        |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.25262213 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.04      |
|    explained_variance   | 0.265      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.69e+03   |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.00782   |
|    std                  | 0.408      |
|    value_loss           | 9.38e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 283834   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 53         |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 284248     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.55983794 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.03      |
|    explained_variance   | 0.464      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.66e+03   |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.00645    |
|    std                  | 0.407      |
|    value_loss           | 8.68e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 72.2       |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 284661     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.96576333 |
|    clip_fraction        | 0.598      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.01      |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.0003     |
|    loss                 | 816        |
|    n_updates            | 4460       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.406      |
|    value_loss           | 2.78e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 82.5       |
|    ep_rew_mean          | 1e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 285062     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.27043116 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.98      |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.95e+03   |
|    n_updates            | 4470       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.405      |
|    value_loss           | 3.31e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 89.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 285467     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.44913098 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.29e+03   |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.043      |
|    std                  | 0.405      |
|    value_loss           | 6.98e+03   |
----------------------------------------
Eval num_timesteps=920000, episode_reward=346.14 +/- 546.23
Episode length: 2168.00 +/- 1741.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.17e+03    |
|    mean_reward          | 346         |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.024655446 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.97       |
|    explained_variance   | 0.802       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.76e+03    |
|    n_updates            | 4490        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.404       |
|    value_loss           | 8.23e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95.1     |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 286962   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 64.2        |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 287367      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.019976322 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.97       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.98e+03    |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.404       |
|    value_loss           | 9.91e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 53.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 452        |
|    time_elapsed         | 287770     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.08587484 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.98e+03   |
|    n_updates            | 4510       |
|    policy_gradient_loss | -0.00833   |
|    std                  | 0.405      |
|    value_loss           | 1.1e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 453        |
|    time_elapsed         | 288170     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.04584501 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.31e+03   |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.404      |
|    value_loss           | 1e+04      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 454         |
|    time_elapsed         | 288567      |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.030173354 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.96       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.88e+03    |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.404       |
|    value_loss           | 8.7e+03     |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=569.77 +/- 546.75
Episode length: 1464.60 +/- 1744.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.46e+03   |
|    mean_reward          | 570        |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.03770853 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.95      |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.31e+03   |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 0.404      |
|    value_loss           | 8.3e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 289701   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 290101      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.038566947 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.94       |
|    explained_variance   | 0.452       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.69e+03    |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.403       |
|    value_loss           | 7.59e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 457         |
|    time_elapsed         | 290505      |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.056281686 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.93       |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.03e+03    |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.402       |
|    value_loss           | 7.85e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 41.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 458         |
|    time_elapsed         | 290910      |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.032486264 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.91       |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.7e+03     |
|    n_updates            | 4570        |
|    policy_gradient_loss | -0.0268     |
|    std                  | 0.401       |
|    value_loss           | 7.62e+03    |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=1019.45 +/- 9.91
Episode length: 50.40 +/- 26.08
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 50.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.054858617 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.91e+03    |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.4         |
|    value_loss           | 7.14e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 291336   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 291736     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.08707334 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.85      |
|    explained_variance   | 0.302      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.81e+03   |
|    n_updates            | 4590       |
|    policy_gradient_loss | -0.026     |
|    std                  | 0.398      |
|    value_loss           | 6.82e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 292137     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.19940656 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.82      |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.19e+03   |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.397      |
|    value_loss           | 6.14e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 462         |
|    time_elapsed         | 292535      |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.053479977 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.81       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.82e+03    |
|    n_updates            | 4610        |
|    policy_gradient_loss | -0.0272     |
|    std                  | 0.397       |
|    value_loss           | 6.19e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 292935     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.13473694 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.8       |
|    explained_variance   | 0.365      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.63e+03   |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.396      |
|    value_loss           | 5.38e+03   |
----------------------------------------
Eval num_timesteps=950000, episode_reward=1017.70 +/- 6.77
Episode length: 40.80 +/- 16.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.8       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.06318146 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.78      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.02e+03   |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.0204    |
|    std                  | 0.395      |
|    value_loss           | 5.52e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 293359   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 293758     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.07804409 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.76      |
|    explained_variance   | 0.364      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.63e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.394      |
|    value_loss           | 5.16e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 34.8      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 466       |
|    time_elapsed         | 294157    |
|    total_timesteps      | 954368    |
| train/                  |           |
|    approx_kl            | 0.1293381 |
|    clip_fraction        | 0.341     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.74     |
|    explained_variance   | 0.396     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.06e+03  |
|    n_updates            | 4650      |
|    policy_gradient_loss | -0.0185   |
|    std                  | 0.393     |
|    value_loss           | 4.75e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 467         |
|    time_elapsed         | 294563      |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.054788478 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.74       |
|    explained_variance   | 0.339       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.6e+03     |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.026      |
|    std                  | 0.394       |
|    value_loss           | 5.15e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 294964      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.121914156 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.75       |
|    explained_variance   | 0.376       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8e+03     |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.394       |
|    value_loss           | 4.53e+03    |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=798.75 +/- 449.36
Episode length: 762.60 +/- 1419.23
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 763         |
|    mean_reward          | 799         |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.083042964 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.76       |
|    explained_variance   | 0.421       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.21e+03    |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.394       |
|    value_loss           | 4.55e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 295745   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 296143     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.04870562 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.75      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.21e+03   |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.0204    |
|    std                  | 0.394      |
|    value_loss           | 4.77e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 296542      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.080121875 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.73       |
|    explained_variance   | 0.487       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73e+03    |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.393       |
|    value_loss           | 3.88e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 296939     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.05882705 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.341      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.88e+03   |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.0251    |
|    std                  | 0.391      |
|    value_loss           | 4.78e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 473         |
|    time_elapsed         | 297342      |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.048629325 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.68       |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.34e+03    |
|    n_updates            | 4720        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 0.39        |
|    value_loss           | 4.44e+03    |
-----------------------------------------
Eval num_timesteps=970000, episode_reward=792.67 +/- 446.25
Episode length: 751.80 +/- 1424.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 752         |
|    mean_reward          | 793         |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.065573186 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.67       |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.85e+03    |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 0.39        |
|    value_loss           | 4.09e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 298118   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 298524      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.053310025 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.66       |
|    explained_variance   | 0.373       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.09e+03    |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.389       |
|    value_loss           | 4.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 476        |
|    time_elapsed         | 298926     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.09314847 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.71e+03   |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.389      |
|    value_loss           | 3.62e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 299326     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.06526176 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.63      |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.56e+03   |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.388      |
|    value_loss           | 3.33e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 299727     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.10173561 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.61      |
|    explained_variance   | 0.396      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.1e+03    |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.387      |
|    value_loss           | 3.67e+03   |
----------------------------------------
Eval num_timesteps=980000, episode_reward=1023.50 +/- 11.25
Episode length: 54.60 +/- 24.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 54.6       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.04217958 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.61      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9e+03    |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.387      |
|    value_loss           | 3.67e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 300154   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 300552      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.107883684 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.61       |
|    explained_variance   | 0.337       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.81e+03    |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.387       |
|    value_loss           | 4.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 300952     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.40541425 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.61      |
|    explained_variance   | 0.512      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+03   |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.000274  |
|    std                  | 0.387      |
|    value_loss           | 3.12e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 482         |
|    time_elapsed         | 301353      |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.051896736 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.58       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.69e+03    |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 0.385       |
|    value_loss           | 4.78e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 483         |
|    time_elapsed         | 301752      |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.047397252 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.55       |
|    explained_variance   | 0.366       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88e+03    |
|    n_updates            | 4820        |
|    policy_gradient_loss | -0.0248     |
|    std                  | 0.384       |
|    value_loss           | 3.89e+03    |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=1025.23 +/- 11.92
Episode length: 58.80 +/- 31.09
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.8        |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.043147616 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.52       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+03    |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.382       |
|    value_loss           | 3.4e+03     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 302184   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 302588     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.12322305 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.51      |
|    explained_variance   | 0.391      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.61e+03   |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.383      |
|    value_loss           | 3.45e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 486         |
|    time_elapsed         | 302990      |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.055868227 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.51       |
|    explained_variance   | 0.37        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67e+03    |
|    n_updates            | 4850        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 0.382       |
|    value_loss           | 3.64e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 303389     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.33394086 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.49      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.88e+03   |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.381      |
|    value_loss           | 3.17e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 303788     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.13480183 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.48      |
|    explained_variance   | 0.492      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.37e+03   |
|    n_updates            | 4870       |
|    policy_gradient_loss | -0.0087    |
|    std                  | 0.381      |
|    value_loss           | 2.78e+03   |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=1019.50 +/- 9.25
Episode length: 40.60 +/- 15.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 40.6       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.05463934 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.47      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.21e+03   |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.0239    |
|    std                  | 0.38       |
|    value_loss           | 3.52e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 304208   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-02-04_22-27-54_llm_triton_qwen_32b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 12:25:20 < 0:00:00 , 5 it/s ]
