####################
/var/spool/slurmd/job5228065/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_3B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-20_12-12-49_llm_triton_qwen_3b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 9
 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 3
 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 1
 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (20.75, -250.00).
 What is the reward score?
 
 Response: -8
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 219  |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.44e+03     |
|    ep_rew_mean          | -1.42e+03    |
| time/                   |              |
|    fps                  | 9            |
|    iterations           | 2            |
|    time_elapsed         | 435          |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0102490615 |
|    clip_fraction        | 0.119        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.236       |
|    learning_rate        | 0.0003       |
|    loss                 | 19.2         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.0165      |
|    std                  | 0.994        |
|    value_loss           | 39.3         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.44e+03    |
|    ep_rew_mean          | -1.42e+03   |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 651         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.011033631 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.637       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.1        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.99        |
|    value_loss           | 36.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.42e+03    |
|    ep_rew_mean          | -1.28e+03   |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 874         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011632936 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.297       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.16        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.987       |
|    value_loss           | 17.8        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.93 +/- 0.04
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.010454641 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.301       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.4         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.988       |
|    value_loss           | 14.1        |
-----------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 3.33e+03  |
|    ep_rew_mean     | -1.33e+03 |
| time/              |           |
|    fps             | 3         |
|    iterations      | 5         |
|    time_elapsed    | 2893      |
|    total_timesteps | 10240     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -1.33e+03   |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 6           |
|    time_elapsed         | 3116        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.008596981 |
|    clip_fraction        | 0.0896      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0024     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.7e+03     |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00633    |
|    std                  | 0.989       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.32e+03    |
|    ep_rew_mean          | -1.25e+03   |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3337        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.012120798 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -2.01       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.991       |
|    value_loss           | 7.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.32e+03    |
|    ep_rew_mean          | -1.25e+03   |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3555        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012562105 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.476      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.99        |
|    value_loss           | 5.83        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -1.18e+03   |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 9           |
|    time_elapsed         | 3774        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.017863493 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.993       |
|    value_loss           | 3.15        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.78 +/- 0.06
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.011190286 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.992       |
|    value_loss           | 3.73        |
-----------------------------------------
New best mean reward!
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 2.86e+03  |
|    ep_rew_mean     | -1.05e+03 |
| time/              |           |
|    fps             | 3         |
|    iterations      | 10        |
|    time_elapsed    | 5805      |
|    total_timesteps | 20480     |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.86e+03    |
|    ep_rew_mean          | -1.05e+03   |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 6021        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.009049201 |
|    clip_fraction        | 0.0703      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.000985   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.46        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00833    |
|    std                  | 0.993       |
|    value_loss           | 929         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.92e+03    |
|    ep_rew_mean          | -1.01e+03   |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 12          |
|    time_elapsed         | 6233        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.014634153 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.47        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.36        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.991       |
|    value_loss           | 3.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.92e+03    |
|    ep_rew_mean          | -1.01e+03   |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6445        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.013342104 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.994       |
|    value_loss           | 2.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.98e+03    |
|    ep_rew_mean          | -982        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6660        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.016574167 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0255     |
|    std                  | 0.995       |
|    value_loss           | 2.86        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.55 +/- 0.10
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.012789481 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.996       |
|    value_loss           | 2.52        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3e+03    |
|    ep_rew_mean     | -1e+03   |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8676     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3e+03       |
|    ep_rew_mean          | -1e+03      |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 8885        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.009661142 |
|    clip_fraction        | 0.0865      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.00318    |
|    learning_rate        | 0.0003      |
|    loss                 | 811         |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00582    |
|    std                  | 0.995       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.05e+03    |
|    ep_rew_mean          | -975        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 9096        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.017424988 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.106       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.994       |
|    value_loss           | 1.98        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.05e+03    |
|    ep_rew_mean          | -975        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 9306        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.017469464 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0208     |
|    std                  | 0.99        |
|    value_loss           | 2.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.08e+03    |
|    ep_rew_mean          | -954        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9515        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.016220473 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.827       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.994       |
|    value_loss           | 1.65        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.50 +/- 0.21
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.017357413 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.969       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.99        |
|    value_loss           | 2.4         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.08e+03 |
|    ep_rew_mean     | -968     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11526    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.08e+03    |
|    ep_rew_mean          | -968        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 11736       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.013052232 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.00954     |
|    learning_rate        | 0.0003      |
|    loss                 | 18.7        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00785    |
|    std                  | 0.99        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.11e+03    |
|    ep_rew_mean          | -950        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11946       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.017079096 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.728       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.983       |
|    value_loss           | 1.93        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.14e+03   |
|    ep_rew_mean          | -932       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 23         |
|    time_elapsed         | 12155      |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.02090768 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.566      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.873      |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.982      |
|    value_loss           | 1.66       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.14e+03   |
|    ep_rew_mean          | -932       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 24         |
|    time_elapsed         | 12365      |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.01680125 |
|    clip_fraction        | 0.195      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.1        |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.986      |
|    value_loss           | 1.66       |
----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.69 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.014745172 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.386       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.51        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.988       |
|    value_loss           | 1.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.13e+03 |
|    ep_rew_mean     | -940     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14376    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | -940        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 14586       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.009682335 |
|    clip_fraction        | 0.0989      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.00306    |
|    learning_rate        | 0.0003      |
|    loss                 | 756         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00715    |
|    std                  | 0.988       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.15e+03    |
|    ep_rew_mean          | -924        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14796       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.028830327 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.904       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.988       |
|    value_loss           | 1.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -908        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 15006       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.017481077 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.334       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.673       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00868    |
|    std                  | 0.99        |
|    value_loss           | 1.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -908        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 15215       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.019819504 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.437       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.588       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.995       |
|    value_loss           | 1.46        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.68 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.018738631 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.993       |
|    value_loss           | 1.92        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -915     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 17225    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -915        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17433       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.012126128 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.00209    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23e+03    |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00672    |
|    std                  | 0.992       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | -901        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17642       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.022563778 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.343      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.871       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.992       |
|    value_loss           | 1.96        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.19e+03    |
|    ep_rew_mean          | -886        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17851       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.016266942 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.99        |
|    value_loss           | 2.02        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.19e+03   |
|    ep_rew_mean          | -886       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 34         |
|    time_elapsed         | 18060      |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.02608446 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.525      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.769      |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.99       |
|    value_loss           | 1.67       |
----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.54 +/- 0.11
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.024437843 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.942       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.987       |
|    value_loss           | 1.7         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.18e+03 |
|    ep_rew_mean     | -891     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 20070    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | -877        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20278       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.009558039 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.0152      |
|    learning_rate        | 0.0003      |
|    loss                 | 16.2        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00912    |
|    std                  | 0.986       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | -877        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20487       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.023164567 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.136      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.885       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.98        |
|    value_loss           | 2.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -863        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20696       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.021949414 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.614       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0067     |
|    std                  | 0.976       |
|    value_loss           | 2.02        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -863        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20905       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.021761049 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.534       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.98        |
|    value_loss           | 2.57        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.72 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.023585076 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.847       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0041     |
|    std                  | 0.979       |
|    value_loss           | 1.19        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.2e+03  |
|    ep_rew_mean     | -867     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22914    |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.21e+03     |
|    ep_rew_mean          | -854         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 41           |
|    time_elapsed         | 23123        |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0067821788 |
|    clip_fraction        | 0.0603       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | -0.00072     |
|    learning_rate        | 0.0003       |
|    loss                 | 3.9          |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00467     |
|    std                  | 0.979        |
|    value_loss           | 1.04e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.21e+03   |
|    ep_rew_mean          | -854       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 42         |
|    time_elapsed         | 23332      |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.01952879 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | -0.0571    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.828      |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.973      |
|    value_loss           | 1.72       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -841        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23540       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.021893911 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.417       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.788       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.971       |
|    value_loss           | 1.82        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.72 +/- 0.02
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.02363896 |
|    clip_fraction        | 0.228      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13       |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.969      |
|    value_loss           | 2.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.21e+03 |
|    ep_rew_mean     | -844     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25549    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -844        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25757       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.006195262 |
|    clip_fraction        | 0.0524      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.00415     |
|    learning_rate        | 0.0003      |
|    loss                 | 644         |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00491    |
|    std                  | 0.969       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -830        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25966       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.030426517 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.472      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.899       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.971       |
|    value_loss           | 1.71        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -830        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 26175       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.032936163 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.386       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.706       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00524    |
|    std                  | 0.97        |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -818        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26385       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.028541401 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.409       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00625    |
|    std                  | 0.97        |
|    value_loss           | 1.59        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.74 +/- 0.11
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.021420626 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.429       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.895       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.967       |
|    value_loss           | 2.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -822     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28394    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -822        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 28603       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.010133706 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.000684   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.13        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00731    |
|    std                  | 0.967       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -812        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28811       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.031404678 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.574      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33        |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00832    |
|    std                  | 0.969       |
|    value_loss           | 1.74        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -812        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 29019       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.030976888 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.388       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.783       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.966       |
|    value_loss           | 1.62        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.24e+03   |
|    ep_rew_mean          | -802       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 53         |
|    time_elapsed         | 29227      |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.03615795 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.622      |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.00905   |
|    std                  | 0.968      |
|    value_loss           | 1.46       |
----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.64 +/- 0.18
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.032542624 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00901    |
|    std                  | 0.968       |
|    value_loss           | 1.25        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.24e+03 |
|    ep_rew_mean     | -804     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 31237    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -804        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31444       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.010290875 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00296    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51e+03    |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00563    |
|    std                  | 0.969       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -793        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31652       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.025033625 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.0671     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.685       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.966       |
|    value_loss           | 1.68        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.24e+03   |
|    ep_rew_mean          | -793       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 57         |
|    time_elapsed         | 31860      |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.02050871 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.72       |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0123    |
|    std                  | 0.966      |
|    value_loss           | 1.45       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.25e+03    |
|    ep_rew_mean          | -784        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 32068       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.030978251 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.382       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.964       |
|    value_loss           | 1.68        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.68 +/- 0.16
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.024650663 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.747       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.963       |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.24e+03 |
|    ep_rew_mean     | -785     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 34076    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -785        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 34285       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.012274349 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00304     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+03     |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00266    |
|    std                  | 0.962       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.25e+03    |
|    ep_rew_mean          | -774        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34493       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.044058632 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.312      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.686       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.962       |
|    value_loss           | 1.83        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.25e+03   |
|    ep_rew_mean          | -774       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 62         |
|    time_elapsed         | 34701      |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.03778765 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.298      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.845      |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.00829   |
|    std                  | 0.959      |
|    value_loss           | 1.72       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -763       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 63         |
|    time_elapsed         | 34908      |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.03288844 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.412      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.6        |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.00524   |
|    std                  | 0.955      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=130000, episode_reward=-96.53 +/- 1.61
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.5       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.046220947 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.584       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00541    |
|    std                  | 0.951       |
|    value_loss           | 1.35        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.25e+03 |
|    ep_rew_mean     | -765     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36917    |
|    total_timesteps | 131072   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.25e+03   |
|    ep_rew_mean          | -765       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 65         |
|    time_elapsed         | 37125      |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.01539457 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.00273    |
|    learning_rate        | 0.0003     |
|    loss                 | 279        |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.00402   |
|    std                  | 0.951      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -755       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 66         |
|    time_elapsed         | 37333      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.03472317 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.0205     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.36       |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.00998   |
|    std                  | 0.949      |
|    value_loss           | 1.26       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.26e+03  |
|    ep_rew_mean          | -745      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 67        |
|    time_elapsed         | 37541     |
|    total_timesteps      | 137216    |
| train/                  |           |
|    approx_kl            | 0.0282088 |
|    clip_fraction        | 0.28      |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.9     |
|    explained_variance   | 0.411     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.426     |
|    n_updates            | 660       |
|    policy_gradient_loss | -0.0156   |
|    std                  | 0.943     |
|    value_loss           | 1.57      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -745        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37749       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.024294509 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.69        |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00972    |
|    std                  | 0.939       |
|    value_loss           | 1.38        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-98.25 +/- 1.62
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.2      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.03409341 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.688      |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.937      |
|    value_loss           | 1.57       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -745     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39759    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -745        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39968       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.022855338 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.000849    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+03    |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00343    |
|    std                  | 0.936       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -735       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 71         |
|    time_elapsed         | 40176      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.03257767 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.0587    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.83       |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.00975   |
|    std                  | 0.936      |
|    value_loss           | 1.68       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -725        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40384       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.027269922 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.524       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32        |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.937       |
|    value_loss           | 2.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -725        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40592       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.040281683 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.851       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00866    |
|    std                  | 0.938       |
|    value_loss           | 1.51        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.75 +/- 0.21
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 150000    |
| train/                  |           |
|    approx_kl            | 0.0373358 |
|    clip_fraction        | 0.314     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.8     |
|    explained_variance   | 0.437     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.693     |
|    n_updates            | 730       |
|    policy_gradient_loss | -0.00978  |
|    std                  | 0.931     |
|    value_loss           | 1.4       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -726     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42600    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -717        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42808       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.018601567 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00459     |
|    learning_rate        | 0.0003      |
|    loss                 | 852         |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00545    |
|    std                  | 0.93        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -717        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 43017       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.035946418 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.164      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61        |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.92        |
|    value_loss           | 3.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -707        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 43225       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.035665113 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.765       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0085     |
|    std                  | 0.914       |
|    value_loss           | 1.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -707        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43433       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.034321733 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.585       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.911       |
|    value_loss           | 1.35        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.58 +/- 0.07
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.032132786 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.913       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0022     |
|    std                  | 0.911       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.27e+03 |
|    ep_rew_mean     | -708     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45442    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -699        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45651       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.029455895 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00471    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.78        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00335    |
|    std                  | 0.912       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -699        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45859       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.031967025 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.281      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.477       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00586    |
|    std                  | 0.913       |
|    value_loss           | 1.68        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.28e+03   |
|    ep_rew_mean          | -691       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 82         |
|    time_elapsed         | 46068      |
|    total_timesteps      | 167936     |
| train/                  |            |
|    approx_kl            | 0.03863117 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 810        |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.914      |
|    value_loss           | 1.25       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -691        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 46278       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.021124788 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.999       |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00872    |
|    std                  | 0.911       |
|    value_loss           | 1.97        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.20 +/- 0.39
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.2      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.03965185 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.758      |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.00881   |
|    std                  | 0.908      |
|    value_loss           | 1.36       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.27e+03 |
|    ep_rew_mean     | -691     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 48288    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -682        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48496       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.040789694 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0019      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00371    |
|    std                  | 0.904       |
|    value_loss           | 922         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -682        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48704       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.031829573 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.196       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00477    |
|    std                  | 0.902       |
|    value_loss           | 1.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -673        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48912       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.035214834 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.505       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.658       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00451    |
|    std                  | 0.905       |
|    value_loss           | 1.73        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.40 +/- 0.50
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.04146106 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.635      |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.00586   |
|    std                  | 0.902      |
|    value_loss           | 1.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.27e+03 |
|    ep_rew_mean     | -672     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50921    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -672        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 51129       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.025455855 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00179    |
|    learning_rate        | 0.0003      |
|    loss                 | 236         |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00483    |
|    std                  | 0.902       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -664        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 51337       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.035309922 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00776    |
|    std                  | 0.896       |
|    value_loss           | 1.79        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -664        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51545       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.051749483 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.57        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.423       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00596    |
|    std                  | 0.893       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -654        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51754       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.058590062 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.685       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.894       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.48 +/- 0.20
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.049036846 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.633       |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00775    |
|    std                  | 0.894       |
|    value_loss           | 1.39        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.28e+03 |
|    ep_rew_mean     | -654     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53763    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -654        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53973       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.039032064 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.000403   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57e+03    |
|    n_updates            | 930         |
|    policy_gradient_loss | 0.00121     |
|    std                  | 0.893       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -645        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 54181       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.037725165 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0139     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.628       |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00203    |
|    std                  | 0.895       |
|    value_loss           | 1.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -645        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 54389       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.032270506 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.53        |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.895       |
|    value_loss           | 1.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -638        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54598       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.035068102 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.526       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.532       |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.00793    |
|    std                  | 0.898       |
|    value_loss           | 1.16        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.53 +/- 0.11
Episode length: 3598.00 +/- 4.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.030449465 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.816       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0093     |
|    std                  | 0.892       |
|    value_loss           | 2.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.28e+03 |
|    ep_rew_mean     | -637     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56607    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -637        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56815       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.040453106 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00346     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.31e+03    |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00266    |
|    std                  | 0.892       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -630        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 57023       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.043636367 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.324      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.787       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00902    |
|    std                  | 0.892       |
|    value_loss           | 1.72        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.28e+03   |
|    ep_rew_mean          | -630       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 101        |
|    time_elapsed         | 57231      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.03224123 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.46       |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.00492   |
|    std                  | 0.89       |
|    value_loss           | 1.29       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -622        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57439       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.035475515 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.407       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.751       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00832    |
|    std                  | 0.888       |
|    value_loss           | 1.61        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.37 +/- 0.18
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.03660869 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.13       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.721      |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.884      |
|    value_loss           | 2.22       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.28e+03 |
|    ep_rew_mean     | -622     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59449    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -622        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59657       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.031019874 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00178     |
|    learning_rate        | 0.0003      |
|    loss                 | 51.6        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00374    |
|    std                  | 0.883       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -614        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59865       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.046535194 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.156      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.429       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00558    |
|    std                  | 0.886       |
|    value_loss           | 1.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -606        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 60074       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.054664694 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.6         |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00924    |
|    std                  | 0.884       |
|    value_loss           | 1.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -606        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 60282       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.045935478 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.488       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00844    |
|    std                  | 0.882       |
|    value_loss           | 1.16        |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.52 +/- 0.10
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.05103996 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.00565   |
|    std                  | 0.877      |
|    value_loss           | 1.27       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.28e+03 |
|    ep_rew_mean     | -605     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 62291    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -605        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62498       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.019371964 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00104    |
|    learning_rate        | 0.0003      |
|    loss                 | 60.5        |
|    n_updates            | 1080        |
|    policy_gradient_loss | 0.000155    |
|    std                  | 0.878       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -597       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 62706      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.04604447 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.379      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.43       |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.00466   |
|    std                  | 0.879      |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -589       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 111        |
|    time_elapsed         | 62914      |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.06777689 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.566      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.783      |
|    n_updates            | 1100       |
|    policy_gradient_loss | 0.00587    |
|    std                  | 0.876      |
|    value_loss           | 0.911      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -589       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 63122      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.06821403 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.481      |
|    n_updates            | 1110       |
|    policy_gradient_loss | -0.00272   |
|    std                  | 0.872      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.29 +/- 0.44
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.06207093 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.00497   |
|    std                  | 0.875      |
|    value_loss           | 0.95       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.29e+03 |
|    ep_rew_mean     | -588     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 65130    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -588        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 65339       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.026427077 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00549     |
|    learning_rate        | 0.0003      |
|    loss                 | 197         |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00504    |
|    std                  | 0.875       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -580       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 115        |
|    time_elapsed         | 65547      |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.04555303 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.21       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.651      |
|    n_updates            | 1140       |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.873      |
|    value_loss           | 1.59       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -573        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65756       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.046271134 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.423       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.874       |
|    value_loss           | 1.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -573        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65964       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.049780935 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.423       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00624    |
|    std                  | 0.875       |
|    value_loss           | 1.03        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.58 +/- 0.22
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.056624632 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.837       |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00564    |
|    std                  | 0.871       |
|    value_loss           | 1.1         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.29e+03 |
|    ep_rew_mean     | -572     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67972    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -564        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 68180       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.051457167 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00166     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.31e+03    |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00179    |
|    std                  | 0.871       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -564       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 120        |
|    time_elapsed         | 68388      |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.05830681 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.253      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.658      |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.00493   |
|    std                  | 0.869      |
|    value_loss           | 1.17       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -557       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 121        |
|    time_elapsed         | 68596      |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.06864396 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.74       |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.00998   |
|    std                  | 0.869      |
|    value_loss           | 1.27       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -557       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 122        |
|    time_elapsed         | 68803      |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.07094593 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.537      |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.00941   |
|    std                  | 0.867      |
|    value_loss           | 1.01       |
----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.52 +/- 0.15
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.033604767 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.296       |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00307    |
|    std                  | 0.864       |
|    value_loss           | 0.954       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.29e+03 |
|    ep_rew_mean     | -557     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70811    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -549        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 71019       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.034220412 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00505     |
|    learning_rate        | 0.0003      |
|    loss                 | 18.3        |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00446    |
|    std                  | 0.863       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -549       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 125        |
|    time_elapsed         | 71226      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.13922381 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.335      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.497      |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.000372  |
|    std                  | 0.862      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.3e+03   |
|    ep_rew_mean          | -542      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 126       |
|    time_elapsed         | 71434     |
|    total_timesteps      | 258048    |
| train/                  |           |
|    approx_kl            | 0.0398025 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.1     |
|    explained_variance   | 0.608     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.515     |
|    n_updates            | 1250      |
|    policy_gradient_loss | -0.00447  |
|    std                  | 0.857     |
|    value_loss           | 0.992     |
---------------------------------------
Eval num_timesteps=260000, episode_reward=-99.55 +/- 0.17
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.045821078 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.908       |
|    n_updates            | 1260        |
|    policy_gradient_loss | 3.72e-07    |
|    std                  | 0.853       |
|    value_loss           | 1.32        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.29e+03 |
|    ep_rew_mean     | -541     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 73442    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -541       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 128        |
|    time_elapsed         | 73651      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.03381422 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 5.35e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 117        |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.00298   |
|    std                  | 0.853      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -534       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 73859      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.08192015 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.0376    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.597      |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.00839   |
|    std                  | 0.852      |
|    value_loss           | 1.37       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.29e+03  |
|    ep_rew_mean          | -534      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 130       |
|    time_elapsed         | 74067     |
|    total_timesteps      | 266240    |
| train/                  |           |
|    approx_kl            | 0.0464549 |
|    clip_fraction        | 0.353     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10       |
|    explained_variance   | 0.596     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.547     |
|    n_updates            | 1290      |
|    policy_gradient_loss | -0.00668  |
|    std                  | 0.848     |
|    value_loss           | 1.03      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -526       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 131        |
|    time_elapsed         | 74274      |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.05136448 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.566      |
|    n_updates            | 1300       |
|    policy_gradient_loss | 0.00484    |
|    std                  | 0.847      |
|    value_loss           | 1.02       |
----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.37 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.031070659 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.527       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00528    |
|    std                  | 0.846       |
|    value_loss           | 1.25        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.29e+03 |
|    ep_rew_mean     | -525     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 76282    |
|    total_timesteps | 270336   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.29e+03   |
|    ep_rew_mean          | -525       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 133        |
|    time_elapsed         | 76490      |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.03284715 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.99      |
|    explained_variance   | -0.000366  |
|    learning_rate        | 0.0003     |
|    loss                 | 122        |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.00626   |
|    std                  | 0.845      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -518       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76698      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.05471677 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | 0.163      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.499      |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.00555   |
|    std                  | 0.841      |
|    value_loss           | 1.24       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -518        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76905       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.035175472 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00304    |
|    std                  | 0.839       |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -512        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 77113       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.059820745 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.00109     |
|    std                  | 0.835       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.13 +/- 0.47
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.07330482 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.42       |
|    n_updates            | 1360       |
|    policy_gradient_loss | 0.00291    |
|    std                  | 0.835      |
|    value_loss           | 1.04       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.29e+03 |
|    ep_rew_mean     | -511     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 79121    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -511        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 79329       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.025503162 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | -0.000232   |
|    learning_rate        | 0.0003      |
|    loss                 | 55.2        |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00141    |
|    std                  | 0.835       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -504       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 139        |
|    time_elapsed         | 79537      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.14280763 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.298      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.449      |
|    n_updates            | 1380       |
|    policy_gradient_loss | 0.00465    |
|    std                  | 0.836      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -504       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 140        |
|    time_elapsed         | 79745      |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.05549833 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.89      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.696      |
|    n_updates            | 1390       |
|    policy_gradient_loss | 0.0028     |
|    std                  | 0.834      |
|    value_loss           | 1.18       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -497       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 79953      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.03587612 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.89      |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.00166   |
|    std                  | 0.833      |
|    value_loss           | 0.877      |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.22 +/- 0.47
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.2       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.095415674 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.615       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.422       |
|    n_updates            | 1410        |
|    policy_gradient_loss | 0.000712    |
|    std                  | 0.834       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -496     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81961    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -496        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 82168       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.059767358 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.00337    |
|    learning_rate        | 0.0003      |
|    loss                 | 64          |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00304    |
|    std                  | 0.834       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -490       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 82376      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.04563152 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.86      |
|    explained_variance   | -0.0859    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.569      |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.00144   |
|    std                  | 0.83       |
|    value_loss           | 1.53       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -490        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82583       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.037432335 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.638       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.601       |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.00408     |
|    std                  | 0.827       |
|    value_loss           | 1.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -484        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82790       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.058778487 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.674       |
|    n_updates            | 1450        |
|    policy_gradient_loss | 0.00301     |
|    std                  | 0.825       |
|    value_loss           | 0.94        |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.44 +/- 0.11
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.03793507 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.527      |
|    n_updates            | 1460       |
|    policy_gradient_loss | 0.00312    |
|    std                  | 0.824      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -483     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84798    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -483        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 85005       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.040232867 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -5.81e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8e+03     |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00145    |
|    std                  | 0.822       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -477       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 149        |
|    time_elapsed         | 85212      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.08659301 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.78      |
|    explained_variance   | 0.0796     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.659      |
|    n_updates            | 1480       |
|    policy_gradient_loss | 0.0017     |
|    std                  | 0.821      |
|    value_loss           | 1.38       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -471       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 150        |
|    time_elapsed         | 85420      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.09731463 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.657      |
|    n_updates            | 1490       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.816      |
|    value_loss           | 1.06       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -471        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 85629       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.038817357 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.57        |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.00354     |
|    std                  | 0.815       |
|    value_loss           | 0.992       |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.53 +/- 0.15
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.066112936 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.589       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.562       |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.000262    |
|    std                  | 0.813       |
|    value_loss           | 1.34        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -470     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87636    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -470       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 153        |
|    time_elapsed         | 87843      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.03332021 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.68      |
|    explained_variance   | 0.000374   |
|    learning_rate        | 0.0003     |
|    loss                 | 306        |
|    n_updates            | 1520       |
|    policy_gradient_loss | 0.000539   |
|    std                  | 0.812      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -464       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 88050      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.15118901 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.65      |
|    explained_variance   | 0.394      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.81       |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.00704    |
|    std                  | 0.807      |
|    value_loss           | 1.07       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -457        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 88258       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.039308384 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | 0.668       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.293       |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.000291   |
|    std                  | 0.804       |
|    value_loss           | 0.825       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -457        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 88465       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.055944204 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.648       |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00353    |
|    std                  | 0.8         |
|    value_loss           | 0.947       |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.54 +/- 0.12
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.05591748 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.56      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.641      |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.00471   |
|    std                  | 0.801      |
|    value_loss           | 1.54       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -457     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 90473    |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -451       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 158        |
|    time_elapsed         | 90681      |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.11569494 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.57      |
|    explained_variance   | -0.00217   |
|    learning_rate        | 0.0003     |
|    loss                 | 735        |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.000449  |
|    std                  | 0.801      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -451       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 159        |
|    time_elapsed         | 90888      |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.06502276 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.53      |
|    explained_variance   | 0.168      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.00115   |
|    std                  | 0.797      |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -444       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 160        |
|    time_elapsed         | 91095      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.16923161 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.325      |
|    n_updates            | 1590       |
|    policy_gradient_loss | 0.0032     |
|    std                  | 0.792      |
|    value_loss           | 0.959      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -444        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 91303       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.076029435 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | 0.697       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.357       |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00133    |
|    std                  | 0.786       |
|    value_loss           | 0.696       |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.40 +/- 0.14
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.06092457 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.41      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.4        |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.00301   |
|    std                  | 0.785      |
|    value_loss           | 0.928      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -443     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 93311    |
|    total_timesteps | 331776   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.3e+03   |
|    ep_rew_mean          | -428      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 163       |
|    time_elapsed         | 93519     |
|    total_timesteps      | 333824    |
| train/                  |           |
|    approx_kl            | 0.0684319 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.4      |
|    explained_variance   | -0.001    |
|    learning_rate        | 0.0003    |
|    loss                 | 39.9      |
|    n_updates            | 1620      |
|    policy_gradient_loss | -0.00144  |
|    std                  | 0.784     |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -428        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93727       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.054489635 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.538       |
|    n_updates            | 1630        |
|    policy_gradient_loss | 0.00507     |
|    std                  | 0.783       |
|    value_loss           | 1.26        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -415       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 165        |
|    time_elapsed         | 93936      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.06834731 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.38      |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.414      |
|    n_updates            | 1640       |
|    policy_gradient_loss | 0.00065    |
|    std                  | 0.782      |
|    value_loss           | 1.01       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -415        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 94144       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.055970546 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.35       |
|    explained_variance   | 0.544       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.633       |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.00176    |
|    std                  | 0.778       |
|    value_loss           | 1.28        |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.50 +/- 0.16
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.058246344 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.644       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.903       |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.00284    |
|    std                  | 0.777       |
|    value_loss           | 1.56        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -404     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 96152    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -392       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 168        |
|    time_elapsed         | 96360      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.05937192 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.32      |
|    explained_variance   | -0.00216   |
|    learning_rate        | 0.0003     |
|    loss                 | 646        |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.000775   |
|    std                  | 0.778      |
|    value_loss           | 1.03e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -392       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 169        |
|    time_elapsed         | 96567      |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.06682536 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.35      |
|    explained_variance   | 0.311      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.678      |
|    n_updates            | 1680       |
|    policy_gradient_loss | 0.00592    |
|    std                  | 0.781      |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -381       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 96775      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.06869528 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.462      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.00809    |
|    std                  | 0.778      |
|    value_loss           | 0.875      |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.63 +/- 0.07
Episode length: 3597.20 +/- 7.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.048144117 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | 0.636       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.347       |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.0337      |
|    std                  | 0.772       |
|    value_loss           | 0.845       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -375     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98784    |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -375       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 172        |
|    time_elapsed         | 98991      |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.05925081 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.27      |
|    explained_variance   | -0.000768  |
|    learning_rate        | 0.0003     |
|    loss                 | 149        |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.00105   |
|    std                  | 0.772      |
|    value_loss           | 1.03e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -368       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 173        |
|    time_elapsed         | 99198      |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.07020506 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.29      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.704      |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0019    |
|    std                  | 0.775      |
|    value_loss           | 1.35       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -368       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 99406      |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.07114432 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.528      |
|    n_updates            | 1730       |
|    policy_gradient_loss | 0.00462    |
|    std                  | 0.772      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -359       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 99613      |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.07503026 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.00293    |
|    std                  | 0.768      |
|    value_loss           | 0.988      |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.53 +/- 0.18
Episode length: 3599.40 +/- 1.96
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.037680797 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.622       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.549       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.00532     |
|    std                  | 0.768       |
|    value_loss           | 0.965       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -355     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101621   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -355        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101828      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.019267341 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | -0.00157    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+03    |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00248    |
|    std                  | 0.768       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | -341      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 178       |
|    time_elapsed         | 102035    |
|    total_timesteps      | 364544    |
| train/                  |           |
|    approx_kl            | 0.4692454 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.22     |
|    explained_variance   | 0.18      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.395     |
|    n_updates            | 1770      |
|    policy_gradient_loss | 0.000496  |
|    std                  | 0.768     |
|    value_loss           | 0.942     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -341        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 102242      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.056840796 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.596       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.627       |
|    n_updates            | 1780        |
|    policy_gradient_loss | 0.00371     |
|    std                  | 0.768       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -332        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 102452      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.066551924 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.552       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.872       |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00202    |
|    std                  | 0.769       |
|    value_loss           | 1.42        |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.57 +/- 0.15
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.061783515 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.497       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.00753     |
|    std                  | 0.767       |
|    value_loss           | 0.964       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -328     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 104459   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -328        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104666      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.036969304 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.00292     |
|    learning_rate        | 0.0003      |
|    loss                 | 38.6        |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00207    |
|    std                  | 0.767       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -315       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 183        |
|    time_elapsed         | 104874     |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.07093715 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.2       |
|    explained_variance   | 0.271      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.00628    |
|    std                  | 0.765      |
|    value_loss           | 0.963      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -315       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 105081     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.15070115 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.362      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.766      |
|    value_loss           | 0.836      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -305        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 105288      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.062106382 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.335       |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.00545     |
|    std                  | 0.764       |
|    value_loss           | 0.746       |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.63 +/- 0.12
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.05058143 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.256      |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.00218   |
|    std                  | 0.765      |
|    value_loss           | 0.638      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -302     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 107296   |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -302       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 187        |
|    time_elapsed         | 107503     |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.04249362 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | -0.00356   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.86e+03   |
|    n_updates            | 1860       |
|    policy_gradient_loss | 0.000926   |
|    std                  | 0.765      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -289       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 107710     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.06755181 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | 0.206      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.855      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.00843    |
|    std                  | 0.763      |
|    value_loss           | 1.37       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -289        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107918      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.058960937 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.00361     |
|    std                  | 0.761       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -280        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 190         |
|    time_elapsed         | 108125      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.052702628 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.16       |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.853       |
|    n_updates            | 1890        |
|    policy_gradient_loss | 0.0036      |
|    std                  | 0.763       |
|    value_loss           | 1.12        |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.46 +/- 0.18
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.051383324 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.429       |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00834    |
|    std                  | 0.762       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -277     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 110133   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -277        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 110340      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.016642552 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.00173     |
|    learning_rate        | 0.0003      |
|    loss                 | 802         |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00407    |
|    std                  | 0.762       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -264        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 110547      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.045133792 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.761       |
|    n_updates            | 1920        |
|    policy_gradient_loss | 0.0018      |
|    std                  | 0.76        |
|    value_loss           | 1.37        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110755      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.052191682 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | 0.562       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.491       |
|    n_updates            | 1930        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.755       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110962      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.042744696 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.483       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.00835     |
|    std                  | 0.752       |
|    value_loss           | 1.54        |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.38 +/- 0.09
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.040417224 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.557       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.619       |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.00213    |
|    std                  | 0.75        |
|    value_loss           | 0.998       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -253     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112970   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -253       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 113177     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.09639359 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.02      |
|    explained_variance   | -0.00281   |
|    learning_rate        | 0.0003     |
|    loss                 | 291        |
|    n_updates            | 1960       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.75       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 113384      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.063610636 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.476       |
|    n_updates            | 1970        |
|    policy_gradient_loss | 0.00488     |
|    std                  | 0.751       |
|    value_loss           | 1.07        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -232       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 113593     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.05834438 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.05      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.488      |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.000449  |
|    std                  | 0.754      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -232        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 200         |
|    time_elapsed         | 113800      |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.042083338 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.372       |
|    n_updates            | 1990        |
|    policy_gradient_loss | 0.00151     |
|    std                  | 0.751       |
|    value_loss           | 0.837       |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.54 +/- 0.13
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.05528713 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.4        |
|    n_updates            | 2000       |
|    policy_gradient_loss | 0.00253    |
|    std                  | 0.753      |
|    value_loss           | 0.84       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -230     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115807   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -218       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 116014     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.18716641 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | -0.00192   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.84e+03   |
|    n_updates            | 2010       |
|    policy_gradient_loss | 2.09e-05   |
|    std                  | 0.753      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -218       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 116221     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.10624759 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.00747    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.326      |
|    n_updates            | 2020       |
|    policy_gradient_loss | 0.00473    |
|    std                  | 0.753      |
|    value_loss           | 1.05       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -211       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 116428     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.04629157 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.641      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.401      |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.000388   |
|    std                  | 0.751      |
|    value_loss           | 0.832      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -211        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 116636      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.069929525 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.313       |
|    n_updates            | 2040        |
|    policy_gradient_loss | 0.00347     |
|    std                  | 0.748       |
|    value_loss           | 0.801       |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.33 +/- 0.09
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.05143603 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.433      |
|    n_updates            | 2050       |
|    policy_gradient_loss | 0.00144    |
|    std                  | 0.744      |
|    value_loss           | 0.967      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -208     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118643   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -197        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118850      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.048902795 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.00224     |
|    learning_rate        | 0.0003      |
|    loss                 | 104         |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00199    |
|    std                  | 0.745       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -197        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 208         |
|    time_elapsed         | 119057      |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.056938544 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.743       |
|    n_updates            | 2070        |
|    policy_gradient_loss | 0.00562     |
|    std                  | 0.74        |
|    value_loss           | 1.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -190        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 119265      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.047006838 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.532       |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.00594     |
|    std                  | 0.74        |
|    value_loss           | 1.11        |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.52 +/- 0.15
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.048290446 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.562       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.00313     |
|    std                  | 0.739       |
|    value_loss           | 1.04        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -188     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 121273   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -188       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 211        |
|    time_elapsed         | 121482     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.11483137 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | -0.000718  |
|    learning_rate        | 0.0003     |
|    loss                 | 25.8       |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.00118   |
|    std                  | 0.739      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -177        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121689      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.056986075 |
|    clip_fraction        | 0.465       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | -0.137      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.74        |
|    value_loss           | 1.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -177        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121896      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.072514884 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.596       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.267       |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.000943    |
|    std                  | 0.741       |
|    value_loss           | 1.17        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -169       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 122103     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.06948447 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.743      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.00482    |
|    std                  | 0.742      |
|    value_loss           | 1.36       |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.17 +/- 0.38
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.2       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.049500935 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.364       |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.00383    |
|    std                  | 0.741       |
|    value_loss           | 0.994       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -167     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 124111   |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -167       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 216        |
|    time_elapsed         | 124319     |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.05575943 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.0056     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.33       |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0033    |
|    std                  | 0.741      |
|    value_loss           | 1.03e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -156       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 217        |
|    time_elapsed         | 124526     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.44907686 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.207      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.528      |
|    n_updates            | 2160       |
|    policy_gradient_loss | 0.00674    |
|    std                  | 0.743      |
|    value_loss           | 1.33       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -156       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 124734     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.05482532 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.93      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.416      |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.00383   |
|    std                  | 0.742      |
|    value_loss           | 1.52       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -150        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124941      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.065320164 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.497       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.587       |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.00112    |
|    std                  | 0.737       |
|    value_loss           | 1.34        |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.09 +/- 0.46
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.1       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.053877056 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.605       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.385       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.00342     |
|    std                  | 0.733       |
|    value_loss           | 0.94        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -148     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126951   |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -148       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 221        |
|    time_elapsed         | 127159     |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.05669826 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.83      |
|    explained_variance   | 0.00319    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.91       |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.000585  |
|    std                  | 0.734      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -138        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 127367      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.085359074 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.81       |
|    explained_variance   | 0.103       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.508       |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.000572   |
|    std                  | 0.73        |
|    value_loss           | 1.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -138        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 127574      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.042672537 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.484       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.669       |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.00278     |
|    std                  | 0.728       |
|    value_loss           | 1.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127781      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.054827925 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.608       |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.00241     |
|    std                  | 0.728       |
|    value_loss           | 1.57        |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-98.21 +/- 0.83
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.2       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.047443904 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.74       |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.527       |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.00202    |
|    std                  | 0.723       |
|    value_loss           | 1.22        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -132     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129788   |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -132       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 226        |
|    time_elapsed         | 129996     |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.06709123 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.71      |
|    explained_variance   | 0.00539    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.78       |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.000743  |
|    std                  | 0.723      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -121       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 130203     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.13107818 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | -0.0201    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.765      |
|    n_updates            | 2260       |
|    policy_gradient_loss | -0.00365   |
|    std                  | 0.716      |
|    value_loss           | 1.46       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -121        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 130411      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.040231302 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.611       |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.00307     |
|    std                  | 0.709       |
|    value_loss           | 1.43        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -115       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 130619     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.06796294 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.57      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.685      |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.00378   |
|    std                  | 0.711      |
|    value_loss           | 1.08       |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-98.71 +/- 1.20
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.7      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.05753915 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.54      |
|    explained_variance   | 0.376      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.615      |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.00551   |
|    std                  | 0.706      |
|    value_loss           | 1.43       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -116     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 132626   |
|    total_timesteps | 471040   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | -116      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 231       |
|    time_elapsed         | 132833    |
|    total_timesteps      | 473088    |
| train/                  |           |
|    approx_kl            | 0.0385452 |
|    clip_fraction        | 0.299     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.52     |
|    explained_variance   | -0.00376  |
|    learning_rate        | 0.0003    |
|    loss                 | 149       |
|    n_updates            | 2300      |
|    policy_gradient_loss | 0.00232   |
|    std                  | 0.706     |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -105        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 232         |
|    time_elapsed         | 133040      |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.046367183 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | 0.0133      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.757       |
|    n_updates            | 2310        |
|    policy_gradient_loss | 0.00507     |
|    std                  | 0.709       |
|    value_loss           | 1.07        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -99.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 133249     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.07676403 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.54      |
|    explained_variance   | 0.422      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.527      |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.000137  |
|    std                  | 0.707      |
|    value_loss           | 1.31       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -99.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 234         |
|    time_elapsed         | 133456      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.054791346 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.382       |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.00161    |
|    std                  | 0.704       |
|    value_loss           | 0.935       |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-98.33 +/- 1.08
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.3       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.045797158 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.425       |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.000253    |
|    std                  | 0.7         |
|    value_loss           | 0.786       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -99.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 135463   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -99.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 135670      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.032609403 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | 0.00442     |
|    learning_rate        | 0.0003      |
|    loss                 | 190         |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00273    |
|    std                  | 0.7         |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -89.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 135878     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.08815801 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | -0.129     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.335      |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.00216   |
|    std                  | 0.698      |
|    value_loss           | 1.21       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -84.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 136086      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.047380224 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.00026    |
|    std                  | 0.696       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -84.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 239         |
|    time_elapsed         | 136293      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.056491036 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.373       |
|    n_updates            | 2380        |
|    policy_gradient_loss | 0.000696    |
|    std                  | 0.692       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-98.39 +/- 0.68
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -98.4     |
| time/                   |           |
|    total_timesteps      | 490000    |
| train/                  |           |
|    approx_kl            | 0.0506555 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.32     |
|    explained_variance   | 0.514     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.467     |
|    n_updates            | 2390      |
|    policy_gradient_loss | 0.00619   |
|    std                  | 0.688     |
|    value_loss           | 1.01      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -85      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 138301   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -75.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 241         |
|    time_elapsed         | 138509      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.078442894 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.000208    |
|    learning_rate        | 0.0003      |
|    loss                 | 322         |
|    n_updates            | 2400        |
|    policy_gradient_loss | 0.00462     |
|    std                  | 0.685       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -75.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 138717     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.12287788 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | 0.12       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.478      |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.00239    |
|    std                  | 0.686      |
|    value_loss           | 1.2        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -69.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 138925     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.05240378 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.26      |
|    explained_variance   | 0.439      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.43       |
|    n_updates            | 2420       |
|    policy_gradient_loss | 0.00392    |
|    std                  | 0.681      |
|    value_loss           | 1.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -69.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 139132      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.047476754 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.489       |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.00266    |
|    std                  | 0.68        |
|    value_loss           | 0.96        |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-98.99 +/- 0.50
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99         |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.064441055 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.492       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.453       |
|    n_updates            | 2440        |
|    policy_gradient_loss | 0.00565     |
|    std                  | 0.676       |
|    value_loss           | 0.901       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -69.7    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 141140   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -59.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 141347      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.041455753 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.17       |
|    explained_variance   | -0.00142    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.55        |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00401    |
|    std                  | 0.676       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -59.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 141555     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.06953986 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.194      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.641      |
|    n_updates            | 2460       |
|    policy_gradient_loss | 0.00381    |
|    std                  | 0.675      |
|    value_loss           | 1.21       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -55         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 141762      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.062523454 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.595       |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.677       |
|    value_loss           | 1.02        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -55         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141970      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.073991075 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.621       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.00262     |
|    std                  | 0.678       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-97.49 +/- 0.88
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -97.5       |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.053289793 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.476       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.559       |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.00294     |
|    std                  | 0.677       |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -55.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143978   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -46.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 144185     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.06100037 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | -0.00204   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.87       |
|    n_updates            | 2500       |
|    policy_gradient_loss | 0.00666    |
|    std                  | 0.677      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -46.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 144392     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.06743501 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.18      |
|    explained_variance   | 0.0785     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 2510       |
|    policy_gradient_loss | 0.00382    |
|    std                  | 0.676      |
|    value_loss           | 1.18       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -41.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 144599     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.10701694 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.396      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.64       |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.00658    |
|    std                  | 0.675      |
|    value_loss           | 1.25       |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.39 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.045853987 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.587       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.00192    |
|    std                  | 0.675       |
|    value_loss           | 1.3         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -42.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 146608   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -42.9       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146814      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.106535226 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.00338     |
|    learning_rate        | 0.0003      |
|    loss                 | 57.6        |
|    n_updates            | 2540        |
|    policy_gradient_loss | 0.00112     |
|    std                  | 0.675       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -33.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 147021     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.08696325 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.167      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 2550       |
|    policy_gradient_loss | 0.00507    |
|    std                  | 0.677      |
|    value_loss           | 1.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -33.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 147228     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.06271117 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.15      |
|    explained_variance   | 0.461      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.499      |
|    n_updates            | 2560       |
|    policy_gradient_loss | 0.00242    |
|    std                  | 0.672      |
|    value_loss           | 1.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -29.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 147435     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.06018781 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.11      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.545      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.00121    |
|    std                  | 0.669      |
|    value_loss           | 0.977      |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.39 +/- 0.13
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.09007734 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.481      |
|    n_updates            | 2580       |
|    policy_gradient_loss | 5.12e-05   |
|    std                  | 0.664      |
|    value_loss           | 0.786      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -29.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 149443   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -29.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 149650     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.12676252 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.04      |
|    explained_variance   | -0.00126   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.58e+03   |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.00241   |
|    std                  | 0.665      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -20.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 149857     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.07779286 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.07      |
|    explained_variance   | 0.0693     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.399      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.00902    |
|    std                  | 0.669      |
|    value_loss           | 1.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -20.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 262        |
|    time_elapsed         | 150065     |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.07631506 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.308      |
|    n_updates            | 2610       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.669      |
|    value_loss           | 0.96       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -15.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 150272      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.046709616 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.06       |
|    explained_variance   | 0.506       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.466       |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.0094      |
|    std                  | 0.666       |
|    value_loss           | 1.07        |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.44 +/- 0.10
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.061570205 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.535       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.00666     |
|    std                  | 0.664       |
|    value_loss           | 1.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -16.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 152279   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -16.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 152486      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.059205547 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.03       |
|    explained_variance   | -0.0033     |
|    learning_rate        | 0.0003      |
|    loss                 | 162         |
|    n_updates            | 2640        |
|    policy_gradient_loss | 0.00159     |
|    std                  | 0.665       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -6.67      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 152695     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.26893476 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | -0.075     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.663      |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -6.67       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 152902      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.051206518 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.01       |
|    explained_variance   | 0.456       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.505       |
|    n_updates            | 2660        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.663       |
|    value_loss           | 1.06        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -1.93      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 153109     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.08592528 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.369      |
|    n_updates            | 2670       |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.66       |
|    value_loss           | 0.796      |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-98.91 +/- 0.80
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.9      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.06010749 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.762      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.654      |
|    value_loss           | 1.05       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -3.31    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 155117   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -3.31      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 270        |
|    time_elapsed         | 155324     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.03859847 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.00518    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.74       |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.00348   |
|    std                  | 0.654      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 4.88       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 155531     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.40912962 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.205      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.492      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0075     |
|    std                  | 0.652      |
|    value_loss           | 1.12       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 4.88        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 155738      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.057030983 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.526       |
|    n_updates            | 2710        |
|    policy_gradient_loss | 0.00386     |
|    std                  | 0.651       |
|    value_loss           | 1.6         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 8.02       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 155946     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.06524695 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.285      |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.646      |
|    value_loss           | 0.837      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.11 +/- 0.49
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.1       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.061151084 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.81       |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.583       |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.000863   |
|    std                  | 0.648       |
|    value_loss           | 1.5         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 5.67     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157955   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 5.67        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 158162      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.027963853 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | 0.00768     |
|    learning_rate        | 0.0003      |
|    loss                 | 60.2        |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00381    |
|    std                  | 0.648       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 14.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 158369     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.09004435 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.81      |
|    explained_variance   | 0.00125    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.614      |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.646      |
|    value_loss           | 1.25       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 18.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 158576     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.06322062 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.79      |
|    explained_variance   | 0.519      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.589      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.00806    |
|    std                  | 0.644      |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 18.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 158782     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.09685497 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.77      |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.707      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.00892    |
|    std                  | 0.643      |
|    value_loss           | 1.38       |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-98.63 +/- 1.29
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.6       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.058348738 |
|    clip_fraction        | 0.448       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.77       |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.00543     |
|    std                  | 0.645       |
|    value_loss           | 0.924       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 16.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160790   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 16.4        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160998      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.026008602 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | -0.000139   |
|    learning_rate        | 0.0003      |
|    loss                 | 444         |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.00586    |
|    std                  | 0.644       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 25.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 161205     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.32573488 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.78      |
|    explained_variance   | -0.0962    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.433      |
|    n_updates            | 2800       |
|    policy_gradient_loss | 0.00846    |
|    std                  | 0.645      |
|    value_loss           | 0.982      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 28.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 161412     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.08076291 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.81      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.489      |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.648      |
|    value_loss           | 1.17       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 28.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 161618     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.27910924 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.79      |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.651      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.644      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.10 +/- 0.51
Episode length: 3600.20 +/- 0.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.15129182 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.581      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.0059     |
|    std                  | 0.641      |
|    value_loss           | 1.01       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 26.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 163626   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 35.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163832      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.061079934 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.73       |
|    explained_variance   | 0.00186     |
|    learning_rate        | 0.0003      |
|    loss                 | 60.5        |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.00216     |
|    std                  | 0.641       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 35.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 286         |
|    time_elapsed         | 164038      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.054888822 |
|    clip_fraction        | 0.454       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | 0.0928      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.358       |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.000391   |
|    std                  | 0.643       |
|    value_loss           | 1.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 38.3       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 164245     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.26843885 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.246      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.642      |
|    value_loss           | 0.774      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 38.3       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 164451     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.10659875 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.475      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.637      |
|    value_loss           | 1          |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.06 +/- 0.56
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.18740152 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.424      |
|    n_updates            | 2880       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.635      |
|    value_loss           | 0.972      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 36.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 166459   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 45.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 166666     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.07568046 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.65      |
|    explained_variance   | 0.00182    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.42e+03   |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.00153   |
|    std                  | 0.636      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 45.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166874     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.15749684 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | 0.299      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.633      |
|    value_loss           | 1.19       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 48.3      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 292       |
|    time_elapsed         | 167080    |
|    total_timesteps      | 598016    |
| train/                  |           |
|    approx_kl            | 0.1972343 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.63     |
|    explained_variance   | 0.568     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.552     |
|    n_updates            | 2910      |
|    policy_gradient_loss | 0.0235    |
|    std                  | 0.633     |
|    value_loss           | 0.925     |
---------------------------------------
Eval num_timesteps=600000, episode_reward=-99.30 +/- 0.08
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.3     |
| time/                   |           |
|    total_timesteps      | 600000    |
| train/                  |           |
|    approx_kl            | 0.2287935 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.63     |
|    explained_variance   | 0.595     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.342     |
|    n_updates            | 2920      |
|    policy_gradient_loss | 0.00995   |
|    std                  | 0.634     |
|    value_loss           | 0.915     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 45.5     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 169089   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 45.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 169296      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.022703841 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | 0.00234     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.95        |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.00246    |
|    std                  | 0.633       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 53.2      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 295       |
|    time_elapsed         | 169503    |
|    total_timesteps      | 604160    |
| train/                  |           |
|    approx_kl            | 0.7732725 |
|    clip_fraction        | 0.532     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.63     |
|    explained_variance   | -0.0224   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.337     |
|    n_updates            | 2940      |
|    policy_gradient_loss | 0.0023    |
|    std                  | 0.632     |
|    value_loss           | 0.872     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 53.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 169710     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.15421154 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.2        |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.633      |
|    value_loss           | 0.72       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 56.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 169917     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.14786054 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | 0.519      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.704      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.00814    |
|    std                  | 0.635      |
|    value_loss           | 1.12       |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.33 +/- 0.13
Episode length: 3599.20 +/- 2.23
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.29438594 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.36       |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.632      |
|    value_loss           | 0.769      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 53.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171924   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 53.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 172132     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.04631204 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.00309    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.45e+03   |
|    n_updates            | 2980       |
|    policy_gradient_loss | 0.00208    |
|    std                  | 0.633      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 61.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 300         |
|    time_elapsed         | 172339      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.105268195 |
|    clip_fraction        | 0.466       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | -0.115      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 2990        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.632       |
|    value_loss           | 1.05        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 61.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 172547     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.08036626 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.394      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.00774    |
|    std                  | 0.631      |
|    value_loss           | 1.35       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 63.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 172754     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.13918152 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 3010       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.627      |
|    value_loss           | 0.755      |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.50 +/- 0.10
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.06615871 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 3020       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.626      |
|    value_loss           | 0.724      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 60.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 174762   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 60.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 174968      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.048672058 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.56       |
|    explained_variance   | 0.00274     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.13        |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.00133    |
|    std                  | 0.627       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 68.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 305         |
|    time_elapsed         | 175175      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.095206246 |
|    clip_fraction        | 0.465       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.566       |
|    n_updates            | 3040        |
|    policy_gradient_loss | 0.0258      |
|    std                  | 0.628       |
|    value_loss           | 0.893       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 68.2      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 306       |
|    time_elapsed         | 175383    |
|    total_timesteps      | 626688    |
| train/                  |           |
|    approx_kl            | 0.1484502 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.59     |
|    explained_variance   | 0.891     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.404     |
|    n_updates            | 3050      |
|    policy_gradient_loss | 0.00243   |
|    std                  | 0.629     |
|    value_loss           | 1.76      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 69.8       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 175590     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.05463653 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.432      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.00962    |
|    std                  | 0.63       |
|    value_loss           | 0.923      |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.44 +/- 0.09
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.13649607 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.578      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.629      |
|    value_loss           | 0.965      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 66.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 177598   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 66.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 177805     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.08763589 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | -0.000396  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.65e+03   |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00745    |
|    std                  | 0.629      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 73.8       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 178012     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.11024213 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | -0.0412    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 3090       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.628      |
|    value_loss           | 1.21       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 73.8        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 178219      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.075815186 |
|    clip_fraction        | 0.444       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.56       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.358       |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.0211      |
|    std                  | 0.627       |
|    value_loss           | 0.892       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 76.9      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 312       |
|    time_elapsed         | 178426    |
|    total_timesteps      | 638976    |
| train/                  |           |
|    approx_kl            | 0.0847816 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.55     |
|    explained_variance   | 0.54      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.622     |
|    n_updates            | 3110      |
|    policy_gradient_loss | 0.021     |
|    std                  | 0.625     |
|    value_loss           | 1.05      |
---------------------------------------
Eval num_timesteps=640000, episode_reward=-99.51 +/- 0.21
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.10495933 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.675      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.627      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 73.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 180434   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 73.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 180641      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.083426476 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | -0.000748   |
|    learning_rate        | 0.0003      |
|    loss                 | 10.2        |
|    n_updates            | 3130        |
|    policy_gradient_loss | 0.00277     |
|    std                  | 0.628       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 81.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 315         |
|    time_elapsed         | 180848      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.082899615 |
|    clip_fraction        | 0.464       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.58       |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.509       |
|    n_updates            | 3140        |
|    policy_gradient_loss | 0.00719     |
|    std                  | 0.629       |
|    value_loss           | 1.05        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 83.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 181056     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.13744858 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.378      |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.00826    |
|    std                  | 0.629      |
|    value_loss           | 0.894      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 83.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 181263     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.23294613 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.509      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.628      |
|    value_loss           | 0.989      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.44 +/- 0.15
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.06943722 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.711      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.628      |
|    value_loss           | 1.19       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 80.1     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 183271   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 80.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 319        |
|    time_elapsed         | 183478     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.13897756 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | -0.00189   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18e+03   |
|    n_updates            | 3180       |
|    policy_gradient_loss | 0.00459    |
|    std                  | 0.628      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 87.6        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 320         |
|    time_elapsed         | 183686      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.118300624 |
|    clip_fraction        | 0.49        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.649       |
|    n_updates            | 3190        |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.632       |
|    value_loss           | 1.4         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 90         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 183893     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.08528182 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.43       |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.632      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 90         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 184101     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.31487042 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.322      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.629      |
|    value_loss           | 0.715      |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.53 +/- 0.11
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.25158453 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.29       |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.00779    |
|    std                  | 0.63       |
|    value_loss           | 0.775      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 86.1     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 186109   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 86.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 186316     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.10454465 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | -0.000739  |
|    learning_rate        | 0.0003     |
|    loss                 | 93.3       |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.00287    |
|    std                  | 0.631      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 94         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 186524     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.45006442 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | -0.234     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.46       |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.632      |
|    value_loss           | 1.44       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 96.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 186732     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.16443336 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.33       |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.00763    |
|    std                  | 0.628      |
|    value_loss           | 0.819      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 96.2      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 327       |
|    time_elapsed         | 186940    |
|    total_timesteps      | 669696    |
| train/                  |           |
|    approx_kl            | 0.0968367 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.58     |
|    explained_variance   | 0.598     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.488     |
|    n_updates            | 3260      |
|    policy_gradient_loss | 0.0166    |
|    std                  | 0.627     |
|    value_loss           | 1.03      |
---------------------------------------
Eval num_timesteps=670000, episode_reward=-99.56 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.063159965 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.375       |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.627       |
|    value_loss           | 0.854       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 92.9     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188948   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 100        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 189157     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.16515681 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | -0.00108   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.32       |
|    n_updates            | 3280       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.627      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 100        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 189365     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.13089848 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.316      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.501      |
|    n_updates            | 3290       |
|    policy_gradient_loss | 0.00976    |
|    std                  | 0.63       |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 102        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 189573     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.08034153 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.372      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.631      |
|    value_loss           | 0.888      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 102       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 332       |
|    time_elapsed         | 189780    |
|    total_timesteps      | 679936    |
| train/                  |           |
|    approx_kl            | 0.1959774 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.59     |
|    explained_variance   | 0.57      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.405     |
|    n_updates            | 3310      |
|    policy_gradient_loss | 0.0141    |
|    std                  | 0.628     |
|    value_loss           | 0.892     |
---------------------------------------
Eval num_timesteps=680000, episode_reward=-99.48 +/- 0.11
Episode length: 3599.40 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.06927337 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.723      |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.623      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 97.9     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 191788   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 106        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 191995     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.05181981 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | 0.00444    |
|    learning_rate        | 0.0003     |
|    loss                 | 287        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.00833    |
|    std                  | 0.623      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 106       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 335       |
|    time_elapsed         | 192203    |
|    total_timesteps      | 686080    |
| train/                  |           |
|    approx_kl            | 0.1910546 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.5      |
|    explained_variance   | -0.0924   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.507     |
|    n_updates            | 3340      |
|    policy_gradient_loss | 0.0138    |
|    std                  | 0.623     |
|    value_loss           | 0.92      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 107         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 336         |
|    time_elapsed         | 192410      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.108086154 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.656       |
|    n_updates            | 3350        |
|    policy_gradient_loss | 0.00664     |
|    std                  | 0.624       |
|    value_loss           | 0.898       |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.37 +/- 0.41
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.41147217 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.453      |
|    n_updates            | 3360       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.624      |
|    value_loss           | 1.05       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 104      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 194418   |
|    total_timesteps | 690176   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 104       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 338       |
|    time_elapsed         | 194625    |
|    total_timesteps      | 692224    |
| train/                  |           |
|    approx_kl            | 0.076804  |
|    clip_fraction        | 0.263     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.52     |
|    explained_variance   | 2.68e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 934       |
|    n_updates            | 3370      |
|    policy_gradient_loss | -0.000231 |
|    std                  | 0.625     |
|    value_loss           | 1.04e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 111         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 339         |
|    time_elapsed         | 194832      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.105109565 |
|    clip_fraction        | 0.501       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | -0.049      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 3380        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.624       |
|    value_loss           | 1.06        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 111        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 195039     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.08120802 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.49      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.62       |
|    value_loss           | 0.821      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 112        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 195246     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.10951688 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.545      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.568      |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.00802    |
|    std                  | 0.617      |
|    value_loss           | 1.05       |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.26 +/- 0.38
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.07484405 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.669      |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.00113   |
|    std                  | 0.617      |
|    value_loss           | 1.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 108      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 197254   |
|    total_timesteps | 700416   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 108       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 343       |
|    time_elapsed         | 197461    |
|    total_timesteps      | 702464    |
| train/                  |           |
|    approx_kl            | 0.0804296 |
|    clip_fraction        | 0.305     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.44     |
|    explained_variance   | -0.00302  |
|    learning_rate        | 0.0003    |
|    loss                 | 168       |
|    n_updates            | 3420      |
|    policy_gradient_loss | -0.0036   |
|    std                  | 0.618     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 115        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 197668     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.11926737 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.43      |
|    explained_variance   | 0.227      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.401      |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.616      |
|    value_loss           | 0.837      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 115        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 197875     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.11733715 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.473      |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.612      |
|    value_loss           | 0.953      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 117         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 198082      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.058052644 |
|    clip_fraction        | 0.444       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.611       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.48 +/- 0.03
Episode length: 3599.80 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.11370639 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.499      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.611      |
|    value_loss           | 0.793      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 113      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 200089   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 113         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 200296      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.046346914 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | 0.0032      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.93e+03    |
|    n_updates            | 3470        |
|    policy_gradient_loss | 0.00459     |
|    std                  | 0.611       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 120        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 349        |
|    time_elapsed         | 200503     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.22904629 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | 0.107      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.341      |
|    n_updates            | 3480       |
|    policy_gradient_loss | 0.00245    |
|    std                  | 0.609      |
|    value_loss           | 1.19       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 120        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 200710     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.07249224 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.489      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.477      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.61       |
|    value_loss           | 0.867      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 121        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 200917     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.06572033 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.388      |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.607      |
|    value_loss           | 0.817      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.28 +/- 0.32
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.065997586 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.536       |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.61        |
|    value_loss           | 1.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 117      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202926   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 117         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 203132      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.068003014 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.35       |
|    explained_variance   | -0.00599    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.55        |
|    n_updates            | 3520        |
|    policy_gradient_loss | 0.00216     |
|    std                  | 0.611       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 124       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 203341    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.3819235 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.34     |
|    explained_variance   | 0.0976    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.407     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.61      |
|    value_loss           | 1.24      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 124        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 203547     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.18623117 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.549      |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.611      |
|    value_loss           | 1.21       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 125       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 356       |
|    time_elapsed         | 203754    |
|    total_timesteps      | 729088    |
| train/                  |           |
|    approx_kl            | 0.0871937 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.36     |
|    explained_variance   | 0.58      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.493     |
|    n_updates            | 3550      |
|    policy_gradient_loss | 0.0113    |
|    std                  | 0.612     |
|    value_loss           | 0.869     |
---------------------------------------
Eval num_timesteps=730000, episode_reward=-99.53 +/- 0.16
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.09872578 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.432      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.00551    |
|    std                  | 0.615      |
|    value_loss           | 1.04       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 121      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 205762   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 121        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 358        |
|    time_elapsed         | 205969     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.10464071 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.4       |
|    explained_variance   | 0.00177    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.34       |
|    n_updates            | 3570       |
|    policy_gradient_loss | 0.00205    |
|    std                  | 0.615      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 128      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 359      |
|    time_elapsed         | 206176   |
|    total_timesteps      | 735232   |
| train/                  |          |
|    approx_kl            | 0.227316 |
|    clip_fraction        | 0.461    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.39    |
|    explained_variance   | 0.378    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.489    |
|    n_updates            | 3580     |
|    policy_gradient_loss | 0.00981  |
|    std                  | 0.615    |
|    value_loss           | 0.901    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 130        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 206384     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.12993692 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | 0.794      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.633      |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.00104   |
|    std                  | 0.612      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 130         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 206591      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.074311666 |
|    clip_fraction        | 0.442       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.35       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.517       |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00921     |
|    std                  | 0.609       |
|    value_loss           | 0.859       |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.48 +/- 0.12
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.13698086 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.5        |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.606      |
|    value_loss           | 0.842      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 125      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 208598   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 125        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 363        |
|    time_elapsed         | 208805     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.10978704 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.000436   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09e+03   |
|    n_updates            | 3620       |
|    policy_gradient_loss | 0.00573    |
|    std                  | 0.606      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 132         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 364         |
|    time_elapsed         | 209013      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.102707975 |
|    clip_fraction        | 0.478       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.28        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.444       |
|    n_updates            | 3630        |
|    policy_gradient_loss | 0.022       |
|    std                  | 0.606       |
|    value_loss           | 0.968       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 134         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 365         |
|    time_elapsed         | 209221      |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.100769326 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.38        |
|    n_updates            | 3640        |
|    policy_gradient_loss | 0.00769     |
|    std                  | 0.604       |
|    value_loss           | 0.938       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 134        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 209428     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.05939424 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.356      |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.00499    |
|    std                  | 0.601      |
|    value_loss           | 0.904      |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.51 +/- 0.14
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.080204144 |
|    clip_fraction        | 0.422       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | 0.589       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.428       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.00453     |
|    std                  | 0.597       |
|    value_loss           | 0.821       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 129      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 211435   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 135        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 211642     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.27903646 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | -0.00109   |
|    learning_rate        | 0.0003     |
|    loss                 | 125        |
|    n_updates            | 3670       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.596      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 135        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 211849     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.10244045 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.363      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.441      |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.597      |
|    value_loss           | 1.12       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 212056      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.116615586 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | 0.521       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 3690        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.598       |
|    value_loss           | 0.722       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 136        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 212263     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.06378288 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.416      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.597      |
|    value_loss           | 0.915      |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.64 +/- 0.07
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 760000    |
| train/                  |           |
|    approx_kl            | 0.1720181 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.17     |
|    explained_variance   | 0.519     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.55      |
|    n_updates            | 3710      |
|    policy_gradient_loss | 0.0184    |
|    std                  | 0.596     |
|    value_loss           | 1.07      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 132      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 214271   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 139         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 214477      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.040389918 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.00322     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.42        |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00363    |
|    std                  | 0.597       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 139       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 374       |
|    time_elapsed         | 214684    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 1.8410805 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.17     |
|    explained_variance   | 0.126     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.294     |
|    n_updates            | 3730      |
|    policy_gradient_loss | 0.00806   |
|    std                  | 0.595     |
|    value_loss           | 0.82      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 140        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 214891     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.09458783 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.13      |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.332      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.592      |
|    value_loss           | 0.721      |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.15 +/- 0.81
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.2      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.06873818 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.506      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.595      |
|    value_loss           | 0.713      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 136      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 216899   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 217107      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.019205362 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.00271     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.23        |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.00331    |
|    std                  | 0.594       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 142        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 217314     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.07779583 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.0993     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.421      |
|    n_updates            | 3770       |
|    policy_gradient_loss | 0.0289     |
|    std                  | 0.595      |
|    value_loss           | 1.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 142        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 217520     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.11905792 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.561      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.592      |
|    value_loss           | 0.902      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 144        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 217727     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.15205966 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.337      |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.59       |
|    value_loss           | 0.771      |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.44 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.15438667 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.532      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.587      |
|    value_loss           | 0.972      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 139      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 219735   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 139        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 219942     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.03568685 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.03      |
|    explained_variance   | 0.00327    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+03   |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.000676  |
|    std                  | 0.586      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 146        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 383        |
|    time_elapsed         | 220149     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.20257962 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7         |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.605      |
|    n_updates            | 3820       |
|    policy_gradient_loss | 0.0291     |
|    std                  | 0.583      |
|    value_loss           | 1.14       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 220356      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.071736105 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.98       |
|    explained_variance   | 0.606       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.44        |
|    n_updates            | 3830        |
|    policy_gradient_loss | 0.00358     |
|    std                  | 0.582       |
|    value_loss           | 0.822       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 148         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 385         |
|    time_elapsed         | 220563      |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.075762585 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.98       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.372       |
|    n_updates            | 3840        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.584       |
|    value_loss           | 0.795       |
-----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.28 +/- 0.30
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.10000068 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.99      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.342      |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.00903    |
|    std                  | 0.583      |
|    value_loss           | 0.888      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 144      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 222571   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 144        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 387        |
|    time_elapsed         | 222778     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.03108316 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | 0.00534    |
|    learning_rate        | 0.0003     |
|    loss                 | 16         |
|    n_updates            | 3860       |
|    policy_gradient_loss | 0.00117    |
|    std                  | 0.583      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 151        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 222986     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.14683041 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.96      |
|    explained_variance   | 0.069      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.596      |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.579      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 151        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 223192     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.21051958 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.409      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.0246     |
|    std                  | 0.577      |
|    value_loss           | 0.947      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 153        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 223399     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.07221429 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.397      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.00997    |
|    std                  | 0.578      |
|    value_loss           | 0.936      |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.62 +/- 0.06
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 800000    |
| train/                  |           |
|    approx_kl            | 0.0753968 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.91     |
|    explained_variance   | 0.639     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.798     |
|    n_updates            | 3900      |
|    policy_gradient_loss | 0.0111    |
|    std                  | 0.578     |
|    value_loss           | 1.1       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 149      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 225406   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 149        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 225613     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.19479454 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | -0.00241   |
|    learning_rate        | 0.0003     |
|    loss                 | 17.5       |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.00943    |
|    std                  | 0.577      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 156        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 225820     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.46143812 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.136      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.541      |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.576      |
|    value_loss           | 1.17       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 156         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 226027      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.064281605 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.88       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 3930        |
|    policy_gradient_loss | 0.00678     |
|    std                  | 0.576       |
|    value_loss           | 1.2         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 157        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 226233     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.10846065 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.374      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.806      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.00263    |
|    std                  | 0.576      |
|    value_loss           | 1.47       |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.65 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.062623635 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | 0.467       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.687       |
|    n_updates            | 3950        |
|    policy_gradient_loss | 0.00537     |
|    std                  | 0.579       |
|    value_loss           | 1.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 152      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 228241   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 152        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 228449     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.22375014 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.00164    |
|    learning_rate        | 0.0003     |
|    loss                 | 65.9       |
|    n_updates            | 3960       |
|    policy_gradient_loss | 0.00399    |
|    std                  | 0.579      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 158        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 228656     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.79716814 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.193      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.00327    |
|    std                  | 0.579      |
|    value_loss           | 1.07       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 160        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 228863     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.08977524 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.58       |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 160        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 229071     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.11319899 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.94      |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.437      |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.583      |
|    value_loss           | 0.987      |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.38 +/- 0.12
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.06612782 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.465      |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.581      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 156      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 231078   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 156        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 231285     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.19294275 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.94      |
|    explained_variance   | 0.00503    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.8e+03    |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.00233    |
|    std                  | 0.581      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 163         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 403         |
|    time_elapsed         | 231493      |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.060608093 |
|    clip_fraction        | 0.457       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.95       |
|    explained_variance   | -0.115      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.364       |
|    n_updates            | 4020        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.582       |
|    value_loss           | 1.3         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 164        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 231700     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.10891329 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.388      |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.579      |
|    value_loss           | 1.07       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 164        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 231907     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.25184804 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.335      |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.578      |
|    value_loss           | 0.984      |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.55 +/- 0.03
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.15345168 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.669      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.00589    |
|    std                  | 0.575      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 159      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 233915   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 159        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 234122     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.06376468 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | -0.00357   |
|    learning_rate        | 0.0003     |
|    loss                 | 43.2       |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.577      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 165        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 234329     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.20767558 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.0436     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.636      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.0033     |
|    std                  | 0.577      |
|    value_loss           | 1.26       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 165       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 409       |
|    time_elapsed         | 234536    |
|    total_timesteps      | 837632    |
| train/                  |           |
|    approx_kl            | 0.1708299 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.91     |
|    explained_variance   | 0.402     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.324     |
|    n_updates            | 4080      |
|    policy_gradient_loss | 0.0156    |
|    std                  | 0.58      |
|    value_loss           | 1.32      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 165        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 234744     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.11123509 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.532      |
|    n_updates            | 4090       |
|    policy_gradient_loss | 0.00582    |
|    std                  | 0.58       |
|    value_loss           | 0.882      |
----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.36 +/- 0.16
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.05081697 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.51       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.326      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0059     |
|    std                  | 0.579      |
|    value_loss           | 1.03       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 160      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 236753   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 166         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 236959      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.033602763 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.91       |
|    explained_variance   | 0.000748    |
|    learning_rate        | 0.0003      |
|    loss                 | 99.2        |
|    n_updates            | 4110        |
|    policy_gradient_loss | 0.00106     |
|    std                  | 0.579       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 166        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 237166     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.07689993 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.334      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.354      |
|    n_updates            | 4120       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.576      |
|    value_loss           | 0.869      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 166      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 414      |
|    time_elapsed         | 237373   |
|    total_timesteps      | 847872   |
| train/                  |          |
|    approx_kl            | 0.180999 |
|    clip_fraction        | 0.42     |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.88    |
|    explained_variance   | 0.562    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.405    |
|    n_updates            | 4130     |
|    policy_gradient_loss | 0.00595  |
|    std                  | 0.578    |
|    value_loss           | 0.958    |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 166         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 415         |
|    time_elapsed         | 237581      |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.064190984 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.526       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.378       |
|    n_updates            | 4140        |
|    policy_gradient_loss | 0.0143      |
|    std                  | 0.575       |
|    value_loss           | 0.94        |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.14 +/- 0.46
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.1       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.054147556 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.588       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.358       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.577       |
|    value_loss           | 0.856       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 161      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 239589   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 167        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 239796     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.06434066 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | -0.000685  |
|    learning_rate        | 0.0003     |
|    loss                 | 69.1       |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.000666   |
|    std                  | 0.576      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 167       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 240003    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 0.2141989 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.87     |
|    explained_variance   | 0.213     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.589     |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.576     |
|    value_loss           | 1.32      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 168        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 240211     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.23257273 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.575      |
|    value_loss           | 0.629      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.49 +/- 0.14
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.092682585 |
|    clip_fraction        | 0.434       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.84       |
|    explained_variance   | 0.72        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.509       |
|    n_updates            | 4190        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.574       |
|    value_loss           | 0.838       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 162      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 242218   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 162        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 242427     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.21264303 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.000622   |
|    learning_rate        | 0.0003     |
|    loss                 | 32.3       |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.576      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 168       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 422       |
|    time_elapsed         | 242634    |
|    total_timesteps      | 864256    |
| train/                  |           |
|    approx_kl            | 0.7809471 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.86     |
|    explained_variance   | -0.328    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.501     |
|    n_updates            | 4210      |
|    policy_gradient_loss | -0.0152   |
|    std                  | 0.575     |
|    value_loss           | 1.29      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 168        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 242842     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.08616931 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.586      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.57       |
|    value_loss           | 0.994      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 168        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 243048     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.08458577 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.73      |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.546      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.564      |
|    value_loss           | 1.19       |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.36 +/- 0.10
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.30053788 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.353      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.561      |
|    value_loss           | 0.995      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 162      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 245056   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 162         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 426         |
|    time_elapsed         | 245263      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.085270286 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.66       |
|    explained_variance   | 0.000409    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.77e+03    |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.000218   |
|    std                  | 0.562       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 169       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 427       |
|    time_elapsed         | 245470    |
|    total_timesteps      | 874496    |
| train/                  |           |
|    approx_kl            | 0.0945735 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.68     |
|    explained_variance   | 0.187     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.415     |
|    n_updates            | 4260      |
|    policy_gradient_loss | 0.0113    |
|    std                  | 0.563     |
|    value_loss           | 1.01      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 169        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 245677     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.11040183 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.422      |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.56       |
|    value_loss           | 1.1        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 169        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 245884     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.21065189 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.65      |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.444      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.561      |
|    value_loss           | 0.862      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.54 +/- 0.10
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.13193944 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.64      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.397      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.56       |
|    value_loss           | 1          |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 164      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 247891   |
|    total_timesteps | 880640   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 164       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 431       |
|    time_elapsed         | 248098    |
|    total_timesteps      | 882688    |
| train/                  |           |
|    approx_kl            | 0.2371722 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.63     |
|    explained_variance   | 0.00203   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.33e+03  |
|    n_updates            | 4300      |
|    policy_gradient_loss | 0.00929   |
|    std                  | 0.56      |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 170       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 248305    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 0.3620356 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.65     |
|    explained_variance   | 0.0702    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.39      |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.0235    |
|    std                  | 0.561     |
|    value_loss           | 1.15      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 170        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 248512     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.07731301 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.67      |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.382      |
|    n_updates            | 4320       |
|    policy_gradient_loss | 0.00779    |
|    std                  | 0.563      |
|    value_loss           | 0.816      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 171        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 248718     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.23511045 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.69      |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.365      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.564      |
|    value_loss           | 0.948      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.48 +/- 0.05
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.18448535 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 4340       |
|    policy_gradient_loss | 0.0246     |
|    std                  | 0.565      |
|    value_loss           | 0.953      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 167      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 250725   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 167        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 250933     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.03434527 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.000155   |
|    learning_rate        | 0.0003     |
|    loss                 | 6.21       |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.000642  |
|    std                  | 0.564      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 251139     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.18045922 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.513      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.566      |
|    value_loss           | 1.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 251346     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.09589185 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.667      |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.565      |
|    value_loss           | 0.958      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 251553     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.09246147 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.644      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.567      |
|    value_loss           | 1.2        |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.38 +/- 0.13
Episode length: 3598.00 +/- 5.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.13428916 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.74      |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.713      |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.569      |
|    value_loss           | 1          |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 168      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 253560   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 253768      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.064849526 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | -0.00512    |
|    learning_rate        | 0.0003      |
|    loss                 | 20.2        |
|    n_updates            | 4400        |
|    policy_gradient_loss | -0.00366    |
|    std                  | 0.569       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 174       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 442       |
|    time_elapsed         | 253975    |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 0.8669976 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.74     |
|    explained_variance   | -0.817    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.61      |
|    n_updates            | 4410      |
|    policy_gradient_loss | 0.00828   |
|    std                  | 0.567     |
|    value_loss           | 1.41      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 254182     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.08789029 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.631      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0345     |
|    std                  | 0.564      |
|    value_loss           | 1.17       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 254388     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.14309603 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.616      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.563      |
|    value_loss           | 1.01       |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.46 +/- 0.09
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.05434894 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.424      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.00735    |
|    std                  | 0.564      |
|    value_loss           | 0.988      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 168      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 256396   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 168        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 256603     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.03640605 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | -0.000986  |
|    learning_rate        | 0.0003     |
|    loss                 | 215        |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.00546   |
|    std                  | 0.564      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 256810     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.14315747 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | 0.014      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.623      |
|    n_updates            | 4460       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.562      |
|    value_loss           | 1.43       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 172        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 257017     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.08480532 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.63      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.559      |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 172        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 257224     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.07757312 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.536      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.632      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.558      |
|    value_loss           | 1.02       |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.45 +/- 0.06
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.06767474 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | 0.48       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.487      |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.558      |
|    value_loss           | 1.23       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 166      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 259231   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 171         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 259438      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.054960124 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | -0.000825   |
|    learning_rate        | 0.0003      |
|    loss                 | 46.8        |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.00627    |
|    std                  | 0.557       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 171         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 259646      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.091331586 |
|    clip_fraction        | 0.468       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | 0.0296      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.686       |
|    n_updates            | 4510        |
|    policy_gradient_loss | 0.0204      |
|    std                  | 0.557       |
|    value_loss           | 1.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 170         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 453         |
|    time_elapsed         | 259854      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.051144052 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.569       |
|    n_updates            | 4520        |
|    policy_gradient_loss | 0.00328     |
|    std                  | 0.557       |
|    value_loss           | 1.24        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 170        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 260061     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.08903734 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.701      |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.555      |
|    value_loss           | 1.29       |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.42 +/- 0.14
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.21254668 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.548      |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.556      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 165      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 262070   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 170         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 262278      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.017792372 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | 0.00642     |
|    learning_rate        | 0.0003      |
|    loss                 | 121         |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.00258    |
|    std                  | 0.557       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 170        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 262486     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.11635072 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | -0.281     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.59       |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.00879    |
|    std                  | 0.557      |
|    value_loss           | 1.51       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 170         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 458         |
|    time_elapsed         | 262693      |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.058698967 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.419       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.848       |
|    n_updates            | 4570        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.557       |
|    value_loss           | 1.41        |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.35 +/- 0.08
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.13986102 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.503      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0081     |
|    std                  | 0.556      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 165      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 264700   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 165        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 264907     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.10743567 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.000497   |
|    learning_rate        | 0.0003     |
|    loss                 | 8.49       |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.00411    |
|    std                  | 0.556      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 171        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 265114     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.34797916 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.0987     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.433      |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.555      |
|    value_loss           | 1.21       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 171        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 265321     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.10632649 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.532      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.00801    |
|    std                  | 0.558      |
|    value_loss           | 1.18       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 170        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 265528     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.08684757 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | 0.295      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.838      |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.00591    |
|    std                  | 0.558      |
|    value_loss           | 1.59       |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.49 +/- 0.11
Episode length: 3600.20 +/- 0.98
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 950000    |
| train/                  |           |
|    approx_kl            | 0.2591235 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.58     |
|    explained_variance   | 0.582     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.592     |
|    n_updates            | 4630      |
|    policy_gradient_loss | 0.00392   |
|    std                  | 0.559     |
|    value_loss           | 1.36      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 166      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 267535   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 166        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 267742     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.05837482 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | 0.0045     |
|    learning_rate        | 0.0003     |
|    loss                 | 10.8       |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.00128   |
|    std                  | 0.56       |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 172        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 267951     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.08321808 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | 0.221      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.578      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.56       |
|    value_loss           | 1.2        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 172        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 268157     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.07052627 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.498      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.633      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.561      |
|    value_loss           | 1.25       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 172       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 468       |
|    time_elapsed         | 268364    |
|    total_timesteps      | 958464    |
| train/                  |           |
|    approx_kl            | 0.2166591 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.57     |
|    explained_variance   | 0.478     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.481     |
|    n_updates            | 4670      |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.556     |
|    value_loss           | 1.1       |
---------------------------------------
Eval num_timesteps=960000, episode_reward=-99.56 +/- 0.06
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.06697685 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.409      |
|    n_updates            | 4680       |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.557      |
|    value_loss           | 0.966      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 169      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 270372   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 169         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 270579      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.029078724 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.53       |
|    explained_variance   | 0.00205     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.58e+03    |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.000835    |
|    std                  | 0.556       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 175        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 471        |
|    time_elapsed         | 270786     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.10315162 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.251      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 4700       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.559      |
|    value_loss           | 0.987      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 175        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 270993     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.07500394 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.54      |
|    explained_variance   | 0.558      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.522      |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.557      |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 177        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 271199     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.21582259 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.51      |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.554      |
|    value_loss           | 0.997      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.43 +/- 0.10
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.05912769 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.5       |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.394      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.00566    |
|    std                  | 0.555      |
|    value_loss           | 0.998      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 171      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 273207   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 171        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 273414     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.07685657 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | -0.00136   |
|    learning_rate        | 0.0003     |
|    loss                 | 298        |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.00188   |
|    std                  | 0.554      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 177       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 273620    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 0.0639046 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.49     |
|    explained_variance   | 0.0572    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.453     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.553     |
|    value_loss           | 0.957     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 177        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 273829     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.07019983 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.48      |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.596      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.554      |
|    value_loss           | 1.18       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 178       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 478       |
|    time_elapsed         | 274035    |
|    total_timesteps      | 978944    |
| train/                  |           |
|    approx_kl            | 0.1193906 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.5      |
|    explained_variance   | 0.564     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.434     |
|    n_updates            | 4770      |
|    policy_gradient_loss | 0.0124    |
|    std                  | 0.556     |
|    value_loss           | 0.916     |
---------------------------------------
Eval num_timesteps=980000, episode_reward=-99.51 +/- 0.17
Episode length: 3598.00 +/- 3.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.09860687 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.52      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.673      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.556      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 173      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 276043   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 276249     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.08325796 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.00126    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.28       |
|    n_updates            | 4790       |
|    policy_gradient_loss | 0.00924    |
|    std                  | 0.557      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 179        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 276456     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.15984881 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.52      |
|    explained_variance   | -0.0341    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.00643    |
|    std                  | 0.556      |
|    value_loss           | 0.981      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 179        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 276663     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.13575524 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.518      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.552      |
|    value_loss           | 0.908      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 180        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 276870     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.06236083 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.44      |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.55       |
|    value_loss           | 0.946      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.38 +/- 0.18
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.4     |
| time/                   |           |
|    total_timesteps      | 990000    |
| train/                  |           |
|    approx_kl            | 0.2241164 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.43     |
|    explained_variance   | 0.57      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.416     |
|    n_updates            | 4830      |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.549     |
|    value_loss           | 0.992     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 175      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 278877   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 175         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 279084      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.016657459 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.42       |
|    explained_variance   | -0.000552   |
|    learning_rate        | 0.0003      |
|    loss                 | 351         |
|    n_updates            | 4840        |
|    policy_gradient_loss | 0.00191     |
|    std                  | 0.549       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 181        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 279291     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.21566904 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.368      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.501      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.551      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 182       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 279499    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.1039389 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.45     |
|    explained_variance   | 0.569     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.459     |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.0251    |
|    std                  | 0.55      |
|    value_loss           | 1.09      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 182        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 279706     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.21263131 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.44      |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.442      |
|    n_updates            | 4870       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.55       |
|    value_loss           | 0.951      |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.58 +/- 0.15
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.09554444 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.461      |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.549      |
|    value_loss           | 0.821      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 177      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 281713   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-20_12-12-49_llm_triton_qwen_3b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 6:12:39 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-99.988273 -99.873203 -99.889758 -99.964676 -99.952975]
 [-99.851076 -99.758926 -99.817757 -99.80171  -99.678097]
 [-99.476351 -99.496982 -99.544792 -99.739861 -99.497316]
 [-99.317787 -99.905787 -99.437509 -99.374571 -99.44125 ]
 [-99.730444 -99.649968 -99.657252 -99.642129 -99.74828 ]
 [-99.723884 -99.63471  -99.672251 -99.67363  -99.683796]
 [-99.601829 -99.380132 -99.690871 -99.572224 -99.44909 ]
 [-99.768164 -99.725168 -99.715172 -99.670467 -99.740687]
 [-99.735457 -99.694395 -99.704331 -99.728432 -99.74365 ]
 [-99.659708 -99.653966 -99.942672 -99.737806 -99.702979]
 [-99.416213 -99.908778 -99.467238 -99.754415 -99.652917]
 [-99.536894 -99.701945 -99.463995 -99.874316 -99.822039]
 [-95.478718 -99.542169 -96.498368 -94.859797 -96.279284]
 [-95.382744 -99.610485 -97.796734 -99.92529  -98.520747]
 [-99.776508 -99.89563  -99.9157   -99.796762 -99.342606]
 [-99.670557 -99.609652 -99.580747 -99.46004  -99.596322]
 [-99.404077 -98.733623 -99.705564 -98.752106 -99.415247]
 [-99.477606 -99.933539 -99.71068  -99.431954 -98.458456]
 [-99.383346 -99.28527  -99.844249 -99.364796 -99.499915]
 [-99.69436  -99.58901  -99.537393 -99.44691  -99.364508]
 [-99.281698 -99.30304  -99.271447 -99.730754 -99.277067]
 [-99.642985 -99.422837 -99.442824 -99.444946 -99.626515]
 [-99.292625 -99.55071  -99.41568  -99.734111 -98.469597]
 [-99.291377 -99.788404 -99.50917  -99.434541 -99.896167]
 [-99.335353 -99.599278 -99.493829 -99.765476 -99.429553]
 [-99.595647 -99.742486 -99.710889 -99.299747 -99.40682 ]
 [-99.316262 -99.346732 -99.509672 -99.392664 -99.285316]
 [-98.429037 -99.539428 -99.621741 -98.730342 -99.348682]
 [-98.311315 -99.559871 -99.367736 -99.583763 -99.255789]
 [-99.402105 -99.401059 -99.375379 -99.65081  -99.375433]
 [-99.371299 -99.577535 -99.476633 -99.448873 -99.799086]
 [-99.339893 -99.709527 -99.515911 -99.545294 -99.607905]
 [-99.421957 -99.473906 -99.20223  -99.607421 -99.304488]
 [-99.522594 -99.408337 -99.441729 -99.786378 -99.327752]
 [-99.523842 -99.711904 -99.695672 -99.581165 -99.63551 ]
 [-99.562172 -99.438323 -99.795528 -99.256291 -99.617676]
 [-99.603536 -99.519295 -99.488124 -99.855378 -99.404689]
 [-99.743356 -99.425623 -99.561361 -99.73859  -99.692727]
 [-99.595432 -99.546488 -99.663741 -99.291492 -99.189718]
 [-99.21813  -99.418351 -99.473986 -99.379494 -99.403702]
 [-99.422047 -99.606055 -99.361181 -99.714895 -99.578325]
 [-99.33068  -99.467628 -99.341579 -99.334572 -99.170902]
 [-99.29624  -99.574305 -99.435838 -99.731626 -99.574747]
 [-98.449943 -99.340029 -99.135499 -99.360313 -99.539331]
 [-99.313591 -99.512671 -99.175423 -98.199001 -99.248977]
 [-97.454284 -98.485849 -98.460015 -97.164166 -99.487232]
 [-96.325531 -99.34951  -99.306981 -99.402535 -99.168822]
 [-99.350042 -99.417119 -98.096408 -96.45809  -98.3144  ]
 [-97.305106 -98.377969 -99.161464 -98.036754 -99.05469 ]
 [-99.244719 -98.258722 -98.527761 -99.418951 -99.510681]
 [-98.43375  -96.123115 -97.21459  -97.23211  -98.460724]
 [-99.33214  -99.449775 -99.490384 -99.292937 -99.383355]
 [-99.286009 -99.608735 -99.287153 -99.463076 -99.292816]
 [-99.493774 -99.45837  -99.51015  -99.496944 -99.253571]
 [-99.323962 -99.207778 -97.319266 -99.371978 -99.32658 ]
 [-99.174266 -99.251183 -98.168541 -99.602373 -99.340694]
 [-99.563207 -98.357325 -99.486436 -96.213145 -99.551218]
 [-99.425997 -99.72416  -98.488173 -99.35561  -98.485156]
 [-98.548014 -99.435059 -99.678504 -98.24463  -99.371069]
 [-99.252471 -99.438419 -99.320939 -99.286225 -99.199466]
 [-99.504811 -99.202231 -99.215351 -99.452329 -99.269457]
 [-99.451846 -99.694685 -99.479556 -99.384482 -99.48954 ]
 [-99.459621 -99.37582  -99.451902 -99.59147  -99.326082]
 [-99.627399 -99.690691 -99.255019 -99.257678 -99.702386]
 [-99.280201 -99.692907 -99.500832 -99.406647 -99.306393]
 [-99.691593 -99.494131 -99.635287 -99.411164 -99.421315]
 [-99.538395 -99.680802 -99.616432 -99.473764 -99.480447]
 [-99.665559 -99.451815 -99.517004 -99.318706 -99.433638]
 [-99.735809 -99.497223 -99.609902 -99.413254 -98.579177]
 [-99.543036 -98.518678 -99.408731 -99.545391 -99.269081]
 [-99.479584 -99.519354 -99.494911 -99.449677 -99.458659]
 [-99.5095   -99.491372 -98.656214 -99.339549 -99.38954 ]
 [-99.42128  -99.541899 -99.29767  -99.775442 -99.594129]
 [-99.402348 -99.475887 -99.629796 -99.56909  -99.301797]
 [-99.627302 -99.352496 -99.726726 -99.419492 -99.437159]
 [-99.516476 -99.720342 -99.647201 -99.623153 -99.668284]
 [-97.534801 -99.645067 -99.597105 -99.523046 -99.451212]
 [-99.385525 -99.396945 -99.503223 -99.453121 -99.438609]
 [-99.331395 -99.395451 -99.580454 -98.712653 -99.385763]
 [-99.58691  -99.666206 -99.663339 -99.523011 -99.667822]
 [-99.666044 -99.560469 -99.696114 -99.641157 -99.68188 ]
 [-99.368543 -99.568352 -99.386087 -99.390588 -99.191393]
 [-99.562715 -99.50838  -99.521307 -99.585139 -99.585287]
 [-99.161971 -99.505828 -99.40266  -99.189443 -99.544844]
 [-98.241349 -99.386551 -99.256324 -99.486958 -99.335209]
 [-99.268779 -99.638998 -99.600756 -99.38793  -99.570516]
 [-99.347678 -99.510351 -99.234775 -99.427258 -99.258632]
 [-99.584023 -99.632776 -99.632334 -99.453045 -99.385464]
 [-99.419561 -99.493157 -99.43251  -99.529843 -99.542044]
 [-99.532229 -99.187375 -99.39043  -99.279038 -99.502783]
 [-99.558108 -99.310455 -99.398218 -99.507249 -99.503308]
 [-99.555407 -99.454513 -99.454284 -99.410587 -99.398096]
 [-99.489975 -99.654558 -99.30264  -99.367061 -99.269759]
 [-99.263419 -99.284393 -99.379611 -99.499004 -99.344789]
 [-99.658628 -99.314447 -99.531511 -99.494872 -99.458701]
 [-99.454763 -99.545739 -99.597649 -99.646062 -99.559329]
 [-99.325066 -99.314112 -99.584309 -99.446085 -99.471562]
 [-99.727323 -99.645234 -99.524831 -99.407251 -99.235397]
 [-99.724039 -99.295576 -99.232855 -99.402943 -99.262855]
 [-99.324672 -99.642907 -99.772105 -99.574609 -99.600978]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3582 3601]
 [3601 3601 3601 3583 3601]
 [3601 3601 3595 3601 3601]
 [3591 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3600 3601 3599]
 [3601 3601 3600 3601 3601]
 [3589 3601 3601 3601 3601]
 [3601 3601 3597 3590 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3583 3601 3601]
 [3601 3601 3601 3601 3592]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3583 3601 3601]
 [3601 3601 3594 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3583 3601 3601]
 [3601 3601 3597 3597 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3586 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3587 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3597 3601 3601]
 [3601 3601 3594 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3598 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3600 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3599 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3597 3601 3596 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3596]
 [3601 3601 3586 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3597 3597 3601 3601]
 [3601 3586 3601 3601 3601]
 [3601 3601 3601 3601 3592]
 [3599 3597 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3600 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3596 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3594 3601 3601 3601]
 [3588 3601 3601 3601 3599]
 [3601 3601 3601 3594 3601]
 [3601 3597 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3584 3601 3601 3601]
 [3599 3599 3601 3601 3601]
 [3601 3601 3601 3601 3600]
 [3584 3601 3601 3601 3601]
 [3600 3597 3601 3591 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3597 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-20_12-12-49_llm_triton_qwen_3b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-20_12-12-49_llm_triton_qwen_3b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
