####################
/var/spool/slurmd/job5228055/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_3B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_1_example_explanation.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-21_06-30-08_llm_triton_qwen_3b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the movement of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0. You have to output the following calculations:
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 1
 
 Explanation (Do not generate this in your output): The score is 1 since the particle started at (17.25, -160.50) and ended at (16.50, -159.75), while the goal was at (5.75, -57.00). The distance to the goal at starting position was 104.13 while the distance at ending position was 103.31. Since, 103.31 < 104.13, the particle moved closer to the goal. Therefore, the particle moved closer to the goal.
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 210  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.6e+03     |
|    ep_rew_mean          | 915         |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 416         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011128496 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.104       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.14        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.994       |
|    value_loss           | 17.6        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.6e+03    |
|    ep_rew_mean          | 915        |
| time/                   |            |
|    fps                  | 9          |
|    iterations           | 3          |
|    time_elapsed         | 621        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.01112257 |
|    clip_fraction        | 0.111      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.196      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.87       |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.995      |
|    value_loss           | 15         |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | 997         |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 826         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.009179128 |
|    clip_fraction        | 0.0998      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.68        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.997       |
|    value_loss           | 15.2        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.89 +/- 0.01
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.007354181 |
|    clip_fraction        | 0.0604      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.09        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.996       |
|    value_loss           | 15.4        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 800      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2832     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 800          |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 6            |
|    time_elapsed         | 3038         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0037132339 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00966     |
|    learning_rate        | 0.0003       |
|    loss                 | 331          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00512     |
|    std                  | 0.996        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 899         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3243        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008065894 |
|    clip_fraction        | 0.0747      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.452       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.77        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.999       |
|    value_loss           | 13.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 899         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3448        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.008093052 |
|    clip_fraction        | 0.0788      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.239       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.46        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.998       |
|    value_loss           | 11.1        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.44e+03   |
|    ep_rew_mean          | 956        |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 9          |
|    time_elapsed         | 3654       |
|    total_timesteps      | 18432      |
| train/                  |            |
|    approx_kl            | 0.01059202 |
|    clip_fraction        | 0.106      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.84       |
|    n_updates            | 80         |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.996      |
|    value_loss           | 8.07       |
----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.97 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.013661511 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.253      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.38        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.994       |
|    value_loss           | 6.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 878      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5660     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 878          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 5865         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0031035023 |
|    clip_fraction        | 0.00596      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00357     |
|    learning_rate        | 0.0003       |
|    loss                 | 14.3         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00246     |
|    std                  | 0.994        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 923         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6070        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.009170353 |
|    clip_fraction        | 0.0848      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.393       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.35        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.992       |
|    value_loss           | 5.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 923         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6276        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.009734446 |
|    clip_fraction        | 0.0867      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.993       |
|    value_loss           | 4.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 964         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6481        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.019124057 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.164       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.99        |
|    value_loss           | 2.2         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-100.01 +/- 0.05
Episode length: 3599.20 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.010940337 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.386       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.12        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.989       |
|    value_loss           | 7.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8487     |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 912          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 8693         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0007647335 |
|    clip_fraction        | 0.000537     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00488     |
|    learning_rate        | 0.0003       |
|    loss                 | 43.3         |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00205     |
|    std                  | 0.99         |
|    value_loss           | 978          |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 949        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 17         |
|    time_elapsed         | 8898       |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.01247651 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | -1.28      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.41       |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.987      |
|    value_loss           | 11.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 949         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9103        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015258947 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.0711      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00947    |
|    std                  | 0.984       |
|    value_loss           | 2.49        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | 979         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9309        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.011088651 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.339       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.981       |
|    value_loss           | 2.78        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.99 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.016661167 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.058       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.983       |
|    value_loss           | 1.87        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 939      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11315    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 939          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 11520        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0050634374 |
|    clip_fraction        | 0.0269       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | -0.000635    |
|    learning_rate        | 0.0003       |
|    loss                 | 1.03e+03     |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.000841    |
|    std                  | 0.983        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 968         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11728       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.018965421 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.167      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.625       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.985       |
|    value_loss           | 2.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 968         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11933       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.020668603 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.138       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.595       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.983       |
|    value_loss           | 1.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 996         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12140       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.017249469 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.98        |
|    value_loss           | 1.46        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.99 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.012789616 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.58       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.744       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.979       |
|    value_loss           | 1.64        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 967      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14145    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 967          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 14351        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0024221537 |
|    clip_fraction        | 0.00762      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | -0.00164     |
|    learning_rate        | 0.0003       |
|    loss                 | 62.3         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.979        |
|    value_loss           | 1.05e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 990        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 27         |
|    time_elapsed         | 14556      |
|    total_timesteps      | 55296      |
| train/                  |            |
|    approx_kl            | 0.01567368 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.61       |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.973      |
|    value_loss           | 1.54       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14762       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.013287567 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.705       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.971       |
|    value_loss           | 1.66        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14967       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.015075821 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.217       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.781       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.969       |
|    value_loss           | 1.48        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.95 +/- 0.03
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.028671175 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.2         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.667       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.968       |
|    value_loss           | 1.55        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 989      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16973    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 989         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17178       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.015807534 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.000328   |
|    learning_rate        | 0.0003      |
|    loss                 | 18.4        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00122    |
|    std                  | 0.969       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 32         |
|    time_elapsed         | 17384      |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.02168566 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | -0.202     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15       |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.00677   |
|    std                  | 0.964      |
|    value_loss           | 2.22       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17589       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.017182218 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.526       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.958       |
|    value_loss           | 1.78        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 34         |
|    time_elapsed         | 17794      |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.01708898 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.265      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.563      |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.952      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.99 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.023605224 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.201       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.008      |
|    std                  | 0.953       |
|    value_loss           | 1.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19801    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20006       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.009993535 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0013     |
|    learning_rate        | 0.0003      |
|    loss                 | 71.1        |
|    n_updates            | 350         |
|    policy_gradient_loss | 3.29e-05    |
|    std                  | 0.954       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20212       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.018561047 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0219     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.379       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.955       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20417       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.022267208 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.504       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.951       |
|    value_loss           | 1.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20622       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.008079154 |
|    clip_fraction        | 0.0937      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0912      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.953       |
|    value_loss           | 2.1         |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.89 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.02048494 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.159      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.568      |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.00937   |
|    std                  | 0.951      |
|    value_loss           | 1.08       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22629    |
|    total_timesteps | 81920    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.06e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 41           |
|    time_elapsed         | 22834        |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0078078257 |
|    clip_fraction        | 0.101        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | 0.00116      |
|    learning_rate        | 0.0003       |
|    loss                 | 446          |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00119     |
|    std                  | 0.95         |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23039       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.020504482 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.182      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00752    |
|    std                  | 0.946       |
|    value_loss           | 1.35        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.35e+03  |
|    ep_rew_mean          | 1.07e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 43        |
|    time_elapsed         | 23245     |
|    total_timesteps      | 88064     |
| train/                  |           |
|    approx_kl            | 0.0118297 |
|    clip_fraction        | 0.105     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.9     |
|    explained_variance   | 0.16      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.69      |
|    n_updates            | 420       |
|    policy_gradient_loss | -0.00915  |
|    std                  | 0.947     |
|    value_loss           | 2.49      |
---------------------------------------
Eval num_timesteps=90000, episode_reward=-100.00 +/- 0.07
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.021662261 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.774       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00733    |
|    std                  | 0.936       |
|    value_loss           | 1.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25251    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25456       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.009486863 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0011      |
|    learning_rate        | 0.0003      |
|    loss                 | 13.4        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.000179   |
|    std                  | 0.935       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25662       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.024047915 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0652      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.792       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00811    |
|    std                  | 0.932       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25867       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.018424109 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.739       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00616    |
|    std                  | 0.932       |
|    value_loss           | 1.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26072       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.018893078 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.614       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.924       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.91 +/- 0.04
Episode length: 3598.20 +/- 2.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.015821703 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.366      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08        |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.927       |
|    value_loss           | 2.31        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28078    |
|    total_timesteps | 100352   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 50         |
|    time_elapsed         | 28285      |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.01251233 |
|    clip_fraction        | 0.0515     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.000173   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.34e+03   |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.00263   |
|    std                  | 0.926      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28490       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.023314636 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.0405      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.429       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00565    |
|    std                  | 0.923       |
|    value_loss           | 1.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28695       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.020432804 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.388      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.946       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00507    |
|    std                  | 0.923       |
|    value_loss           | 3.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28901       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.020100556 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.125       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.5         |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0047     |
|    std                  | 0.922       |
|    value_loss           | 1.21        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.93 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.023127014 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.213       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.363       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00918    |
|    std                  | 0.914       |
|    value_loss           | 1.1         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30906    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31112       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.011474748 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00121    |
|    learning_rate        | 0.0003      |
|    loss                 | 125         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0029     |
|    std                  | 0.914       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31318       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.025532246 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.153      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.649       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00819    |
|    std                  | 0.91        |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31524       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.019283297 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -1.18       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.908       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00595    |
|    std                  | 0.91        |
|    value_loss           | 2.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31729       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.021118136 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.161       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.823       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00698    |
|    std                  | 0.904       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.92 +/- 0.04
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.024631737 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.134       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.553       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00462    |
|    std                  | 0.907       |
|    value_loss           | 1.32        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33735    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 33940       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.009546075 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000368   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.74        |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00171    |
|    std                  | 0.907       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34146       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.024889762 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.515      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.577       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00173    |
|    std                  | 0.91        |
|    value_loss           | 1.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34351       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.018704388 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -1.51       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.519       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.912       |
|    value_loss           | 1.83        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34556       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.024907712 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.618       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00578    |
|    std                  | 0.908       |
|    value_loss           | 1.28        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.89 +/- 0.04
Episode length: 3597.60 +/- 4.18
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.9        |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0145739615 |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.6        |
|    explained_variance   | 0.437        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.938        |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.0086      |
|    std                  | 0.908        |
|    value_loss           | 2.05         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36562    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.14e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 65           |
|    time_elapsed         | 36768        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0036875047 |
|    clip_fraction        | 0.0491       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.6        |
|    explained_variance   | -0.000709    |
|    learning_rate        | 0.0003       |
|    loss                 | 863          |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00364     |
|    std                  | 0.908        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 36973       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.020692464 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.319      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.686       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00676    |
|    std                  | 0.908       |
|    value_loss           | 1.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37179       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.023026764 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.152       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00651    |
|    std                  | 0.914       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37384       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.029181402 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.636       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0034     |
|    std                  | 0.914       |
|    value_loss           | 1.54        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.89 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.03033498 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.709      |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.00873   |
|    std                  | 0.905      |
|    value_loss           | 1.63       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39390    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39595       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.029418409 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000873   |
|    learning_rate        | 0.0003      |
|    loss                 | 85.9        |
|    n_updates            | 690         |
|    policy_gradient_loss | 0.00229     |
|    std                  | 0.904       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39801       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.036341343 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.211      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.00322     |
|    std                  | 0.907       |
|    value_loss           | 1.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40006       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.020517625 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.164       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.901       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00711    |
|    std                  | 0.904       |
|    value_loss           | 1.76        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40211       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.027488492 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.191       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.56        |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.000496   |
|    std                  | 0.906       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.92 +/- 0.03
Episode length: 3597.60 +/- 5.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.027866773 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.465       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00745    |
|    std                  | 0.904       |
|    value_loss           | 1.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42217    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42423       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.011175595 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00169    |
|    learning_rate        | 0.0003      |
|    loss                 | 209         |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00398    |
|    std                  | 0.904       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42628       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.028579578 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.502      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.756       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0062     |
|    std                  | 0.9         |
|    value_loss           | 1.68        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42833       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.029638479 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.923       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00348    |
|    std                  | 0.899       |
|    value_loss           | 1.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43040       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.028547043 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.32        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.67        |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.902       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.89 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.030915583 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.163       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.416       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00673    |
|    std                  | 0.899       |
|    value_loss           | 1.12        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45047    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45252       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.010524883 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00345    |
|    learning_rate        | 0.0003      |
|    loss                 | 87.9        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00653    |
|    std                  | 0.898       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45458       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.019926095 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00595     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.438       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00792    |
|    std                  | 0.895       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45663       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.025830783 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.514       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00121    |
|    std                  | 0.89        |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45869       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.031378698 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00957    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.885       |
|    value_loss           | 1.41        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.86 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.024618272 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.244       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.614       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00632    |
|    std                  | 0.878       |
|    value_loss           | 1.16        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47876    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48081       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.019543719 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.000921   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.878       |
|    value_loss           | 936         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48286       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.025722519 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.453       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00249    |
|    std                  | 0.872       |
|    value_loss           | 1.09        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 87         |
|    time_elapsed         | 48492      |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.03217818 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.274      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 860        |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.867      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.87 +/- 0.05
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.023414582 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.609      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.828       |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00507    |
|    std                  | 0.863       |
|    value_loss           | 1.32        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50498    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50704       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.010170158 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000372   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.96e+03    |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00464    |
|    std                  | 0.863       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 50909       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.029514603 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0895     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.427       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00625    |
|    std                  | 0.859       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51114       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.024112105 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.858       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51320       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.023887383 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.253       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.707       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.00189    |
|    std                  | 0.851       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.85 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.030964594 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.00388    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.798       |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00102    |
|    std                  | 0.847       |
|    value_loss           | 1.3         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53326    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 94         |
|    time_elapsed         | 53532      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.04227106 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.000903   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53e+03   |
|    n_updates            | 930        |
|    policy_gradient_loss | 0.00141    |
|    std                  | 0.846      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53738       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.048877075 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.138       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.449       |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.00606     |
|    std                  | 0.845       |
|    value_loss           | 0.972       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 53943       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.024934161 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.13       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.642       |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00507    |
|    std                  | 0.85        |
|    value_loss           | 1.43        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 54148      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.02830416 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.237      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.522      |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.000653  |
|    std                  | 0.847      |
|    value_loss           | 1.05       |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.91 +/- 0.03
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.02995018 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.283      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09       |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.00125   |
|    std                  | 0.846      |
|    value_loss           | 4.22       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56154    |
|    total_timesteps | 200704   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.24e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 99           |
|    time_elapsed         | 56360        |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0114582125 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10          |
|    explained_variance   | -0.00617     |
|    learning_rate        | 0.0003       |
|    loss                 | 15.8         |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00344     |
|    std                  | 0.847        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56565       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.030840226 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -2.51       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.547       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00278    |
|    std                  | 0.844       |
|    value_loss           | 1.38        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 101        |
|    time_elapsed         | 56770      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.02701971 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.99      |
|    explained_variance   | -0.102     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.587      |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.00446   |
|    std                  | 0.844      |
|    value_loss           | 1.22       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 56976       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.028450517 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.471       |
|    n_updates            | 1010        |
|    policy_gradient_loss | 0.00374     |
|    std                  | 0.84        |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.76 +/- 0.04
Episode length: 3599.00 +/- 2.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.036322277 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.317       |
|    n_updates            | 1020        |
|    policy_gradient_loss | 0.00347     |
|    std                  | 0.835       |
|    value_loss           | 1           |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.25e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 58982    |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 104        |
|    time_elapsed         | 59187      |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.03086118 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | 0.000254   |
|    learning_rate        | 0.0003     |
|    loss                 | 5.47       |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.000143  |
|    std                  | 0.836      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59393       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.046147138 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.0505      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.372       |
|    n_updates            | 1040        |
|    policy_gradient_loss | 0.00321     |
|    std                  | 0.831       |
|    value_loss           | 1.01        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 59598      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.03233058 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | 0.291      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.454      |
|    n_updates            | 1050       |
|    policy_gradient_loss | 0.00445    |
|    std                  | 0.826      |
|    value_loss           | 0.901      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 59804      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.03522632 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | 0.278      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.664      |
|    n_updates            | 1060       |
|    policy_gradient_loss | 0.00737    |
|    std                  | 0.822      |
|    value_loss           | 1.07       |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.83 +/- 0.07
Episode length: 3598.00 +/- 4.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.029117247 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.584       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00142    |
|    std                  | 0.821       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61810    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62015       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.039123233 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | -0.0031     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.39        |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00379    |
|    std                  | 0.821       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 62220      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.03823019 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | 0.0415     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.36       |
|    n_updates            | 1090       |
|    policy_gradient_loss | 0.00275    |
|    std                  | 0.818      |
|    value_loss           | 1.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 111        |
|    time_elapsed         | 62426      |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.02689417 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.7       |
|    explained_variance   | 0.3        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 1100       |
|    policy_gradient_loss | 0.00589    |
|    std                  | 0.812      |
|    value_loss           | 1          |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 62631       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.044380225 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.537       |
|    n_updates            | 1110        |
|    policy_gradient_loss | 0.00169     |
|    std                  | 0.81        |
|    value_loss           | 0.965       |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.81 +/- 0.08
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.031149674 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | 0.258       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.459       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00245     |
|    std                  | 0.805       |
|    value_loss           | 1.15        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64637    |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 114        |
|    time_elapsed         | 64843      |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.03027803 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | -0.00495   |
|    learning_rate        | 0.0003     |
|    loss                 | 91.7       |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.00402   |
|    std                  | 0.804      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 115        |
|    time_elapsed         | 65048      |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.04856729 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | 0.105      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.664      |
|    n_updates            | 1140       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.803      |
|    value_loss           | 1.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65254       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.033103086 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -0.00268    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.727       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.801       |
|    value_loss           | 1.7         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65459       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.029621787 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -0.0735     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.356       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00533    |
|    std                  | 0.802       |
|    value_loss           | 1.17        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.72 +/- 0.17
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.024404932 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.466       |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.000943   |
|    std                  | 0.8         |
|    value_loss           | 1.17        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67466    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67672       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.043939725 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | 0.00159     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.94e+03    |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.00252     |
|    std                  | 0.8         |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67877       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.030998603 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.141       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 1190        |
|    policy_gradient_loss | 0.00972     |
|    std                  | 0.795       |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.31e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68082       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.028400771 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.000474   |
|    std                  | 0.793       |
|    value_loss           | 1.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.31e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68288       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.042451724 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.241       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.651       |
|    n_updates            | 1210        |
|    policy_gradient_loss | 0.000314    |
|    std                  | 0.789       |
|    value_loss           | 1.3         |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.69 +/- 0.12
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.02252382 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.227      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.777      |
|    n_updates            | 1220       |
|    policy_gradient_loss | 0.00155    |
|    std                  | 0.783      |
|    value_loss           | 1.49       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70295    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70500       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.027193654 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.000218    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+03    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00115    |
|    std                  | 0.784       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70705       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.038267985 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -1.88       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 1240        |
|    policy_gradient_loss | 0.00516     |
|    std                  | 0.783       |
|    value_loss           | 4.5         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70911       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.041679516 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -0.0235     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.589       |
|    n_updates            | 1250        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.783       |
|    value_loss           | 1.36        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.68 +/- 0.07
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.04218357 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | -2.88      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.614      |
|    n_updates            | 1260       |
|    policy_gradient_loss | 0.0029     |
|    std                  | 0.778      |
|    value_loss           | 1.31       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72917    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 128        |
|    time_elapsed         | 73122      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.04028974 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.31      |
|    explained_variance   | -0.00208   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+03   |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.000235  |
|    std                  | 0.778      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 73328      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.04066082 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | 0.0682     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.644      |
|    n_updates            | 1280       |
|    policy_gradient_loss | 0.00908    |
|    std                  | 0.773      |
|    value_loss           | 1.67       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 130        |
|    time_elapsed         | 73533      |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.04497928 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | 0.191      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04       |
|    n_updates            | 1290       |
|    policy_gradient_loss | 0.00298    |
|    std                  | 0.768      |
|    value_loss           | 1.4        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 131        |
|    time_elapsed         | 73739      |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.04322088 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.241      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.512      |
|    n_updates            | 1300       |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.763      |
|    value_loss           | 1.12       |
----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.77 +/- 0.14
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.039221056 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.16       |
|    explained_variance   | -1.07       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.878       |
|    n_updates            | 1310        |
|    policy_gradient_loss | 0.00359     |
|    std                  | 0.761       |
|    value_loss           | 2.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75744    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 75950       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.042439986 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.000815    |
|    learning_rate        | 0.0003      |
|    loss                 | 805         |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00113    |
|    std                  | 0.761       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76155      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.04404921 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.13      |
|    explained_variance   | 0.014      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.903      |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.759      |
|    value_loss           | 1.49       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76361       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.045786478 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | 0.0669      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.906       |
|    n_updates            | 1340        |
|    policy_gradient_loss | 0.00926     |
|    std                  | 0.754       |
|    value_loss           | 1.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 76566       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.042118255 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.258       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.527       |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.00967     |
|    std                  | 0.749       |
|    value_loss           | 1.07        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-98.91 +/- 0.75
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.9       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.044883963 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | -0.109      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.882       |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.00606     |
|    std                  | 0.749       |
|    value_loss           | 2.02        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78573    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78778       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.026671372 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | 0.000566    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.29        |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00472    |
|    std                  | 0.749       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 78984       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.037186425 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | -0.0982     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.654       |
|    n_updates            | 1380        |
|    policy_gradient_loss | 0.00374     |
|    std                  | 0.747       |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79191       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.029637404 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.196       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 1390        |
|    policy_gradient_loss | 0.00516     |
|    std                  | 0.742       |
|    value_loss           | 1.38        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 79396      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.03031056 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.95      |
|    explained_variance   | 0.231      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.834      |
|    n_updates            | 1400       |
|    policy_gradient_loss | 0.00654    |
|    std                  | 0.743      |
|    value_loss           | 1.34       |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-97.33 +/- 1.39
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -97.3      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.05235777 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | 0.306      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.52       |
|    n_updates            | 1410       |
|    policy_gradient_loss | 0.00721    |
|    std                  | 0.745      |
|    value_loss           | 1.11       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81402    |
|    total_timesteps | 290816   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 143        |
|    time_elapsed         | 81607      |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.03365214 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | -0.000629  |
|    learning_rate        | 0.0003     |
|    loss                 | 697        |
|    n_updates            | 1420       |
|    policy_gradient_loss | 0.00547    |
|    std                  | 0.745      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 81813       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.038773905 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | 0.133       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.83        |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.00261     |
|    std                  | 0.743       |
|    value_loss           | 1.49        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82019       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.037334077 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.299       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.742       |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82224       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.037381545 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.313       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 1450        |
|    policy_gradient_loss | 0.00862     |
|    std                  | 0.74        |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-98.74 +/- 1.14
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.7      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.04002109 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | 0.272      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.0016    |
|    std                  | 0.737      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84231    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 84438       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.042840607 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | -0.00084    |
|    learning_rate        | 0.0003      |
|    loss                 | 740         |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.000579   |
|    std                  | 0.739       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84643       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.057835132 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | -0.194      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.678       |
|    n_updates            | 1480        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.738       |
|    value_loss           | 1.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 84848       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.047822297 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.485       |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00475    |
|    std                  | 0.736       |
|    value_loss           | 1.17        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85054      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.02653243 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.83      |
|    explained_variance   | 0.316      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.425      |
|    n_updates            | 1500       |
|    policy_gradient_loss | 0.00594    |
|    std                  | 0.73       |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.25 +/- 0.77
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.3     |
| time/                   |           |
|    total_timesteps      | 310000    |
| train/                  |           |
|    approx_kl            | 0.0360791 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.79     |
|    explained_variance   | 0.352     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.381     |
|    n_updates            | 1510      |
|    policy_gradient_loss | 0.0019    |
|    std                  | 0.73      |
|    value_loss           | 1.12      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87060    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87265       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.027504671 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.00112     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.01        |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.000975    |
|    std                  | 0.73        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 87470      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.03550808 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.78      |
|    explained_variance   | 0.0644     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.389      |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.00605    |
|    std                  | 0.726      |
|    value_loss           | 1.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 87676       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.039884947 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | 0.309       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 1540        |
|    policy_gradient_loss | 0.00449     |
|    std                  | 0.728       |
|    value_loss           | 1.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 87881       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.030350296 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | 0.311       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.518       |
|    n_updates            | 1550        |
|    policy_gradient_loss | 0.00414     |
|    std                  | 0.727       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.35 +/- 0.41
Episode length: 3600.20 +/- 0.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.03417869 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | 0.329      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.653      |
|    n_updates            | 1560       |
|    policy_gradient_loss | 0.00157    |
|    std                  | 0.721      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89887    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90092       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.040259134 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.7        |
|    explained_variance   | 0.00241     |
|    learning_rate        | 0.0003      |
|    loss                 | 188         |
|    n_updates            | 1570        |
|    policy_gradient_loss | 0.00288     |
|    std                  | 0.721       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90298       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.037291564 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.134       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.487       |
|    n_updates            | 1580        |
|    policy_gradient_loss | 0.00611     |
|    std                  | 0.716       |
|    value_loss           | 1.19        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 90503       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.059686165 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.622       |
|    n_updates            | 1590        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.713       |
|    value_loss           | 1.06        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 161        |
|    time_elapsed         | 90709      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.06064261 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.287      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.425      |
|    n_updates            | 1600       |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.715      |
|    value_loss           | 0.983      |
----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.80 +/- 0.11
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.040398538 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.269       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.85        |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00891     |
|    std                  | 0.713       |
|    value_loss           | 1.31        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92715    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 163         |
|    time_elapsed         | 92920       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.024735559 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | 0.000716    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.45        |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.000207   |
|    std                  | 0.713       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93125       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.041986205 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | -1.68       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.677       |
|    n_updates            | 1630        |
|    policy_gradient_loss | 0.00631     |
|    std                  | 0.708       |
|    value_loss           | 2.94        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93331       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.059645955 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | 0.328       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.516       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.705       |
|    value_loss           | 0.93        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 93536      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.04078417 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | -4.65      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18       |
|    n_updates            | 1650       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.702      |
|    value_loss           | 1.84       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.78 +/- 0.07
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 340000    |
| train/                  |           |
|    approx_kl            | 0.0448654 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.47     |
|    explained_variance   | 0.312     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.777     |
|    n_updates            | 1660      |
|    policy_gradient_loss | 0.00415   |
|    std                  | 0.702     |
|    value_loss           | 1.23      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95542    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 168        |
|    time_elapsed         | 95748      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.04334703 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.47      |
|    explained_variance   | -0.00389   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.00229    |
|    std                  | 0.702      |
|    value_loss           | 1.03e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 95954       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.065278366 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | 0.279       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.513       |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.00633     |
|    std                  | 0.701       |
|    value_loss           | 1.17        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 96160      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.04555829 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.249      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.987      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.7        |
|    value_loss           | 1.53       |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.74 +/- 0.12
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.050993092 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.366       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.419       |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.00492     |
|    std                  | 0.701       |
|    value_loss           | 1.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98166    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98371       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.020061608 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | -0.000449   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.11        |
|    n_updates            | 1710        |
|    policy_gradient_loss | 0.00494     |
|    std                  | 0.702       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 98576       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.061525013 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.596       |
|    n_updates            | 1720        |
|    policy_gradient_loss | 0.00706     |
|    std                  | 0.702       |
|    value_loss           | 1.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 98782       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.051446274 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | 0.298       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.558       |
|    n_updates            | 1730        |
|    policy_gradient_loss | 0.00425     |
|    std                  | 0.699       |
|    value_loss           | 1.3         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 98989      |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.05495403 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.47       |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.696      |
|    value_loss           | 1.21       |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.90 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.042418644 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.391       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.604       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.694       |
|    value_loss           | 0.922       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 100995   |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 177        |
|    time_elapsed         | 101200     |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.04346788 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.39      |
|    explained_variance   | 0.00176    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.69e+03   |
|    n_updates            | 1760       |
|    policy_gradient_loss | 0.00209    |
|    std                  | 0.695      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 101406     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.18622315 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.39      |
|    explained_variance   | 0.168      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.33       |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.695      |
|    value_loss           | 0.942      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 101612     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.05851204 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | 0.414      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.639      |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.0065     |
|    std                  | 0.69       |
|    value_loss           | 1.07       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 101817      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.048547745 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | 0.447       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.43        |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.00914     |
|    std                  | 0.688       |
|    value_loss           | 0.822       |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.74 +/- 0.10
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.036517143 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | -4.25       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.00454     |
|    std                  | 0.685       |
|    value_loss           | 1.94        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103823   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104029      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.043315195 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | -0.000873   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.02        |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00251    |
|    std                  | 0.685       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 104234      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.056408726 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.0804      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.703       |
|    n_updates            | 1820        |
|    policy_gradient_loss | 0.0172      |
|    std                  | 0.681       |
|    value_loss           | 1.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 104439      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.043883722 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.698       |
|    n_updates            | 1830        |
|    policy_gradient_loss | 0.00567     |
|    std                  | 0.684       |
|    value_loss           | 1.04        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.51e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 104645     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.04980717 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.21      |
|    explained_variance   | 0.339      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.58       |
|    n_updates            | 1840       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.678      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.84 +/- 0.10
Episode length: 3599.20 +/- 2.23
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.046095572 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.54        |
|    n_updates            | 1850        |
|    policy_gradient_loss | 0.00854     |
|    std                  | 0.675       |
|    value_loss           | 1.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106651   |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.51e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 187        |
|    time_elapsed         | 106857     |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.05093019 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.14      |
|    explained_variance   | 0.00131    |
|    learning_rate        | 0.0003     |
|    loss                 | 132        |
|    n_updates            | 1860       |
|    policy_gradient_loss | 0.00571    |
|    std                  | 0.675      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 188         |
|    time_elapsed         | 107063      |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.090636574 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.13       |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.584       |
|    n_updates            | 1870        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.673       |
|    value_loss           | 1.2         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 189        |
|    time_elapsed         | 107268     |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.10618657 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.324      |
|    n_updates            | 1880       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.671      |
|    value_loss           | 0.862      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 190         |
|    time_elapsed         | 107473      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.057692762 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.619       |
|    n_updates            | 1890        |
|    policy_gradient_loss | 0.00847     |
|    std                  | 0.67        |
|    value_loss           | 1.31        |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.81 +/- 0.07
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.078526534 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.08       |
|    explained_variance   | -1.16       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 1900        |
|    policy_gradient_loss | 0.00747     |
|    std                  | 0.667       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109479   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 109685     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.07191464 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.000807   |
|    learning_rate        | 0.0003     |
|    loss                 | 18.4       |
|    n_updates            | 1910       |
|    policy_gradient_loss | 0.00307    |
|    std                  | 0.667      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.55e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 193       |
|    time_elapsed         | 109890    |
|    total_timesteps      | 395264    |
| train/                  |           |
|    approx_kl            | 0.5515193 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.06     |
|    explained_variance   | 0.0777    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.456     |
|    n_updates            | 1920      |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.669     |
|    value_loss           | 1.2       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.55e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 194        |
|    time_elapsed         | 110096     |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.05604656 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.1       |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.692      |
|    n_updates            | 1930       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.672      |
|    value_loss           | 1.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.55e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 195        |
|    time_elapsed         | 110301     |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.05924017 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | -4.18      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.54       |
|    n_updates            | 1940       |
|    policy_gradient_loss | 0.00772    |
|    std                  | 0.672      |
|    value_loss           | 2.34       |
----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.88 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.040062733 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.231       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.988       |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.672       |
|    value_loss           | 1.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.55e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112307   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112512      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.061969243 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | -9.91e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 202         |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00755     |
|    std                  | 0.672       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.56e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 198       |
|    time_elapsed         | 112718    |
|    total_timesteps      | 405504    |
| train/                  |           |
|    approx_kl            | 0.5208522 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.1      |
|    explained_variance   | -0.00244  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.499     |
|    n_updates            | 1970      |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.668     |
|    value_loss           | 1.11      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.57e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 112923     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07225409 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.329      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.461      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.00828    |
|    std                  | 0.669      |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.57e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 200       |
|    time_elapsed         | 113128    |
|    total_timesteps      | 409600    |
| train/                  |           |
|    approx_kl            | 0.0585399 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.08     |
|    explained_variance   | -0.625    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.592     |
|    n_updates            | 1990      |
|    policy_gradient_loss | 0.00616   |
|    std                  | 0.668     |
|    value_loss           | 1.94      |
---------------------------------------
Eval num_timesteps=410000, episode_reward=-99.89 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.051567905 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.462       |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.00398     |
|    std                  | 0.665       |
|    value_loss           | 1.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.57e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115135   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 115340     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.04114496 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | -0.00222   |
|    learning_rate        | 0.0003     |
|    loss                 | 479        |
|    n_updates            | 2010       |
|    policy_gradient_loss | 0.00252    |
|    std                  | 0.665      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 115546     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.20682429 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.0663     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.604      |
|    n_updates            | 2020       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.667      |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.59e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 115753     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.04790559 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.558      |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.662      |
|    value_loss           | 1.09       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 115959      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.116368085 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.96       |
|    explained_variance   | 0.363       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 2040        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.659       |
|    value_loss           | 1.14        |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.79 +/- 0.06
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.100679666 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.92       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.456       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.00935     |
|    std                  | 0.655       |
|    value_loss           | 0.925       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 117965   |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.6e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 207        |
|    time_elapsed         | 118170     |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.05086147 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.000572   |
|    learning_rate        | 0.0003     |
|    loss                 | 265        |
|    n_updates            | 2060       |
|    policy_gradient_loss | 0.00295    |
|    std                  | 0.655      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.6e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118376     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.19245768 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | -1.96      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.764      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.655      |
|    value_loss           | 1.75       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 118582      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.074823394 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | 0.31        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.52        |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.651       |
|    value_loss           | 1.17        |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.80 +/- 0.05
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.050276272 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | -1.14       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.65        |
|    value_loss           | 1.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120588   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 120793      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.047722846 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | -0.000231   |
|    learning_rate        | 0.0003      |
|    loss                 | 94.4        |
|    n_updates            | 2100        |
|    policy_gradient_loss | 0.00744     |
|    std                  | 0.65        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 212        |
|    time_elapsed         | 120999     |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.07487212 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | 0.173      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.696      |
|    n_updates            | 2110       |
|    policy_gradient_loss | 0.00794    |
|    std                  | 0.651      |
|    value_loss           | 1.58       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121204      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.050231464 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.81       |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.0168      |
|    std                  | 0.647       |
|    value_loss           | 1.19        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.62e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 121410     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.06443547 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.78      |
|    explained_variance   | 0.264      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.717      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.00818    |
|    std                  | 0.646      |
|    value_loss           | 1.34       |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.84 +/- 0.06
Episode length: 3598.80 +/- 4.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.06714584 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.276      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.494      |
|    n_updates            | 2140       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.643      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.62e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123416   |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.62e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 216        |
|    time_elapsed         | 123621     |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.06880279 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.000824   |
|    learning_rate        | 0.0003     |
|    loss                 | 834        |
|    n_updates            | 2150       |
|    policy_gradient_loss | 0.00638    |
|    std                  | 0.642      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.63e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 217        |
|    time_elapsed         | 123826     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.06761564 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.109      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.502      |
|    n_updates            | 2160       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.643      |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.63e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 124032     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.07013021 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.74      |
|    explained_variance   | 0.41       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.495      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.643      |
|    value_loss           | 0.977      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 219        |
|    time_elapsed         | 124237     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.04268864 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 0.4        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.437      |
|    n_updates            | 2180       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.639      |
|    value_loss           | 0.969      |
----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.78 +/- 0.08
Episode length: 3599.40 +/- 1.96
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.055258226 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.69       |
|    explained_variance   | 0.399       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.346       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.0069      |
|    std                  | 0.638       |
|    value_loss           | 0.951       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126244   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 126449      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.078115955 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.68       |
|    explained_variance   | 0.0007      |
|    learning_rate        | 0.0003      |
|    loss                 | 44.7        |
|    n_updates            | 2200        |
|    policy_gradient_loss | 0.00515     |
|    std                  | 0.639       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 126655      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.056982607 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 2210        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.634       |
|    value_loss           | 1.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 126860      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.054064512 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | -6.48       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.753       |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.00533     |
|    std                  | 0.635       |
|    value_loss           | 1.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127065      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.072189644 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.551       |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.0191      |
|    std                  | 0.637       |
|    value_loss           | 1.11        |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.81 +/- 0.10
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.057104334 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.66       |
|    explained_variance   | 0.35        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.45        |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.0195      |
|    std                  | 0.638       |
|    value_loss           | 0.865       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.65e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129074   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 129280      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.042221062 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | -0.0182     |
|    learning_rate        | 0.0003      |
|    loss                 | 31.5        |
|    n_updates            | 2250        |
|    policy_gradient_loss | 0.00847     |
|    std                  | 0.638       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.66e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 227       |
|    time_elapsed         | 129485    |
|    total_timesteps      | 464896    |
| train/                  |           |
|    approx_kl            | 0.1622134 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.67     |
|    explained_variance   | 0.294     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.321     |
|    n_updates            | 2260      |
|    policy_gradient_loss | 0.0309    |
|    std                  | 0.638     |
|    value_loss           | 0.834     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 129691     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.05853671 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.65      |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.41       |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.635      |
|    value_loss           | 0.882      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 129896      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.066244096 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | 0.425       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.357       |
|    n_updates            | 2280        |
|    policy_gradient_loss | 0.0185      |
|    std                  | 0.635       |
|    value_loss           | 0.703       |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.78 +/- 0.05
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.070433185 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.64       |
|    explained_variance   | 0.274       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.000311   |
|    std                  | 0.636       |
|    value_loss           | 0.883       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131902   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 132107      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.033567946 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | -0.00105    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.68e+03    |
|    n_updates            | 2300        |
|    policy_gradient_loss | 0.00603     |
|    std                  | 0.637       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 132313     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.25839588 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | 0.114      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.416      |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.636      |
|    value_loss           | 0.887      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 132518     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.07198637 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | -0.496     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.352      |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.00928    |
|    std                  | 0.635      |
|    value_loss           | 0.621      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 132724     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.07540877 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | 0.424      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.35       |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.634      |
|    value_loss           | 0.724      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.78 +/- 0.07
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.04048358 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.375      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.417      |
|    n_updates            | 2340       |
|    policy_gradient_loss | 0.00656    |
|    std                  | 0.631      |
|    value_loss           | 0.887      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134730   |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 236        |
|    time_elapsed         | 134935     |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.04305501 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.000795   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.54e+03   |
|    n_updates            | 2350       |
|    policy_gradient_loss | 0.00343    |
|    std                  | 0.633      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 135141     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.07503913 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | 0.138      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.454      |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.633      |
|    value_loss           | 1.06       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 135346      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.042353667 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | -4.3        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.52        |
|    n_updates            | 2370        |
|    policy_gradient_loss | 0.00678     |
|    std                  | 0.629       |
|    value_loss           | 1.5         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135552     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.09057905 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.54      |
|    explained_variance   | 0.341      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.443      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.63       |
|    value_loss           | 1.04       |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.78 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.075046256 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.54       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.444       |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.629       |
|    value_loss           | 0.848       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137559   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 137764     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.04244236 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | 0.000552   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.52e+03   |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.00103   |
|    std                  | 0.629      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 137970     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.15075517 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | 0.197      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.518      |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.63       |
|    value_loss           | 0.79       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 138175      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.054873414 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.393       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.334       |
|    n_updates            | 2420        |
|    policy_gradient_loss | 0.0199      |
|    std                  | 0.627       |
|    value_loss           | 0.781       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 138380      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.080035135 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.49       |
|    explained_variance   | 0.0177      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.604       |
|    n_updates            | 2430        |
|    policy_gradient_loss | 0.0248      |
|    std                  | 0.624       |
|    value_loss           | 0.982       |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.65 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.07892882 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.49      |
|    explained_variance   | 0.376      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.374      |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.626      |
|    value_loss           | 0.893      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140386   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.72e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 140592     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.09788561 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | 0.00129    |
|    learning_rate        | 0.0003     |
|    loss                 | 37.2       |
|    n_updates            | 2450       |
|    policy_gradient_loss | 0.000984   |
|    std                  | 0.625      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.72e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 140797     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.10330193 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | -4.25      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.592      |
|    n_updates            | 2460       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.625      |
|    value_loss           | 1.77       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 141002      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.052799165 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.46       |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 2470        |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.622       |
|    value_loss           | 1.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141208      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.052361976 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.45       |
|    explained_variance   | -0.0515     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.333       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.00872     |
|    std                  | 0.622       |
|    value_loss           | 1.05        |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.77 +/- 0.07
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 510000    |
| train/                  |           |
|    approx_kl            | 0.0365106 |
|    clip_fraction        | 0.357     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.45     |
|    explained_variance   | 0.42      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.297     |
|    n_updates            | 2490      |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.622     |
|    value_loss           | 0.726     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.72e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143215   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 143421      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.061192427 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.45       |
|    explained_variance   | 0.000105    |
|    learning_rate        | 0.0003      |
|    loss                 | 43.8        |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.00595     |
|    std                  | 0.623       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 143626     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.08193606 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.431      |
|    n_updates            | 2510       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.621      |
|    value_loss           | 0.965      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 143831      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.059680607 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.551       |
|    n_updates            | 2520        |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.621       |
|    value_loss           | 0.797       |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.76 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.045856383 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | -4.53       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.491       |
|    n_updates            | 2530        |
|    policy_gradient_loss | 0.00824     |
|    std                  | 0.622       |
|    value_loss           | 2.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145837   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146043      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.023755226 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | -0.00205    |
|    learning_rate        | 0.0003      |
|    loss                 | 109         |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00338    |
|    std                  | 0.621       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.74e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 256       |
|    time_elapsed         | 146248    |
|    total_timesteps      | 524288    |
| train/                  |           |
|    approx_kl            | 0.0762025 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.42     |
|    explained_variance   | 0.0567    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.418     |
|    n_updates            | 2550      |
|    policy_gradient_loss | 0.019     |
|    std                  | 0.619     |
|    value_loss           | 1.03      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 146453      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.057072893 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.4        |
|    explained_variance   | 0.432       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.332       |
|    n_updates            | 2560        |
|    policy_gradient_loss | 0.0181      |
|    std                  | 0.617       |
|    value_loss           | 0.658       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 146659      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.044106156 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.39       |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.381       |
|    n_updates            | 2570        |
|    policy_gradient_loss | 0.00145     |
|    std                  | 0.617       |
|    value_loss           | 0.771       |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.75 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.061652455 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.38       |
|    explained_variance   | -2.6        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.302       |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.0175      |
|    std                  | 0.615       |
|    value_loss           | 0.848       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148665   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.74e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 148871     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.07958189 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.000992   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.89       |
|    n_updates            | 2590       |
|    policy_gradient_loss | 0.00458    |
|    std                  | 0.615      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 149076     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.13478123 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | 0.212      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.386      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.614      |
|    value_loss           | 0.856      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 262        |
|    time_elapsed         | 149281     |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.05125973 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | -1.16      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.376      |
|    n_updates            | 2610       |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.613      |
|    value_loss           | 3.66       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 263        |
|    time_elapsed         | 149487     |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.06114754 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.369      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.359      |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.613      |
|    value_loss           | 0.826      |
----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.69 +/- 0.05
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.08322402 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | -0.679     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.383      |
|    n_updates            | 2630       |
|    policy_gradient_loss | 0.00391    |
|    std                  | 0.613      |
|    value_loss           | 0.989      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151493   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 265        |
|    time_elapsed         | 151698     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.04166112 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | -0.00111   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.59e+03   |
|    n_updates            | 2640       |
|    policy_gradient_loss | 0.00214    |
|    std                  | 0.614      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 151903     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.06984371 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.221      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.409      |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0228     |
|    std                  | 0.612      |
|    value_loss           | 0.826      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 152109     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.13386309 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | 0.373      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.648      |
|    n_updates            | 2660       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.61       |
|    value_loss           | 0.876      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 152314      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.053952202 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.376       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.375       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.609       |
|    value_loss           | 0.809       |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.71 +/- 0.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.059315287 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.3        |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.355       |
|    n_updates            | 2680        |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.611       |
|    value_loss           | 0.602       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154320   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 154525      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.061707973 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.000536    |
|    learning_rate        | 0.0003      |
|    loss                 | 463         |
|    n_updates            | 2690        |
|    policy_gradient_loss | 0.0038      |
|    std                  | 0.61        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 154731     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.08358768 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.057      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.424      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.608      |
|    value_loss           | 0.917      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 154936     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.09771847 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.26      |
|    explained_variance   | 0.214      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.401      |
|    n_updates            | 2710       |
|    policy_gradient_loss | 0.00735    |
|    std                  | 0.606      |
|    value_loss           | 0.862      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 155142     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.06284387 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | 0.386      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.492      |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.607      |
|    value_loss           | 0.918      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.72 +/- 0.07
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.058741532 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.397       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.522       |
|    n_updates            | 2730        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.606       |
|    value_loss           | 0.853       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157149   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 157354     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.04193954 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | 0.000251   |
|    learning_rate        | 0.0003     |
|    loss                 | 723        |
|    n_updates            | 2740       |
|    policy_gradient_loss | 0.00374    |
|    std                  | 0.607      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.78e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 157559     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.07984139 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.22      |
|    explained_variance   | 0.302      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.31       |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.602      |
|    value_loss           | 0.845      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 157765      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.059078664 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | 0.394       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.0163      |
|    std                  | 0.601       |
|    value_loss           | 0.877       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 157970      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.070211045 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.493       |
|    n_updates            | 2770        |
|    policy_gradient_loss | 0.0174      |
|    std                  | 0.597       |
|    value_loss           | 0.984       |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.76 +/- 0.09
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.070167325 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.0162      |
|    std                  | 0.597       |
|    value_loss           | 0.843       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 159976   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160182      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.034818746 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | -0.00113    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.62        |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.00456     |
|    std                  | 0.597       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.78e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 160387     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.06301587 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.15      |
|    explained_variance   | 0.147      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.524      |
|    n_updates            | 2800       |
|    policy_gradient_loss | 0.0295     |
|    std                  | 0.598      |
|    value_loss           | 0.973      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 160593      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.064327374 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.15       |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.412       |
|    n_updates            | 2810        |
|    policy_gradient_loss | 0.0162      |
|    std                  | 0.597       |
|    value_loss           | 0.879       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 160798     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.08648291 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.13      |
|    explained_variance   | 0.366      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.416      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.596      |
|    value_loss           | 0.856      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.72 +/- 0.08
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.05803587 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 0.46       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.287      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.595      |
|    value_loss           | 0.652      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162804   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163009      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.052939244 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | -0.00111    |
|    learning_rate        | 0.0003      |
|    loss                 | 130         |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.00205    |
|    std                  | 0.595       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 163215     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.23590198 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | -0.215     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.617      |
|    n_updates            | 2850       |
|    policy_gradient_loss | 0.00648    |
|    std                  | 0.595      |
|    value_loss           | 1.2        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 287         |
|    time_elapsed         | 163420      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.046038598 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.471       |
|    n_updates            | 2860        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.592       |
|    value_loss           | 0.775       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 288         |
|    time_elapsed         | 163625      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.053692136 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.09       |
|    explained_variance   | 0.366       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 2870        |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.594       |
|    value_loss           | 0.953       |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.74 +/- 0.08
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.04000996 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.335      |
|    n_updates            | 2880       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.594      |
|    value_loss           | 0.881      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165631   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 165837      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.029593855 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.11       |
|    explained_variance   | 0.00102     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.46        |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.594       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166042     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.08923951 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.13      |
|    explained_variance   | 0.14       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.329      |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.597      |
|    value_loss           | 0.756      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 166247     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.14659396 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.284      |
|    n_updates            | 2910       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.597      |
|    value_loss           | 0.712      |
----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.67 +/- 0.10
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.072956756 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.595       |
|    n_updates            | 2920        |
|    policy_gradient_loss | 0.0268      |
|    std                  | 0.595       |
|    value_loss           | 0.836       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168253   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168459      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.069622844 |
|    clip_fraction        | 0.433       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.11       |
|    explained_variance   | 8.01e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78e+03    |
|    n_updates            | 2930        |
|    policy_gradient_loss | 0.00887     |
|    std                  | 0.594       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 168664     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.13384402 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.1       |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 2940       |
|    policy_gradient_loss | 0.0386     |
|    std                  | 0.593      |
|    value_loss           | 0.995      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 168871     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.07504619 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.57       |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.0201     |
|    std                  | 0.591      |
|    value_loss           | 1.03       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 297         |
|    time_elapsed         | 169076      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.046980247 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.03       |
|    explained_variance   | 0.303       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 2960        |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.586       |
|    value_loss           | 0.989       |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.75 +/- 0.07
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.08247179 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | -1.54      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.363      |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.582      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171082   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 171287      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.059009276 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.94       |
|    explained_variance   | -9.18e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 130         |
|    n_updates            | 2980        |
|    policy_gradient_loss | 0.00534     |
|    std                  | 0.583       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171493     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.30342424 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.143      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.454      |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.0284     |
|    std                  | 0.582      |
|    value_loss           | 1.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 171698      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.113234684 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.92       |
|    explained_variance   | -0.793      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.579       |
|    value_loss           | 0.988       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 171904      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.045748793 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.91       |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.357       |
|    n_updates            | 3010        |
|    policy_gradient_loss | 0.0146      |
|    std                  | 0.58        |
|    value_loss           | 0.829       |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.70 +/- 0.09
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.058547925 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.86       |
|    explained_variance   | -5.98       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 3020        |
|    policy_gradient_loss | 0.0072      |
|    std                  | 0.574       |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 173909   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 174115     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.06546898 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.82      |
|    explained_variance   | -0.00109   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.24e+03   |
|    n_updates            | 3030       |
|    policy_gradient_loss | 0.00109    |
|    std                  | 0.573      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.82e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 174321    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 0.1621097 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.8      |
|    explained_variance   | 0.0126    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.309     |
|    n_updates            | 3040      |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.572     |
|    value_loss           | 1.14      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 306         |
|    time_elapsed         | 174527      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.107452996 |
|    clip_fraction        | 0.45        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.377       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.423       |
|    n_updates            | 3050        |
|    policy_gradient_loss | 0.0299      |
|    std                  | 0.576       |
|    value_loss           | 0.885       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 174733     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.06884605 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.396      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.474      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.576      |
|    value_loss           | 0.863      |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.80 +/- 0.12
Episode length: 3600.00 +/- 2.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 630000    |
| train/                  |           |
|    approx_kl            | 0.1158113 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.84     |
|    explained_variance   | 0.317     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.579     |
|    n_updates            | 3070      |
|    policy_gradient_loss | 0.0145    |
|    std                  | 0.576     |
|    value_loss           | 0.879     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176739   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 176944     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.16349158 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | -0.00293   |
|    learning_rate        | 0.0003     |
|    loss                 | 8.68       |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00815    |
|    std                  | 0.578      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.83e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 310       |
|    time_elapsed         | 177150    |
|    total_timesteps      | 634880    |
| train/                  |           |
|    approx_kl            | 0.6768376 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.84     |
|    explained_variance   | -0.123    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.431     |
|    n_updates            | 3090      |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.574     |
|    value_loss           | 0.845     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 177355      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.078437045 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | 0.344       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.38        |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.0211      |
|    std                  | 0.574       |
|    value_loss           | 0.915       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 312        |
|    time_elapsed         | 177561     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.19403937 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.8       |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.366      |
|    n_updates            | 3110       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.572      |
|    value_loss           | 0.685      |
----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.72 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.049711138 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.79       |
|    explained_variance   | 0.377       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 3120        |
|    policy_gradient_loss | 0.0166      |
|    std                  | 0.572       |
|    value_loss           | 0.826       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179567   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 179773     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.06219911 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.000551   |
|    learning_rate        | 0.0003     |
|    loss                 | 49.4       |
|    n_updates            | 3130       |
|    policy_gradient_loss | 0.00673    |
|    std                  | 0.572      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 315         |
|    time_elapsed         | 179978      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.069809556 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 3140        |
|    policy_gradient_loss | 0.0176      |
|    std                  | 0.57        |
|    value_loss           | 0.928       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 180184      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.072482295 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.75       |
|    explained_variance   | 0.417       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.391       |
|    n_updates            | 3150        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.568       |
|    value_loss           | 0.75        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 180389     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.10643292 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.398      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.529      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.565      |
|    value_loss           | 0.904      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.72 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.08854371 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.66      |
|    explained_variance   | 0.332      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.441      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.562      |
|    value_loss           | 0.987      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182395   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182600      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.040559404 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.65       |
|    explained_variance   | -0.000997   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.45e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.0097      |
|    std                  | 0.562       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 320        |
|    time_elapsed         | 182806     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.07978437 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.64      |
|    explained_variance   | 0.245      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.376      |
|    n_updates            | 3190       |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.56       |
|    value_loss           | 0.965      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 183011     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.04599678 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.393      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.226      |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.558      |
|    value_loss           | 0.733      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 322         |
|    time_elapsed         | 183216      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.075181305 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 3210        |
|    policy_gradient_loss | 0.0231      |
|    std                  | 0.556       |
|    value_loss           | 0.882       |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.75 +/- 0.04
Episode length: 3599.60 +/- 1.96
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 660000    |
| train/                  |           |
|    approx_kl            | 0.0823092 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.56     |
|    explained_variance   | 0.431     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.527     |
|    n_updates            | 3220      |
|    policy_gradient_loss | 0.0108    |
|    std                  | 0.555     |
|    value_loss           | 0.902     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185223   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 185428     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.08417082 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | 0.000273   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+03   |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.00332    |
|    std                  | 0.555      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 185633     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.07615296 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.201      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.357      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.554      |
|    value_loss           | 0.831      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 185839     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.09870664 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.312      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.553      |
|    value_loss           | 0.66       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 327         |
|    time_elapsed         | 186047      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.081118196 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.5        |
|    explained_variance   | 0.405       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.424       |
|    n_updates            | 3260        |
|    policy_gradient_loss | 0.00902     |
|    std                  | 0.55        |
|    value_loss           | 0.918       |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.68 +/- 0.12
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.05569812 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.5       |
|    explained_variance   | 0.476      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 3270       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.552      |
|    value_loss           | 0.799      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188054   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 188259      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.076051764 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.51       |
|    explained_variance   | -0.00158    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.59        |
|    n_updates            | 3280        |
|    policy_gradient_loss | 0.00121     |
|    std                  | 0.552       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 188464     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.10283145 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.47      |
|    explained_variance   | 0.185      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.284      |
|    n_updates            | 3290       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.548      |
|    value_loss           | 0.765      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188670     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.16540222 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.45      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.534      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0397     |
|    std                  | 0.548      |
|    value_loss           | 0.761      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 332         |
|    time_elapsed         | 188875      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.097950466 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.45       |
|    explained_variance   | -0.485      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.378       |
|    n_updates            | 3310        |
|    policy_gradient_loss | 0.00578     |
|    std                  | 0.547       |
|    value_loss           | 0.847       |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.69 +/- 0.03
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.06529913 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.44      |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.548      |
|    value_loss           | 0.617      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190881   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 334         |
|    time_elapsed         | 191087      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.050872244 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.45       |
|    explained_variance   | -0.0204     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.73        |
|    n_updates            | 3330        |
|    policy_gradient_loss | 0.00507     |
|    std                  | 0.548       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 335         |
|    time_elapsed         | 191292      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.080834955 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.43       |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.351       |
|    n_updates            | 3340        |
|    policy_gradient_loss | 0.0172      |
|    std                  | 0.545       |
|    value_loss           | 0.84        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 191498     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.28869042 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.447      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.545      |
|    value_loss           | 0.6        |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.76 +/- 0.06
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.045678258 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.39       |
|    explained_variance   | 0.375       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.0147      |
|    std                  | 0.544       |
|    value_loss           | 0.922       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193504   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 193709      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.066418886 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.39       |
|    explained_variance   | -0.00122    |
|    learning_rate        | 0.0003      |
|    loss                 | 31.7        |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00081    |
|    std                  | 0.545       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 193916     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.23971999 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.125      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.389      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.543      |
|    value_loss           | 0.927      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 194121     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.35793948 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.34      |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.345      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.54       |
|    value_loss           | 0.893      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 194327      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.117580704 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.33       |
|    explained_variance   | 0.497       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.459       |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.0216      |
|    std                  | 0.54        |
|    value_loss           | 0.699       |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.42 +/- 0.42
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.06981164 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.32      |
|    explained_variance   | 0.429      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.486      |
|    n_updates            | 3410       |
|    policy_gradient_loss | 0.00972    |
|    std                  | 0.539      |
|    value_loss           | 0.889      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196332   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 196538      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.043627605 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.32       |
|    explained_variance   | -0.00111    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.53e+03    |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.00528    |
|    std                  | 0.539       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 196744     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.32419658 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.29      |
|    explained_variance   | -0.0132    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.309      |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.536      |
|    value_loss           | 0.791      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 196949     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.12859571 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | -1.72      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.57       |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.537      |
|    value_loss           | 3.76       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 197155      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.064865306 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.206       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.666       |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.533       |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.70 +/- 0.09
Episode length: 3597.40 +/- 6.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.14899087 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.21      |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.585      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.53       |
|    value_loss           | 1.33       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199160   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 199366     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.07534764 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.18      |
|    explained_variance   | -0.00112   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+03   |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.00595   |
|    std                  | 0.53       |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.86e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 349       |
|    time_elapsed         | 199571    |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 0.3671709 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.16     |
|    explained_variance   | -0.0491   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.347     |
|    n_updates            | 3480      |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.528     |
|    value_loss           | 0.884     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 199777     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.08705507 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.13      |
|    explained_variance   | 0.434      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.384      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.525      |
|    value_loss           | 0.764      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 199982     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.07228646 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.07      |
|    explained_variance   | 0.45       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.336      |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.521      |
|    value_loss           | 0.701      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.75 +/- 0.08
Episode length: 3600.00 +/- 1.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.09666916 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.04      |
|    explained_variance   | 0.268      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.509      |
|    n_updates            | 3510       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.52       |
|    value_loss           | 0.976      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 201991   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 202196      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.120952815 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.03       |
|    explained_variance   | 0.00107     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.76        |
|    n_updates            | 3520        |
|    policy_gradient_loss | 0.00883     |
|    std                  | 0.52        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 202401    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.4017775 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.04     |
|    explained_variance   | -0.137    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.637     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.521     |
|    value_loss           | 1.24      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 202607     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.18010908 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | -4.81      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.634      |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.52       |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 356       |
|    time_elapsed         | 202812    |
|    total_timesteps      | 729088    |
| train/                  |           |
|    approx_kl            | 0.1024321 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.03     |
|    explained_variance   | 0.423     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.397     |
|    n_updates            | 3550      |
|    policy_gradient_loss | 0.0209    |
|    std                  | 0.519     |
|    value_loss           | 0.773     |
---------------------------------------
Eval num_timesteps=730000, episode_reward=-99.67 +/- 0.09
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.059989303 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6          |
|    explained_variance   | 0.403       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.365       |
|    n_updates            | 3560        |
|    policy_gradient_loss | 0.0186      |
|    std                  | 0.518       |
|    value_loss           | 0.845       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204818   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205024      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.055752575 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.00051     |
|    learning_rate        | 0.0003      |
|    loss                 | 216         |
|    n_updates            | 3570        |
|    policy_gradient_loss | 0.00396     |
|    std                  | 0.519       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 359       |
|    time_elapsed         | 205229    |
|    total_timesteps      | 735232    |
| train/                  |           |
|    approx_kl            | 0.7993076 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.01     |
|    explained_variance   | -0.308    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.351     |
|    n_updates            | 3580      |
|    policy_gradient_loss | 0.0158    |
|    std                  | 0.518     |
|    value_loss           | 0.891     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 205435      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.047241807 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -6          |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.486       |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.0197      |
|    std                  | 0.518       |
|    value_loss           | 0.847       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 205640     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.10194355 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.254      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.478      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.517      |
|    value_loss           | 0.83       |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.44 +/- 0.40
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.11573544 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.344      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.515      |
|    value_loss           | 0.85       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207646   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 207851      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.035268977 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.94       |
|    explained_variance   | 0.000723    |
|    learning_rate        | 0.0003      |
|    loss                 | 10.7        |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.00141    |
|    std                  | 0.515       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 364        |
|    time_elapsed         | 208058     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.17038202 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.93      |
|    explained_variance   | -0.315     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.391      |
|    n_updates            | 3630       |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.513      |
|    value_loss           | 0.893      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 208264     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.07893509 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.515      |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.0092     |
|    std                  | 0.513      |
|    value_loss           | 1          |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 366       |
|    time_elapsed         | 208469    |
|    total_timesteps      | 749568    |
| train/                  |           |
|    approx_kl            | 0.1808295 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.91     |
|    explained_variance   | 0.417     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.328     |
|    n_updates            | 3650      |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.513     |
|    value_loss           | 0.758     |
---------------------------------------
Eval num_timesteps=750000, episode_reward=-97.91 +/- 1.21
Episode length: 3598.20 +/- 3.92
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -97.9      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.08981284 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.514      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210475   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 210681     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.04505993 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | 0.000496   |
|    learning_rate        | 0.0003     |
|    loss                 | 12.7       |
|    n_updates            | 3670       |
|    policy_gradient_loss | 0.00103    |
|    std                  | 0.514      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 369         |
|    time_elapsed         | 210886      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.043857485 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.93       |
|    explained_variance   | -0.757      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 3680        |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.514       |
|    value_loss           | 1.26        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 211092     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.12479778 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.487      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.515      |
|    value_loss           | 0.819      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 211297     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.06840569 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.94      |
|    explained_variance   | 0.293      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.515      |
|    value_loss           | 0.906      |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.72 +/- 0.10
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.07925595 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.93      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.445      |
|    n_updates            | 3710       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.514      |
|    value_loss           | 0.801      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213303   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 213508     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.07871094 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.93      |
|    explained_variance   | -0.00288   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.43       |
|    n_updates            | 3720       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.514      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 374       |
|    time_elapsed         | 213715    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 0.1550859 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.95     |
|    explained_variance   | -0.683    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.419     |
|    n_updates            | 3730      |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.517     |
|    value_loss           | 1.24      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.87e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 375      |
|    time_elapsed         | 213921   |
|    total_timesteps      | 768000   |
| train/                  |          |
|    approx_kl            | 0.117997 |
|    clip_fraction        | 0.462    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.95    |
|    explained_variance   | 0.409    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.455    |
|    n_updates            | 3740     |
|    policy_gradient_loss | 0.023    |
|    std                  | 0.515    |
|    value_loss           | 0.88     |
--------------------------------------
Eval num_timesteps=770000, episode_reward=-97.46 +/- 1.17
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -97.5      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.07176234 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.93      |
|    explained_variance   | 0.318      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.41       |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.513      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 215927   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216132      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.030115534 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.91       |
|    explained_variance   | 0.000547    |
|    learning_rate        | 0.0003      |
|    loss                 | 236         |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00735     |
|    std                  | 0.513       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 378         |
|    time_elapsed         | 216337      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.075074516 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.91       |
|    explained_variance   | 0.0807      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 3770        |
|    policy_gradient_loss | 0.0136      |
|    std                  | 0.513       |
|    value_loss           | 0.785       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 379         |
|    time_elapsed         | 216543      |
|    total_timesteps      | 776192      |
| train/                  |             |
|    approx_kl            | 0.063507065 |
|    clip_fraction        | 0.452       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.91       |
|    explained_variance   | 0.416       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.346       |
|    n_updates            | 3780        |
|    policy_gradient_loss | 0.0228      |
|    std                  | 0.513       |
|    value_loss           | 0.733       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 380         |
|    time_elapsed         | 216748      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.057686616 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.335       |
|    n_updates            | 3790        |
|    policy_gradient_loss | 0.00838     |
|    std                  | 0.51        |
|    value_loss           | 0.739       |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=-98.68 +/- 1.67
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.7      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.05212588 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.85      |
|    explained_variance   | 0.213      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.42       |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.0064     |
|    std                  | 0.508      |
|    value_loss           | 0.896      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218754   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 218959     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.03556338 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.00175    |
|    learning_rate        | 0.0003     |
|    loss                 | 694        |
|    n_updates            | 3810       |
|    policy_gradient_loss | 0.00318    |
|    std                  | 0.509      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.88e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 383       |
|    time_elapsed         | 219165    |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 0.6398219 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.85     |
|    explained_variance   | 0.128     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.5       |
|    n_updates            | 3820      |
|    policy_gradient_loss | 0.0205    |
|    std                  | 0.509     |
|    value_loss           | 0.868     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 219370     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.26919138 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.466      |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.509      |
|    value_loss           | 1.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 219575     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.10697015 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.83      |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.323      |
|    n_updates            | 3840       |
|    policy_gradient_loss | 0.00986    |
|    std                  | 0.509      |
|    value_loss           | 0.639      |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.73 +/- 0.15
Episode length: 3599.80 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.08173354 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.82      |
|    explained_variance   | -0.981     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.32       |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.506      |
|    value_loss           | 1.38       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221582   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 387        |
|    time_elapsed         | 221787     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.08358515 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.000584   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.73e+03   |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.00111   |
|    std                  | 0.506      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 221993     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.16931464 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.78      |
|    explained_variance   | 0.207      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.422      |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.505      |
|    value_loss           | 0.846      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.88e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 389       |
|    time_elapsed         | 222198    |
|    total_timesteps      | 796672    |
| train/                  |           |
|    approx_kl            | 0.0584521 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.79     |
|    explained_variance   | 0.449     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.421     |
|    n_updates            | 3880      |
|    policy_gradient_loss | 0.0115    |
|    std                  | 0.506     |
|    value_loss           | 0.829     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 390         |
|    time_elapsed         | 222403      |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.074435085 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.8        |
|    explained_variance   | 0.52        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.409       |
|    n_updates            | 3890        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.506       |
|    value_loss           | 0.689       |
-----------------------------------------
Eval num_timesteps=800000, episode_reward=-98.43 +/- 1.59
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.4       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.046062283 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.78       |
|    explained_variance   | 0.53        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.384       |
|    n_updates            | 3900        |
|    policy_gradient_loss | 0.0142      |
|    std                  | 0.504       |
|    value_loss           | 0.668       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224409   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 224619      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.056599565 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.77       |
|    explained_variance   | -0.000227   |
|    learning_rate        | 0.0003      |
|    loss                 | 311         |
|    n_updates            | 3910        |
|    policy_gradient_loss | 0.00198     |
|    std                  | 0.505       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 224824     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.08506037 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.77      |
|    explained_variance   | 0.00303    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.616      |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.00155    |
|    std                  | 0.505      |
|    value_loss           | 1.11       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 225029      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.076366246 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.76       |
|    explained_variance   | 0.499       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.415       |
|    n_updates            | 3930        |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.504       |
|    value_loss           | 0.83        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 225235     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.08171733 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.75      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.352      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0238     |
|    std                  | 0.504      |
|    value_loss           | 0.68       |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.03 +/- 1.29
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99         |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.051814366 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | 0.59        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.32        |
|    n_updates            | 3950        |
|    policy_gradient_loss | 0.00349     |
|    std                  | 0.502       |
|    value_loss           | 0.632       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227241   |
|    total_timesteps | 811008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.87e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 397       |
|    time_elapsed         | 227447    |
|    total_timesteps      | 813056    |
| train/                  |           |
|    approx_kl            | 0.0781652 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.72     |
|    explained_variance   | 0.00255   |
|    learning_rate        | 0.0003    |
|    loss                 | 449       |
|    n_updates            | 3960      |
|    policy_gradient_loss | 0.00306   |
|    std                  | 0.502     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 227652     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.09178379 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.72      |
|    explained_variance   | 0.213      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.00766    |
|    std                  | 0.502      |
|    value_loss           | 1.15       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 399         |
|    time_elapsed         | 227857      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.056869242 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.71       |
|    explained_variance   | -0.326      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 3980        |
|    policy_gradient_loss | 0.00787     |
|    std                  | 0.502       |
|    value_loss           | 1.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 400         |
|    time_elapsed         | 228063      |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.054495405 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.66       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.286       |
|    n_updates            | 3990        |
|    policy_gradient_loss | 0.00937     |
|    std                  | 0.497       |
|    value_loss           | 0.716       |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.27 +/- 0.72
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.047378357 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.64       |
|    explained_variance   | 0.336       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 4000        |
|    policy_gradient_loss | 0.00647     |
|    std                  | 0.498       |
|    value_loss           | 0.914       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230072   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 230278      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.043207504 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.64       |
|    explained_variance   | -0.000777   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00329    |
|    std                  | 0.497       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 230483     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.44056568 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.6       |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.423      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.494      |
|    value_loss           | 0.988      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 230689     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.09078801 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.56      |
|    explained_variance   | 0.517      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.443      |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.492      |
|    value_loss           | 0.651      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 230896     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.05924588 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.56      |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.54       |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.493      |
|    value_loss           | 0.723      |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.06 +/- 0.84
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.1     |
| time/                   |           |
|    total_timesteps      | 830000    |
| train/                  |           |
|    approx_kl            | 0.2977032 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.56     |
|    explained_variance   | 0.515     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.428     |
|    n_updates            | 4050      |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.491     |
|    value_loss           | 0.763     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 232903   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.88e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233108     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.09368469 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.55      |
|    explained_variance   | -0.000232  |
|    learning_rate        | 0.0003     |
|    loss                 | 636        |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.00469    |
|    std                  | 0.492      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 408         |
|    time_elapsed         | 233314      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.093956485 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.56       |
|    explained_variance   | 0.21        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 4070        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.493       |
|    value_loss           | 0.823       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 233519     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.07740694 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.56      |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.411      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.00751    |
|    std                  | 0.492      |
|    value_loss           | 0.815      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 410         |
|    time_elapsed         | 233724      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.045400783 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.55       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.341       |
|    n_updates            | 4090        |
|    policy_gradient_loss | 0.00543     |
|    std                  | 0.491       |
|    value_loss           | 0.792       |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-91.17 +/- 2.05
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -91.2      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.09282267 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.52      |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.337      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.49       |
|    value_loss           | 0.768      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235735   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 235941     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.07630864 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.52      |
|    explained_variance   | -0.00253   |
|    learning_rate        | 0.0003     |
|    loss                 | 163        |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.00509    |
|    std                  | 0.49       |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.89e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 413      |
|    time_elapsed         | 236146   |
|    total_timesteps      | 845824   |
| train/                  |          |
|    approx_kl            | 0.5216   |
|    clip_fraction        | 0.444    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.51    |
|    explained_variance   | 0.107    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.595    |
|    n_updates            | 4120     |
|    policy_gradient_loss | 0.00876  |
|    std                  | 0.488    |
|    value_loss           | 1.08     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 414        |
|    time_elapsed         | 236351     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.06255165 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.5       |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.56       |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.00386    |
|    std                  | 0.49       |
|    value_loss           | 1.12       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 415         |
|    time_elapsed         | 236557      |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.051676106 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.52       |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.441       |
|    n_updates            | 4140        |
|    policy_gradient_loss | 0.00603     |
|    std                  | 0.488       |
|    value_loss           | 0.937       |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-87.59 +/- 5.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -87.6       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.047874283 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.5        |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.293       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.00417     |
|    std                  | 0.488       |
|    value_loss           | 0.753       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238566   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 238772     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.10606764 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.5       |
|    explained_variance   | -0.000498  |
|    learning_rate        | 0.0003     |
|    loss                 | 679        |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.0011     |
|    std                  | 0.489      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 418         |
|    time_elapsed         | 238977      |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.069517046 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.51       |
|    explained_variance   | -1.64       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.358       |
|    n_updates            | 4170        |
|    policy_gradient_loss | 0.00163     |
|    std                  | 0.49        |
|    value_loss           | 1.18        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 239183     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.07356723 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.5       |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.627      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.00533    |
|    std                  | 0.487      |
|    value_loss           | 0.953      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.43 +/- 0.46
Episode length: 3597.00 +/- 8.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.07148151 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.48      |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.278      |
|    n_updates            | 4190       |
|    policy_gradient_loss | 0.00976    |
|    std                  | 0.486      |
|    value_loss           | 0.746      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241191   |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 421         |
|    time_elapsed         | 241397      |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.032805476 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.47       |
|    explained_variance   | -0.000824   |
|    learning_rate        | 0.0003      |
|    loss                 | 98.6        |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.487       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.9e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 422       |
|    time_elapsed         | 241603    |
|    total_timesteps      | 864256    |
| train/                  |           |
|    approx_kl            | 0.4173873 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.48     |
|    explained_variance   | 0.142     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.43      |
|    n_updates            | 4210      |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.487     |
|    value_loss           | 1.05      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 241808     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.09284053 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.48      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.339      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.488      |
|    value_loss           | 0.775      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 424         |
|    time_elapsed         | 242013      |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.053046167 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.47       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.404       |
|    n_updates            | 4230        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.486       |
|    value_loss           | 0.762       |
-----------------------------------------
Eval num_timesteps=870000, episode_reward=-96.88 +/- 1.80
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -96.9      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.07281573 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.45      |
|    explained_variance   | 0.484      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.301      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.00688    |
|    std                  | 0.486      |
|    value_loss           | 0.798      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244025   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244230     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.04902242 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | -0.00221   |
|    learning_rate        | 0.0003     |
|    loss                 | 32         |
|    n_updates            | 4250       |
|    policy_gradient_loss | 0.00685    |
|    std                  | 0.487      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 244436     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.18858205 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.43      |
|    explained_variance   | -0.0795    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.334      |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.00673    |
|    std                  | 0.484      |
|    value_loss           | 1.01       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 428         |
|    time_elapsed         | 244642      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.074127756 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.43       |
|    explained_variance   | 0.443       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.318       |
|    n_updates            | 4270        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.486       |
|    value_loss           | 0.916       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 429         |
|    time_elapsed         | 244848      |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.050770637 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.284       |
|    n_updates            | 4280        |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.486       |
|    value_loss           | 0.759       |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=-96.64 +/- 1.21
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.6       |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.075124316 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.45       |
|    explained_variance   | 0.54        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.313       |
|    n_updates            | 4290        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.487       |
|    value_loss           | 0.669       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246854   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 247063      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.054507986 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.46       |
|    explained_variance   | -0.00157    |
|    learning_rate        | 0.0003      |
|    loss                 | 152         |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.000578    |
|    std                  | 0.487       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 432        |
|    time_elapsed         | 247270     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.14033362 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.192      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.619      |
|    n_updates            | 4310       |
|    policy_gradient_loss | 0.00751    |
|    std                  | 0.487      |
|    value_loss           | 1.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 247475      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.062079556 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.51        |
|    n_updates            | 4320        |
|    policy_gradient_loss | 0.00737     |
|    std                  | 0.486       |
|    value_loss           | 0.876       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 247680     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.08266921 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | 0.477      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.482      |
|    value_loss           | 0.823      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-97.80 +/- 1.25
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -97.8      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.05487153 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.34      |
|    explained_variance   | -3.71      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.509      |
|    n_updates            | 4340       |
|    policy_gradient_loss | 0.00712    |
|    std                  | 0.48       |
|    value_loss           | 1.34       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249692   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 249898      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.030974329 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.32       |
|    explained_variance   | -0.00117    |
|    learning_rate        | 0.0003      |
|    loss                 | 17.2        |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.00289    |
|    std                  | 0.48        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.91e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 437       |
|    time_elapsed         | 250104    |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 0.7520239 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.28     |
|    explained_variance   | -0.201    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.4       |
|    n_updates            | 4360      |
|    policy_gradient_loss | 0.0226    |
|    std                  | 0.477     |
|    value_loss           | 0.97      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 250309     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.17588858 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.25      |
|    explained_variance   | 0.388      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.609      |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.476      |
|    value_loss           | 1.17       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 439         |
|    time_elapsed         | 250514      |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.084712595 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.23       |
|    explained_variance   | 0.408       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 4380        |
|    policy_gradient_loss | 0.00919     |
|    std                  | 0.475       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=-95.42 +/- 2.05
Episode length: 3597.00 +/- 8.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -95.4      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.05481895 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.22      |
|    explained_variance   | -1.87      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.622      |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.00879    |
|    std                  | 0.474      |
|    value_loss           | 1.74       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252523   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 252729      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.060941916 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.21       |
|    explained_variance   | -0.00186    |
|    learning_rate        | 0.0003      |
|    loss                 | 221         |
|    n_updates            | 4400        |
|    policy_gradient_loss | 0.00465     |
|    std                  | 0.474       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 252935     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.13401252 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.21      |
|    explained_variance   | 0.201      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.575      |
|    n_updates            | 4410       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.473      |
|    value_loss           | 1.63       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 253140     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.06528818 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.17      |
|    explained_variance   | 0.424      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.603      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.00774    |
|    std                  | 0.471      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 253345     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.08173798 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.13      |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.521      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.00919    |
|    std                  | 0.469      |
|    value_loss           | 1.38       |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-95.22 +/- 2.75
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -95.2       |
| time/                   |             |
|    total_timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.068396024 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.11       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.583       |
|    n_updates            | 4440        |
|    policy_gradient_loss | 0.00687     |
|    std                  | 0.468       |
|    value_loss           | 1.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255352   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 255557      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.031861417 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.1        |
|    explained_variance   | 0.000755    |
|    learning_rate        | 0.0003      |
|    loss                 | 804         |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.000743   |
|    std                  | 0.468       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 255763     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.64429015 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.08      |
|    explained_variance   | -0.248     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.388      |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.000325  |
|    std                  | 0.465      |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 255969     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.15556997 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.06      |
|    explained_variance   | 0.369      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.743      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.465      |
|    value_loss           | 1.27       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 256174     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.10292031 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.04      |
|    explained_variance   | 0.404      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.463      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0265     |
|    std                  | 0.463      |
|    value_loss           | 1.25       |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.42 +/- 0.36
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.11687563 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.01      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.562      |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.462      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258180   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 258386      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.047314666 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.01       |
|    explained_variance   | 0.003       |
|    learning_rate        | 0.0003      |
|    loss                 | 612         |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.000293   |
|    std                  | 0.463       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 452        |
|    time_elapsed         | 258591     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.42828792 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.01      |
|    explained_variance   | 0.138      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.565      |
|    n_updates            | 4510       |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.463      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 453        |
|    time_elapsed         | 258797     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.08365107 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.99      |
|    explained_variance   | 0.373      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.492      |
|    n_updates            | 4520       |
|    policy_gradient_loss | 0.00446    |
|    std                  | 0.46       |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 259002     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.04570944 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.94      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.48       |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.458      |
|    value_loss           | 1.1        |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-53.41 +/- 7.14
Episode length: 3597.00 +/- 8.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -53.4      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.12985784 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.94      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.359      |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.46       |
|    value_loss           | 0.862      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261013   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261219      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.046614125 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.96       |
|    explained_variance   | 0.000232    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+03    |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.00418     |
|    std                  | 0.46        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 261425     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.18554676 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.96      |
|    explained_variance   | -0.0426    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.502      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.0096     |
|    std                  | 0.46       |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 261630     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.09614823 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.95      |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.344      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.459      |
|    value_loss           | 0.924      |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-89.76 +/- 4.87
Episode length: 3598.80 +/- 4.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -89.8     |
| time/                   |           |
|    total_timesteps      | 940000    |
| train/                  |           |
|    approx_kl            | 0.0950573 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.92     |
|    explained_variance   | 0.504     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.298     |
|    n_updates            | 4580      |
|    policy_gradient_loss | 0.00712   |
|    std                  | 0.458     |
|    value_loss           | 0.973     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263639   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 263845     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.04342608 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.92      |
|    explained_variance   | -0.00016   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.08       |
|    n_updates            | 4590       |
|    policy_gradient_loss | -0.00227   |
|    std                  | 0.458      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 264052     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.23941572 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.93      |
|    explained_variance   | 0.0921     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.242      |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.458      |
|    value_loss           | 0.889      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264258     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.08638714 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.94      |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.262      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.00935    |
|    std                  | 0.459      |
|    value_loss           | 0.749      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 264463      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.098641016 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.93       |
|    explained_variance   | 0.485       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 4620        |
|    policy_gradient_loss | 0.00837     |
|    std                  | 0.458       |
|    value_loss           | 0.796       |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-55.42 +/- 3.93
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -55.4      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.06089288 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.89      |
|    explained_variance   | 0.326      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.676      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.00775    |
|    std                  | 0.456      |
|    value_loss           | 1.57       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266470   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 266676      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.029907618 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.87       |
|    explained_variance   | -0.000856   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.86        |
|    n_updates            | 4640        |
|    policy_gradient_loss | -3.54e-05   |
|    std                  | 0.456       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 266881     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.08588673 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.87      |
|    explained_variance   | 0.286      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.393      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.00885    |
|    std                  | 0.457      |
|    value_loss           | 1.05       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.92e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 467      |
|    time_elapsed         | 267087   |
|    total_timesteps      | 956416   |
| train/                  |          |
|    approx_kl            | 0.055229 |
|    clip_fraction        | 0.413    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.88    |
|    explained_variance   | 0.514    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.353    |
|    n_updates            | 4660     |
|    policy_gradient_loss | 0.0148   |
|    std                  | 0.458    |
|    value_loss           | 0.88     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.92e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 468       |
|    time_elapsed         | 267295    |
|    total_timesteps      | 958464    |
| train/                  |           |
|    approx_kl            | 0.3463822 |
|    clip_fraction        | 0.415     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.87     |
|    explained_variance   | 0.531     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.463     |
|    n_updates            | 4670      |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.457     |
|    value_loss           | 0.804     |
---------------------------------------
Eval num_timesteps=960000, episode_reward=-98.52 +/- 1.17
Episode length: 3600.00 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.5      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.09737443 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.87      |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.5        |
|    n_updates            | 4680       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.458      |
|    value_loss           | 0.866      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269303   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 269509     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.06767722 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.89      |
|    explained_variance   | 0.000413   |
|    learning_rate        | 0.0003     |
|    loss                 | 491        |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.00235   |
|    std                  | 0.459      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 269714      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.087316744 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.89       |
|    explained_variance   | 0.112       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.467       |
|    n_updates            | 4700        |
|    policy_gradient_loss | 0.00517     |
|    std                  | 0.458       |
|    value_loss           | 0.827       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 472         |
|    time_elapsed         | 269920      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.061204523 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.9        |
|    explained_variance   | 0.488       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.462       |
|    n_updates            | 4710        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.458       |
|    value_loss           | 0.861       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.92e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 473       |
|    time_elapsed         | 270125    |
|    total_timesteps      | 968704    |
| train/                  |           |
|    approx_kl            | 0.1457643 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.9      |
|    explained_variance   | 0.57      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.399     |
|    n_updates            | 4720      |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.458     |
|    value_loss           | 0.691     |
---------------------------------------
Eval num_timesteps=970000, episode_reward=-99.71 +/- 0.07
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.06667453 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.87      |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.0263     |
|    std                  | 0.455      |
|    value_loss           | 0.812      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.91e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272136   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 272343      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.075596154 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.85       |
|    explained_variance   | -0.00601    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.83        |
|    n_updates            | 4740        |
|    policy_gradient_loss | 0.000291    |
|    std                  | 0.456       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.92e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 272548    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 0.8671099 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.86     |
|    explained_variance   | -0.172    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.378     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.456     |
|    value_loss           | 0.853     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 272754     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.06455048 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.82      |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.307      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.453      |
|    value_loss           | 0.759      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 478         |
|    time_elapsed         | 272959      |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.093874365 |
|    clip_fraction        | 0.458       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.8        |
|    explained_variance   | 0.466       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.327       |
|    n_updates            | 4770        |
|    policy_gradient_loss | 0.0183      |
|    std                  | 0.453       |
|    value_loss           | 0.84        |
-----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.38 +/- 0.43
Episode length: 3595.40 +/- 9.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.05604148 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.8       |
|    explained_variance   | -0.807     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.271      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.452      |
|    value_loss           | 0.543      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 274970   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275177      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.040692173 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.79       |
|    explained_variance   | 0.0031      |
|    learning_rate        | 0.0003      |
|    loss                 | 577         |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.00191    |
|    std                  | 0.452       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 481         |
|    time_elapsed         | 275382      |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.070821956 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.78       |
|    explained_variance   | 0.0623      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.731       |
|    n_updates            | 4800        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.452       |
|    value_loss           | 1.1         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275588     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.38582176 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.79      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.362      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.453      |
|    value_loss           | 0.829      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.93e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 275793     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.43949223 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.8       |
|    explained_variance   | 0.477      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.444      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.0417     |
|    std                  | 0.454      |
|    value_loss           | 0.754      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-98.05 +/- 1.99
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98        |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.16564263 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.78      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.452      |
|    value_loss           | 0.851      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277800   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 278005     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.06761056 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.77      |
|    explained_variance   | -0.000273  |
|    learning_rate        | 0.0003     |
|    loss                 | 134        |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.00522   |
|    std                  | 0.453      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.93e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 486       |
|    time_elapsed         | 278213    |
|    total_timesteps      | 995328    |
| train/                  |           |
|    approx_kl            | 0.7554908 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.79     |
|    explained_variance   | -0.271    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.524     |
|    n_updates            | 4850      |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.453     |
|    value_loss           | 0.963     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.93e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 278418    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.0639175 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.79     |
|    explained_variance   | 0.443     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.389     |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.453     |
|    value_loss           | 0.798     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 488         |
|    time_elapsed         | 278624      |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.057926204 |
|    clip_fraction        | 0.443       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.8        |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.388       |
|    n_updates            | 4870        |
|    policy_gradient_loss | 0.0204      |
|    std                  | 0.454       |
|    value_loss           | 0.779       |
-----------------------------------------
Eval num_timesteps=1000000, episode_reward=-95.88 +/- 1.12
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -95.9       |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.058292687 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.84       |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.611       |
|    n_updates            | 4880        |
|    policy_gradient_loss | 0.0251      |
|    std                  | 0.456       |
|    value_loss           | 0.749       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.93e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280633   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-21_06-30-08_llm_triton_qwen_3b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 5:54:38 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.87542   -99.886518  -99.910473  -99.875694  -99.890062]
 [ -99.939152  -99.920072  -99.953812 -100.039404  -99.984623]
 [ -99.938752 -100.020401  -99.988464 -100.024876 -100.097312]
 [ -99.934608 -100.063749  -99.963612 -100.003527  -99.982519]
 [ -99.951071  -99.953545 -100.053842  -99.942991 -100.04197 ]
 [ -99.916342  -99.913267  -99.980716  -99.999359  -99.945891]
 [-100.018252  -99.966487  -99.956286 -100.044854  -99.986514]
 [ -99.856155  -99.903513  -99.835733  -99.852332  -99.986934]
 [ -99.875044 -100.056373 -100.04225   -99.964754 -100.038137]
 [ -99.972637  -99.946178  -99.876055  -99.903998  -99.868997]
 [ -99.885526  -99.939184  -99.966211  -99.91028   -99.951981]
 [ -99.884408  -99.966929  -99.964032  -99.933149  -99.860893]
 [ -99.861965  -99.86327   -99.880224  -99.861086  -99.971979]
 [ -99.905688  -99.941587  -99.921223  -99.828981  -99.850808]
 [ -99.928797  -99.955639  -99.927005  -99.863247  -99.940633]
 [ -99.859662  -99.942377  -99.784093  -99.907847  -99.935294]
 [ -99.973308  -99.863001  -99.758313  -99.841655  -99.852735]
 [ -99.854947  -99.820145  -99.824261  -99.916256  -99.942619]
 [ -99.927688  -99.812803  -99.90095   -99.796249  -99.807423]
 [ -99.881765  -99.92204   -99.908954  -99.977626  -99.883793]
 [ -99.710873  -99.817249  -99.714963  -99.761284  -99.783635]
 [ -99.791913  -99.919797  -99.858767  -99.864835  -99.720125]
 [ -99.839249  -99.851157  -99.638138  -99.848058  -99.855312]
 [ -99.47756   -99.73644   -99.868177  -99.919034  -99.575024]
 [ -99.833673  -99.669551  -99.828547  -99.54904   -99.564614]
 [ -99.561545  -99.657619  -99.762943  -99.693212  -99.736116]
 [ -99.574305  -99.947077  -99.695073  -99.89886   -99.725649]
 [ -99.748701  -98.610307  -98.823193  -97.714246  -99.671167]
 [ -95.738307  -97.733167  -98.632705  -98.895416  -95.637363]
 [ -96.637993  -98.862963  -98.690592  -99.724675  -99.807157]
 [ -99.006992  -99.882527  -99.654562  -97.85322   -99.868742]
 [ -99.54623   -98.910991  -98.803172  -99.758646  -99.725029]
 [ -99.930393  -99.901223  -99.83178   -99.627069  -99.724798]
 [ -99.737579  -99.699676  -99.866668  -99.725853  -99.873997]
 [ -99.757164  -99.719466  -99.951764  -99.596694  -99.680161]
 [ -99.816237  -99.855227  -99.964071  -99.936594  -99.950479]
 [ -99.587439  -99.86464   -99.678405  -99.824635  -99.720078]
 [ -99.869357  -99.935688  -99.839327  -99.661843  -99.905715]
 [ -99.891027  -99.8891    -99.800253  -99.695084  -99.77169 ]
 [ -99.866001  -99.84281   -99.927316  -99.874536  -99.871869]
 [ -99.885461  -99.770527  -99.945582  -99.840201  -99.998584]
 [ -99.76204   -99.843879  -99.688098  -99.841886  -99.792088]
 [ -99.809692  -99.759149  -99.81052   -99.740425  -99.892129]
 [ -99.759081  -99.835971  -99.822802  -99.860728  -99.930469]
 [ -99.765883  -99.935819  -99.75099   -99.768371  -99.700985]
 [ -99.908572  -99.645566  -99.908608  -99.837173  -99.732186]
 [ -99.744232  -99.717225  -99.803636  -99.852532  -99.785496]
 [ -99.694663  -99.751522  -99.913696  -99.794145  -99.738099]
 [ -99.840121  -99.84391   -99.714969  -99.731586  -99.773236]
 [ -99.684019  -99.741524  -99.561878  -99.605193  -99.645743]
 [ -99.723909  -99.880549  -99.729899  -99.697509  -99.830184]
 [ -99.768431  -99.804618  -99.772483  -99.727792  -99.723809]
 [ -99.770496  -99.705954  -99.848715  -99.740813  -99.661758]
 [ -99.633649  -99.660949  -99.784118  -99.697068  -99.66643 ]
 [ -99.720412  -99.683165  -99.88878   -99.612783  -99.647545]
 [ -99.645633  -99.801029  -99.800429  -99.669845  -99.705357]
 [ -99.75043   -99.935261  -99.691928  -99.674823  -99.737345]
 [ -99.822456  -99.816375  -99.657866  -99.641596  -99.665721]
 [ -99.697982  -99.794067  -99.595542  -99.773219  -99.830719]
 [ -99.849562  -99.624946  -99.614313  -99.717587  -99.56839 ]
 [ -99.798726  -99.634285  -99.721245  -99.789518  -99.818951]
 [ -99.74644   -99.836263  -99.581236  -99.685296  -99.648297]
 [ -99.679659  -99.630133  -99.915501  -99.908098  -99.849812]
 [ -99.676517  -99.665982  -99.678542  -99.772196  -99.795862]
 [ -99.794973  -99.753302  -99.664526  -99.679712  -99.684535]
 [ -99.741567  -99.686575  -99.736011  -99.784268  -99.793312]
 [ -99.864397  -99.568199  -99.596798  -99.801186  -99.593439]
 [ -99.687326  -99.647359  -99.662264  -99.723199  -99.720405]
 [ -99.710975  -99.699891  -99.834421  -99.837942  -99.70885 ]
 [ -99.652347  -99.666592  -99.576825  -98.583245  -99.621619]
 [ -99.587212  -99.588032  -99.78173   -99.799234  -99.735581]
 [ -99.641206  -99.83538   -99.72466   -99.838491  -99.704569]
 [ -99.548268  -99.835398  -99.643129  -99.642483  -99.669214]
 [ -99.814733  -99.546925  -99.681669  -99.461275  -98.682538]
 [ -96.676915  -97.720333  -98.727178  -99.784708  -96.642735]
 [ -99.649641  -99.84991   -99.82363   -99.586445  -99.679247]
 [ -98.573415  -97.580257  -98.760304  -95.592171  -96.812895]
 [ -99.729847  -98.73406   -95.419374  -99.767952  -99.732479]
 [ -99.929909  -99.643418  -99.642674  -99.537836  -99.87562 ]
 [ -98.570015  -99.65949   -95.41531   -98.691199  -99.837517]
 [ -96.490899  -99.831628  -99.390942  -99.937278  -99.508395]
 [ -97.860061  -99.744636  -99.454081  -99.837006  -99.4366  ]
 [ -99.755908  -99.529078  -97.600303  -98.618583  -99.788294]
 [ -91.720904  -91.748931  -88.470972  -94.390667  -89.53208 ]
 [ -86.705297  -95.484205  -80.679922  -84.4289    -90.655777]
 [ -99.821667  -98.534793  -99.519829  -99.687502  -99.562646]
 [ -99.774831  -94.542439  -96.84019   -95.583651  -97.666546]
 [ -98.391154  -96.747423  -96.505576  -96.955989  -94.616672]
 [ -95.485537  -98.686586  -98.761281  -98.621265  -97.463065]
 [ -98.605029  -92.800391  -96.465286  -95.515071  -93.713861]
 [ -92.799982  -93.639317  -98.616875  -98.48785   -92.536378]
 [ -98.707139  -99.591846  -99.599391  -99.56238   -99.644916]
 [ -65.482307  -51.746097  -56.716384  -45.68453   -47.422055]
 [ -91.57926   -92.536329  -87.447506  -95.665574  -81.555109]
 [ -53.658844  -60.728324  -50.689149  -52.607657  -59.392279]
 [ -96.855328  -99.733156  -98.67764   -99.799748  -97.551141]
 [ -99.734358  -99.5816    -99.740791  -99.764255  -99.752717]
 [ -99.515017  -99.591083  -99.684233  -98.536799  -99.577365]
 [ -98.620021  -99.864127  -97.503084  -99.785446  -94.473519]
 [ -95.788027  -94.668015  -94.746545  -97.609151  -96.571847]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3592 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3594]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3594 3601 3601 3599 3596]
 [3601 3601 3601 3600 3601]
 [3583 3601 3601 3601 3601]
 [3601 3593 3601 3601 3592]
 [3601 3598 3601 3601 3601]
 [3586 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3587 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3596 3601 3601 3601 3601]
 [3594 3601 3601 3598 3601]
 [3601 3601 3598 3589 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3598 3601 3601]
 [3600 3601 3601 3601 3601]
 [3600 3601 3601 3601 3600]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3599 3601 3601 3601 3599]
 [3601 3601 3601 3599 3601]
 [3597 3601 3601 3601 3601]
 [3600 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3600]
 [3597 3596 3601 3601 3601]
 [3600 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3601 3586 3601 3601 3601]
 [3601 3601 3601 3601 3590]
 [3597 3597 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3592 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3587 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3598 3601]
 [3601 3600 3601 3600 3601]
 [3601 3601 3601 3601 3600]
 [3601 3601 3596 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3596 3599 3601 3601 3601]
 [3601 3601 3601 3600 3600]
 [3601 3601 3594 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3599 3601 3601 3600]
 [3601 3584 3601 3601 3600]
 [3598 3599 3601 3601 3601]
 [3601 3601 3601 3601 3600]
 [3584 3601 3601 3601 3601]
 [3597 3601 3601 3591 3601]
 [3601 3601 3600 3600 3601]
 [3601 3597 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3595 3601 3601 3601 3601]
 [3585 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3594 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3581 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3581]
 [3598 3601 3601 3597 3601]
 [3601 3601 3601 3599 3601]
 [3601 3581 3601 3601 3601]
 [3601 3601 3601 3601 3590]
 [3601 3601 3601 3601 3601]
 [3600 3601 3597 3601 3601]
 [3582 3601 3601 3601 3601]
 [3597 3601 3601 3577 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-21_06-30-08_llm_triton_qwen_3b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-21_06-30-08_llm_triton_qwen_3b_binary_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/model
