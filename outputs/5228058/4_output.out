####################
/var/spool/slurmd/job5473477/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_32B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-02-01_23-47-49_llm_triton_qwen_32b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the movement of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0. You have to output the following calculations:
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 Response: 1
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 6    |
|    iterations      | 1    |
|    time_elapsed    | 334  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.26e+03    |
|    ep_rew_mean          | 539         |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 2           |
|    time_elapsed         | 661         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011426533 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.25       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.11        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.996       |
|    value_loss           | 14.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.27e+03    |
|    ep_rew_mean          | 576         |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 3           |
|    time_elapsed         | 985         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009705516 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.00267    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.85        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0195     |
|    std                  | 1           |
|    value_loss           | 15.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.27e+03    |
|    ep_rew_mean          | 607         |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 4           |
|    time_elapsed         | 1308        |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011084542 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.209       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.54        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.021      |
|    std                  | 1           |
|    value_loss           | 10.5        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.66 +/- 0.40
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.010265594 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.23        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.999       |
|    value_loss           | 10.9        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 456      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 5        |
|    time_elapsed    | 3433     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.04e+03     |
|    ep_rew_mean          | 493          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 6            |
|    time_elapsed         | 3759         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0048945025 |
|    clip_fraction        | 0.0268       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00551     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.36e+03     |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00656     |
|    std                  | 0.998        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 493         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 7           |
|    time_elapsed         | 4086        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008840736 |
|    clip_fraction        | 0.0775      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.317      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.999       |
|    value_loss           | 10.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.07e+03    |
|    ep_rew_mean          | 519         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 8           |
|    time_elapsed         | 4409        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.008420087 |
|    clip_fraction        | 0.0849      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0736      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.62        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0147     |
|    std                  | 1           |
|    value_loss           | 6.86        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.1e+03     |
|    ep_rew_mean          | 544         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 9           |
|    time_elapsed         | 4729        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.007972176 |
|    clip_fraction        | 0.0802      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.997       |
|    value_loss           | 6.28        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.86 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.009950759 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.59        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.994       |
|    value_loss           | 4.82        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 491      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 10       |
|    time_elapsed    | 6850     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.03e+03     |
|    ep_rew_mean          | 517          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 7169         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0044693286 |
|    clip_fraction        | 0.0282       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00174     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.36e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00456     |
|    std                  | 0.994        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | 517         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 12          |
|    time_elapsed         | 7488        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.009508166 |
|    clip_fraction        | 0.0909      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0522     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.63        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.991       |
|    value_loss           | 4.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | 543         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 7811        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.014290795 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.163       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.99        |
|    value_loss           | 3.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.07e+03    |
|    ep_rew_mean          | 562         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 8131        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014332466 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.328       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.988       |
|    value_loss           | 3.55        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.84 +/- 0.03
Episode length: 3592.20 +/- 15.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.021752525 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.984       |
|    value_loss           | 2.96        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 527      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 15       |
|    time_elapsed    | 10258    |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.02e+03     |
|    ep_rew_mean          | 546          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 10579        |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0044803275 |
|    clip_fraction        | 0.0405       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.0114       |
|    learning_rate        | 0.0003       |
|    loss                 | 1.64e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00139     |
|    std                  | 0.984        |
|    value_loss           | 1.01e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 10899       |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.011563566 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.38        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.983       |
|    value_loss           | 6.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 561         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 11217       |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.017825313 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.229       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.98        |
|    value_loss           | 3.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | 577         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 11536       |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.020699615 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.444       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.976       |
|    value_loss           | 2.33        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-39.21 +/- 6.79
Episode length: 3597.00 +/- 8.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -39.2      |
| time/                   |            |
|    total_timesteps      | 40000      |
| train/                  |            |
|    approx_kl            | 0.01800338 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.124      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07       |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.00973   |
|    std                  | 0.974      |
|    value_loss           | 2.37       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 550      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 20       |
|    time_elapsed    | 13663    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | 567         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 13982       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.010957166 |
|    clip_fraction        | 0.0858      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.00649     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.53e+03    |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00754    |
|    std                  | 0.974       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | 581         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 14301       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.019907098 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.0135     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.971       |
|    value_loss           | 2.93        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.04e+03   |
|    ep_rew_mean          | 595        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 23         |
|    time_elapsed         | 14619      |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.02333109 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04       |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.968      |
|    value_loss           | 2.56       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 595         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 24          |
|    time_elapsed         | 14937       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.023778448 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.274       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.94        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.964       |
|    value_loss           | 2.61        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-1.81 +/- 10.26
Episode length: 3594.20 +/- 12.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -1.81      |
| time/                   |            |
|    total_timesteps      | 50000      |
| train/                  |            |
|    approx_kl            | 0.02503693 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05       |
|    n_updates            | 240        |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.96       |
|    value_loss           | 2.06       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 576      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 17064    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | 588         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 17386       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.022718402 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00772     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.7         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.005      |
|    std                  | 0.96        |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 600         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 17705       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.017246958 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.843      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.3         |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.958       |
|    value_loss           | 6.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | 611         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 18024       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.021416886 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.358      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.21        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.957       |
|    value_loss           | 3.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 621         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 18350       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.029441394 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0868      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.95        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.947       |
|    value_loss           | 1.91        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=85.97 +/- 24.41
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 86          |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.029565584 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.947       |
|    value_loss           | 2.05        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 593      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 20471    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | 605         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 20791       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.016199768 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00533    |
|    learning_rate        | 0.0003      |
|    loss                 | 39.3        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00236    |
|    std                  | 0.946       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 614         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 21111       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.021515489 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.148      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.944       |
|    value_loss           | 2.85        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | 625         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 21430       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.027509397 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.94        |
|    value_loss           | 3.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | 635         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 21749       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.024860928 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.941       |
|    value_loss           | 2.56        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=175.19 +/- 23.79
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 175         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.028459897 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.311       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51        |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.94        |
|    value_loss           | 2.68        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 611      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 23874    |
|    total_timesteps | 71680    |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.01e+03  |
|    ep_rew_mean          | 622       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 36        |
|    time_elapsed         | 24194     |
|    total_timesteps      | 73728     |
| train/                  |           |
|    approx_kl            | 0.0087577 |
|    clip_fraction        | 0.0918    |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.9     |
|    explained_variance   | 0.00154   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.92e+03  |
|    n_updates            | 350       |
|    policy_gradient_loss | -0.00635  |
|    std                  | 0.94      |
|    value_loss           | 1.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 632         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 24513       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.024487345 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.012       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.939       |
|    value_loss           | 2.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 640         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 24832       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.025915267 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.932       |
|    value_loss           | 2.72        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 661         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 25150       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.023168173 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.929       |
|    value_loss           | 3.32        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=162.33 +/- 11.16
Episode length: 3599.80 +/- 1.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 162         |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.025906911 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.000416   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.927       |
|    value_loss           | 860         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 656      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 27270    |
|    total_timesteps | 81920    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | 665        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 41         |
|    time_elapsed         | 27596      |
|    total_timesteps      | 83968      |
| train/                  |            |
|    approx_kl            | 0.01110139 |
|    clip_fraction        | 0.108      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.000151  |
|    learning_rate        | 0.0003     |
|    loss                 | 516        |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.926      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | 672        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 42         |
|    time_elapsed         | 27918      |
|    total_timesteps      | 86016      |
| train/                  |            |
|    approx_kl            | 0.02302845 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.518     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.45       |
|    n_updates            | 410        |
|    policy_gradient_loss | -0.0204    |
|    std                  | 0.926      |
|    value_loss           | 3.69       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 682         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 28237       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.027930886 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.201       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41        |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.921       |
|    value_loss           | 2.6         |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=217.92 +/- 18.96
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 218         |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.025976356 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.03        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.915       |
|    value_loss           | 3.39        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 673      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 44       |
|    time_elapsed    | 30359    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 673         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 30678       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.009190833 |
|    clip_fraction        | 0.0669      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00326    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.28        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00787    |
|    std                  | 0.915       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | 682         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 30997       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.029297205 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.264      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.89        |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.912       |
|    value_loss           | 4.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | 691         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 31316       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.025992975 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0649      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.46        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.026      |
|    std                  | 0.907       |
|    value_loss           | 4.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 700         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 31642       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.029799901 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0953      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5         |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0243     |
|    std                  | 0.904       |
|    value_loss           | 3.24        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=331.36 +/- 8.87
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | 331       |
| time/                   |           |
|    total_timesteps      | 100000    |
| train/                  |           |
|    approx_kl            | 0.0275615 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | 0.0835    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.92      |
|    n_updates            | 480       |
|    policy_gradient_loss | -0.0267   |
|    std                  | 0.898     |
|    value_loss           | 3.72      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 694      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 49       |
|    time_elapsed    | 33765    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.97e+03    |
|    ep_rew_mean          | 705         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 34085       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.007996675 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00119    |
|    learning_rate        | 0.0003      |
|    loss                 | 92.8        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00825    |
|    std                  | 0.898       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.98e+03    |
|    ep_rew_mean          | 715         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 34405       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.013310699 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0011      |
|    learning_rate        | 0.0003      |
|    loss                 | 545         |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00478    |
|    std                  | 0.896       |
|    value_loss           | 3.91e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.98e+03   |
|    ep_rew_mean          | 724        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 52         |
|    time_elapsed         | 34724      |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.02930139 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.264     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.48       |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.0263    |
|    std                  | 0.894      |
|    value_loss           | 5.88       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.99e+03    |
|    ep_rew_mean          | 732         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 35043       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.033149347 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00151     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.07        |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0285     |
|    std                  | 0.889       |
|    value_loss           | 4.47        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=458.80 +/- 313.61
Episode length: 3027.80 +/- 1143.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.03e+03    |
|    mean_reward          | 459         |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.026520729 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0158      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0281     |
|    std                  | 0.887       |
|    value_loss           | 4.75        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.96e+03 |
|    ep_rew_mean     | 723      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 54       |
|    time_elapsed    | 36885    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.97e+03    |
|    ep_rew_mean          | 733         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 37206       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.014287554 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.000317    |
|    learning_rate        | 0.0003      |
|    loss                 | 152         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00889    |
|    std                  | 0.884       |
|    value_loss           | 750         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.96e+03    |
|    ep_rew_mean          | 753         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 37525       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.037249807 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.182      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8         |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0287     |
|    std                  | 0.878       |
|    value_loss           | 4.49        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.97e+03    |
|    ep_rew_mean          | 764         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 37844       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.011023025 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 5.82e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 14.7        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.877       |
|    value_loss           | 3.84e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.97e+03   |
|    ep_rew_mean          | 775        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 58         |
|    time_elapsed         | 38165      |
|    total_timesteps      | 118784     |
| train/                  |            |
|    approx_kl            | 0.03605193 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | -1.57      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.83       |
|    n_updates            | 570        |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.872      |
|    value_loss           | 5.84       |
----------------------------------------
Eval num_timesteps=120000, episode_reward=848.41 +/- 464.44
Episode length: 3162.40 +/- 534.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.16e+03   |
|    mean_reward          | 848        |
| time/                   |            |
|    total_timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.03587978 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.0109    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.56       |
|    n_updates            | 580        |
|    policy_gradient_loss | -0.036     |
|    std                  | 0.865      |
|    value_loss           | 6.78       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.94e+03 |
|    ep_rew_mean     | 781      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 40066    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.94e+03    |
|    ep_rew_mean          | 781         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 40386       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.010640843 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.000836    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+03    |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00745    |
|    std                  | 0.865       |
|    value_loss           | 4.63e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.95e+03    |
|    ep_rew_mean          | 812         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 40713       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.025071438 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.627      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.06        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0275     |
|    std                  | 0.862       |
|    value_loss           | 7           |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.95e+03    |
|    ep_rew_mean          | 823         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 41033       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.013509186 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.000354    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.45e+03    |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.861       |
|    value_loss           | 3.77e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.95e+03    |
|    ep_rew_mean          | 846         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 41352       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.030337792 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -1.11       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.62        |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.857       |
|    value_loss           | 7.21        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=677.13 +/- 388.53
Episode length: 2684.20 +/- 1220.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.68e+03    |
|    mean_reward          | 677         |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.014092227 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.000234    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.7e+03     |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.856       |
|    value_loss           | 3.71e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.94e+03 |
|    ep_rew_mean     | 841      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 43016    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.95e+03    |
|    ep_rew_mean          | 852         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 43337       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.018742008 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0264     |
|    learning_rate        | 0.0003      |
|    loss                 | 680         |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.854       |
|    value_loss           | 564         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.93e+03   |
|    ep_rew_mean          | 867        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 66         |
|    time_elapsed         | 43657      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.03487836 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.892     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.26       |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.0297    |
|    std                  | 0.844      |
|    value_loss           | 6.92       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.92e+03    |
|    ep_rew_mean          | 888         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 43978       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.015015899 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -0.00105    |
|    learning_rate        | 0.0003      |
|    loss                 | 15.9        |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.843       |
|    value_loss           | 3.66e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.88e+03    |
|    ep_rew_mean          | 920         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 44300       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.016948171 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.00249     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.41e+03    |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.843       |
|    value_loss           | 3.67e+03    |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=1195.02 +/- 137.51
Episode length: 1189.00 +/- 911.91
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 1.19e+03    |
|    mean_reward          | 1.2e+03     |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.015552189 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.000755    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.12e+03    |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00887    |
|    std                  | 0.842       |
|    value_loss           | 1.08e+04    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.84e+03 |
|    ep_rew_mean     | 915      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 45222    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.81e+03    |
|    ep_rew_mean          | 949         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 45544       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.019724682 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.00367    |
|    learning_rate        | 0.0003      |
|    loss                 | 364         |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.842       |
|    value_loss           | 3.72e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.71e+03    |
|    ep_rew_mean          | 970         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 45865       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.013092925 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.00109     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.57e+03    |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.84        |
|    value_loss           | 1.06e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.69e+03    |
|    ep_rew_mean          | 972         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 46185       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.012237694 |
|    clip_fraction        | 0.08        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -0.000594   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.35e+03    |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.838       |
|    value_loss           | 2.02e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.64e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 46505       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.018180896 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.000756    |
|    learning_rate        | 0.0003      |
|    loss                 | 720         |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.837       |
|    value_loss           | 3.49e+03    |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=1091.09 +/- 39.57
Episode length: 293.60 +/- 142.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 294        |
|    mean_reward          | 1.09e+03   |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.00813173 |
|    clip_fraction        | 0.0661     |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | 0.00543    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.78e+03   |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00949   |
|    std                  | 0.837      |
|    value_loss           | 1.7e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.55e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 46971    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.51e+03    |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 47290       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.013051236 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.00187     |
|    learning_rate        | 0.0003      |
|    loss                 | 9.27e+03    |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.836       |
|    value_loss           | 2.06e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.42e+03    |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 47609       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.024051048 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.000784   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.8e+03     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.834       |
|    value_loss           | 1e+04       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.38e+03    |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 47928       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.019522335 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -0.000817   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.68e+03    |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.832       |
|    value_loss           | 1.63e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.33e+03    |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 48247       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.016964564 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.00188     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.81e+03    |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.83        |
|    value_loss           | 9.73e+03    |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=1069.94 +/- 15.17
Episode length: 226.20 +/- 35.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 226         |
|    mean_reward          | 1.07e+03    |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.015936468 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.00367     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.98e+03    |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.83        |
|    value_loss           | 1.28e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.28e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 48682    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.16e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 49007       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.018227102 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | 0.00182     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+03    |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.828       |
|    value_loss           | 9.53e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.11e+03    |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 49331       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.014573487 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | 0.000759    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.38e+04    |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.826       |
|    value_loss           | 2.18e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.08e+03    |
|    ep_rew_mean          | 1.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 49652       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.022275297 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -4.54e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 9.22e+03    |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.825       |
|    value_loss           | 1.24e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 976        |
|    ep_rew_mean          | 1.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 83         |
|    time_elapsed         | 49973      |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.02035201 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.78      |
|    explained_variance   | 0.00216    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.83e+03   |
|    n_updates            | 820        |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.823      |
|    value_loss           | 9.27e+03   |
----------------------------------------
Eval num_timesteps=170000, episode_reward=1012.52 +/- 22.97
Episode length: 568.20 +/- 680.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 568         |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.018770976 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | 0.00991     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.4e+03     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.823       |
|    value_loss           | 1.56e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 948      |
|    ep_rew_mean     | 1.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 50578    |
|    total_timesteps | 172032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 895        |
|    ep_rew_mean          | 1.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 85         |
|    time_elapsed         | 50898      |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.05333186 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | 0.00477    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.69e+03   |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.817      |
|    value_loss           | 3.18e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 814         |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 51219       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.020313744 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.00667     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.95e+03    |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.814       |
|    value_loss           | 1.22e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 768         |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 51539       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.018073391 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.00767     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+04    |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.813       |
|    value_loss           | 1.5e+04     |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=1037.44 +/- 16.15
Episode length: 162.60 +/- 154.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 163         |
|    mean_reward          | 1.04e+03    |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.022400493 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | 0.0179      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.85e+03    |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.812       |
|    value_loss           | 1.2e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 602      |
|    ep_rew_mean     | 1.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 51942    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 499         |
|    ep_rew_mean          | 1.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 52263       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.016620746 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.0115      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8e+04     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.807       |
|    value_loss           | 2.91e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 466         |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 52586       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.020135392 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.000359    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.84e+03    |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.805       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 460         |
|    ep_rew_mean          | 1.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 52905       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.025484916 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.00388     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.39e+03    |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.798       |
|    value_loss           | 1.15e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 424         |
|    ep_rew_mean          | 1.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 53226       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.019868782 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.00552     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.89e+03    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.792       |
|    value_loss           | 1.15e+04    |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=1057.04 +/- 27.96
Episode length: 134.00 +/- 69.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 134         |
|    mean_reward          | 1.06e+03    |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.023264673 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.45       |
|    explained_variance   | 0.0127      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.19e+04    |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.0231     |
|    std                  | 0.787       |
|    value_loss           | 2.5e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 402      |
|    ep_rew_mean     | 1.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53614    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 394         |
|    ep_rew_mean          | 1.31e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53934       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.024297358 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | 0.00552     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.29e+04    |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0248     |
|    std                  | 0.783       |
|    value_loss           | 2.18e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 399        |
|    ep_rew_mean          | 1.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 95         |
|    time_elapsed         | 54254      |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.02578486 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.36      |
|    explained_variance   | 0.00404    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.83e+03   |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.78       |
|    value_loss           | 1.9e+04    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 377         |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 54574       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.030674975 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.00266     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.33e+03    |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.775       |
|    value_loss           | 1.35e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 353         |
|    ep_rew_mean          | 1.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54896       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.021834655 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.00107     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.36e+03    |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.772       |
|    value_loss           | 1.38e+04    |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=1020.76 +/- 17.56
Episode length: 54.20 +/- 45.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 54.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.01536959 |
|    clip_fraction        | 0.138      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.26      |
|    explained_variance   | 0.00439    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.34e+04   |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0204    |
|    std                  | 0.77       |
|    value_loss           | 2.86e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 330      |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 55243    |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 329        |
|    ep_rew_mean          | 1.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 99         |
|    time_elapsed         | 55563      |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.02859471 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.2       |
|    explained_variance   | 0.00209    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.24e+03   |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.763      |
|    value_loss           | 1.82e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 294         |
|    ep_rew_mean          | 1.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 55884       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.021016726 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | -0.0164     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3e+04     |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.759       |
|    value_loss           | 1.31e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 280         |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56205       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.027084945 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.00709     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.42e+03    |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.756       |
|    value_loss           | 2.04e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 271         |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 56525       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.022171184 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.00892     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.65e+04    |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.756       |
|    value_loss           | 3.46e+04    |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=1020.06 +/- 6.40
Episode length: 42.20 +/- 10.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 42.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.03546864 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.00693    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.0267    |
|    std                  | 0.749      |
|    value_loss           | 2.47e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 235      |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 56868    |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 231        |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 104        |
|    time_elapsed         | 57189      |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.01923699 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | 0.0132     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.71e+04   |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.745      |
|    value_loss           | 3.47e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 215         |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 57519       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.030958181 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.00794     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.07e+04    |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0236     |
|    std                  | 0.742       |
|    value_loss           | 2.82e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 199         |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 57843       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.026085272 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.00932     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+04    |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.024      |
|    std                  | 0.736       |
|    value_loss           | 2.32e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 58164       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.027418867 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.0122      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+04     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0245     |
|    std                  | 0.728       |
|    value_loss           | 2.3e+04     |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=1016.60 +/- 7.18
Episode length: 38.60 +/- 13.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 38.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.017269306 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.00602     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+04    |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.725       |
|    value_loss           | 3.14e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 160      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 58505    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 151         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 58835       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.018617924 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | 0.00444     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.89e+04    |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.724       |
|    value_loss           | 3.88e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 139         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 59161       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.029949917 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.72       |
|    explained_variance   | 0.00694     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.27e+03    |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 0.719       |
|    value_loss           | 4.14e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 126         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 59483       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.022652743 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.0114      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+04    |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.717       |
|    value_loss           | 4.25e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 112         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 59805       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.035379358 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.00859     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.39e+04    |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.712       |
|    value_loss           | 3.4e+04     |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=1023.77 +/- 9.94
Episode length: 54.40 +/- 19.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 54.4       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.02179281 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.00931    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+04   |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.0271    |
|    std                  | 0.708      |
|    value_loss           | 4.13e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 111      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 60154    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 102         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 60477       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.032234527 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | 0.011       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.44e+04    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0303     |
|    std                  | 0.703       |
|    value_loss           | 4.02e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 103         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 60798       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.025943704 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.0137      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76e+04    |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.7         |
|    value_loss           | 4.75e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 99.5      |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 116       |
|    time_elapsed         | 61121     |
|    total_timesteps      | 237568    |
| train/                  |           |
|    approx_kl            | 0.0429461 |
|    clip_fraction        | 0.298     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.45     |
|    explained_variance   | 0.00268   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.72e+04  |
|    n_updates            | 1150      |
|    policy_gradient_loss | -0.0144   |
|    std                  | 0.696     |
|    value_loss           | 3.35e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96          |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 61443       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.051314414 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.00429     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.6e+04     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.691       |
|    value_loss           | 4.27e+04    |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=1023.30 +/- 17.03
Episode length: 48.40 +/- 34.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 48.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.031740442 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.00155     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.78e+04    |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.682       |
|    value_loss           | 3.81e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 92.9     |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 61790    |
|    total_timesteps | 241664   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 94.4       |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 119        |
|    time_elapsed         | 62113      |
|    total_timesteps      | 243712     |
| train/                  |            |
|    approx_kl            | 0.02298091 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.24      |
|    explained_variance   | 0.00322    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.31e+04   |
|    n_updates            | 1180       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.678      |
|    value_loss           | 4.82e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 84.3        |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 62438       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.027725076 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.00548     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.025      |
|    std                  | 0.674       |
|    value_loss           | 4.22e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 86.2        |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 62768       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.043267645 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.00279     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.41e+04    |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.671       |
|    value_loss           | 5.19e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 82.8       |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 122        |
|    time_elapsed         | 63096      |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.04914474 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.11      |
|    explained_variance   | 0.00108    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+04   |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.666      |
|    value_loss           | 3.58e+04   |
----------------------------------------
Eval num_timesteps=250000, episode_reward=1013.30 +/- 2.22
Episode length: 32.60 +/- 6.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 32.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.02292867 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.0161     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.42e+04   |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.662      |
|    value_loss           | 4.52e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 80.9     |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 63436    |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 79.3       |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 124        |
|    time_elapsed         | 63759      |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.03406713 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | 0.00456    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.59e+04   |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.0244    |
|    std                  | 0.66       |
|    value_loss           | 4.55e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 68          |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 64084       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.056126237 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8          |
|    explained_variance   | 0.0192      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.44e+04    |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 0.658       |
|    value_loss           | 4.89e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 66.2       |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 126        |
|    time_elapsed         | 64408      |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.04208763 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.0125     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.89e+04   |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.0222    |
|    std                  | 0.655      |
|    value_loss           | 5.91e+04   |
----------------------------------------
Eval num_timesteps=260000, episode_reward=1011.18 +/- 1.09
Episode length: 24.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.06958756 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.00149    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.48e+04   |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0234    |
|    std                  | 0.65       |
|    value_loss           | 4.54e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 62.4     |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 127      |
|    time_elapsed    | 64744    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 64         |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 128        |
|    time_elapsed         | 65073      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.05316689 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | 0.00346    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+04   |
|    n_updates            | 1270       |
|    policy_gradient_loss | -0.023     |
|    std                  | 0.645      |
|    value_loss           | 5.04e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 65.6        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 129         |
|    time_elapsed         | 65397       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.066284865 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | 0.00516     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.38e+04    |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0235     |
|    std                  | 0.642       |
|    value_loss           | 4.82e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 67.2       |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 130        |
|    time_elapsed         | 65721      |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.04508476 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | 0.00326    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.23e+04   |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.0307    |
|    std                  | 0.639      |
|    value_loss           | 4.84e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 68.3        |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 131         |
|    time_elapsed         | 66051       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.048191126 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.73       |
|    explained_variance   | 0.00394     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.07e+04    |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0247     |
|    std                  | 0.638       |
|    value_loss           | 4.16e+04    |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=1020.08 +/- 8.47
Episode length: 42.20 +/- 19.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 42.2        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.056931835 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.69       |
|    explained_variance   | 0.00778     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.6e+04     |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.633       |
|    value_loss           | 4.4e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 65.8     |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 132      |
|    time_elapsed    | 66397    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 58.2        |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 133         |
|    time_elapsed         | 66722       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.033155814 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | 0.00828     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.41e+04    |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.628       |
|    value_loss           | 5.4e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 53.9       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 134        |
|    time_elapsed         | 67050      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.03802155 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.00765    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.96e+04   |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.025     |
|    std                  | 0.625      |
|    value_loss           | 5.32e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 53.3        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 135         |
|    time_elapsed         | 67377       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.050425906 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | 0.00463     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.42e+04    |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 0.624       |
|    value_loss           | 4.95e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 55.1       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 136        |
|    time_elapsed         | 67701      |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.15552619 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | 0.00846    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.06e+04   |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0123    |
|    std                  | 0.622      |
|    value_loss           | 5.09e+04   |
----------------------------------------
Eval num_timesteps=280000, episode_reward=1013.09 +/- 2.51
Episode length: 26.40 +/- 3.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.041546453 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.48       |
|    explained_variance   | 0.00236     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.14e+04    |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.617       |
|    value_loss           | 4.74e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 55.2     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 137      |
|    time_elapsed    | 68040    |
|    total_timesteps | 280576   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 53.3       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 138        |
|    time_elapsed         | 68365      |
|    total_timesteps      | 282624     |
| train/                  |            |
|    approx_kl            | 0.05624634 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.41      |
|    explained_variance   | 0.0051     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83e+04   |
|    n_updates            | 1370       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.613      |
|    value_loss           | 4.97e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 56.7       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 139        |
|    time_elapsed         | 68689      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.07781668 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.0022     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.99e+04   |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0269    |
|    std                  | 0.612      |
|    value_loss           | 4.76e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 58.9        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 140         |
|    time_elapsed         | 69014       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.040633425 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | 0.00199     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.58e+04    |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.609       |
|    value_loss           | 3.68e+04    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 60       |
|    ep_rew_mean          | 1.07e+03 |
| time/                   |          |
|    fps                  | 4        |
|    iterations           | 141      |
|    time_elapsed         | 69339    |
|    total_timesteps      | 288768   |
| train/                  |          |
|    approx_kl            | 0.031591 |
|    clip_fraction        | 0.232    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.32    |
|    explained_variance   | 0.0173   |
|    learning_rate        | 0.0003   |
|    loss                 | 2.51e+04 |
|    n_updates            | 1400     |
|    policy_gradient_loss | -0.0237  |
|    std                  | 0.606    |
|    value_loss           | 4.31e+04 |
--------------------------------------
Eval num_timesteps=290000, episode_reward=1016.85 +/- 7.41
Episode length: 36.80 +/- 14.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 36.8       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.03087105 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.0166     |
|    learning_rate        | 0.0003     |
|    loss                 | 8e+03      |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0254    |
|    std                  | 0.604      |
|    value_loss           | 4.35e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 57       |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 142      |
|    time_elapsed    | 69684    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 55.7        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 143         |
|    time_elapsed         | 70014       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.029569771 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.0131      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.37e+04    |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 0.601       |
|    value_loss           | 4.28e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 54.7        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 144         |
|    time_elapsed         | 70339       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.030956427 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | 0.00945     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84e+04    |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.6         |
|    value_loss           | 4.44e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 54.6        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 145         |
|    time_elapsed         | 70664       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.036075894 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | 0.0102      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.13e+04    |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.595       |
|    value_loss           | 4.47e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.5        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 146         |
|    time_elapsed         | 70989       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.040820744 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.00783     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.15e+04    |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 0.591       |
|    value_loss           | 4.03e+04    |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=1011.81 +/- 1.60
Episode length: 29.00 +/- 5.44
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.055492185 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | 0.00444     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.17e+04    |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.588       |
|    value_loss           | 4.06e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 53.4     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 147      |
|    time_elapsed    | 71332    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.6        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 148         |
|    time_elapsed         | 71657       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.047673114 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.02       |
|    explained_variance   | 0.0148      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.46e+04    |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.584       |
|    value_loss           | 4.53e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.1        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 149         |
|    time_elapsed         | 71986       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.050863583 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.00712     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.02e+04    |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.0264     |
|    std                  | 0.581       |
|    value_loss           | 4.18e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 46.8        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 150         |
|    time_elapsed         | 72312       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.028569905 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 0.0328      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.7e+04     |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.578       |
|    value_loss           | 4.59e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.4       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 151        |
|    time_elapsed         | 72639      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.06602463 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.00651    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.92e+04   |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.0247    |
|    std                  | 0.577      |
|    value_loss           | 4.49e+04   |
----------------------------------------
Eval num_timesteps=310000, episode_reward=1014.51 +/- 3.62
Episode length: 25.80 +/- 6.52
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.04886698 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | 0.00697    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.96e+04   |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.575      |
|    value_loss           | 4.32e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.4     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 152      |
|    time_elapsed    | 72980    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 43.1       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 153        |
|    time_elapsed         | 73306      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.06625354 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.0165     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.53e+03   |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.573      |
|    value_loss           | 4.49e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.2        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 154         |
|    time_elapsed         | 73637       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.069000766 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.79       |
|    explained_variance   | 0.00262     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.61e+04    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 0.568       |
|    value_loss           | 4.16e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.3        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 155         |
|    time_elapsed         | 73974       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.048320517 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | 0.00564     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6e+04     |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.029      |
|    std                  | 0.566       |
|    value_loss           | 3.91e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.2        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 156         |
|    time_elapsed         | 74301       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.063072026 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.74       |
|    explained_variance   | 0.0189      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.32e+04    |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.566       |
|    value_loss           | 4.33e+04    |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=1012.88 +/- 4.84
Episode length: 27.60 +/- 7.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.059430134 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.73       |
|    explained_variance   | 0.00641     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+04    |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 0.564       |
|    value_loss           | 4.03e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 43.7     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 157      |
|    time_elapsed    | 74649    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 41.9        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 158         |
|    time_elapsed         | 74976       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.063204855 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.02        |
|    learning_rate        | 0.0003      |
|    loss                 | 2.1e+04     |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 0.562       |
|    value_loss           | 4.26e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 42.2       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 159        |
|    time_elapsed         | 75302      |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.08956495 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | 0.0135     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.28e+04   |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.559      |
|    value_loss           | 4.22e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 43.3       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 160        |
|    time_elapsed         | 75629      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.10155064 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.63      |
|    explained_variance   | 0.00569    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.88e+04   |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.0278    |
|    std                  | 0.557      |
|    value_loss           | 3.81e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 161        |
|    time_elapsed         | 75959      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.12377785 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.62      |
|    explained_variance   | 0.0238     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.55e+04   |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.556      |
|    value_loss           | 3.92e+04   |
----------------------------------------
Eval num_timesteps=330000, episode_reward=1011.75 +/- 1.45
Episode length: 24.20 +/- 2.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.11716472 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.00519    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.11e+04   |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.556      |
|    value_loss           | 4.49e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.2     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 162      |
|    time_elapsed    | 76299    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 163        |
|    time_elapsed         | 76628      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.17451796 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.00659    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83e+04   |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.0309    |
|    std                  | 0.551      |
|    value_loss           | 4.34e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 164        |
|    time_elapsed         | 76956      |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.10385847 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.51      |
|    explained_variance   | 0.0015     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+04   |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.549      |
|    value_loss           | 3.73e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.1        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 165         |
|    time_elapsed         | 77283       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.053377565 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.46       |
|    explained_variance   | 0.000813    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88e+04    |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 0.545       |
|    value_loss           | 3.81e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.5       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 166        |
|    time_elapsed         | 77619      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.07012729 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0.00494    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.81e+04   |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.543      |
|    value_loss           | 3.38e+04   |
----------------------------------------
Eval num_timesteps=340000, episode_reward=1014.72 +/- 6.43
Episode length: 33.40 +/- 13.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 33.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.05588845 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.02       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.24e+04   |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.541      |
|    value_loss           | 3.51e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.5     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 167      |
|    time_elapsed    | 77966    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 168        |
|    time_elapsed         | 78293      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.13101125 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.37      |
|    explained_variance   | 0.00985    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.02e+04   |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.538      |
|    value_loss           | 3.7e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.4       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 169        |
|    time_elapsed         | 78620      |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.08140296 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.32      |
|    explained_variance   | 0.0081     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.65e+04   |
|    n_updates            | 1680       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.534      |
|    value_loss           | 3.43e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39          |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 170         |
|    time_elapsed         | 78947       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.059582226 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.00384     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.534       |
|    value_loss           | 3.11e+04    |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=1011.50 +/- 1.64
Episode length: 25.80 +/- 5.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.06984541 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.27      |
|    explained_variance   | 0.0208     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.43e+04   |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.533      |
|    value_loss           | 3.44e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.5     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 171      |
|    time_elapsed    | 79288    |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.9       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 172        |
|    time_elapsed         | 79617      |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.23813182 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.25      |
|    explained_variance   | 0.00202    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.65e+04   |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.531      |
|    value_loss           | 3.41e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 173        |
|    time_elapsed         | 79945      |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.17654769 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.21      |
|    explained_variance   | 0.0024     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36e+04   |
|    n_updates            | 1720       |
|    policy_gradient_loss | -0.0265    |
|    std                  | 0.528      |
|    value_loss           | 3.48e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 174         |
|    time_elapsed         | 80273       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.123352595 |
|    clip_fraction        | 0.434       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.18       |
|    explained_variance   | 0.00692     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.62e+04    |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.526       |
|    value_loss           | 3.14e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 175         |
|    time_elapsed         | 80602       |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.069901854 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.16       |
|    explained_variance   | 0.0102      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.83e+03    |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.525       |
|    value_loss           | 3.04e+04    |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=1013.82 +/- 6.25
Episode length: 29.40 +/- 11.98
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 29.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 360000    |
| train/                  |           |
|    approx_kl            | 0.2153377 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.13     |
|    explained_variance   | 0.00636   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.34e+04  |
|    n_updates            | 1750      |
|    policy_gradient_loss | -0.012    |
|    std                  | 0.523     |
|    value_loss           | 3e+04     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37       |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 176      |
|    time_elapsed    | 80944    |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 177         |
|    time_elapsed         | 81273       |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.033924803 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.11       |
|    explained_variance   | 0.0281      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56e+04    |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.522       |
|    value_loss           | 2.76e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.9       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 178        |
|    time_elapsed         | 81609      |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.14638427 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.09      |
|    explained_variance   | 0.019      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.58e+04   |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.00183    |
|    std                  | 0.521      |
|    value_loss           | 3.22e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 179         |
|    time_elapsed         | 81939       |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.069037445 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.0119      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.52        |
|    value_loss           | 2.79e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 180         |
|    time_elapsed         | 82266       |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.073397115 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.06       |
|    explained_variance   | 0.00915     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.37e+04    |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00611    |
|    std                  | 0.519       |
|    value_loss           | 2.74e+04    |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=1011.96 +/- 2.92
Episode length: 23.80 +/- 4.62
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 23.8      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 370000    |
| train/                  |           |
|    approx_kl            | 0.0443039 |
|    clip_fraction        | 0.259     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.05     |
|    explained_variance   | 0.0252    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.8e+04   |
|    n_updates            | 1800      |
|    policy_gradient_loss | -0.0279   |
|    std                  | 0.518     |
|    value_loss           | 2.64e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.1     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 181      |
|    time_elapsed    | 82606    |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 182        |
|    time_elapsed         | 82935      |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.18696603 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.0295     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25e+04   |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.517      |
|    value_loss           | 2.71e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 183        |
|    time_elapsed         | 83263      |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.07842697 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | 0.0316     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83e+04   |
|    n_updates            | 1820       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.517      |
|    value_loss           | 2.83e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 36.8      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 184       |
|    time_elapsed         | 83591     |
|    total_timesteps      | 376832    |
| train/                  |           |
|    approx_kl            | 0.0667696 |
|    clip_fraction        | 0.314     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.0268    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.12e+04  |
|    n_updates            | 1830      |
|    policy_gradient_loss | -0.0168   |
|    std                  | 0.517     |
|    value_loss           | 2.5e+04   |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 185         |
|    time_elapsed         | 83919       |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.067482404 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.99       |
|    explained_variance   | 0.0107      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+04    |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.514       |
|    value_loss           | 2.42e+04    |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=1012.89 +/- 3.38
Episode length: 26.20 +/- 4.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.04643006 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.0278     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.41e+04   |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.512      |
|    value_loss           | 2.56e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 186      |
|    time_elapsed    | 84262    |
|    total_timesteps | 380928   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 32.8      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 187       |
|    time_elapsed         | 84591     |
|    total_timesteps      | 382976    |
| train/                  |           |
|    approx_kl            | 0.7321241 |
|    clip_fraction        | 0.635     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.92     |
|    explained_variance   | 0.0459    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.35e+04  |
|    n_updates            | 1860      |
|    policy_gradient_loss | 0.106     |
|    std                  | 0.509     |
|    value_loss           | 2.83e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 35.7      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 188       |
|    time_elapsed         | 84919     |
|    total_timesteps      | 385024    |
| train/                  |           |
|    approx_kl            | 0.3791002 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.9      |
|    explained_variance   | 0.0107    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.08e+04  |
|    n_updates            | 1870      |
|    policy_gradient_loss | 0.00885   |
|    std                  | 0.509     |
|    value_loss           | 2.27e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.5        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 189         |
|    time_elapsed         | 85247       |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.065223806 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.89       |
|    explained_variance   | 0.0258      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+04    |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.508       |
|    value_loss           | 2.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 190         |
|    time_elapsed         | 85591       |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.047357343 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.87       |
|    explained_variance   | 0.0254      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15e+04    |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.506       |
|    value_loss           | 2.3e+04     |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=1010.91 +/- 1.91
Episode length: 26.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.08798629 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.85      |
|    explained_variance   | 0.0388     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.96e+03   |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.00526   |
|    std                  | 0.505      |
|    value_loss           | 2.26e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.4     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 191      |
|    time_elapsed    | 85936    |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 192        |
|    time_elapsed         | 86264      |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.21863215 |
|    clip_fraction        | 0.543      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.0285     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.22e+03   |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.00672   |
|    std                  | 0.501      |
|    value_loss           | 2.39e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 193        |
|    time_elapsed         | 86592      |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.17047286 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.74      |
|    explained_variance   | 0.00697    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+04   |
|    n_updates            | 1920       |
|    policy_gradient_loss | -0.00795   |
|    std                  | 0.499      |
|    value_loss           | 2.08e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 194         |
|    time_elapsed         | 86919       |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.067908525 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | 0.0265      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.54e+03    |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.499       |
|    value_loss           | 2.13e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 195         |
|    time_elapsed         | 87247       |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.040489964 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.73       |
|    explained_variance   | 0.019       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.72e+03    |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.498       |
|    value_loss           | 2.04e+04    |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=1013.59 +/- 3.83
Episode length: 29.60 +/- 5.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.074392855 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.72       |
|    explained_variance   | 0.0169      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.34e+03    |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.497       |
|    value_loss           | 2.05e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.5     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 196      |
|    time_elapsed    | 87591    |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 197        |
|    time_elapsed         | 87920      |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.13758734 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.71      |
|    explained_variance   | 0.0367     |
|    learning_rate        | 0.0003     |
|    loss                 | 1e+04      |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.0159    |
|    std                  | 0.497      |
|    value_loss           | 2.05e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 198        |
|    time_elapsed         | 88249      |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.46184137 |
|    clip_fraction        | 0.53       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.7       |
|    explained_variance   | 0.027      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.3e+03    |
|    n_updates            | 1970       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.495      |
|    value_loss           | 2.11e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 199        |
|    time_elapsed         | 88578      |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.09459975 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.67      |
|    explained_variance   | 0.0315     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25e+04   |
|    n_updates            | 1980       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.493      |
|    value_loss           | 1.96e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 200         |
|    time_elapsed         | 88907       |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.028833076 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.65       |
|    explained_variance   | 0.0365      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.95e+03    |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.493       |
|    value_loss           | 1.73e+04    |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=1012.25 +/- 4.02
Episode length: 28.80 +/- 11.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.07105193 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.63      |
|    explained_variance   | 0.075      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.84e+03   |
|    n_updates            | 2000       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.491      |
|    value_loss           | 1.78e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32       |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 201      |
|    time_elapsed    | 89254    |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 202        |
|    time_elapsed         | 89587      |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.12526205 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.61      |
|    explained_variance   | 0.0477     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+04   |
|    n_updates            | 2010       |
|    policy_gradient_loss | 0.00398    |
|    std                  | 0.49       |
|    value_loss           | 1.81e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 203        |
|    time_elapsed         | 89915      |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.45809448 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.6       |
|    explained_variance   | 0.0355     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04e+04   |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.00455   |
|    std                  | 0.489      |
|    value_loss           | 1.71e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 204         |
|    time_elapsed         | 90242       |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.059997812 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.58       |
|    explained_variance   | 0.0645      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.22e+03    |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.488       |
|    value_loss           | 1.57e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 205         |
|    time_elapsed         | 90571       |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.033542007 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.55       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.22e+03    |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.486       |
|    value_loss           | 1.57e+04    |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=1012.29 +/- 2.78
Episode length: 26.00 +/- 3.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.05899652 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.53      |
|    explained_variance   | 0.0931     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.8e+03    |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.0261    |
|    std                  | 0.485      |
|    value_loss           | 1.69e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 206      |
|    time_elapsed    | 90913    |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 207         |
|    time_elapsed         | 91242       |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.064803235 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.51       |
|    explained_variance   | 0.0511      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.47e+03    |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.484       |
|    value_loss           | 1.66e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 208        |
|    time_elapsed         | 91571      |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.13466159 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.49      |
|    explained_variance   | 0.0413     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+04   |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.483      |
|    value_loss           | 1.59e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.8       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 209        |
|    time_elapsed         | 91901      |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.07753627 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.48      |
|    explained_variance   | 0.0482     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.51e+03   |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0231    |
|    std                  | 0.482      |
|    value_loss           | 1.51e+04   |
----------------------------------------
Eval num_timesteps=430000, episode_reward=1014.39 +/- 2.21
Episode length: 30.60 +/- 5.43
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.08605929 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.47      |
|    explained_variance   | 0.077      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.8e+03    |
|    n_updates            | 2090       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.482      |
|    value_loss           | 1.55e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.1     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 210      |
|    time_elapsed    | 92245    |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 211        |
|    time_elapsed         | 92573      |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.28437746 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.0759     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.15e+03   |
|    n_updates            | 2100       |
|    policy_gradient_loss | 0.00422    |
|    std                  | 0.48       |
|    value_loss           | 1.37e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 212         |
|    time_elapsed         | 92902       |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.041584358 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.21e+03    |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 0.48        |
|    value_loss           | 1.23e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 213        |
|    time_elapsed         | 93238      |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.04829214 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.43      |
|    explained_variance   | 0.14       |
|    learning_rate        | 0.0003     |
|    loss                 | 7.78e+03   |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.479      |
|    value_loss           | 1.4e+04    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 214         |
|    time_elapsed         | 93568       |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.030534161 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.42       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.52e+03    |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.478       |
|    value_loss           | 1.31e+04    |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=1011.53 +/- 2.60
Episode length: 24.80 +/- 5.38
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 24.8      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 440000    |
| train/                  |           |
|    approx_kl            | 0.5885525 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.39     |
|    explained_variance   | 0.0689    |
|    learning_rate        | 0.0003    |
|    loss                 | 6.67e+03  |
|    n_updates            | 2140      |
|    policy_gradient_loss | 0.000731  |
|    std                  | 0.477     |
|    value_loss           | 1.36e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30       |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 215      |
|    time_elapsed    | 93910    |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 216        |
|    time_elapsed         | 94240      |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.10333076 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.058      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.47e+03   |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.477      |
|    value_loss           | 1.3e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 217        |
|    time_elapsed         | 94569      |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.10055937 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.0761     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.89e+03   |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.00973   |
|    std                  | 0.476      |
|    value_loss           | 1.34e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 218        |
|    time_elapsed         | 94903      |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.14708112 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | 0.0663     |
|    learning_rate        | 0.0003     |
|    loss                 | 4.78e+03   |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.476      |
|    value_loss           | 1.17e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 219        |
|    time_elapsed         | 95231      |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.06044698 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.36      |
|    explained_variance   | 0.0947     |
|    learning_rate        | 0.0003     |
|    loss                 | 4.47e+03   |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0224    |
|    std                  | 0.475      |
|    value_loss           | 1.15e+04   |
----------------------------------------
Eval num_timesteps=450000, episode_reward=1011.34 +/- 1.40
Episode length: 24.20 +/- 2.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.053635195 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.36       |
|    explained_variance   | 0.0788      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.19e+03    |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.475       |
|    value_loss           | 1.1e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 220      |
|    time_elapsed    | 95573    |
|    total_timesteps | 450560   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 221       |
|    time_elapsed         | 95902     |
|    total_timesteps      | 452608    |
| train/                  |           |
|    approx_kl            | 0.4631592 |
|    clip_fraction        | 0.306     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.33     |
|    explained_variance   | 0.123     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.25e+03  |
|    n_updates            | 2200      |
|    policy_gradient_loss | 0.00783   |
|    std                  | 0.473     |
|    value_loss           | 1.13e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 222         |
|    time_elapsed         | 96231       |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.045647804 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.3        |
|    explained_variance   | 0.109       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.35e+03    |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.471       |
|    value_loss           | 9.93e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 223        |
|    time_elapsed         | 96561      |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.05174897 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.27      |
|    explained_variance   | 0.153      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.33e+03   |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.022     |
|    std                  | 0.47       |
|    value_loss           | 9.76e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.4       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 224        |
|    time_elapsed         | 96890      |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.11449233 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.26      |
|    explained_variance   | 0.173      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.89e+03   |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.47       |
|    value_loss           | 9.1e+03    |
----------------------------------------
Eval num_timesteps=460000, episode_reward=1012.10 +/- 1.86
Episode length: 26.80 +/- 3.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.06031962 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.26      |
|    explained_variance   | 0.174      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.05e+03   |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.47       |
|    value_loss           | 8.42e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.2     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 225      |
|    time_elapsed    | 97239    |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 226         |
|    time_elapsed         | 97572       |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.033462185 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.24       |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.36e+03    |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.468       |
|    value_loss           | 8.84e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.7       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 227        |
|    time_elapsed         | 97901      |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.37536588 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.21      |
|    explained_variance   | 0.202      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.29e+03   |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.0038     |
|    std                  | 0.467      |
|    value_loss           | 8.73e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.3        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 228         |
|    time_elapsed         | 98229       |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.114413224 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.19       |
|    explained_variance   | 0.181       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.63e+03    |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.465       |
|    value_loss           | 7.87e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 229        |
|    time_elapsed         | 98559      |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.08495414 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.16      |
|    explained_variance   | 0.207      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.77e+03   |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0285    |
|    std                  | 0.463      |
|    value_loss           | 7.23e+03   |
----------------------------------------
Eval num_timesteps=470000, episode_reward=1013.44 +/- 2.92
Episode length: 29.60 +/- 5.35
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.061910354 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.13       |
|    explained_variance   | 0.249       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.86e+03    |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0247     |
|    std                  | 0.462       |
|    value_loss           | 7.37e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 230      |
|    time_elapsed    | 98903    |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.1       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 231        |
|    time_elapsed         | 99231      |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.11164329 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.258      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.98e+03   |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.00438   |
|    std                  | 0.46       |
|    value_loss           | 7.01e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31         |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 232        |
|    time_elapsed         | 99561      |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.05233456 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.08      |
|    explained_variance   | 0.231      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.21e+03   |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.459      |
|    value_loss           | 6.5e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 233         |
|    time_elapsed         | 99891       |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.058966465 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.07       |
|    explained_variance   | 0.303       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.5e+03     |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.458       |
|    value_loss           | 6.32e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 234        |
|    time_elapsed         | 100221     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.05993925 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.04      |
|    explained_variance   | 0.342      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.56e+03   |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.0192    |
|    std                  | 0.456      |
|    value_loss           | 6.01e+03   |
----------------------------------------
Eval num_timesteps=480000, episode_reward=1011.88 +/- 1.96
Episode length: 27.00 +/- 5.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.08732064 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.01      |
|    explained_variance   | 0.268      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.55e+03   |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0252    |
|    std                  | 0.455      |
|    value_loss           | 5.75e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.5     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 235      |
|    time_elapsed    | 100565   |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 236        |
|    time_elapsed         | 100895     |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.09135923 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.99      |
|    explained_variance   | 0.245      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.37e+03   |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.454      |
|    value_loss           | 5.68e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 237        |
|    time_elapsed         | 101233     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.11830112 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.99      |
|    explained_variance   | 0.318      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.79e+03   |
|    n_updates            | 2360       |
|    policy_gradient_loss | -0.0251    |
|    std                  | 0.454      |
|    value_loss           | 5.01e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 238        |
|    time_elapsed         | 101564     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.07306015 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.97      |
|    explained_variance   | 0.328      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.94e+03   |
|    n_updates            | 2370       |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.452      |
|    value_loss           | 5.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 239         |
|    time_elapsed         | 101894      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.056558616 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.94       |
|    explained_variance   | 0.287       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.37e+03    |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.45        |
|    value_loss           | 4.67e+03    |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=1010.91 +/- 1.17
Episode length: 25.40 +/- 6.18
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 25.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 490000    |
| train/                  |           |
|    approx_kl            | 0.0697597 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.91     |
|    explained_variance   | 0.379     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.32e+03  |
|    n_updates            | 2390      |
|    policy_gradient_loss | -0.0226   |
|    std                  | 0.449     |
|    value_loss           | 4.43e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 240      |
|    time_elapsed    | 102236   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 241         |
|    time_elapsed         | 102566      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.046231605 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.91       |
|    explained_variance   | 0.322       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.53e+03    |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.449       |
|    value_loss           | 4.32e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 242        |
|    time_elapsed         | 102896     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.06598668 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.9       |
|    explained_variance   | 0.311      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.34e+03   |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.449      |
|    value_loss           | 4.49e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 243        |
|    time_elapsed         | 103227     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.07502817 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.87      |
|    explained_variance   | 0.321      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72e+03   |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.0105    |
|    std                  | 0.446      |
|    value_loss           | 4.1e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 244        |
|    time_elapsed         | 103557     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.08086097 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.84      |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.04e+03   |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.445      |
|    value_loss           | 4.1e+03    |
----------------------------------------
Eval num_timesteps=500000, episode_reward=1011.35 +/- 1.78
Episode length: 24.60 +/- 2.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.109825715 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.82       |
|    explained_variance   | 0.365       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42e+03    |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.444       |
|    value_loss           | 3.55e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 245      |
|    time_elapsed    | 103901   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 246        |
|    time_elapsed         | 104231     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.15187423 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.8       |
|    explained_variance   | 0.427      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.71e+03   |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.443      |
|    value_loss           | 3.26e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 247        |
|    time_elapsed         | 104563     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.09127124 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.79      |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.67e+03   |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.442      |
|    value_loss           | 3.28e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 248        |
|    time_elapsed         | 104902     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.06612483 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.77      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.56e+03   |
|    n_updates            | 2470       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.442      |
|    value_loss           | 3.24e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 249        |
|    time_elapsed         | 105236     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.08338997 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.76      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.31e+03   |
|    n_updates            | 2480       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.44       |
|    value_loss           | 2.77e+03   |
----------------------------------------
Eval num_timesteps=510000, episode_reward=1013.34 +/- 3.59
Episode length: 25.60 +/- 6.65
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 25.6      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 510000    |
| train/                  |           |
|    approx_kl            | 0.1889422 |
|    clip_fraction        | 0.346     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.74     |
|    explained_variance   | 0.366     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.31e+03  |
|    n_updates            | 2490      |
|    policy_gradient_loss | -0.0148   |
|    std                  | 0.439     |
|    value_loss           | 2.98e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 250      |
|    time_elapsed    | 105581   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 251        |
|    time_elapsed         | 105912     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.14874445 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.72      |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.61e+03   |
|    n_updates            | 2500       |
|    policy_gradient_loss | -0.0072    |
|    std                  | 0.438      |
|    value_loss           | 2.69e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 252         |
|    time_elapsed         | 106244      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.059050027 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.71       |
|    explained_variance   | 0.344       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41e+03    |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0249     |
|    std                  | 0.437       |
|    value_loss           | 2.95e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 253         |
|    time_elapsed         | 106575      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.074902885 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.68       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5e+03     |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.435       |
|    value_loss           | 2.61e+03    |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=1011.76 +/- 1.68
Episode length: 24.80 +/- 2.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.06527244 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.66      |
|    explained_variance   | 0.318      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83e+03   |
|    n_updates            | 2530       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.435      |
|    value_loss           | 2.97e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 254      |
|    time_elapsed    | 106919   |
|    total_timesteps | 520192   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.3      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 255       |
|    time_elapsed         | 107251    |
|    total_timesteps      | 522240    |
| train/                  |           |
|    approx_kl            | 0.0694885 |
|    clip_fraction        | 0.299     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.65     |
|    explained_variance   | 0.433     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.37e+03  |
|    n_updates            | 2540      |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.434     |
|    value_loss           | 2.62e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 256        |
|    time_elapsed         | 107582     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.06981855 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.63      |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+03   |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.000971  |
|    std                  | 0.433      |
|    value_loss           | 1.98e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.3      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 257       |
|    time_elapsed         | 107915    |
|    total_timesteps      | 526336    |
| train/                  |           |
|    approx_kl            | 0.1041383 |
|    clip_fraction        | 0.315     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.6      |
|    explained_variance   | 0.459     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.38e+03  |
|    n_updates            | 2560      |
|    policy_gradient_loss | -0.0216   |
|    std                  | 0.431     |
|    value_loss           | 2.15e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 258        |
|    time_elapsed         | 108246     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.06263846 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.57      |
|    explained_variance   | 0.384      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+03   |
|    n_updates            | 2570       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.43       |
|    value_loss           | 2.48e+03   |
----------------------------------------
Eval num_timesteps=530000, episode_reward=1013.27 +/- 4.28
Episode length: 27.60 +/- 10.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.04613954 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.54      |
|    explained_variance   | 0.369      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+03   |
|    n_updates            | 2580       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.428      |
|    value_loss           | 2.45e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 259      |
|    time_elapsed    | 108593   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 260        |
|    time_elapsed         | 108932     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.07615791 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.53      |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13e+03   |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.428      |
|    value_loss           | 2e+03      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 261        |
|    time_elapsed         | 109266     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.05644063 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.52      |
|    explained_variance   | 0.444      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.26e+03   |
|    n_updates            | 2600       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.427      |
|    value_loss           | 2.21e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 262         |
|    time_elapsed         | 109597      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.039381094 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.51       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.427       |
|    value_loss           | 2.18e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 263         |
|    time_elapsed         | 109929      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.069533974 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.51       |
|    explained_variance   | 0.479       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+03    |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.427       |
|    value_loss           | 1.86e+03    |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=1010.83 +/- 0.44
Episode length: 21.40 +/- 3.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.07537581 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.5       |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.0003     |
|    loss                 | 731        |
|    n_updates            | 2630       |
|    policy_gradient_loss | -0.0259    |
|    std                  | 0.426      |
|    value_loss           | 1.85e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 264      |
|    time_elapsed    | 110271   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 265        |
|    time_elapsed         | 110602     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.06322372 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.49      |
|    explained_variance   | 0.425      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.6e+03    |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.426      |
|    value_loss           | 2.18e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 266        |
|    time_elapsed         | 110934     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.09777835 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.47      |
|    explained_variance   | 0.469      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+03   |
|    n_updates            | 2650       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.424      |
|    value_loss           | 1.99e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 267        |
|    time_elapsed         | 111264     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.07701106 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.46      |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | 940        |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.424      |
|    value_loss           | 1.76e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.8      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 268       |
|    time_elapsed         | 111601    |
|    total_timesteps      | 548864    |
| train/                  |           |
|    approx_kl            | 0.0582676 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.45     |
|    explained_variance   | 0.535     |
|    learning_rate        | 0.0003    |
|    loss                 | 839       |
|    n_updates            | 2670      |
|    policy_gradient_loss | -0.0148   |
|    std                  | 0.422     |
|    value_loss           | 1.6e+03   |
---------------------------------------
Eval num_timesteps=550000, episode_reward=1012.15 +/- 3.40
Episode length: 24.40 +/- 4.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.09407959 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.43      |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.0003     |
|    loss                 | 492        |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.422      |
|    value_loss           | 1.42e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 269      |
|    time_elapsed    | 111944   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 270        |
|    time_elapsed         | 112276     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.06777625 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.43      |
|    explained_variance   | 0.454      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08e+03   |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.422      |
|    value_loss           | 1.85e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 271        |
|    time_elapsed         | 112609     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.07210937 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.44      |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.0003     |
|    loss                 | 656        |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.423      |
|    value_loss           | 1.52e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 272         |
|    time_elapsed         | 112949      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.051943716 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.43       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.0003      |
|    loss                 | 473         |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.422       |
|    value_loss           | 1.48e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 273        |
|    time_elapsed         | 113283     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.11218096 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.41      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 498        |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.421      |
|    value_loss           | 1.39e+03   |
----------------------------------------
Eval num_timesteps=560000, episode_reward=1010.99 +/- 0.59
Episode length: 22.80 +/- 3.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.06290136 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.38      |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.0003     |
|    loss                 | 732        |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.419      |
|    value_loss           | 1.71e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 274      |
|    time_elapsed    | 113627   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 275         |
|    time_elapsed         | 113958      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.060385413 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.37       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15e+03    |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.419       |
|    value_loss           | 1.75e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25        |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 276       |
|    time_elapsed         | 114290    |
|    total_timesteps      | 565248    |
| train/                  |           |
|    approx_kl            | 0.0759207 |
|    clip_fraction        | 0.311     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.36     |
|    explained_variance   | 0.44      |
|    learning_rate        | 0.0003    |
|    loss                 | 983       |
|    n_updates            | 2750      |
|    policy_gradient_loss | -0.0172   |
|    std                  | 0.418     |
|    value_loss           | 1.87e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 277        |
|    time_elapsed         | 114622     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.07882525 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.35      |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.0003     |
|    loss                 | 573        |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.418      |
|    value_loss           | 1.29e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 278        |
|    time_elapsed         | 114954     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.08378351 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.35      |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.0003     |
|    loss                 | 683        |
|    n_updates            | 2770       |
|    policy_gradient_loss | -0.00738   |
|    std                  | 0.417      |
|    value_loss           | 1.46e+03   |
----------------------------------------
Eval num_timesteps=570000, episode_reward=1010.45 +/- 0.47
Episode length: 21.60 +/- 1.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.097201645 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.33       |
|    explained_variance   | 0.532       |
|    learning_rate        | 0.0003      |
|    loss                 | 1e+03       |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.416       |
|    value_loss           | 1.51e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 279      |
|    time_elapsed    | 115296   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 280         |
|    time_elapsed         | 115629      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.061624542 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.31       |
|    explained_variance   | 0.461       |
|    learning_rate        | 0.0003      |
|    loss                 | 980         |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.416       |
|    value_loss           | 1.96e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 281        |
|    time_elapsed         | 115961     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.06027332 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.3       |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.0003     |
|    loss                 | 723        |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.0234    |
|    std                  | 0.415      |
|    value_loss           | 1.36e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 282        |
|    time_elapsed         | 116293     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.05588688 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.3       |
|    explained_variance   | 0.549      |
|    learning_rate        | 0.0003     |
|    loss                 | 809        |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.415      |
|    value_loss           | 1.36e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 283        |
|    time_elapsed         | 116636     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.18550014 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.31      |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.0003     |
|    loss                 | 531        |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.000274   |
|    std                  | 0.416      |
|    value_loss           | 1.29e+03   |
----------------------------------------
Eval num_timesteps=580000, episode_reward=1011.01 +/- 0.01
Episode length: 22.00 +/- 0.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.06697804 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.32      |
|    explained_variance   | 0.504      |
|    learning_rate        | 0.0003     |
|    loss                 | 730        |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.0219    |
|    std                  | 0.416      |
|    value_loss           | 1.55e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 284      |
|    time_elapsed    | 116981   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 285         |
|    time_elapsed         | 117313      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.040751815 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.31       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.27e+03    |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.415       |
|    value_loss           | 1.92e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 286        |
|    time_elapsed         | 117645     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.11492483 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.28      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | 597        |
|    n_updates            | 2850       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.414      |
|    value_loss           | 1.31e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 287        |
|    time_elapsed         | 117980     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.08165131 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.26      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.0003     |
|    loss                 | 954        |
|    n_updates            | 2860       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.413      |
|    value_loss           | 1.36e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 288        |
|    time_elapsed         | 118312     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.19944866 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.25      |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.0003     |
|    loss                 | 518        |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.00186   |
|    std                  | 0.413      |
|    value_loss           | 1.28e+03   |
----------------------------------------
Eval num_timesteps=590000, episode_reward=1015.97 +/- 6.21
Episode length: 32.60 +/- 10.25
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 32.6       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.06961399 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | 473        |
|    n_updates            | 2880       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.412      |
|    value_loss           | 1.19e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 289      |
|    time_elapsed    | 118660   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 290        |
|    time_elapsed         | 118996     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.06059423 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.22      |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.0003     |
|    loss                 | 823        |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.411      |
|    value_loss           | 1.47e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 291         |
|    time_elapsed         | 119329      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.092000455 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.21       |
|    explained_variance   | 0.639       |
|    learning_rate        | 0.0003      |
|    loss                 | 649         |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.411       |
|    value_loss           | 1.11e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 292        |
|    time_elapsed         | 119669     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.05080934 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.2       |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 648        |
|    n_updates            | 2910       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.41       |
|    value_loss           | 1.2e+03    |
----------------------------------------
Eval num_timesteps=600000, episode_reward=1013.69 +/- 3.10
Episode length: 26.00 +/- 3.69
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.07770473 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.0003     |
|    loss                 | 503        |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.409      |
|    value_loss           | 951        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 293      |
|    time_elapsed    | 120015   |
|    total_timesteps | 600064   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.5      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 294       |
|    time_elapsed         | 120356    |
|    total_timesteps      | 602112    |
| train/                  |           |
|    approx_kl            | 0.0814867 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.16     |
|    explained_variance   | 0.569     |
|    learning_rate        | 0.0003    |
|    loss                 | 427       |
|    n_updates            | 2930      |
|    policy_gradient_loss | -0.0189   |
|    std                  | 0.408     |
|    value_loss           | 1.22e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 295         |
|    time_elapsed         | 120697      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.102259934 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.15       |
|    explained_variance   | 0.531       |
|    learning_rate        | 0.0003      |
|    loss                 | 559         |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.408       |
|    value_loss           | 1.36e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 296        |
|    time_elapsed         | 121034     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.16775346 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.13      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 496        |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0072    |
|    std                  | 0.407      |
|    value_loss           | 1.1e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 297        |
|    time_elapsed         | 121367     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.08227205 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.13      |
|    explained_variance   | 0.55       |
|    learning_rate        | 0.0003     |
|    loss                 | 466        |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.00447    |
|    std                  | 0.406      |
|    value_loss           | 1.3e+03    |
----------------------------------------
Eval num_timesteps=610000, episode_reward=1011.01 +/- 0.05
Episode length: 22.00 +/- 1.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.08966345 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.12      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 668        |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.406      |
|    value_loss           | 1.12e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 298      |
|    time_elapsed    | 121713   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 299         |
|    time_elapsed         | 122046      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.069850616 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.12       |
|    explained_variance   | 0.527       |
|    learning_rate        | 0.0003      |
|    loss                 | 553         |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.406       |
|    value_loss           | 1.39e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 300         |
|    time_elapsed         | 122379      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.076568276 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.12       |
|    explained_variance   | 0.593       |
|    learning_rate        | 0.0003      |
|    loss                 | 506         |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.406       |
|    value_loss           | 1.2e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 301         |
|    time_elapsed         | 122712      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.061498836 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.11       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 605         |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.406       |
|    value_loss           | 1.31e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 302         |
|    time_elapsed         | 123047      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.051780988 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.12       |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0003      |
|    loss                 | 733         |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.406       |
|    value_loss           | 1.42e+03    |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=1011.16 +/- 0.97
Episode length: 23.40 +/- 3.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.08799745 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.12      |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.0003     |
|    loss                 | 979        |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.00965   |
|    std                  | 0.406      |
|    value_loss           | 1.37e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 303      |
|    time_elapsed    | 123391   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 304         |
|    time_elapsed         | 123723      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.072719924 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.09       |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.0003      |
|    loss                 | 779         |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.404       |
|    value_loss           | 1.38e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 305        |
|    time_elapsed         | 124058     |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.09077954 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.05      |
|    explained_variance   | 0.58       |
|    learning_rate        | 0.0003     |
|    loss                 | 542        |
|    n_updates            | 3040       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.402      |
|    value_loss           | 1.28e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 306         |
|    time_elapsed         | 124396      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.109287396 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.03       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.0003      |
|    loss                 | 378         |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.402       |
|    value_loss           | 958         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 307        |
|    time_elapsed         | 124734     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.06801961 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.01      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | 560        |
|    n_updates            | 3060       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.401      |
|    value_loss           | 1.16e+03   |
----------------------------------------
Eval num_timesteps=630000, episode_reward=1013.86 +/- 5.73
Episode length: 28.20 +/- 10.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.07511158 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.99      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | 582        |
|    n_updates            | 3070       |
|    policy_gradient_loss | -0.00883   |
|    std                  | 0.4        |
|    value_loss           | 937        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 308      |
|    time_elapsed    | 125081   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 309         |
|    time_elapsed         | 125414      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.066004656 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.99       |
|    explained_variance   | 0.523       |
|    learning_rate        | 0.0003      |
|    loss                 | 896         |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.4         |
|    value_loss           | 1.44e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 310        |
|    time_elapsed         | 125747     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.10999652 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.99      |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.0003     |
|    loss                 | 597        |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.399      |
|    value_loss           | 910        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 311        |
|    time_elapsed         | 126082     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.11740593 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.99      |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | 407        |
|    n_updates            | 3100       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.4        |
|    value_loss           | 1.02e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 312        |
|    time_elapsed         | 126413     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.05956591 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4         |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | 522        |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.401      |
|    value_loss           | 921        |
----------------------------------------
Eval num_timesteps=640000, episode_reward=1010.44 +/- 0.49
Episode length: 20.60 +/- 1.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.046956144 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.98       |
|    explained_variance   | 0.418       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+03    |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.0263     |
|    std                  | 0.398       |
|    value_loss           | 1.78e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 313      |
|    time_elapsed    | 126755   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 314         |
|    time_elapsed         | 127088      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.089938745 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.95       |
|    explained_variance   | 0.594       |
|    learning_rate        | 0.0003      |
|    loss                 | 510         |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.398       |
|    value_loss           | 1.19e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 315        |
|    time_elapsed         | 127421     |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.06196235 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.95      |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | 710        |
|    n_updates            | 3140       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.397      |
|    value_loss           | 1.23e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 316         |
|    time_elapsed         | 127754      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.105815984 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.95       |
|    explained_variance   | 0.661       |
|    learning_rate        | 0.0003      |
|    loss                 | 378         |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.398       |
|    value_loss           | 892         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 317        |
|    time_elapsed         | 128087     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.09573257 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.0003     |
|    loss                 | 570        |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.399      |
|    value_loss           | 1.2e+03    |
----------------------------------------
Eval num_timesteps=650000, episode_reward=1012.04 +/- 2.90
Episode length: 22.20 +/- 3.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.06831267 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.98      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 476        |
|    n_updates            | 3170       |
|    policy_gradient_loss | -0.00322   |
|    std                  | 0.399      |
|    value_loss           | 1.1e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 318      |
|    time_elapsed    | 128438   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 319         |
|    time_elapsed         | 128775      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.056362025 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.98       |
|    explained_variance   | 0.582       |
|    learning_rate        | 0.0003      |
|    loss                 | 542         |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.399       |
|    value_loss           | 1.13e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 22.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 320       |
|    time_elapsed         | 129108    |
|    total_timesteps      | 655360    |
| train/                  |           |
|    approx_kl            | 0.0725589 |
|    clip_fraction        | 0.341     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.97     |
|    explained_variance   | 0.551     |
|    learning_rate        | 0.0003    |
|    loss                 | 581       |
|    n_updates            | 3190      |
|    policy_gradient_loss | -0.0253   |
|    std                  | 0.398     |
|    value_loss           | 1.28e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 321        |
|    time_elapsed         | 129442     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.06235786 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.95      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.0003     |
|    loss                 | 978        |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.398      |
|    value_loss           | 1.46e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 322        |
|    time_elapsed         | 129776     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.12305014 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.94      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0003     |
|    loss                 | 652        |
|    n_updates            | 3210       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.397      |
|    value_loss           | 1.04e+03   |
----------------------------------------
Eval num_timesteps=660000, episode_reward=1011.15 +/- 1.42
Episode length: 23.60 +/- 1.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.07865209 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.92      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | 538        |
|    n_updates            | 3220       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.396      |
|    value_loss           | 888        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 323      |
|    time_elapsed    | 130122   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 324         |
|    time_elapsed         | 130456      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.111726716 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.9        |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.0003      |
|    loss                 | 298         |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.0039     |
|    std                  | 0.395       |
|    value_loss           | 856         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 325         |
|    time_elapsed         | 130789      |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.045133196 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.88       |
|    explained_variance   | 0.641       |
|    learning_rate        | 0.0003      |
|    loss                 | 570         |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.394       |
|    value_loss           | 882         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 326        |
|    time_elapsed         | 131123     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.07555581 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.86      |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 447        |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.393      |
|    value_loss           | 1.27e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 327         |
|    time_elapsed         | 131456      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.060766626 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.84       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.0003      |
|    loss                 | 472         |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.393       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=1011.72 +/- 1.60
Episode length: 25.00 +/- 4.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.084983714 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.85       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.0003      |
|    loss                 | 462         |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.00435    |
|    std                  | 0.393       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 328      |
|    time_elapsed    | 131801   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 329        |
|    time_elapsed         | 132135     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.07093574 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.84      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 767        |
|    n_updates            | 3280       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.392      |
|    value_loss           | 1.13e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 330         |
|    time_elapsed         | 132474      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.059116565 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.82       |
|    explained_variance   | 0.634       |
|    learning_rate        | 0.0003      |
|    loss                 | 553         |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.391       |
|    value_loss           | 988         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 331        |
|    time_elapsed         | 132812     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.08542343 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.81      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.0003     |
|    loss                 | 503        |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.391      |
|    value_loss           | 998        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 332         |
|    time_elapsed         | 133147      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.061588377 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.79       |
|    explained_variance   | 0.528       |
|    learning_rate        | 0.0003      |
|    loss                 | 481         |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.39        |
|    value_loss           | 1.23e+03    |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=1013.10 +/- 5.24
Episode length: 27.00 +/- 7.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.080958195 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.76       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.0003      |
|    loss                 | 429         |
|    n_updates            | 3320        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.388       |
|    value_loss           | 873         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 333      |
|    time_elapsed    | 133493   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 334        |
|    time_elapsed         | 133826     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.04821977 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.74      |
|    explained_variance   | 0.477      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.3e+03    |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.387      |
|    value_loss           | 1.52e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 335        |
|    time_elapsed         | 134162     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.08186358 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.0003     |
|    loss                 | 723        |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.386      |
|    value_loss           | 1.08e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 336        |
|    time_elapsed         | 134495     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.12495369 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 719        |
|    n_updates            | 3350       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.386      |
|    value_loss           | 1.02e+03   |
----------------------------------------
Eval num_timesteps=690000, episode_reward=1011.42 +/- 1.44
Episode length: 21.80 +/- 3.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.08852382 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.7       |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0003     |
|    loss                 | 402        |
|    n_updates            | 3360       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.385      |
|    value_loss           | 933        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 337      |
|    time_elapsed    | 134845   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 338         |
|    time_elapsed         | 135178      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.066880465 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.67       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.0003      |
|    loss                 | 375         |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.384       |
|    value_loss           | 942         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 339        |
|    time_elapsed         | 135517     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.16741683 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.66      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 522        |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.384      |
|    value_loss           | 1.13e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 340        |
|    time_elapsed         | 135850     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.10321627 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.0003     |
|    loss                 | 322        |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.384      |
|    value_loss           | 850        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 341         |
|    time_elapsed         | 136190      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.055501368 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.65       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.0003      |
|    loss                 | 583         |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 0.384       |
|    value_loss           | 1.12e+03    |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=1010.45 +/- 0.47
Episode length: 21.40 +/- 2.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.15136492 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.0003     |
|    loss                 | 543        |
|    n_updates            | 3410       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.383      |
|    value_loss           | 841        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 342      |
|    time_elapsed    | 136537   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 343        |
|    time_elapsed         | 136871     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.08846021 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.64      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 434        |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.00998   |
|    std                  | 0.383      |
|    value_loss           | 816        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 344         |
|    time_elapsed         | 137205      |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.114225164 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.62       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.0003      |
|    loss                 | 376         |
|    n_updates            | 3430        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.382       |
|    value_loss           | 1.08e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.7      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 345       |
|    time_elapsed         | 137538    |
|    total_timesteps      | 706560    |
| train/                  |           |
|    approx_kl            | 0.0889357 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.59     |
|    explained_variance   | 0.64      |
|    learning_rate        | 0.0003    |
|    loss                 | 550       |
|    n_updates            | 3440      |
|    policy_gradient_loss | -0.0109   |
|    std                  | 0.38      |
|    value_loss           | 941       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 346        |
|    time_elapsed         | 137872     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.06661194 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.56      |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.0003     |
|    loss                 | 313        |
|    n_updates            | 3450       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.379      |
|    value_loss           | 701        |
----------------------------------------
Eval num_timesteps=710000, episode_reward=1010.69 +/- 0.47
Episode length: 19.60 +/- 2.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.10666632 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.55      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.0003     |
|    loss                 | 373        |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.378      |
|    value_loss           | 710        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 347      |
|    time_elapsed    | 138215   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 348        |
|    time_elapsed         | 138549     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.07370189 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 368        |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.377      |
|    value_loss           | 1.02e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 349        |
|    time_elapsed         | 138883     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.12140505 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.51      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.0003     |
|    loss                 | 400        |
|    n_updates            | 3480       |
|    policy_gradient_loss | -0.00707   |
|    std                  | 0.377      |
|    value_loss           | 1.01e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 350        |
|    time_elapsed         | 139218     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.12409352 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.49      |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0003     |
|    loss                 | 626        |
|    n_updates            | 3490       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.375      |
|    value_loss           | 752        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 351        |
|    time_elapsed         | 139552     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.09306218 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.49      |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.0003     |
|    loss                 | 253        |
|    n_updates            | 3500       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.377      |
|    value_loss           | 792        |
----------------------------------------
Eval num_timesteps=720000, episode_reward=1011.22 +/- 0.37
Episode length: 21.20 +/- 2.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.099040635 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.52       |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.0003      |
|    loss                 | 267         |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.00791    |
|    std                  | 0.377       |
|    value_loss           | 688         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 352      |
|    time_elapsed    | 139900   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 353        |
|    time_elapsed         | 140241     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.17430693 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.5       |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 372        |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.00867   |
|    std                  | 0.375      |
|    value_loss           | 700        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 354        |
|    time_elapsed         | 140578     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.10406833 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.47      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.0003     |
|    loss                 | 241        |
|    n_updates            | 3530       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.374      |
|    value_loss           | 567        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 355        |
|    time_elapsed         | 140913     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.06730956 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.44      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 354        |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.00454   |
|    std                  | 0.374      |
|    value_loss           | 847        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 356        |
|    time_elapsed         | 141248     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.19649604 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.44      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.0003     |
|    loss                 | 305        |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.0159    |
|    std                  | 0.373      |
|    value_loss           | 631        |
----------------------------------------
Eval num_timesteps=730000, episode_reward=1010.47 +/- 0.80
Episode length: 20.20 +/- 0.98
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.100115284 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.42       |
|    explained_variance   | 0.672       |
|    learning_rate        | 0.0003      |
|    loss                 | 408         |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.372       |
|    value_loss           | 800         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 357      |
|    time_elapsed    | 141592   |
|    total_timesteps | 731136   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.2      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 358       |
|    time_elapsed         | 141928    |
|    total_timesteps      | 733184    |
| train/                  |           |
|    approx_kl            | 0.1407241 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.4      |
|    explained_variance   | 0.647     |
|    learning_rate        | 0.0003    |
|    loss                 | 458       |
|    n_updates            | 3570      |
|    policy_gradient_loss | -0.0153   |
|    std                  | 0.372     |
|    value_loss           | 867       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 359        |
|    time_elapsed         | 142264     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.10666932 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.4       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0003     |
|    loss                 | 423        |
|    n_updates            | 3580       |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.372      |
|    value_loss           | 714        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 360        |
|    time_elapsed         | 142599     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.11662357 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.39      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | 391        |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.371      |
|    value_loss           | 896        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 361        |
|    time_elapsed         | 142937     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.43242106 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.37      |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.0003     |
|    loss                 | 247        |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.00235    |
|    std                  | 0.371      |
|    value_loss           | 484        |
----------------------------------------
Eval num_timesteps=740000, episode_reward=1013.74 +/- 4.15
Episode length: 25.40 +/- 6.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.08644436 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.36      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 377        |
|    n_updates            | 3610       |
|    policy_gradient_loss | 8.07e-05   |
|    std                  | 0.369      |
|    value_loss           | 709        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 362      |
|    time_elapsed    | 143285   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 363        |
|    time_elapsed         | 143620     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.13154194 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.34      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 319        |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.00289   |
|    std                  | 0.369      |
|    value_loss           | 640        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 364        |
|    time_elapsed         | 143961     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.31593752 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.31      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 294        |
|    n_updates            | 3630       |
|    policy_gradient_loss | 0.000391   |
|    std                  | 0.367      |
|    value_loss           | 586        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 365         |
|    time_elapsed         | 144296      |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.090414435 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.29       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.0003      |
|    loss                 | 202         |
|    n_updates            | 3640        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.367       |
|    value_loss           | 667         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20        |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 366       |
|    time_elapsed         | 144631    |
|    total_timesteps      | 749568    |
| train/                  |           |
|    approx_kl            | 0.1863997 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.27     |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.0003    |
|    loss                 | 322       |
|    n_updates            | 3650      |
|    policy_gradient_loss | 0.0151    |
|    std                  | 0.365     |
|    value_loss           | 839       |
---------------------------------------
Eval num_timesteps=750000, episode_reward=1011.79 +/- 0.90
Episode length: 23.00 +/- 2.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.10174962 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.26      |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | 330        |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.365      |
|    value_loss           | 774        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 367      |
|    time_elapsed    | 144978   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 368        |
|    time_elapsed         | 145313     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.12606168 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.25      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.0003     |
|    loss                 | 427        |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.000313  |
|    std                  | 0.365      |
|    value_loss           | 601        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 369        |
|    time_elapsed         | 145648     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.13008338 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.26      |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.0003     |
|    loss                 | 193        |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.000793  |
|    std                  | 0.366      |
|    value_loss           | 545        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 370        |
|    time_elapsed         | 145983     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.07217668 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.27      |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.0003     |
|    loss                 | 311        |
|    n_updates            | 3690       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.366      |
|    value_loss           | 694        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 371        |
|    time_elapsed         | 146318     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.16604383 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.26      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.0003     |
|    loss                 | 349        |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.0027     |
|    std                  | 0.365      |
|    value_loss           | 633        |
----------------------------------------
Eval num_timesteps=760000, episode_reward=1012.39 +/- 3.68
Episode length: 23.40 +/- 5.35
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 23.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 760000    |
| train/                  |           |
|    approx_kl            | 0.1201943 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.24     |
|    explained_variance   | 0.687     |
|    learning_rate        | 0.0003    |
|    loss                 | 240       |
|    n_updates            | 3710      |
|    policy_gradient_loss | -0.0099   |
|    std                  | 0.365     |
|    value_loss           | 737       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 372      |
|    time_elapsed    | 146665   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 373         |
|    time_elapsed         | 147000      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.070935264 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.22       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.0003      |
|    loss                 | 237         |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.363       |
|    value_loss           | 712         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 374         |
|    time_elapsed         | 147334      |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.101111695 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.18       |
|    explained_variance   | 0.737       |
|    learning_rate        | 0.0003      |
|    loss                 | 255         |
|    n_updates            | 3730        |
|    policy_gradient_loss | -0.00794    |
|    std                  | 0.362       |
|    value_loss           | 574         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 375        |
|    time_elapsed         | 147669     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.11042358 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.16      |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.0003     |
|    loss                 | 418        |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.361      |
|    value_loss           | 881        |
----------------------------------------
Eval num_timesteps=770000, episode_reward=1010.25 +/- 0.38
Episode length: 20.60 +/- 1.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.17965871 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.15      |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.0003     |
|    loss                 | 234        |
|    n_updates            | 3750       |
|    policy_gradient_loss | -0.00632   |
|    std                  | 0.361      |
|    value_loss           | 555        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 376      |
|    time_elapsed    | 148019   |
|    total_timesteps | 770048   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 377        |
|    time_elapsed         | 148355     |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.12390064 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.14      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.0003     |
|    loss                 | 408        |
|    n_updates            | 3760       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.36       |
|    value_loss           | 692        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 378         |
|    time_elapsed         | 148689      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.110130966 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.13       |
|    explained_variance   | 0.682       |
|    learning_rate        | 0.0003      |
|    loss                 | 333         |
|    n_updates            | 3770        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.359       |
|    value_loss           | 714         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 379        |
|    time_elapsed         | 149023     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.09313198 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.11      |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.0003     |
|    loss                 | 518        |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.00753   |
|    std                  | 0.359      |
|    value_loss           | 1e+03      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 380        |
|    time_elapsed         | 149359     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.29960406 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.1       |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 390        |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.00919    |
|    std                  | 0.358      |
|    value_loss           | 1.03e+03   |
----------------------------------------
Eval num_timesteps=780000, episode_reward=1011.05 +/- 1.01
Episode length: 20.80 +/- 2.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.18499261 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.09      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 271        |
|    n_updates            | 3800       |
|    policy_gradient_loss | -0.00838   |
|    std                  | 0.359      |
|    value_loss           | 639        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 381      |
|    time_elapsed    | 149704   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 382         |
|    time_elapsed         | 150041      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.109471746 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.11       |
|    explained_variance   | 0.72        |
|    learning_rate        | 0.0003      |
|    loss                 | 309         |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.359       |
|    value_loss           | 637         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 383        |
|    time_elapsed         | 150376     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.08397302 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.11      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 457        |
|    n_updates            | 3820       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.359      |
|    value_loss           | 788        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20        |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 384       |
|    time_elapsed         | 150714    |
|    total_timesteps      | 786432    |
| train/                  |           |
|    approx_kl            | 0.2736561 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.1      |
|    explained_variance   | 0.692     |
|    learning_rate        | 0.0003    |
|    loss                 | 303       |
|    n_updates            | 3830      |
|    policy_gradient_loss | 0.0079    |
|    std                  | 0.359     |
|    value_loss           | 660       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 385        |
|    time_elapsed         | 151049     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.12760785 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.08      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.0003     |
|    loss                 | 212        |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.00394   |
|    std                  | 0.358      |
|    value_loss           | 543        |
----------------------------------------
Eval num_timesteps=790000, episode_reward=1010.66 +/- 1.14
Episode length: 21.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.092781425 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.06       |
|    explained_variance   | 0.755       |
|    learning_rate        | 0.0003      |
|    loss                 | 155         |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.357       |
|    value_loss           | 542         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 386      |
|    time_elapsed    | 151395   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 387        |
|    time_elapsed         | 151730     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.39409754 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.04      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.0003     |
|    loss                 | 247        |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.00482   |
|    std                  | 0.355      |
|    value_loss           | 576        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 388         |
|    time_elapsed         | 152076      |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.079509854 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.02       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.0003      |
|    loss                 | 555         |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.356       |
|    value_loss           | 838         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 389        |
|    time_elapsed         | 152412     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.18044034 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.03      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 215        |
|    n_updates            | 3880       |
|    policy_gradient_loss | 9.81e-05   |
|    std                  | 0.356      |
|    value_loss           | 538        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 390        |
|    time_elapsed         | 152750     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.11700267 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.02      |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.0003     |
|    loss                 | 209        |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.00894   |
|    std                  | 0.355      |
|    value_loss           | 527        |
----------------------------------------
Eval num_timesteps=800000, episode_reward=1010.64 +/- 0.46
Episode length: 20.40 +/- 2.73
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 20.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 800000    |
| train/                  |           |
|    approx_kl            | 0.1295295 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.01     |
|    explained_variance   | 0.711     |
|    learning_rate        | 0.0003    |
|    loss                 | 320       |
|    n_updates            | 3900      |
|    policy_gradient_loss | -0.0101   |
|    std                  | 0.355     |
|    value_loss           | 613       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 391      |
|    time_elapsed    | 153095   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 392        |
|    time_elapsed         | 153431     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.10280304 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3         |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.0003     |
|    loss                 | 263        |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.00882   |
|    std                  | 0.355      |
|    value_loss           | 622        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 393        |
|    time_elapsed         | 153765     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.16247185 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 332        |
|    n_updates            | 3920       |
|    policy_gradient_loss | -0.00786   |
|    std                  | 0.354      |
|    value_loss           | 641        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 394        |
|    time_elapsed         | 154107     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.10082641 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.98      |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.0003     |
|    loss                 | 238        |
|    n_updates            | 3930       |
|    policy_gradient_loss | -0.0097    |
|    std                  | 0.354      |
|    value_loss           | 575        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 395        |
|    time_elapsed         | 154442     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.10525714 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.98      |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.0003     |
|    loss                 | 306        |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.00646    |
|    std                  | 0.354      |
|    value_loss           | 492        |
----------------------------------------
Eval num_timesteps=810000, episode_reward=1011.65 +/- 1.80
Episode length: 21.20 +/- 2.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.19044605 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.0003     |
|    loss                 | 207        |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.00248   |
|    std                  | 0.354      |
|    value_loss           | 495        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 396      |
|    time_elapsed    | 154788   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 397         |
|    time_elapsed         | 155123      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.119284555 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.99       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.0003      |
|    loss                 | 287         |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.00956    |
|    std                  | 0.355       |
|    value_loss           | 665         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 398         |
|    time_elapsed         | 155460      |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.050068744 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3          |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.0003      |
|    loss                 | 322         |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.355       |
|    value_loss           | 738         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 399        |
|    time_elapsed         | 155802     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.18290438 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.0003     |
|    loss                 | 192        |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.000639   |
|    std                  | 0.355      |
|    value_loss           | 459        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 400        |
|    time_elapsed         | 156145     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.18934532 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3         |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.0003     |
|    loss                 | 176        |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.00328    |
|    std                  | 0.354      |
|    value_loss           | 408        |
----------------------------------------
Eval num_timesteps=820000, episode_reward=1011.03 +/- 1.08
Episode length: 22.20 +/- 2.23
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.12979269 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.96      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.0003     |
|    loss                 | 230        |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.00422   |
|    std                  | 0.352      |
|    value_loss           | 518        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 401      |
|    time_elapsed    | 156492   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 402        |
|    time_elapsed         | 156829     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.10410826 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.95      |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.0003     |
|    loss                 | 229        |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.0026     |
|    std                  | 0.353      |
|    value_loss           | 466        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.6      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 403       |
|    time_elapsed         | 157164    |
|    total_timesteps      | 825344    |
| train/                  |           |
|    approx_kl            | 0.2660728 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.95     |
|    explained_variance   | 0.733     |
|    learning_rate        | 0.0003    |
|    loss                 | 281       |
|    n_updates            | 4020      |
|    policy_gradient_loss | -0.00777  |
|    std                  | 0.352     |
|    value_loss           | 538       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 404        |
|    time_elapsed         | 157499     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.22449872 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.95      |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.0003     |
|    loss                 | 224        |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.00044    |
|    std                  | 0.353      |
|    value_loss           | 473        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 405        |
|    time_elapsed         | 157836     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.08930389 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.95      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.0003     |
|    loss                 | 297        |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.00534   |
|    std                  | 0.352      |
|    value_loss           | 634        |
----------------------------------------
Eval num_timesteps=830000, episode_reward=1011.46 +/- 1.25
Episode length: 21.40 +/- 4.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.08853114 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.95      |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | 326        |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.352      |
|    value_loss           | 824        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 406      |
|    time_elapsed    | 158182   |
|    total_timesteps | 831488   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 19.4     |
|    ep_rew_mean          | 1.03e+03 |
| time/                   |          |
|    fps                  | 5        |
|    iterations           | 407      |
|    time_elapsed         | 158522   |
|    total_timesteps      | 833536   |
| train/                  |          |
|    approx_kl            | 0.412261 |
|    clip_fraction        | 0.552    |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.96    |
|    explained_variance   | 0.729    |
|    learning_rate        | 0.0003   |
|    loss                 | 331      |
|    n_updates            | 4060     |
|    policy_gradient_loss | 0.0382   |
|    std                  | 0.353    |
|    value_loss           | 570      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 408         |
|    time_elapsed         | 158857      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.086799406 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.98       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.0003      |
|    loss                 | 364         |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.354       |
|    value_loss           | 552         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 409         |
|    time_elapsed         | 159197      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.093869485 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.98       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.0003      |
|    loss                 | 279         |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.353       |
|    value_loss           | 554         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 410        |
|    time_elapsed         | 159533     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.10939146 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.96      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.0003     |
|    loss                 | 274        |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.00926   |
|    std                  | 0.353      |
|    value_loss           | 606        |
----------------------------------------
Eval num_timesteps=840000, episode_reward=1010.67 +/- 0.50
Episode length: 20.60 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.14067781 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.94      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.0003     |
|    loss                 | 309        |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.00981   |
|    std                  | 0.351      |
|    value_loss           | 490        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 411      |
|    time_elapsed    | 159885   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 412        |
|    time_elapsed         | 160221     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.18895847 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.94      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 222        |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.353      |
|    value_loss           | 560        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 413        |
|    time_elapsed         | 160557     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.14580491 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.93      |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.0003     |
|    loss                 | 342        |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.35       |
|    value_loss           | 714        |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 19.1     |
|    ep_rew_mean          | 1.03e+03 |
| time/                   |          |
|    fps                  | 5        |
|    iterations           | 414      |
|    time_elapsed         | 160893   |
|    total_timesteps      | 847872   |
| train/                  |          |
|    approx_kl            | 0.176325 |
|    clip_fraction        | 0.487    |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.9     |
|    explained_variance   | 0.713    |
|    learning_rate        | 0.0003   |
|    loss                 | 286      |
|    n_updates            | 4130     |
|    policy_gradient_loss | -0.0016  |
|    std                  | 0.35     |
|    value_loss           | 570      |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 415        |
|    time_elapsed         | 161234     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.20118004 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.89      |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.0003     |
|    loss                 | 264        |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.00407   |
|    std                  | 0.349      |
|    value_loss           | 436        |
----------------------------------------
Eval num_timesteps=850000, episode_reward=1010.82 +/- 0.36
Episode length: 21.20 +/- 1.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.15925099 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.89      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.0003     |
|    loss                 | 244        |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.00814   |
|    std                  | 0.35       |
|    value_loss           | 549        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 416      |
|    time_elapsed    | 161581   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 417         |
|    time_elapsed         | 161916      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.117219776 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.91       |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.0003      |
|    loss                 | 308         |
|    n_updates            | 4160        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.351       |
|    value_loss           | 554         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 418        |
|    time_elapsed         | 162252     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.12328633 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.9       |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.0003     |
|    loss                 | 306        |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.0124    |
|    std                  | 0.35       |
|    value_loss           | 640        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 419        |
|    time_elapsed         | 162588     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.12531242 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.89      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.0003     |
|    loss                 | 241        |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.349      |
|    value_loss           | 511        |
----------------------------------------
Eval num_timesteps=860000, episode_reward=1010.82 +/- 1.12
Episode length: 21.00 +/- 3.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.105467305 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.89       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.0003      |
|    loss                 | 378         |
|    n_updates            | 4190        |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.35        |
|    value_loss           | 534         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 420      |
|    time_elapsed    | 162934   |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 421         |
|    time_elapsed         | 163270      |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.107741535 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.9        |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.0003      |
|    loss                 | 226         |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.00692    |
|    std                  | 0.35        |
|    value_loss           | 569         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 422        |
|    time_elapsed         | 163612     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.07981559 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.88      |
|    explained_variance   | 0.747      |
|    learning_rate        | 0.0003     |
|    loss                 | 172        |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.349      |
|    value_loss           | 512        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.7      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 423       |
|    time_elapsed         | 163949    |
|    total_timesteps      | 866304    |
| train/                  |           |
|    approx_kl            | 0.2090893 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.85     |
|    explained_variance   | 0.774     |
|    learning_rate        | 0.0003    |
|    loss                 | 189       |
|    n_updates            | 4220      |
|    policy_gradient_loss | -0.00445  |
|    std                  | 0.347     |
|    value_loss           | 436       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 424         |
|    time_elapsed         | 164285      |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.107686535 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.0003      |
|    loss                 | 197         |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.347       |
|    value_loss           | 613         |
-----------------------------------------
Eval num_timesteps=870000, episode_reward=1010.27 +/- 0.34
Episode length: 19.80 +/- 0.75
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 19.8     |
|    mean_reward          | 1.01e+03 |
| time/                   |          |
|    total_timesteps      | 870000   |
| train/                  |          |
|    approx_kl            | 1.341394 |
|    clip_fraction        | 0.655    |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.82    |
|    explained_variance   | 0.774    |
|    learning_rate        | 0.0003   |
|    loss                 | 230      |
|    n_updates            | 4240     |
|    policy_gradient_loss | 0.0755   |
|    std                  | 0.347    |
|    value_loss           | 420      |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 425      |
|    time_elapsed    | 164629   |
|    total_timesteps | 870400   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.8      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 426       |
|    time_elapsed         | 164964    |
|    total_timesteps      | 872448    |
| train/                  |           |
|    approx_kl            | 0.0812974 |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.82     |
|    explained_variance   | 0.633     |
|    learning_rate        | 0.0003    |
|    loss                 | 454       |
|    n_updates            | 4250      |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.346     |
|    value_loss           | 813       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 427        |
|    time_elapsed         | 165299     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.11540687 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.82      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.0003     |
|    loss                 | 340        |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.016     |
|    std                  | 0.347      |
|    value_loss           | 687        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 428         |
|    time_elapsed         | 165634      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.111900315 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.0003      |
|    loss                 | 239         |
|    n_updates            | 4270        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.346       |
|    value_loss           | 635         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 429        |
|    time_elapsed         | 165969     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.23207936 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.8       |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0003     |
|    loss                 | 244        |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0047     |
|    std                  | 0.345      |
|    value_loss           | 542        |
----------------------------------------
Eval num_timesteps=880000, episode_reward=1010.45 +/- 0.43
Episode length: 21.40 +/- 3.88
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.06458181 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.78      |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | 301        |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.344      |
|    value_loss           | 774        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 430      |
|    time_elapsed    | 166314   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 431        |
|    time_elapsed         | 166649     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.08346715 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.75      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 359        |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.343      |
|    value_loss           | 664        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 432        |
|    time_elapsed         | 166983     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.12241058 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.71      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.0003     |
|    loss                 | 223        |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.341      |
|    value_loss           | 615        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 433        |
|    time_elapsed         | 167319     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.09003328 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.69      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 173        |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.00996   |
|    std                  | 0.341      |
|    value_loss           | 570        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 434         |
|    time_elapsed         | 167659      |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.101431176 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.69       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.0003      |
|    loss                 | 185         |
|    n_updates            | 4330        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.341       |
|    value_loss           | 494         |
-----------------------------------------
Eval num_timesteps=890000, episode_reward=1010.67 +/- 0.50
Episode length: 20.00 +/- 2.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.11796656 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.67      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 221        |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.00962   |
|    std                  | 0.34       |
|    value_loss           | 567        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 435      |
|    time_elapsed    | 168006   |
|    total_timesteps | 890880   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.3      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 436       |
|    time_elapsed         | 168344    |
|    total_timesteps      | 892928    |
| train/                  |           |
|    approx_kl            | 0.3919762 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.67     |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.0003    |
|    loss                 | 311       |
|    n_updates            | 4350      |
|    policy_gradient_loss | 0.0249    |
|    std                  | 0.341     |
|    value_loss           | 531       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 437        |
|    time_elapsed         | 168679     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.07211239 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.67      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.0003     |
|    loss                 | 247        |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.34       |
|    value_loss           | 567        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 438        |
|    time_elapsed         | 169016     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.07521173 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.66      |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.0003     |
|    loss                 | 371        |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.34       |
|    value_loss           | 631        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 439         |
|    time_elapsed         | 169352      |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.090066016 |
|    clip_fraction        | 0.438       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.0003      |
|    loss                 | 335         |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.34        |
|    value_loss           | 638         |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=1010.31 +/- 0.39
Episode length: 18.80 +/- 1.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 18.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.11105466 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.782      |
|    learning_rate        | 0.0003     |
|    loss                 | 176        |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.00896   |
|    std                  | 0.341      |
|    value_loss           | 451        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 440      |
|    time_elapsed    | 169701   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 441         |
|    time_elapsed         | 170036      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.115088806 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.0003      |
|    loss                 | 123         |
|    n_updates            | 4400        |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.34        |
|    value_loss           | 390         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 442        |
|    time_elapsed         | 170382     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.11990832 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.0003     |
|    loss                 | 245        |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.00677   |
|    std                  | 0.341      |
|    value_loss           | 483        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 443        |
|    time_elapsed         | 170717     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.18675703 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.7       |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.0003     |
|    loss                 | 304        |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.000454   |
|    std                  | 0.341      |
|    value_loss           | 515        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 444        |
|    time_elapsed         | 171052     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.10467303 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.0003     |
|    loss                 | 414        |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.34       |
|    value_loss           | 503        |
----------------------------------------
Eval num_timesteps=910000, episode_reward=1011.59 +/- 2.14
Episode length: 23.60 +/- 5.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.15222962 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.67      |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.0003     |
|    loss                 | 241        |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.000346   |
|    std                  | 0.341      |
|    value_loss           | 405        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 445      |
|    time_elapsed    | 171406   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 446        |
|    time_elapsed         | 171749     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.18306118 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.0003     |
|    loss                 | 182        |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.00782    |
|    std                  | 0.34       |
|    value_loss           | 447        |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 19.8     |
|    ep_rew_mean          | 1.03e+03 |
| time/                   |          |
|    fps                  | 5        |
|    iterations           | 447      |
|    time_elapsed         | 172084   |
|    total_timesteps      | 915456   |
| train/                  |          |
|    approx_kl            | 0.300434 |
|    clip_fraction        | 0.483    |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.67    |
|    explained_variance   | 0.768    |
|    learning_rate        | 0.0003   |
|    loss                 | 330      |
|    n_updates            | 4460     |
|    policy_gradient_loss | 0.00861  |
|    std                  | 0.34     |
|    value_loss           | 484      |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.1      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 448       |
|    time_elapsed         | 172425    |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 0.1569243 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.67     |
|    explained_variance   | 0.753     |
|    learning_rate        | 0.0003    |
|    loss                 | 325       |
|    n_updates            | 4470      |
|    policy_gradient_loss | -0.00979  |
|    std                  | 0.34      |
|    value_loss           | 513       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 449        |
|    time_elapsed         | 172761     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.11928491 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.0003     |
|    loss                 | 245        |
|    n_updates            | 4480       |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.341      |
|    value_loss           | 509        |
----------------------------------------
Eval num_timesteps=920000, episode_reward=1010.90 +/- 0.40
Episode length: 19.00 +/- 0.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.14867467 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.68      |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.0003     |
|    loss                 | 255        |
|    n_updates            | 4490       |
|    policy_gradient_loss | -0.00633   |
|    std                  | 0.34       |
|    value_loss           | 490        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 450      |
|    time_elapsed    | 173111   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 451        |
|    time_elapsed         | 173448     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.10448162 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.67      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 413        |
|    n_updates            | 4500       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.34       |
|    value_loss           | 566        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 452        |
|    time_elapsed         | 173787     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.19746053 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.66      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.0003     |
|    loss                 | 244        |
|    n_updates            | 4510       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.339      |
|    value_loss           | 484        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 453        |
|    time_elapsed         | 174124     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.07679751 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.65      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.0003     |
|    loss                 | 320        |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.339      |
|    value_loss           | 576        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 454        |
|    time_elapsed         | 174463     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.15427393 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.63      |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.0003     |
|    loss                 | 186        |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.337      |
|    value_loss           | 444        |
----------------------------------------
Eval num_timesteps=930000, episode_reward=1010.89 +/- 0.35
Episode length: 19.20 +/- 2.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.11055446 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.61      |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.0003     |
|    loss                 | 239        |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.338      |
|    value_loss           | 540        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 455      |
|    time_elapsed    | 174808   |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 456        |
|    time_elapsed         | 175144     |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.10951625 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.59      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.0003     |
|    loss                 | 258        |
|    n_updates            | 4550       |
|    policy_gradient_loss | 0.00391    |
|    std                  | 0.336      |
|    value_loss           | 591        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 457        |
|    time_elapsed         | 175487     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.15707418 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.55      |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.0003     |
|    loss                 | 389        |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.00202    |
|    std                  | 0.334      |
|    value_loss           | 573        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 458        |
|    time_elapsed         | 175825     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.13486505 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0003     |
|    loss                 | 252        |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.00204   |
|    std                  | 0.334      |
|    value_loss           | 463        |
----------------------------------------
Eval num_timesteps=940000, episode_reward=1011.10 +/- 1.17
Episode length: 21.00 +/- 3.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.36432523 |
|    clip_fraction        | 0.529      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.52      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.0003     |
|    loss                 | 211        |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.00643    |
|    std                  | 0.333      |
|    value_loss           | 484        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.3     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 459      |
|    time_elapsed    | 176172   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 460        |
|    time_elapsed         | 176507     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.54160297 |
|    clip_fraction        | 0.574      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.0003     |
|    loss                 | 84         |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.332      |
|    value_loss           | 328        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 461         |
|    time_elapsed         | 176843      |
|    total_timesteps      | 944128      |
| train/                  |             |
|    approx_kl            | 0.085348815 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.48       |
|    explained_variance   | 0.651       |
|    learning_rate        | 0.0003      |
|    loss                 | 259         |
|    n_updates            | 4600        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.332       |
|    value_loss           | 720         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 462        |
|    time_elapsed         | 177184     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.22036469 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.48      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.0003     |
|    loss                 | 326        |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.332      |
|    value_loss           | 468        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 17.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 463        |
|    time_elapsed         | 177521     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.13191928 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 368        |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.333      |
|    value_loss           | 591        |
----------------------------------------
Eval num_timesteps=950000, episode_reward=1010.49 +/- 0.53
Episode length: 19.60 +/- 1.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.18028858 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.51      |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.0003     |
|    loss                 | 169        |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.00472    |
|    std                  | 0.334      |
|    value_loss           | 435        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 464      |
|    time_elapsed    | 177867   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 465         |
|    time_elapsed         | 178203      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.109627105 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.51       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.0003      |
|    loss                 | 265         |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.0095     |
|    std                  | 0.333       |
|    value_loss           | 483         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 466        |
|    time_elapsed         | 178539     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.11880641 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.5       |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.0003     |
|    loss                 | 200        |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.00705   |
|    std                  | 0.333      |
|    value_loss           | 386        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 467        |
|    time_elapsed         | 178874     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.16706589 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.5       |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.0003     |
|    loss                 | 233        |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.333      |
|    value_loss           | 538        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 468        |
|    time_elapsed         | 179217     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.33301765 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.0003     |
|    loss                 | 197        |
|    n_updates            | 4670       |
|    policy_gradient_loss | -0.00345   |
|    std                  | 0.333      |
|    value_loss           | 503        |
----------------------------------------
Eval num_timesteps=960000, episode_reward=1010.47 +/- 0.48
Episode length: 19.80 +/- 2.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.45611715 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0003     |
|    loss                 | 319        |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.00492   |
|    std                  | 0.332      |
|    value_loss           | 555        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 469      |
|    time_elapsed    | 179564   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 470        |
|    time_elapsed         | 179899     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.61607444 |
|    clip_fraction        | 0.576      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.0003     |
|    loss                 | 391        |
|    n_updates            | 4690       |
|    policy_gradient_loss | 0.027      |
|    std                  | 0.333      |
|    value_loss           | 714        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 471        |
|    time_elapsed         | 180235     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.43954086 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.0003     |
|    loss                 | 219        |
|    n_updates            | 4700       |
|    policy_gradient_loss | -0.00636   |
|    std                  | 0.332      |
|    value_loss           | 522        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 472        |
|    time_elapsed         | 180571     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.10558972 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.48      |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.0003     |
|    loss                 | 189        |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.00678   |
|    std                  | 0.332      |
|    value_loss           | 373        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 473        |
|    time_elapsed         | 180917     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.16824692 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.47      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.0003     |
|    loss                 | 166        |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.00646    |
|    std                  | 0.331      |
|    value_loss           | 342        |
----------------------------------------
Eval num_timesteps=970000, episode_reward=1010.66 +/- 0.45
Episode length: 20.40 +/- 2.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.39418632 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.46      |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.0003     |
|    loss                 | 176        |
|    n_updates            | 4730       |
|    policy_gradient_loss | -0.00261   |
|    std                  | 0.332      |
|    value_loss           | 447        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 474      |
|    time_elapsed    | 181263   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 475        |
|    time_elapsed         | 181599     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.11803503 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.46      |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.0003     |
|    loss                 | 286        |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.331      |
|    value_loss           | 573        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 476        |
|    time_elapsed         | 181935     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.50346875 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.44      |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.0003     |
|    loss                 | 206        |
|    n_updates            | 4750       |
|    policy_gradient_loss | 0.00455    |
|    std                  | 0.33       |
|    value_loss           | 476        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 477        |
|    time_elapsed         | 182270     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.12866306 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.42      |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.0003     |
|    loss                 | 258        |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.00863   |
|    std                  | 0.33       |
|    value_loss           | 430        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 478        |
|    time_elapsed         | 182607     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.16696835 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.41      |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.0003     |
|    loss                 | 150        |
|    n_updates            | 4770       |
|    policy_gradient_loss | 0.00571    |
|    std                  | 0.329      |
|    value_loss           | 496        |
----------------------------------------
Eval num_timesteps=980000, episode_reward=1010.29 +/- 0.37
Episode length: 19.80 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.093437254 |
|    clip_fraction        | 0.437       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.39       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.0003      |
|    loss                 | 215         |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.328       |
|    value_loss           | 429         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 479      |
|    time_elapsed    | 182955   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 480        |
|    time_elapsed         | 183298     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.20200594 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.37      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.0003     |
|    loss                 | 275        |
|    n_updates            | 4790       |
|    policy_gradient_loss | 0.00139    |
|    std                  | 0.328      |
|    value_loss           | 480        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 481       |
|    time_elapsed         | 183640    |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 1.1659596 |
|    clip_fraction        | 0.605     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.36     |
|    explained_variance   | 0.777     |
|    learning_rate        | 0.0003    |
|    loss                 | 264       |
|    n_updates            | 4800      |
|    policy_gradient_loss | 0.0351    |
|    std                  | 0.327     |
|    value_loss           | 386       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 482        |
|    time_elapsed         | 183975     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.62751734 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.35      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.0003     |
|    loss                 | 174        |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.00432   |
|    std                  | 0.327      |
|    value_loss           | 497        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 483        |
|    time_elapsed         | 184319     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.39975196 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.35      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.0003     |
|    loss                 | 148        |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.00451   |
|    std                  | 0.327      |
|    value_loss           | 375        |
----------------------------------------
Eval num_timesteps=990000, episode_reward=1010.26 +/- 0.41
Episode length: 19.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.20429051 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.35      |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.0003     |
|    loss                 | 165        |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.00618   |
|    std                  | 0.327      |
|    value_loss           | 348        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 484      |
|    time_elapsed    | 184664   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 485        |
|    time_elapsed         | 185000     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.12972586 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.36      |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.0003     |
|    loss                 | 182        |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.00687   |
|    std                  | 0.328      |
|    value_loss           | 413        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 486        |
|    time_elapsed         | 185335     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.32397556 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.35      |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.0003     |
|    loss                 | 160        |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.0056     |
|    std                  | 0.327      |
|    value_loss           | 328        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 487        |
|    time_elapsed         | 185671     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.08130579 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.33      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.0003     |
|    loss                 | 146        |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.326      |
|    value_loss           | 368        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.7      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 488       |
|    time_elapsed         | 186011    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.2616679 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.32     |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.0003    |
|    loss                 | 200       |
|    n_updates            | 4870      |
|    policy_gradient_loss | 0.00501   |
|    std                  | 0.327     |
|    value_loss           | 360       |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=1011.07 +/- 1.51
Episode length: 20.20 +/- 2.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.26934645 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.32      |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.0003     |
|    loss                 | 289        |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.00454    |
|    std                  | 0.326      |
|    value_loss           | 460        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 489      |
|    time_elapsed    | 186356   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-02-01_23-47-49_llm_triton_qwen_32b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 2 days, 3:41:44 < 0:00:00 , 6 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.856744  -99.933003  -99.813206  -99.847331  -98.874022]
 [ -99.91707   -99.838534  -99.832077  -99.815153  -99.903647]
 [ -99.77703   -99.846149  -99.828807  -99.877589  -99.847358]
 [ -32.091519  -39.686194  -51.07552   -40.153997  -33.03873 ]
 [ -16.564009   -6.357008    8.416784   -5.703795   11.163665]
 [  92.500293   53.523532   80.53575   127.748423   75.564725]
 [ 199.936527  137.669468  196.933367  182.868744  158.552941]
 [ 175.79926   162.137538  165.91827   165.863445  141.932034]
 [ 190.690662  234.780578  205.931012  215.335871  242.851443]
 [ 330.627887  326.607877  317.68518   341.144536  340.721442]
 [1085.721072  297.4658    291.659872  320.352407  298.78195 ]
 [1249.756714  290.887651 1207.764789  268.879358 1224.75757 ]
 [ 317.343903  366.808361  404.055845 1079.185412 1218.246653]
 [1329.609677 1009.949144 1364.69409  1079.328165 1191.521177]
 [1151.149404 1086.788938 1030.535967 1109.69869  1077.253312]
 [1063.457914 1052.652168 1097.385508 1073.06242  1063.13846 ]
 [ 971.340336 1037.726497 1009.972922 1029.79731  1013.743877]
 [1022.795036 1063.980945 1040.955623 1018.461172 1041.00141 ]
 [1061.391881 1059.13241  1031.678468 1027.359533 1105.638199]
 [1010.761107 1011.730796 1055.829033 1013.741905 1011.757536]
 [1024.459374 1029.916681 1017.691933 1011.643002 1016.589329]
 [1011.905823 1023.03248  1027.366156 1010.685779 1010.017155]
 [1042.145476 1023.451391 1016.504349 1023.12889  1013.641495]
 [1056.582094 1019.327114 1010.949188 1018.68552  1010.959592]
 [1012.67857  1010.021224 1012.458078 1016.580556 1014.73749 ]
 [1011.104052 1012.907077 1009.990124 1010.117162 1011.787059]
 [1034.628851 1024.228772 1014.797558 1010.906674 1015.824342]
 [1010.919099 1014.91066  1009.957875 1012.872689 1016.775245]
 [1028.078319 1010.026458 1023.336688 1010.950746 1011.873634]
 [1013.650207 1009.978831 1012.984146 1012.613522 1009.809   ]
 [1017.796814 1010.13754  1010.070299 1016.749276 1017.807776]
 [1022.527488 1009.994813 1010.773963 1011.070293 1010.028709]
 [1009.99232  1013.938848 1012.909715 1010.923094 1010.979843]
 [1010.026422 1026.228567 1017.392826 1009.929113 1010.029025]
 [1014.695063 1010.039797 1011.045959 1010.784195 1010.938727]
 [1011.865639 1010.040895 1010.986192 1026.247984 1009.980433]
 [1009.984128 1011.069931 1010.893813 1010.115396 1017.735291]
 [1010.893295 1012.000157 1019.608923 1010.927388 1011.025276]
 [1010.0757   1014.724927 1010.025899 1010.052471 1009.686235]
 [1016.686701 1019.572835 1010.826271 1009.956927 1010.921181]
 [1010.033793 1009.92232  1010.987277 1010.043659 1020.256782]
 [1009.996709 1010.83598  1017.714772 1010.98715  1011.917958]
 [1014.752541 1012.812107 1016.653181 1011.038601 1016.700037]
 [1010.017638 1010.912036 1010.072975 1016.678433 1009.982756]
 [1011.820697 1010.041516 1010.063443 1010.974154 1013.822889]
 [1009.899206 1010.896336 1013.828587 1011.102277 1014.757137]
 [1010.050024 1009.832528 1015.782043 1014.845268 1016.709233]
 [1013.703046 1010.123906 1014.71485  1009.946151 1010.888225]
 [1012.889766 1011.614458 1010.052209 1010.068483 1009.944223]
 [1014.799346 1009.956726 1010.027073 1011.017579 1010.965039]
 [1011.075255 1017.70858  1017.740174 1010.063405 1010.131021]
 [1011.077329 1010.902639 1014.884161 1011.942549 1010.016998]
 [1021.386173 1013.751741 1010.073612 1011.111325 1010.022245]
 [1009.954582 1010.887559 1011.088861 1011.128054 1011.071478]
 [1010.030481 1018.800847 1009.990086 1011.877952 1010.059689]
 [1010.9628   1010.069294 1011.917118 1010.952583 1011.036263]
 [1010.089556 1011.001645 1010.081549 1011.05266  1010.010032]
 [1011.006545 1010.995823 1011.018334 1011.019981 1010.994512]
 [1021.440159 1011.069978 1025.392004 1010.939054 1011.008567]
 [1016.764745 1010.057668 1017.825082 1010.961499 1012.842924]
 [1011.036837 1010.949646 1011.100064 1010.9753   1010.972459]
 [1011.121876 1010.801128 1010.994889 1012.924736 1009.97633 ]
 [1011.867596 1011.005117 1010.044346 1025.254979 1011.121229]
 [1009.966759 1010.079358 1011.066509 1010.078972 1011.007441]
 [1017.77707  1010.145332 1011.086541 1011.073172 1010.124587]
 [1009.980951 1010.98101  1013.84257  1010.964778 1009.969378]
 [1011.901455 1010.962747 1010.062018 1010.986844 1014.710749]
 [1010.090441 1009.900303 1010.953715 1011.036433 1023.541349]
 [1010.995474 1013.944106 1010.117201 1011.981342 1010.077734]
 [1010.027462 1010.066925 1011.032421 1010.999068 1010.103084]
 [1011.049523 1010.132848 1011.053565 1010.108419 1011.117475]
 [1011.958121 1011.008333 1011.112372 1010.991751 1011.032317]
 [1010.044616 1010.11838  1009.996678 1012.075552 1010.137278]
 [1021.721562 1013.945079 1010.991831 1010.968878 1011.067159]
 [1012.853549 1011.074629 1011.018975 1012.945746 1011.073533]
 [1010.060347 1010.112457 1011.091864 1011.010366 1019.699256]
 [1010.052742 1010.075431 1011.01052  1010.005463 1010.119125]
 [1010.093236 1010.116084 1011.081797 1012.874369 1011.059611]
 [1010.037075 1010.067207 1012.943808 1010.095761 1010.149291]
 [1011.014621 1010.0521   1011.072764 1010.963212 1010.103875]
 [1012.006004 1010.165597 1010.02474  1011.084178 1014.949956]
 [1011.099683 1010.999333 1010.0302   1010.02782  1012.980447]
 [1011.0592   1013.839385 1011.178405 1011.090608 1010.143173]
 [1011.025487 1010.021127 1010.112173 1011.109303 1011.104751]
 [1010.104118 1010.95804  1011.017302 1011.057006 1010.971228]
 [1009.92253  1012.904872 1010.054702 1011.09651  1010.143011]
 [1010.103045 1010.951964 1010.0248   1010.178805 1010.105219]
 [1010.096028 1010.90643  1010.089942 1011.048141 1010.129658]
 [1010.018096 1011.085311 1011.126946 1010.087993 1011.029124]
 [1011.090817 1010.167172 1010.135129 1010.043942 1010.131629]
 [1011.005553 1011.072273 1010.175648 1015.773944 1009.90673 ]
 [1011.135916 1010.108616 1011.052923 1011.125163 1011.059593]
 [1011.108568 1011.077626 1011.085083 1010.18784  1010.997615]
 [1012.066381 1012.922584 1010.204522 1010.164677 1010.147238]
 [1011.148969 1010.140377 1010.045545 1011.129516 1009.999832]
 [1010.131607 1011.13822  1010.971253 1010.082907 1010.030431]
 [1010.141841 1011.060173 1010.975549 1011.059864 1010.074923]
 [1010.04927  1010.165995 1010.108938 1011.01242  1010.091723]
 [1011.067691 1010.008358 1010.13458  1010.084214 1010.007404]
 [1010.110466 1013.990671 1010.096484 1011.06432  1010.069307]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3596 3562 3601 3601 3601]
 [3601 3601 3601 3581 3601]
 [3601 3601 3601 3570 3598]
 [3601 3601 3601 3601 3601]
 [3601 3585 3601 3601 3601]
 [3600 3601 3596 3601 3601]
 [3601 3601 3601 3601 3595]
 [3601 3599 3601 3601 3601]
 [ 741 3601 3601 3595 3601]
 [3470 3601 2217 3601 2923]
 [3596 3601 3601  549 2074]
 [2052   24 2420  491  958]
 [ 515  299   77  338  239]
 [ 203  229  239  283  177]
 [1703 1013   25   67   33]
 [  68  465  138   44   98]
 [ 118  130   71   84  267]
 [  31   31  146   30   33]
 [  43   63   36   33   36]
 [  27   58   51   33   24]
 [  91   47   40   57   37]
 [ 116   44   26   33   23]
 [  33   22   42   35   31]
 [  20   28   25   20   28]
 [  77   51   31   25   27]
 [  23   29   22   26   32]
 [  58   22   51   26   27]
 [  36   21   26   34   28]
 [  31   17   19   33   29]
 [  40   22   31   21   24]
 [  21   28   26   25   21]
 [  23   51   48   22   23]
 [  34   20   19   31   25]
 [  27   22   24   53   21]
 [  23   20   25   19   32]
 [  25   23   36   23   24]
 [  21   34   22   19   34]
 [  34   38   29   22   25]
 [  23   24   22   24   51]
 [  24   26   32   21   27]
 [  31   28   38   22   34]
 [  21   25   20   35   23]
 [  27   22   23   22   27]
 [  28   26   28   21   31]
 [  21   27   32   31   37]
 [  32   20   35   23   25]
 [  28   36   18   22   23]
 [  28   23   22   24   26]
 [  21   32   35   22   18]
 [  22   28   28   25   21]
 [  46   32   21   20   19]
 [  24   26   19   20   18]
 [  20   33   23   25   21]
 [  24   18   28   24   20]
 [  22   24   20   21   21]
 [  22   21   23   23   21]
 [  43   23   47   26   24]
 [  29   21   29   22   29]
 [  19   23   21   23   24]
 [  19   28   22   25   23]
 [  28   24   20   48   21]
 [  22   18   20   22   21]
 [  29   18   22   23   19]
 [  23   24   27   22   22]
 [  24   23   22   23   33]
 [  19   27   24   23   42]
 [  22   27   19   24   17]
 [  22   21   24   23   17]
 [  22   16   21   19   20]
 [  26   20   19   20   21]
 [  19   21   21   21   19]
 [  37   25   22   23   20]
 [  27   21   21   25   21]
 [  21   20   20   22   34]
 [  20   19   22   21   21]
 [  17   21   22   24   20]
 [  22   20   24   21   18]
 [  20   23   18   24   17]
 [  24   19   19   20   24]
 [  20   23   20   22   26]
 [  19   30   18   21   19]
 [  21   24   18   20   20]
 [  20   22   21   20   23]
 [  25   26   20   18   16]
 [  19   21   20   19   20]
 [  18   28   22   22   17]
 [  20   18   19   19   24]
 [  21   18   19   20   16]
 [  20   21   18   31   28]
 [  18   19   20   19   19]
 [  19   19   18   17   23]
 [  22   27   17   19   20]
 [  20   18   18   20   22]
 [  17   20   21   18   23]
 [  18   20   26   20   18]
 [  19   19   20   22   19]
 [  20   20   20   19   20]
 [  19   23   17   22   20]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-02-01_23-47-49_llm_triton_qwen_32b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-02-01_23-47-49_llm_triton_qwen_32b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
