####################
/var/spool/slurmd/job5304694/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_14B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-24_14-12-14_llm_triton_qwen_14b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 9
 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 3
 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 1
 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (20.75, -250.00).
 What is the reward score?
 
 Response: -8
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 8    |
|    iterations      | 1    |
|    time_elapsed    | 240  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | -545        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 2           |
|    time_elapsed         | 477         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.010523997 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0229      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.8         |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.996       |
|    value_loss           | 9.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | -545        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 3           |
|    time_elapsed         | 709         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010951906 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.994       |
|    value_loss           | 4.59        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.15e+03    |
|    ep_rew_mean          | -531        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 4           |
|    time_elapsed         | 942         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.014291327 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.723       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.992       |
|    value_loss           | 2.75        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.85 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 10000      |
| train/                  |            |
|    approx_kl            | 0.01366297 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.342      |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.0236    |
|    std                  | 0.99       |
|    value_loss           | 1.3        |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -513     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2976     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -513         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 6            |
|    time_elapsed         | 3208         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0069633704 |
|    clip_fraction        | 0.0445       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00525     |
|    learning_rate        | 0.0003       |
|    loss                 | 6.74         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00491     |
|    std                  | 0.991        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.63e+03    |
|    ep_rew_mean          | -492        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3442        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.014255879 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.518       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.995       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.72e+03    |
|    ep_rew_mean          | -474        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3675        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.013862693 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.541       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.208       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.999       |
|    value_loss           | 0.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.72e+03    |
|    ep_rew_mean          | -474        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 9           |
|    time_elapsed         | 3908        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.017950578 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.552       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.176       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0258     |
|    std                  | 0.998       |
|    value_loss           | 0.652       |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.86 +/- 0.40
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.014427524 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.285       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.995       |
|    value_loss           | 0.628       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -472     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5942     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -472         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 6174         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0051335166 |
|    clip_fraction        | 0.0539       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.00452      |
|    learning_rate        | 0.0003       |
|    loss                 | 4.59         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.994        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.58e+03    |
|    ep_rew_mean          | -459        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 12          |
|    time_elapsed         | 6405        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.014659299 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.32        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.278       |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.993       |
|    value_loss           | 0.57        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.64e+03    |
|    ep_rew_mean          | -451        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6640        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.014788821 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.411       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.231       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.989       |
|    value_loss           | 0.634       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.64e+03   |
|    ep_rew_mean          | -451       |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 14         |
|    time_elapsed         | 6873       |
|    total_timesteps      | 28672      |
| train/                  |            |
|    approx_kl            | 0.01618883 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.404      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.167      |
|    n_updates            | 130        |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.989      |
|    value_loss           | 0.505      |
----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.91 +/- 0.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.016611954 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.417       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.985       |
|    value_loss           | 0.604       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -449     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8905     |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -449         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 9139         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0056782905 |
|    clip_fraction        | 0.0766       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.00285      |
|    learning_rate        | 0.0003       |
|    loss                 | 1.94e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.985        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.55e+03    |
|    ep_rew_mean          | -441        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 9371        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.014710898 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -1.1        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.269       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.987       |
|    value_loss           | 0.724       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.6e+03     |
|    ep_rew_mean          | -433        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 9603        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.019109724 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.986       |
|    value_loss           | 0.524       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.6e+03     |
|    ep_rew_mean          | -433        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 9840        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.020859713 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.582       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.199       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.983       |
|    value_loss           | 0.41        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.88 +/- 0.07
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 40000      |
| train/                  |            |
|    approx_kl            | 0.01913079 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.194      |
|    n_updates            | 190        |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.984      |
|    value_loss           | 0.426      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -432     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11875    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -432        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 12109       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.009292932 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00461     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.01        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00838    |
|    std                  | 0.985       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | -421        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 12343       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.019870112 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.312       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.238       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.983       |
|    value_loss           | 0.518       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.57e+03    |
|    ep_rew_mean          | -412        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 12575       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.019433403 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.237       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.976       |
|    value_loss           | 0.398       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.57e+03    |
|    ep_rew_mean          | -412        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 24          |
|    time_elapsed         | 12810       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.021196138 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.276       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.973       |
|    value_loss           | 0.542       |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.94 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.020017866 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.471       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.274       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.974       |
|    value_loss           | 0.538       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -410     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14846    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.53e+03     |
|    ep_rew_mean          | -400         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 15082        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0081615755 |
|    clip_fraction        | 0.124        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.00156      |
|    learning_rate        | 0.0003       |
|    loss                 | 1.84e+03     |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00468     |
|    std                  | 0.973        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -400        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 15316       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.018136187 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.266       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.167       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00902    |
|    std                  | 0.966       |
|    value_loss           | 0.423       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.56e+03   |
|    ep_rew_mean          | -390       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 28         |
|    time_elapsed         | 15552      |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.02799379 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.175      |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.965      |
|    value_loss           | 0.361      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.56e+03    |
|    ep_rew_mean          | -390        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 15787       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.020335583 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.128       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.961       |
|    value_loss           | 0.408       |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.84 +/- 0.08
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.027130093 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.183       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00924    |
|    std                  | 0.955       |
|    value_loss           | 0.342       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -387     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 17821    |
|    total_timesteps | 61440    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | -382       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 31         |
|    time_elapsed         | 18056      |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.00831252 |
|    clip_fraction        | 0.0938     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.00945   |
|    learning_rate        | 0.0003     |
|    loss                 | 566        |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.00188   |
|    std                  | 0.956      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -382        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 18291       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.027409269 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.433       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.135       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0075     |
|    std                  | 0.954       |
|    value_loss           | 0.462       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.55e+03    |
|    ep_rew_mean          | -373        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 18528       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.025654327 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.174       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.949       |
|    value_loss           | 0.396       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.57e+03    |
|    ep_rew_mean          | -364        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 18764       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.026117988 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.587       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.171       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.946       |
|    value_loss           | 0.417       |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.91 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.02261443 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.221      |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.00754   |
|    std                  | 0.941      |
|    value_loss           | 0.458      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -370     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 20801    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -362        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 21037       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.016641395 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0013      |
|    learning_rate        | 0.0003      |
|    loss                 | 24.8        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.94        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -362       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 37         |
|    time_elapsed         | 21274      |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.03215237 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.235      |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.00486   |
|    std                  | 0.937      |
|    value_loss           | 0.398      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | -353        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 21512       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.025913846 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.16        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.00706    |
|    std                  | 0.933       |
|    value_loss           | 0.382       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.56e+03    |
|    ep_rew_mean          | -346        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 21748       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.029905805 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.184       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00323    |
|    std                  | 0.931       |
|    value_loss           | 0.344       |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.92 +/- 0.07
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.029075919 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.778       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.306       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.929       |
|    value_loss           | 0.926       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -351     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 23785    |
|    total_timesteps | 81920    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -342       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 41         |
|    time_elapsed         | 24018      |
|    total_timesteps      | 83968      |
| train/                  |            |
|    approx_kl            | 0.02332621 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.00171   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.69       |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.00563   |
|    std                  | 0.928      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -342        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 24255       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.027209278 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.249       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.929       |
|    value_loss           | 0.692       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | -338        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 24492       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.023646716 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.622       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.134       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00727    |
|    std                  | 0.924       |
|    value_loss           | 0.463       |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.89 +/- 0.07
Episode length: 3597.20 +/- 6.21
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.027517628 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.11        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00383    |
|    std                  | 0.918       |
|    value_loss           | 0.272       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -335     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 26530    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -335        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 26767       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.023427479 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.000643    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.68        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.918       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -328       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 46         |
|    time_elapsed         | 27003      |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.18399964 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.475      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.262      |
|    n_updates            | 450        |
|    policy_gradient_loss | 0.00319    |
|    std                  | 0.917      |
|    value_loss           | 0.327      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -321        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 27238       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.050325423 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.107       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.000474   |
|    std                  | 0.912       |
|    value_loss           | 0.333       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | -321       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 48         |
|    time_elapsed         | 27472      |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.03388767 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.00217   |
|    std                  | 0.906      |
|    value_loss           | 0.365      |
----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.84 +/- 0.04
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.03368806 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.218      |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.903      |
|    value_loss           | 0.431      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -323     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 29506    |
|    total_timesteps | 100352   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -323       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 50         |
|    time_elapsed         | 29742      |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.01566618 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.0439     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.35e+03   |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.899      |
|    value_loss           | 991        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -317        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 29978       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.034329724 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.493       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.226       |
|    n_updates            | 500         |
|    policy_gradient_loss | -4.13e-05   |
|    std                  | 0.898       |
|    value_loss           | 0.367       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -311        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 30215       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.028285176 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.213       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00334    |
|    std                  | 0.9         |
|    value_loss           | 0.307       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -311        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 30451       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.032510392 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.596       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.2         |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00569    |
|    std                  | 0.902       |
|    value_loss           | 0.396       |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.84 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.028009932 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.572       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.184       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00474    |
|    std                  | 0.897       |
|    value_loss           | 0.392       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -310     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 32487    |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -310       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 55         |
|    time_elapsed         | 32723      |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.03846409 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.00924    |
|    learning_rate        | 0.0003     |
|    loss                 | 70         |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.00664   |
|    std                  | 0.896      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -304        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 32959       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.042740464 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.185       |
|    n_updates            | 550         |
|    policy_gradient_loss | 0.00214     |
|    std                  | 0.897       |
|    value_loss           | 0.401       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | -298       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 57         |
|    time_elapsed         | 33196      |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.03575344 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.222      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.104      |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.00924   |
|    std                  | 0.898      |
|    value_loss           | 0.471      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -298        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 33434       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.039737754 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.483       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.204       |
|    n_updates            | 570         |
|    policy_gradient_loss | 0.000805    |
|    std                  | 0.896       |
|    value_loss           | 0.436       |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.84 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.036642276 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0878      |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.000428   |
|    std                  | 0.894       |
|    value_loss           | 0.266       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -296     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 35470    |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -296       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 60         |
|    time_elapsed         | 35707      |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.02620763 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.00128    |
|    learning_rate        | 0.0003     |
|    loss                 | 200        |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.00461   |
|    std                  | 0.894      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -290        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 35943       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.052366883 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.174       |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.004       |
|    std                  | 0.89        |
|    value_loss           | 0.449       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -285        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 36180       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.032232475 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.16        |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00496    |
|    std                  | 0.889       |
|    value_loss           | 0.409       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -285       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 63         |
|    time_elapsed         | 36417      |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.03428888 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.554      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.154      |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.00794   |
|    std                  | 0.885      |
|    value_loss           | 0.406      |
----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.89 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.034978483 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.239       |
|    n_updates            | 630         |
|    policy_gradient_loss | 0.00362     |
|    std                  | 0.885       |
|    value_loss           | 0.323       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -283     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 38453    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -283        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 38689       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.024260951 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00353    |
|    learning_rate        | 0.0003      |
|    loss                 | 221         |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00717    |
|    std                  | 0.885       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -278       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 66         |
|    time_elapsed         | 38924      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.05023215 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.596     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.191      |
|    n_updates            | 650        |
|    policy_gradient_loss | 0.00436    |
|    std                  | 0.885      |
|    value_loss           | 0.443      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -273        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 39160       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.043342046 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.561       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.176       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.877       |
|    value_loss           | 0.379       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -273       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 68         |
|    time_elapsed         | 39395      |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.06057807 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.199      |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.00278   |
|    std                  | 0.877      |
|    value_loss           | 0.414      |
----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.90 +/- 0.06
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.044226564 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.658       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.113       |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00395    |
|    std                  | 0.873       |
|    value_loss           | 0.335       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -271     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 41431    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -266        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 41667       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.028977742 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00272     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.6e+03     |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00215    |
|    std                  | 0.872       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -266        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 41904       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.061794147 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.183       |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.003       |
|    std                  | 0.872       |
|    value_loss           | 0.408       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 42141       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.054198734 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.16        |
|    n_updates            | 710         |
|    policy_gradient_loss | 0.00205     |
|    std                  | 0.87        |
|    value_loss           | 0.411       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 42378       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.050639987 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.19        |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.00524     |
|    std                  | 0.867       |
|    value_loss           | 0.371       |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.87 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.051021222 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.171       |
|    n_updates            | 730         |
|    policy_gradient_loss | 0.00401     |
|    std                  | 0.865       |
|    value_loss           | 0.3         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 44415    |
|    total_timesteps | 151552   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -254       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 75         |
|    time_elapsed         | 44651      |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.03841423 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.000999  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.05       |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.00513   |
|    std                  | 0.865      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -254       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 76         |
|    time_elapsed         | 44887      |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.07689318 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.334      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.209      |
|    n_updates            | 750        |
|    policy_gradient_loss | -6.72e-05  |
|    std                  | 0.861      |
|    value_loss           | 0.372      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -249       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 77         |
|    time_elapsed         | 45127      |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.04121928 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.118      |
|    n_updates            | 760        |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.859      |
|    value_loss           | 0.351      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -245        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 45366       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.038813658 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.148       |
|    n_updates            | 770         |
|    policy_gradient_loss | 0.00788     |
|    std                  | 0.858       |
|    value_loss           | 0.376       |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.93 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.055421725 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.259       |
|    n_updates            | 780         |
|    policy_gradient_loss | 0.00124     |
|    std                  | 0.85        |
|    value_loss           | 0.417       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -248     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 47405    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -244        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 47643       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.035483554 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.003       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.8         |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00339    |
|    std                  | 0.854       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -244        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 47881       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.106339276 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.2         |
|    n_updates            | 800         |
|    policy_gradient_loss | 0.00378     |
|    std                  | 0.854       |
|    value_loss           | 0.407       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -240        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 48120       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.044511244 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.172       |
|    n_updates            | 810         |
|    policy_gradient_loss | 0.0053      |
|    std                  | 0.858       |
|    value_loss           | 0.345       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 48361       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.047404073 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.135       |
|    n_updates            | 820         |
|    policy_gradient_loss | 0.00046     |
|    std                  | 0.852       |
|    value_loss           | 0.43        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.94 +/- 0.03
Episode length: 3598.20 +/- 4.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.040630717 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.687       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.000366   |
|    std                  | 0.85        |
|    value_loss           | 0.431       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -239     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 50403    |
|    total_timesteps | 172032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -235       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 85         |
|    time_elapsed         | 50642      |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.06263395 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.00389    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.87e+03   |
|    n_updates            | 840        |
|    policy_gradient_loss | -0.000736  |
|    std                  | 0.85       |
|    value_loss           | 926        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -235        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 50882       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.061806552 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.273       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.000622   |
|    std                  | 0.847       |
|    value_loss           | 0.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -230        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 51123       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.044109855 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.164       |
|    n_updates            | 860         |
|    policy_gradient_loss | 0.000629    |
|    std                  | 0.843       |
|    value_loss           | 0.334       |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.91 +/- 0.07
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.04655452 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.212      |
|    n_updates            | 870        |
|    policy_gradient_loss | 0.00412    |
|    std                  | 0.842      |
|    value_loss           | 0.373      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -230     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 53164    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -230        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 53404       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.039399847 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.000495    |
|    learning_rate        | 0.0003      |
|    loss                 | 11.7        |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00672    |
|    std                  | 0.841       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.51e+03  |
|    ep_rew_mean          | -225      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 90        |
|    time_elapsed         | 53645     |
|    total_timesteps      | 184320    |
| train/                  |           |
|    approx_kl            | 0.0805731 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.93     |
|    explained_variance   | 0.459     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.283     |
|    n_updates            | 890       |
|    policy_gradient_loss | 0.044     |
|    std                  | 0.839     |
|    value_loss           | 0.443     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -221        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 53884       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.065957606 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.156       |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.00209     |
|    std                  | 0.835       |
|    value_loss           | 0.492       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -221        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 54123       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.044579014 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.157       |
|    n_updates            | 910         |
|    policy_gradient_loss | 0.00237     |
|    std                  | 0.84        |
|    value_loss           | 0.312       |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.91 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.048430115 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.103       |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00162    |
|    std                  | 0.839       |
|    value_loss           | 0.357       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -221     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 56165    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -221       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 94         |
|    time_elapsed         | 56405      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.03219755 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | 0.00165    |
|    learning_rate        | 0.0003     |
|    loss                 | 165        |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.00694   |
|    std                  | 0.839      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -217       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 95         |
|    time_elapsed         | 56645      |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.08193999 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.231      |
|    n_updates            | 940        |
|    policy_gradient_loss | 0.000971   |
|    std                  | 0.839      |
|    value_loss           | 0.522      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -213       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 96         |
|    time_elapsed         | 56887      |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.07063466 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.152      |
|    n_updates            | 950        |
|    policy_gradient_loss | 0.00154    |
|    std                  | 0.837      |
|    value_loss           | 0.397      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -213        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 57127       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.077593796 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.299       |
|    n_updates            | 960         |
|    policy_gradient_loss | 0.00596     |
|    std                  | 0.835       |
|    value_loss           | 0.393       |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.07472433 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.197      |
|    n_updates            | 970        |
|    policy_gradient_loss | 0.00368    |
|    std                  | 0.834      |
|    value_loss           | 0.365      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -213     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 59166    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -213        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 59406       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.042893834 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -0.00335    |
|    learning_rate        | 0.0003      |
|    loss                 | 44.4        |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00505    |
|    std                  | 0.834       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -210       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 100        |
|    time_elapsed         | 59644      |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.12803222 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | -1.07      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.206      |
|    n_updates            | 990        |
|    policy_gradient_loss | 0.000294   |
|    std                  | 0.839      |
|    value_loss           | 0.737      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -207        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 59881       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.059514448 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.6         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.214       |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.0067      |
|    std                  | 0.835       |
|    value_loss           | 0.49        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -207       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 102        |
|    time_elapsed         | 60119      |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.06130854 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.253      |
|    n_updates            | 1010       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.836      |
|    value_loss           | 0.398      |
----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.84 +/- 0.06
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.053741924 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.652       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.168       |
|    n_updates            | 1020        |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.839       |
|    value_loss           | 0.401       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -207     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 62160    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -207        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 62399       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.051717937 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.00131     |
|    learning_rate        | 0.0003      |
|    loss                 | 709         |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.841       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -204       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 62638      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.05893355 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.149      |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.00536    |
|    std                  | 0.845      |
|    value_loss           | 0.452      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -201       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 62879      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.04256784 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.98      |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.174      |
|    n_updates            | 1050       |
|    policy_gradient_loss | 0.00439    |
|    std                  | 0.847      |
|    value_loss           | 0.358      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -201        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 63118       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.059248272 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.193       |
|    n_updates            | 1060        |
|    policy_gradient_loss | 0.00463     |
|    std                  | 0.843       |
|    value_loss           | 0.371       |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.91 +/- 0.06
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.048843283 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.216       |
|    n_updates            | 1070        |
|    policy_gradient_loss | 0.00409     |
|    std                  | 0.848       |
|    value_loss           | 0.446       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -201     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 65159    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -198        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 65400       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.041503485 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.00278     |
|    learning_rate        | 0.0003      |
|    loss                 | 185         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00251    |
|    std                  | 0.848       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.51e+03  |
|    ep_rew_mean          | -198      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 110       |
|    time_elapsed         | 65641     |
|    total_timesteps      | 225280    |
| train/                  |           |
|    approx_kl            | 0.1662955 |
|    clip_fraction        | 0.352     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.96     |
|    explained_variance   | 0.525     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.264     |
|    n_updates            | 1090      |
|    policy_gradient_loss | 0.00826   |
|    std                  | 0.844     |
|    value_loss           | 0.494     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -195       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 111        |
|    time_elapsed         | 65882      |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.05187087 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.162      |
|    n_updates            | 1100       |
|    policy_gradient_loss | 0.00221    |
|    std                  | 0.842      |
|    value_loss           | 0.478      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -192       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 66124      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.05279176 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.92      |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.265      |
|    n_updates            | 1110       |
|    policy_gradient_loss | 0.0091     |
|    std                  | 0.841      |
|    value_loss           | 0.386      |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.86 +/- 0.02
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.049592443 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00333     |
|    std                  | 0.842       |
|    value_loss           | 0.371       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -195     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 68166    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -192        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 68408       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.031763002 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.000402    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.839       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -192       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 115        |
|    time_elapsed         | 68649      |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.21399902 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.105      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.178      |
|    n_updates            | 1140       |
|    policy_gradient_loss | 0.00809    |
|    std                  | 0.84       |
|    value_loss           | 0.481      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -189       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 116        |
|    time_elapsed         | 68889      |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.06975244 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.196      |
|    n_updates            | 1150       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.835      |
|    value_loss           | 0.344      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | -186       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 117        |
|    time_elapsed         | 69128      |
|    total_timesteps      | 239616     |
| train/                  |            |
|    approx_kl            | 0.06550704 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.125      |
|    n_updates            | 1160       |
|    policy_gradient_loss | 0.00918    |
|    std                  | 0.837      |
|    value_loss           | 0.436      |
----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.40 +/- 0.80
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 240000   |
| train/                  |          |
|    approx_kl            | 0.073455 |
|    clip_fraction        | 0.362    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.88    |
|    explained_variance   | 0.608    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.19     |
|    n_updates            | 1170     |
|    policy_gradient_loss | 0.00513  |
|    std                  | 0.838    |
|    value_loss           | 0.459    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -189     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 71168    |
|    total_timesteps | 241664   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.51e+03  |
|    ep_rew_mean          | -187      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 119       |
|    time_elapsed         | 71408     |
|    total_timesteps      | 243712    |
| train/                  |           |
|    approx_kl            | 0.0387396 |
|    clip_fraction        | 0.353     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.89     |
|    explained_variance   | -0.000375 |
|    learning_rate        | 0.0003    |
|    loss                 | 2.39e+03  |
|    n_updates            | 1180      |
|    policy_gradient_loss | -0.00168  |
|    std                  | 0.837     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -187       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 120        |
|    time_elapsed         | 71648      |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.25107443 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | -0.767     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.158      |
|    n_updates            | 1190       |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.838      |
|    value_loss           | 0.634      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -184       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 121        |
|    time_elapsed         | 71889      |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.06697245 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.00139   |
|    std                  | 0.836      |
|    value_loss           | 0.381      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -181        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 72130       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.045115814 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.634       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.149       |
|    n_updates            | 1210        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.836       |
|    value_loss           | 0.427       |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.93 +/- 0.05
Episode length: 3598.00 +/- 5.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.058960736 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.17        |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00582     |
|    std                  | 0.835       |
|    value_loss           | 0.383       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -184     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 74171    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -178        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 74414       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.038275026 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.000455    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.89        |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00497    |
|    std                  | 0.835       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -178       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 125        |
|    time_elapsed         | 74655      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.09749148 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.159      |
|    n_updates            | 1240       |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.832      |
|    value_loss           | 0.626      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -171       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 126        |
|    time_elapsed         | 74897      |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.31762695 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.282      |
|    n_updates            | 1250       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.831      |
|    value_loss           | 0.44       |
----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.95 +/- 0.05
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.13262229 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.258      |
|    n_updates            | 1260       |
|    policy_gradient_loss | 0.00904    |
|    std                  | 0.832      |
|    value_loss           | 0.491      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -165     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 76941    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -165        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 77184       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.051742956 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | 0.00228     |
|    learning_rate        | 0.0003      |
|    loss                 | 804         |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00598    |
|    std                  | 0.833       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -161      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 129       |
|    time_elapsed         | 77425     |
|    total_timesteps      | 264192    |
| train/                  |           |
|    approx_kl            | 0.0808353 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.86     |
|    explained_variance   | 0.0522    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.191     |
|    n_updates            | 1280      |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.838     |
|    value_loss           | 0.539     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -156       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 130        |
|    time_elapsed         | 77666      |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.07678366 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.21       |
|    n_updates            | 1290       |
|    policy_gradient_loss | 0.00219    |
|    std                  | 0.835      |
|    value_loss           | 0.399      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -156      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 131       |
|    time_elapsed         | 77907     |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.1766481 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.85     |
|    explained_variance   | 0.703     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.216     |
|    n_updates            | 1300      |
|    policy_gradient_loss | 0.00508   |
|    std                  | 0.834     |
|    value_loss           | 0.359     |
---------------------------------------
Eval num_timesteps=270000, episode_reward=-99.91 +/- 0.05
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.13963582 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.241      |
|    n_updates            | 1310       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.834      |
|    value_loss           | 0.365      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -150     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 79946    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -150        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 80185       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.055111773 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -0.000616   |
|    learning_rate        | 0.0003      |
|    loss                 | 170         |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.000649   |
|    std                  | 0.832       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -146      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 134       |
|    time_elapsed         | 80423     |
|    total_timesteps      | 274432    |
| train/                  |           |
|    approx_kl            | 0.5813551 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.82     |
|    explained_variance   | -0.101    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.171     |
|    n_updates            | 1330      |
|    policy_gradient_loss | -0.0118   |
|    std                  | 0.833     |
|    value_loss           | 0.473     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -141       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 80659      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.22027874 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.216      |
|    n_updates            | 1340       |
|    policy_gradient_loss | 0.00295    |
|    std                  | 0.837      |
|    value_loss           | 0.397      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -141      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 136       |
|    time_elapsed         | 80895     |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0470692 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.86     |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.171     |
|    n_updates            | 1350      |
|    policy_gradient_loss | 0.00116   |
|    std                  | 0.833     |
|    value_loss           | 0.444     |
---------------------------------------
Eval num_timesteps=280000, episode_reward=-99.93 +/- 0.03
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.05089134 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.81      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.181      |
|    n_updates            | 1360       |
|    policy_gradient_loss | 0.00217    |
|    std                  | 0.83       |
|    value_loss           | 0.422      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -136     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 82933    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -136        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 83169       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.046733797 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.00171    |
|    learning_rate        | 0.0003      |
|    loss                 | 461         |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00291    |
|    std                  | 0.827       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -132      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 139       |
|    time_elapsed         | 83407     |
|    total_timesteps      | 284672    |
| train/                  |           |
|    approx_kl            | 0.8654819 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.77     |
|    explained_variance   | 0.0104    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.429     |
|    n_updates            | 1380      |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.827     |
|    value_loss           | 0.603     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -128       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 140        |
|    time_elapsed         | 83646      |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.05525443 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.76      |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.205      |
|    n_updates            | 1390       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.825      |
|    value_loss           | 0.497      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -128       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 83884      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.06516573 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.75      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.199      |
|    n_updates            | 1400       |
|    policy_gradient_loss | 0.00839    |
|    std                  | 0.824      |
|    value_loss           | 0.431      |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.88 +/- 0.06
Episode length: 3598.60 +/- 3.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.072703324 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.19        |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00364    |
|    std                  | 0.819       |
|    value_loss           | 0.614       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -123     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 85922    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -123        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 86160       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.094499074 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.00257     |
|    learning_rate        | 0.0003      |
|    loss                 | 663         |
|    n_updates            | 1420        |
|    policy_gradient_loss | 0.000804    |
|    std                  | 0.82        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -119       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 86397      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.07332376 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.67      |
|    explained_variance   | 0.352      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.215      |
|    n_updates            | 1430       |
|    policy_gradient_loss | 0.0295     |
|    std                  | 0.816      |
|    value_loss           | 0.582      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -116       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 145        |
|    time_elapsed         | 86634      |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.10336157 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.173      |
|    n_updates            | 1440       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.814      |
|    value_loss           | 0.336      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -116       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 86873      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.06273267 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.6       |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.152      |
|    n_updates            | 1450       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.807      |
|    value_loss           | 0.403      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.88 +/- 0.09
Episode length: 3599.60 +/- 2.33
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.070034266 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.166       |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.00832     |
|    std                  | 0.801       |
|    value_loss           | 0.388       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -112     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 88912    |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -109       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 148        |
|    time_elapsed         | 89153      |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.03931673 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.51      |
|    explained_variance   | 0.00335    |
|    learning_rate        | 0.0003     |
|    loss                 | 394        |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.000594  |
|    std                  | 0.8        |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -109      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 149       |
|    time_elapsed         | 89392     |
|    total_timesteps      | 305152    |
| train/                  |           |
|    approx_kl            | 0.7857589 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.46     |
|    explained_variance   | -0.00567  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.124     |
|    n_updates            | 1480      |
|    policy_gradient_loss | -0.000428 |
|    std                  | 0.794     |
|    value_loss           | 0.594     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -106       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 150        |
|    time_elapsed         | 89630      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.21714464 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.136      |
|    n_updates            | 1490       |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.792      |
|    value_loss           | 0.345      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -106        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 89868       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.058464147 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.214       |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.79        |
|    value_loss           | 0.419       |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.91 +/- 0.05
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 310000    |
| train/                  |           |
|    approx_kl            | 0.0618211 |
|    clip_fraction        | 0.355     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.38     |
|    explained_variance   | 0.691     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.24      |
|    n_updates            | 1510      |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.788     |
|    value_loss           | 0.377     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -104     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 91907    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -100        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 92146       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.076239236 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.00275     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+03    |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.000139    |
|    std                  | 0.792       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -100      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 154       |
|    time_elapsed         | 92382     |
|    total_timesteps      | 315392    |
| train/                  |           |
|    approx_kl            | 0.6390234 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.42     |
|    explained_variance   | -0.166    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.129     |
|    n_updates            | 1530      |
|    policy_gradient_loss | 0.00346   |
|    std                  | 0.795     |
|    value_loss           | 0.515     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -97.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 155        |
|    time_elapsed         | 92619      |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.18525416 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.229      |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.000294  |
|    std                  | 0.793      |
|    value_loss           | 0.52       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -94.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 92855      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.07527318 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.41      |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.116      |
|    n_updates            | 1550       |
|    policy_gradient_loss | 0.00809    |
|    std                  | 0.792      |
|    value_loss           | 0.412      |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.20 +/- 0.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.04889178 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.279      |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.00173   |
|    std                  | 0.794      |
|    value_loss           | 0.472      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -94.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 94893    |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -91.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 158        |
|    time_elapsed         | 95130      |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.05636363 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.0262     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.89e+03   |
|    n_updates            | 1570       |
|    policy_gradient_loss | -0.00109   |
|    std                  | 0.795      |
|    value_loss           | 1.03e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -91.6     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 159       |
|    time_elapsed         | 95368     |
|    total_timesteps      | 325632    |
| train/                  |           |
|    approx_kl            | 0.1580917 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.41     |
|    explained_variance   | 0.42      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.274     |
|    n_updates            | 1580      |
|    policy_gradient_loss | 0.00846   |
|    std                  | 0.792     |
|    value_loss           | 0.685     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -89.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 160        |
|    time_elapsed         | 95604      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.14512838 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.39      |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.159      |
|    n_updates            | 1590       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.79       |
|    value_loss           | 0.334      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -87.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 161        |
|    time_elapsed         | 95842      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.06484642 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.36      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.125      |
|    n_updates            | 1600       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.786      |
|    value_loss           | 0.354      |
----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.84 +/- 0.02
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.060720406 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.167       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00496     |
|    std                  | 0.784       |
|    value_loss           | 0.309       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -86.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 97880    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -84.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 98117      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.04698901 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.32      |
|    explained_variance   | -0.00186   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05e+03   |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.000534  |
|    std                  | 0.785      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -84.9     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 164       |
|    time_elapsed         | 98355     |
|    total_timesteps      | 335872    |
| train/                  |           |
|    approx_kl            | 0.2575113 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.32     |
|    explained_variance   | 0.441     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.151     |
|    n_updates            | 1630      |
|    policy_gradient_loss | 0.025     |
|    std                  | 0.784     |
|    value_loss           | 0.564     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -81.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 165        |
|    time_elapsed         | 98592      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.06417176 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.153      |
|    n_updates            | 1640       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.783      |
|    value_loss           | 0.284      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -80       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 166       |
|    time_elapsed         | 98828     |
|    total_timesteps      | 339968    |
| train/                  |           |
|    approx_kl            | 0.1796462 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.29     |
|    explained_variance   | 0.666     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.287     |
|    n_updates            | 1650      |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.782     |
|    value_loss           | 0.419     |
---------------------------------------
Eval num_timesteps=340000, episode_reward=-99.86 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.07569968 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.29      |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.282      |
|    n_updates            | 1660       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.782      |
|    value_loss           | 0.486      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -79.8    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 100867   |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -78        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 168        |
|    time_elapsed         | 101105     |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.14419696 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.29      |
|    explained_variance   | 0.00372    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.58       |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.00545    |
|    std                  | 0.783      |
|    value_loss           | 1.03e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | -78      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 169      |
|    time_elapsed         | 101343   |
|    total_timesteps      | 346112   |
| train/                  |          |
|    approx_kl            | 0.561609 |
|    clip_fraction        | 0.429    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.31    |
|    explained_variance   | 0.214    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.26     |
|    n_updates            | 1680     |
|    policy_gradient_loss | 0.00791  |
|    std                  | 0.787    |
|    value_loss           | 0.614    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -77.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 101583     |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.08597683 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.32      |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.341      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.785      |
|    value_loss           | 0.534      |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.87 +/- 0.02
Episode length: 3598.60 +/- 3.88
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.05857225 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.322      |
|    n_updates            | 1700       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.784      |
|    value_loss           | 0.504      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -74.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 103620   |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -74.9       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 103859      |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.036299814 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.00245     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.96        |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.786       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -74.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 173        |
|    time_elapsed         | 104096     |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.12877336 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.31      |
|    explained_variance   | -0.226     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.465      |
|    n_updates            | 1720       |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.786      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -74.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 104334     |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.34746295 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.33      |
|    explained_variance   | 0.00338    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.278      |
|    n_updates            | 1730       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.787      |
|    value_loss           | 0.592      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -74.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 104574     |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.07266569 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.205      |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.789      |
|    value_loss           | 0.567      |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.14535126 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.286      |
|    n_updates            | 1750       |
|    policy_gradient_loss | 0.0301     |
|    std                  | 0.789      |
|    value_loss           | 0.492      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -74.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 106614   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -74.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 106853      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.068565995 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | 0.00103     |
|    learning_rate        | 0.0003      |
|    loss                 | 147         |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.00155     |
|    std                  | 0.793       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -74.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 107093     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.13486515 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.00397    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.278      |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.798      |
|    value_loss           | 0.821      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -73.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 107333     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.25747606 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.311      |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.797      |
|    value_loss           | 0.508      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -73.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 180        |
|    time_elapsed         | 107571     |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.14373825 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.41      |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 1790       |
|    policy_gradient_loss | 0.00955    |
|    std                  | 0.799      |
|    value_loss           | 0.621      |
----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.87 +/- 0.03
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.088293605 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.205       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.797       |
|    value_loss           | 0.386       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -73      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 109609   |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -73        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 182        |
|    time_elapsed         | 109847     |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.04355658 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.000796   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.69       |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.00268   |
|    std                  | 0.796      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -72.2     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 183       |
|    time_elapsed         | 110086    |
|    total_timesteps      | 374784    |
| train/                  |           |
|    approx_kl            | 0.7722724 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.39     |
|    explained_variance   | 0.407     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.184     |
|    n_updates            | 1820      |
|    policy_gradient_loss | 0.0318    |
|    std                  | 0.793     |
|    value_loss           | 0.43      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -71.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 110325     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.55417585 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.222      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.0455     |
|    std                  | 0.79       |
|    value_loss           | 0.42       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -71.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 110563     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.38787556 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.31      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.219      |
|    n_updates            | 1840       |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.786      |
|    value_loss           | 0.402      |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.82 +/- 0.07
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.42852345 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.215      |
|    n_updates            | 1850       |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.784      |
|    value_loss           | 0.353      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -70.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 112601   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -70.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 112839      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.054011144 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.00311     |
|    learning_rate        | 0.0003      |
|    loss                 | 19.6        |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0097     |
|    std                  | 0.784       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -69.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 113077     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.22605772 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.285      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.23       |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.0098     |
|    std                  | 0.787      |
|    value_loss           | 0.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -68.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 189        |
|    time_elapsed         | 113315     |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.08552445 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.32      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.147      |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.00157   |
|    std                  | 0.787      |
|    value_loss           | 0.366      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -68.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 113555     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.08555551 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.31      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.196      |
|    n_updates            | 1890       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.786      |
|    value_loss           | 0.381      |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.91 +/- 0.09
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.047044054 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 1900        |
|    policy_gradient_loss | 0.00101     |
|    std                  | 0.789       |
|    value_loss           | 0.344       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -67      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 115594   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -66.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 115833     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.04316368 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.33      |
|    explained_variance   | 0.00214    |
|    learning_rate        | 0.0003     |
|    loss                 | 109        |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.00522   |
|    std                  | 0.788      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -66.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 116073      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.107668236 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.338       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.153       |
|    n_updates            | 1920        |
|    policy_gradient_loss | 0.00582     |
|    std                  | 0.788       |
|    value_loss           | 0.544       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -65.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 194        |
|    time_elapsed         | 116312     |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.08735995 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.27      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.357      |
|    n_updates            | 1930       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.782      |
|    value_loss           | 0.464      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -65.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 195        |
|    time_elapsed         | 116551     |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.12592393 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.25      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.201      |
|    n_updates            | 1940       |
|    policy_gradient_loss | 0.00926    |
|    std                  | 0.784      |
|    value_loss           | 0.355      |
----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.07622993 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.25      |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.298      |
|    n_updates            | 1950       |
|    policy_gradient_loss | 0.00721    |
|    std                  | 0.78       |
|    value_loss           | 0.428      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -65.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 118590   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -64.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 118829     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.05868852 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | -0.000241  |
|    learning_rate        | 0.0003     |
|    loss                 | 179        |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.00564   |
|    std                  | 0.782      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -64.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 198        |
|    time_elapsed         | 119066     |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.21282521 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | -0.041     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.185      |
|    n_updates            | 1970       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.78       |
|    value_loss           | 0.526      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -64.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 119304     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.17484538 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.239      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.777      |
|    value_loss           | 0.381      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -63.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 119542     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.17796053 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.183      |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.776      |
|    value_loss           | 0.402      |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.082247734 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.138       |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.00566     |
|    std                  | 0.776       |
|    value_loss           | 0.429       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -63.7    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 121580   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -63.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 121818      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.040051423 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -0.000418   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+03    |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00626    |
|    std                  | 0.775       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -63.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 122055     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.09331685 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | 0.0099     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.401      |
|    n_updates            | 2020       |
|    policy_gradient_loss | 0.00517    |
|    std                  | 0.771      |
|    value_loss           | 0.836      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -62.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 122293      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.098186545 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.194       |
|    n_updates            | 2030        |
|    policy_gradient_loss | 0.00797     |
|    std                  | 0.774       |
|    value_loss           | 0.41        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -61.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 122531     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.05242355 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.233      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.00618    |
|    std                  | 0.777      |
|    value_loss           | 0.487      |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.84 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.06515409 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.241      |
|    n_updates            | 2050       |
|    policy_gradient_loss | 0.00632    |
|    std                  | 0.777      |
|    value_loss           | 0.567      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -61.8    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 124569   |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -61.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 207        |
|    time_elapsed         | 124806     |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.04354673 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.00184    |
|    learning_rate        | 0.0003     |
|    loss                 | 24.4       |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.00464   |
|    std                  | 0.779      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -61.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 125043     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.08389249 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.368      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.000466  |
|    std                  | 0.779      |
|    value_loss           | 0.588      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -60.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 125281     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.04441682 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.186      |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.777      |
|    value_loss           | 0.441      |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.84 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.069983184 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.148       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.00655     |
|    std                  | 0.773       |
|    value_loss           | 0.379       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -60.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 127319   |
|    total_timesteps | 430080   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -60.4     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 211       |
|    time_elapsed         | 127555    |
|    total_timesteps      | 432128    |
| train/                  |           |
|    approx_kl            | 0.0572131 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.14     |
|    explained_variance   | 0.000319  |
|    learning_rate        | 0.0003    |
|    loss                 | 35.8      |
|    n_updates            | 2100      |
|    policy_gradient_loss | -0.00393  |
|    std                  | 0.773     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -60.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 212        |
|    time_elapsed         | 127791     |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.09204881 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.11      |
|    explained_variance   | 0.0569     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 2110       |
|    policy_gradient_loss | 0.00564    |
|    std                  | 0.769      |
|    value_loss           | 0.509      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -60.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 213        |
|    time_elapsed         | 128028     |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.06896091 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | 0.621      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.287      |
|    n_updates            | 2120       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.765      |
|    value_loss           | 0.519      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -59.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 128265     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.07353729 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.21       |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.765      |
|    value_loss           | 0.404      |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.80 +/- 0.07
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.089975595 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.342       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.00995     |
|    std                  | 0.766       |
|    value_loss           | 0.469       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -59      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 130301   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -59         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 130537      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.049652036 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | 0.000564    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.17e+03    |
|    n_updates            | 2150        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.769       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -58.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 217        |
|    time_elapsed         | 130774     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.20887522 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.11      |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 2160       |
|    policy_gradient_loss | 0.00851    |
|    std                  | 0.771      |
|    value_loss           | 0.537      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -57.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 131010     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.13876617 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.202      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.00929    |
|    std                  | 0.767      |
|    value_loss           | 0.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -57.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 219        |
|    time_elapsed         | 131247     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.05247443 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.147      |
|    n_updates            | 2180       |
|    policy_gradient_loss | 0.0056     |
|    std                  | 0.768      |
|    value_loss           | 0.405      |
----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.86 +/- 0.09
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.058124457 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.649       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.187       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.00744     |
|    std                  | 0.764       |
|    value_loss           | 0.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -57.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 133284   |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -57.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 221        |
|    time_elapsed         | 133522     |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.08003926 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.03      |
|    explained_variance   | 0.00324    |
|    learning_rate        | 0.0003     |
|    loss                 | 290        |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.0072    |
|    std                  | 0.761      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -56.7     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 222       |
|    time_elapsed         | 133760    |
|    total_timesteps      | 454656    |
| train/                  |           |
|    approx_kl            | 0.1134679 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9        |
|    explained_variance   | 0.572     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.242     |
|    n_updates            | 2210      |
|    policy_gradient_loss | 0.0178    |
|    std                  | 0.759     |
|    value_loss           | 0.432     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -56        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 133996     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.08938064 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.244      |
|    n_updates            | 2220       |
|    policy_gradient_loss | 0.00168    |
|    std                  | 0.758      |
|    value_loss           | 0.406      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -56        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 224        |
|    time_elapsed         | 134232     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.05295544 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 2230       |
|    policy_gradient_loss | 0.00508    |
|    std                  | 0.758      |
|    value_loss           | 0.502      |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.73 +/- 0.04
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.21705133 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.98      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.19       |
|    n_updates            | 2240       |
|    policy_gradient_loss | 0.00888    |
|    std                  | 0.756      |
|    value_loss           | 0.516      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -55      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 136269   |
|    total_timesteps | 460800   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -55       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 226       |
|    time_elapsed         | 136504    |
|    total_timesteps      | 462848    |
| train/                  |           |
|    approx_kl            | 0.0401367 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.97     |
|    explained_variance   | -8.01e-05 |
|    learning_rate        | 0.0003    |
|    loss                 | 1.51e+03  |
|    n_updates            | 2250      |
|    policy_gradient_loss | -0.00405  |
|    std                  | 0.756     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -54        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 136739     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.56455374 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | -0.132     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.139      |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.00538    |
|    std                  | 0.755      |
|    value_loss           | 0.662      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -53.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 136975     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.13373104 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.151      |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.00685    |
|    std                  | 0.757      |
|    value_loss           | 0.558      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -53.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 229       |
|    time_elapsed         | 137209    |
|    total_timesteps      | 468992    |
| train/                  |           |
|    approx_kl            | 0.0711834 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.98     |
|    explained_variance   | 0.658     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.195     |
|    n_updates            | 2280      |
|    policy_gradient_loss | 0.0193    |
|    std                  | 0.757     |
|    value_loss           | 0.407     |
---------------------------------------
Eval num_timesteps=470000, episode_reward=-99.84 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.068753965 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.162       |
|    n_updates            | 2290        |
|    policy_gradient_loss | 0.000969    |
|    std                  | 0.76        |
|    value_loss           | 0.441       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -53      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 139246   |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -53        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 231        |
|    time_elapsed         | 139481     |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.07279739 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | 0.00397    |
|    learning_rate        | 0.0003     |
|    loss                 | 723        |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.000607  |
|    std                  | 0.76       |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -52.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 139715     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.16245747 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.02      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.275      |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.763      |
|    value_loss           | 0.511      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -51.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 139951     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.08798532 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.99      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.00548    |
|    std                  | 0.759      |
|    value_loss           | 0.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -51.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 140187     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.06377578 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.219      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.756      |
|    value_loss           | 0.439      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.77 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.086125165 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.97       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.178       |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.000873    |
|    std                  | 0.758       |
|    value_loss           | 0.367       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -50.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 142221   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -50.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 142457      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.032815438 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.97       |
|    explained_variance   | 0.00307     |
|    learning_rate        | 0.0003      |
|    loss                 | 14.8        |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.000417   |
|    std                  | 0.758       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -50.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 142693     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.11721617 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | 0.359      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.182      |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.00207    |
|    std                  | 0.758      |
|    value_loss           | 0.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -50.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 142928     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.07139073 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.94      |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.193      |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.00357    |
|    std                  | 0.755      |
|    value_loss           | 0.449      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -50.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 143162     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.08248233 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.256      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.00624    |
|    std                  | 0.75       |
|    value_loss           | 0.497      |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.86 +/- 0.11
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.06731674 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.22       |
|    n_updates            | 2390       |
|    policy_gradient_loss | -0.00114   |
|    std                  | 0.75       |
|    value_loss           | 0.485      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -50.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 145200   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -49.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 241         |
|    time_elapsed         | 145436      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.042466085 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.0018      |
|    learning_rate        | 0.0003      |
|    loss                 | 620         |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.753       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -49.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 145671     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.25862145 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | 0.323      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.356      |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.00952    |
|    std                  | 0.751      |
|    value_loss           | 0.578      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -48.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 145907     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.18545704 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.266      |
|    n_updates            | 2420       |
|    policy_gradient_loss | 0.0357     |
|    std                  | 0.752      |
|    value_loss           | 0.439      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -48.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 146143     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.10053252 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.2        |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.0037     |
|    std                  | 0.752      |
|    value_loss           | 0.483      |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.87 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.069321945 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.469       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.208       |
|    n_updates            | 2440        |
|    policy_gradient_loss | 0.00866     |
|    std                  | 0.757       |
|    value_loss           | 0.742       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -48.1    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 148180   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 148413     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.07152484 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | -0.00197   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.06e+03   |
|    n_updates            | 2450       |
|    policy_gradient_loss | 0.00274    |
|    std                  | 0.759      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 148648     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.23630804 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.99      |
|    explained_variance   | 0.252      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.263      |
|    n_updates            | 2460       |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.759      |
|    value_loss           | 0.736      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 248        |
|    time_elapsed         | 148883     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.07805011 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.98      |
|    explained_variance   | 0.621      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.29       |
|    n_updates            | 2470       |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.758      |
|    value_loss           | 0.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 249        |
|    time_elapsed         | 149118     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.07669813 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.99      |
|    explained_variance   | 0.562      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.329      |
|    n_updates            | 2480       |
|    policy_gradient_loss | 0.00461    |
|    std                  | 0.76       |
|    value_loss           | 0.638      |
----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.79 +/- 0.12
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.101926655 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.157       |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.00859     |
|    std                  | 0.757       |
|    value_loss           | 0.374       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -47.1    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 151154   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -46.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 151389      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.049887322 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | -0.0027     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.15e+03    |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00127    |
|    std                  | 0.755       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -46.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 252       |
|    time_elapsed         | 151624    |
|    total_timesteps      | 516096    |
| train/                  |           |
|    approx_kl            | 0.6913606 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.94     |
|    explained_variance   | -0.385    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.332     |
|    n_updates            | 2510      |
|    policy_gradient_loss | 0.000659  |
|    std                  | 0.753     |
|    value_loss           | 0.745     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 151860     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.85948515 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.94      |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.515      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.0266     |
|    std                  | 0.755      |
|    value_loss           | 0.684      |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.81 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.05027415 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.322      |
|    n_updates            | 2530       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.75       |
|    value_loss           | 0.407      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -47      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 153897   |
|    total_timesteps | 520192   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -47       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 255       |
|    time_elapsed         | 154134    |
|    total_timesteps      | 522240    |
| train/                  |           |
|    approx_kl            | 0.0710991 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.9      |
|    explained_variance   | -0.00221  |
|    learning_rate        | 0.0003    |
|    loss                 | 759       |
|    n_updates            | 2540      |
|    policy_gradient_loss | 0.004     |
|    std                  | 0.752     |
|    value_loss           | 1.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 154369     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.28651512 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | -0.152     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.23       |
|    n_updates            | 2550       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.753      |
|    value_loss           | 0.601      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 154604     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.13771713 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.93      |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.29       |
|    n_updates            | 2560       |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.755      |
|    value_loss           | 0.56       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -47.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 154842     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.08699624 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.291      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.00636    |
|    std                  | 0.748      |
|    value_loss           | 0.61       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.88 +/- 0.02
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.056274965 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.202       |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.748       |
|    value_loss           | 0.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -46.7    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 156878   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 157114     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.05213189 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | -0.00105   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.9        |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.00234   |
|    std                  | 0.749      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 157355     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.59752524 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | -0.231     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.307      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.0265     |
|    std                  | 0.748      |
|    value_loss           | 0.683      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -46.3     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 262       |
|    time_elapsed         | 157590    |
|    total_timesteps      | 536576    |
| train/                  |           |
|    approx_kl            | 0.0944625 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.89     |
|    explained_variance   | 0.635     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.254     |
|    n_updates            | 2610      |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.752     |
|    value_loss           | 0.473     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 263        |
|    time_elapsed         | 157826     |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.07085772 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.217      |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.00452    |
|    std                  | 0.747      |
|    value_loss           | 0.403      |
----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.78 +/- 0.14
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.09029546 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.234      |
|    n_updates            | 2630       |
|    policy_gradient_loss | 0.00963    |
|    std                  | 0.75       |
|    value_loss           | 0.379      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -46.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 159863   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 265        |
|    time_elapsed         | 160100     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.07018916 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.0017     |
|    learning_rate        | 0.0003     |
|    loss                 | 432        |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.00121   |
|    std                  | 0.754      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 160337     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.31457847 |
|    clip_fraction        | 0.532      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.349      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.16       |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0277     |
|    std                  | 0.755      |
|    value_loss           | 0.573      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 160573     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.09880424 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.293      |
|    n_updates            | 2660       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.754      |
|    value_loss           | 0.481      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 160809     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.07425942 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 2670       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.751      |
|    value_loss           | 0.526      |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.87 +/- 0.11
Episode length: 3600.20 +/- 1.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.05596755 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.85      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.285      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.747      |
|    value_loss           | 0.458      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -46.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 162845   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 270        |
|    time_elapsed         | 163083     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.05765194 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.83      |
|    explained_variance   | 0.000208   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.71       |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.00182   |
|    std                  | 0.748      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -46.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 163321     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.37536243 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.81      |
|    explained_variance   | 0.235      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.226      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.743      |
|    value_loss           | 0.591      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -45.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 163559     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.06514681 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.77      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.15       |
|    n_updates            | 2710       |
|    policy_gradient_loss | 0.00832    |
|    std                  | 0.74       |
|    value_loss           | 0.402      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -45.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 163796     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.19573998 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.32       |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.741      |
|    value_loss           | 0.379      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.81 +/- 0.08
Episode length: 3598.20 +/- 5.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.07621392 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.125      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.00449    |
|    std                  | 0.74       |
|    value_loss           | 0.381      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -45.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 165832   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -44.9       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 166069      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.073777124 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | 0.000217    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.64        |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.0018     |
|    std                  | 0.741       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 166306     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.16545905 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.75      |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.241      |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.74       |
|    value_loss           | 0.512      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 166544     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.08753104 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.166      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.735      |
|    value_loss           | 0.437      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 166780     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.04775183 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | 0.663      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.299      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.00372    |
|    std                  | 0.738      |
|    value_loss           | 0.434      |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.74 +/- 0.09
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.06974043 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.77      |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.198      |
|    n_updates            | 2780       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.742      |
|    value_loss           | 0.415      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -44.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 168816   |
|    total_timesteps | 571392   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 280        |
|    time_elapsed         | 169051     |
|    total_timesteps      | 573440     |
| train/                  |            |
|    approx_kl            | 0.05526696 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.78      |
|    explained_variance   | -0.000117  |
|    learning_rate        | 0.0003     |
|    loss                 | 644        |
|    n_updates            | 2790       |
|    policy_gradient_loss | -0.00219   |
|    std                  | 0.741      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 169287     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.51907694 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.79      |
|    explained_variance   | 0.254      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.207      |
|    n_updates            | 2800       |
|    policy_gradient_loss | -0.00166   |
|    std                  | 0.742      |
|    value_loss           | 0.459      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 169524     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.15429258 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.78      |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.386      |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.00524    |
|    std                  | 0.743      |
|    value_loss           | 0.586      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 169759     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.13041298 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.79      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.282      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.743      |
|    value_loss           | 0.557      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.81 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.08402342 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.77      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.00684    |
|    std                  | 0.739      |
|    value_loss           | 0.52       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -44.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 171795   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 285        |
|    time_elapsed         | 172031     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.04318565 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.74      |
|    explained_variance   | 0.00127    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.93e+03   |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.00323   |
|    std                  | 0.74       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -44.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 286         |
|    time_elapsed         | 172267      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.095681354 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | 0.34        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.192       |
|    n_updates            | 2850        |
|    policy_gradient_loss | 0.00236     |
|    std                  | 0.74        |
|    value_loss           | 0.567       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 172502     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.06299426 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.136      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.00593    |
|    std                  | 0.739      |
|    value_loss           | 0.437      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -44.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 172737     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.09258207 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.73      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.252      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.733      |
|    value_loss           | 0.514      |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.82 +/- 0.03
Episode length: 3597.40 +/- 4.84
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.055162035 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.236       |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.000618    |
|    std                  | 0.727       |
|    value_loss           | 0.498       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -43.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 174773   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -43.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 175009     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.06423604 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.00311    |
|    learning_rate        | 0.0003     |
|    loss                 | 70.1       |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.00145   |
|    std                  | 0.727      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -43.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 291         |
|    time_elapsed         | 175245      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.123680845 |
|    clip_fraction        | 0.469       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.399       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.255       |
|    n_updates            | 2900        |
|    policy_gradient_loss | 0.0149      |
|    std                  | 0.727       |
|    value_loss           | 0.479       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -42.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 292         |
|    time_elapsed         | 175481      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.061713506 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.276       |
|    n_updates            | 2910        |
|    policy_gradient_loss | 0.00609     |
|    std                  | 0.729       |
|    value_loss           | 0.634       |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.17417195 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.333      |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.00952    |
|    std                  | 0.728      |
|    value_loss           | 0.572      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -41      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 177518   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -41         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 177754      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.027255662 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.000514    |
|    learning_rate        | 0.0003      |
|    loss                 | 43.1        |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.00959    |
|    std                  | 0.727       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -39.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 177989     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.20718555 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.33       |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.00249   |
|    std                  | 0.728      |
|    value_loss           | 0.622      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -39.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 178223     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.10509357 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.594      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.275      |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.00304    |
|    std                  | 0.731      |
|    value_loss           | 0.584      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -37.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 178458     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.06581269 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.224      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.00304    |
|    std                  | 0.733      |
|    value_loss           | 0.626      |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.83 +/- 0.08
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.057491593 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.153       |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.00628     |
|    std                  | 0.73        |
|    value_loss           | 0.506       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -35.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 180494   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -35.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 180732      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.045370664 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.00352     |
|    learning_rate        | 0.0003      |
|    loss                 | 479         |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00234    |
|    std                  | 0.73        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -33.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 180968     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.07073176 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.00806    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.313      |
|    n_updates            | 2990       |
|    policy_gradient_loss | -0.00378   |
|    std                  | 0.729      |
|    value_loss           | 0.72       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -32.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 181205     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.14800608 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.581      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.316      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.00372    |
|    std                  | 0.727      |
|    value_loss           | 0.553      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -32.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 181441     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.07025514 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.222      |
|    n_updates            | 3010       |
|    policy_gradient_loss | -0.00727   |
|    std                  | 0.732      |
|    value_loss           | 0.508      |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.79 +/- 0.07
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.09080303 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 3020       |
|    policy_gradient_loss | 0.0037     |
|    std                  | 0.729      |
|    value_loss           | 0.498      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -31.8    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 183477   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -31.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 183712     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.03495481 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.000468   |
|    learning_rate        | 0.0003     |
|    loss                 | 418        |
|    n_updates            | 3030       |
|    policy_gradient_loss | -0.00121   |
|    std                  | 0.73       |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -31.4     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 183950    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 0.5306328 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.66     |
|    explained_variance   | -0.245    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.285     |
|    n_updates            | 3040      |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.729     |
|    value_loss           | 0.55      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -31        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 184188     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.11897817 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 3050       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.733      |
|    value_loss           | 0.561      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -31         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 307         |
|    time_elapsed         | 184424      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.090728216 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.32        |
|    n_updates            | 3060        |
|    policy_gradient_loss | 0.00431     |
|    std                  | 0.732       |
|    value_loss           | 0.487       |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.81 +/- 0.08
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.14826523 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.156      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.00754    |
|    std                  | 0.73       |
|    value_loss           | 0.36       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -31      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 186461   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -31         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 186698      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.035043266 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | -0.00217    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+03    |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.00811    |
|    std                  | 0.731       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -31.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 186934     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.26003218 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.258      |
|    n_updates            | 3090       |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.732      |
|    value_loss           | 0.465      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -31.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 311        |
|    time_elapsed         | 187170     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.10206594 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.68      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.193      |
|    n_updates            | 3100       |
|    policy_gradient_loss | 0.00617    |
|    std                  | 0.733      |
|    value_loss           | 0.445      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -31.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 187406      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.058357675 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.325       |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.00232    |
|    std                  | 0.729       |
|    value_loss           | 0.584       |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.87 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.07183323 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.185      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.0025     |
|    std                  | 0.721      |
|    value_loss           | 0.501      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -31.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 189445   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -31.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 189680      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.043948002 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | 0.000299    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.38        |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00628    |
|    std                  | 0.721       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -30.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 315        |
|    time_elapsed         | 189918     |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.19484246 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.57      |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.152      |
|    n_updates            | 3140       |
|    policy_gradient_loss | 0.00054    |
|    std                  | 0.723      |
|    value_loss           | 0.39       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -30.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 190155     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.07664497 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.57      |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.176      |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.00652    |
|    std                  | 0.722      |
|    value_loss           | 0.491      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -30.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 190392     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.08840917 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.55      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.271      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.00944    |
|    std                  | 0.718      |
|    value_loss           | 0.534      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.78 +/- 0.09
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.10625867 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.53      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.254      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.719      |
|    value_loss           | 0.405      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -29.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 192435   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -28.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 192674      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.082104124 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | -0.00144    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.59e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.00155    |
|    std                  | 0.722       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -28.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 320        |
|    time_elapsed         | 192910     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.21757188 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.57      |
|    explained_variance   | -0.303     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.137      |
|    n_updates            | 3190       |
|    policy_gradient_loss | -0.0059    |
|    std                  | 0.722      |
|    value_loss           | 0.565      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -28.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 193147      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.080464035 |
|    clip_fraction        | 0.446       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.2         |
|    n_updates            | 3200        |
|    policy_gradient_loss | 0.0168      |
|    std                  | 0.729       |
|    value_loss           | 0.389       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -27.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 193388     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.10582158 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.199      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.73       |
|    value_loss           | 0.459      |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.76 +/- 0.08
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.09655767 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.268      |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.00934    |
|    std                  | 0.73       |
|    value_loss           | 0.469      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -27.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 195428   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -27.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 195666      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.061681643 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | -0.000217   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+03    |
|    n_updates            | 3230        |
|    policy_gradient_loss | 0.00084     |
|    std                  | 0.728       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -27.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 195902     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.11371735 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.51       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.27       |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.00553    |
|    std                  | 0.733      |
|    value_loss           | 0.499      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -26.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 196139     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.10026179 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.68      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.094      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.006      |
|    std                  | 0.732      |
|    value_loss           | 0.365      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -26.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 196376     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.06354877 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.276      |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.00485    |
|    std                  | 0.728      |
|    value_loss           | 0.504      |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.75 +/- 0.09
Episode length: 3596.20 +/- 7.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.062488697 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.236       |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.00907     |
|    std                  | 0.734       |
|    value_loss           | 0.421       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -26.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 198416   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -26.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 198657     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.04535854 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | -0.00139   |
|    learning_rate        | 0.0003     |
|    loss                 | 350        |
|    n_updates            | 3280       |
|    policy_gradient_loss | 0.00175    |
|    std                  | 0.734      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -26.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 330       |
|    time_elapsed         | 198894    |
|    total_timesteps      | 675840    |
| train/                  |           |
|    approx_kl            | 0.1885568 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.7      |
|    explained_variance   | -0.000844 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.222     |
|    n_updates            | 3290      |
|    policy_gradient_loss | -0.0011   |
|    std                  | 0.735     |
|    value_loss           | 0.569     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -26.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 199131     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.07763088 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.00653    |
|    std                  | 0.734      |
|    value_loss           | 0.433      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | -26.1    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 332      |
|    time_elapsed         | 199368   |
|    total_timesteps      | 679936   |
| train/                  |          |
|    approx_kl            | 0.090166 |
|    clip_fraction        | 0.409    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.68    |
|    explained_variance   | 0.673    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.225    |
|    n_updates            | 3310     |
|    policy_gradient_loss | 0.00375  |
|    std                  | 0.731    |
|    value_loss           | 0.449    |
--------------------------------------
Eval num_timesteps=680000, episode_reward=-99.80 +/- 0.05
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.31525856 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.279      |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.735      |
|    value_loss           | 0.424      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -26.1    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 201407   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 201643     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.06499268 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | 0.00185    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.79       |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.00253   |
|    std                  | 0.735      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 201879     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.06856812 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | 0.214      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.172      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.00474    |
|    std                  | 0.729      |
|    value_loss           | 0.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 202114     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.19594467 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.184      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.00843    |
|    std                  | 0.728      |
|    value_loss           | 0.413      |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.84 +/- 0.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.113745384 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.474       |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.00505     |
|    std                  | 0.724       |
|    value_loss           | 0.66        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -25.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 204153   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -25.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 204392      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.073189326 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | -0.000912   |
|    learning_rate        | 0.0003      |
|    loss                 | 120         |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00653    |
|    std                  | 0.724       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 204628     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.19175494 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | 0.0402     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.178      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0093     |
|    std                  | 0.724      |
|    value_loss           | 0.528      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 204863     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.11688175 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.327      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.723      |
|    value_loss           | 0.596      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 205097     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.21333389 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.54      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.343      |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.00392    |
|    std                  | 0.72       |
|    value_loss           | 0.528      |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.86 +/- 0.05
Episode length: 3597.00 +/- 7.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.06232585 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.51      |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.268      |
|    n_updates            | 3410       |
|    policy_gradient_loss | 0.00283    |
|    std                  | 0.718      |
|    value_loss           | 0.567      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -25.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 207138   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 207377     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.05181145 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | 0.00179    |
|    learning_rate        | 0.0003     |
|    loss                 | 397        |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.00342   |
|    std                  | 0.718      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 207612     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.47523773 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.297      |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.00723    |
|    std                  | 0.715      |
|    value_loss           | 0.469      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 207850     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.10346953 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.24       |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.000334   |
|    std                  | 0.714      |
|    value_loss           | 0.588      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -25.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 208085      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.096831955 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.44       |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.29        |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0026     |
|    std                  | 0.712       |
|    value_loss           | 0.568       |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.78 +/- 0.10
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.08532387 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.252      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.00215    |
|    std                  | 0.709      |
|    value_loss           | 0.462      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -25.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 210125   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -25.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 210362     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.07488332 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.4       |
|    explained_variance   | -0.00119   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.52e+03   |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.00287   |
|    std                  | 0.71       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -25.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 349         |
|    time_elapsed         | 210599      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.057292916 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.215       |
|    n_updates            | 3480        |
|    policy_gradient_loss | 0.00796     |
|    std                  | 0.711       |
|    value_loss           | 0.585       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -24.8     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 350       |
|    time_elapsed         | 210835    |
|    total_timesteps      | 716800    |
| train/                  |           |
|    approx_kl            | 0.0862983 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.4      |
|    explained_variance   | 0.62      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.193     |
|    n_updates            | 3490      |
|    policy_gradient_loss | 0.0127    |
|    std                  | 0.709     |
|    value_loss           | 0.499     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -24.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 211076     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.10301803 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.35      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0871     |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.00897    |
|    std                  | 0.704      |
|    value_loss           | 0.364      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.79 +/- 0.07
Episode length: 3599.80 +/- 1.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.080432996 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.33       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.19        |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.00759     |
|    std                  | 0.705       |
|    value_loss           | 0.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -24.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 213116   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -24.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 213352     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.08242777 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.34      |
|    explained_variance   | -0.00143   |
|    learning_rate        | 0.0003     |
|    loss                 | 18.6       |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.00246   |
|    std                  | 0.705      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -24.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 213588     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.13928959 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.33      |
|    explained_variance   | 0.183      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.191      |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.701      |
|    value_loss           | 0.488      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -23.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 213827     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.10993337 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.27       |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.699      |
|    value_loss           | 0.425      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -23.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 214067     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.09937897 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.27      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.193      |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.00412    |
|    std                  | 0.699      |
|    value_loss           | 0.379      |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.83 +/- 0.11
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.10751367 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.27      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.198      |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.00768    |
|    std                  | 0.698      |
|    value_loss           | 0.336      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -23.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 216107   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -22.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 358        |
|    time_elapsed         | 216345     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.05059294 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.27      |
|    explained_variance   | -0.001     |
|    learning_rate        | 0.0003     |
|    loss                 | 42.2       |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.00709   |
|    std                  | 0.7        |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -22.8     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 359       |
|    time_elapsed         | 216582    |
|    total_timesteps      | 735232    |
| train/                  |           |
|    approx_kl            | 0.1279063 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.26     |
|    explained_variance   | 0.0332    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.178     |
|    n_updates            | 3580      |
|    policy_gradient_loss | 0.00333   |
|    std                  | 0.697     |
|    value_loss           | 0.397     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -22.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 216822     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.08171875 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.23      |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.145      |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.00694    |
|    std                  | 0.695      |
|    value_loss           | 0.397      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -21.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 217062     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.09682201 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.21      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.166      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0018     |
|    std                  | 0.695      |
|    value_loss           | 0.371      |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.79 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.24990448 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.21      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.000549   |
|    std                  | 0.694      |
|    value_loss           | 0.393      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -21.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 219105   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -21.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 219342      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.033035904 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.000627    |
|    learning_rate        | 0.0003      |
|    loss                 | 848         |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.00191    |
|    std                  | 0.694       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -21.2     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 364       |
|    time_elapsed         | 219581    |
|    total_timesteps      | 745472    |
| train/                  |           |
|    approx_kl            | 0.0846574 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.21     |
|    explained_variance   | 0.104     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.167     |
|    n_updates            | 3630      |
|    policy_gradient_loss | 0.0057    |
|    std                  | 0.695     |
|    value_loss           | 0.528     |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | -20.8    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 365      |
|    time_elapsed         | 219820   |
|    total_timesteps      | 747520   |
| train/                  |          |
|    approx_kl            | 0.284194 |
|    clip_fraction        | 0.423    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.21    |
|    explained_variance   | 0.696    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.182    |
|    n_updates            | 3640     |
|    policy_gradient_loss | 0.0183   |
|    std                  | 0.694    |
|    value_loss           | 0.407    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -20.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 220059     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.09378153 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.18      |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.202      |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.00651    |
|    std                  | 0.69       |
|    value_loss           | 0.496      |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.84 +/- 0.10
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.079254426 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.14       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.112       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.686       |
|    value_loss           | 0.366       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -20.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 222100   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -19.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 222341     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.11152409 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | -0.000916  |
|    learning_rate        | 0.0003     |
|    loss                 | 42         |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.00377   |
|    std                  | 0.686      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -19.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 222580     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.46586156 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.212      |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.00622    |
|    std                  | 0.685      |
|    value_loss           | 0.492      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -19        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 222817     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.11652441 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.1       |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.108      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.00765    |
|    std                  | 0.685      |
|    value_loss           | 0.433      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -18.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 223055     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.12353399 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.11      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.201      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.00997    |
|    std                  | 0.686      |
|    value_loss           | 0.412      |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.82 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.10788925 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.1       |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.16       |
|    n_updates            | 3710       |
|    policy_gradient_loss | 0.00917    |
|    std                  | 0.683      |
|    value_loss           | 0.357      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -18.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 225095   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -17.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 225332     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.06261319 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.000292   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.63e+03   |
|    n_updates            | 3720       |
|    policy_gradient_loss | 0.000239   |
|    std                  | 0.685      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -17.8     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 374       |
|    time_elapsed         | 225575    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 0.3138752 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.1      |
|    explained_variance   | 0.138     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.273     |
|    n_updates            | 3730      |
|    policy_gradient_loss | 0.000677  |
|    std                  | 0.684     |
|    value_loss           | 0.549     |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | -16.5    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 375      |
|    time_elapsed         | 225815   |
|    total_timesteps      | 768000   |
| train/                  |          |
|    approx_kl            | 0.27707  |
|    clip_fraction        | 0.467    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.09    |
|    explained_variance   | 0.655    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.222    |
|    n_updates            | 3740     |
|    policy_gradient_loss | 0.0138   |
|    std                  | 0.683    |
|    value_loss           | 0.443    |
--------------------------------------
Eval num_timesteps=770000, episode_reward=-99.87 +/- 0.07
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.21069019 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.679      |
|    value_loss           | 0.547      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -15.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 227855   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -15.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 228093      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.059563346 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.0028      |
|    learning_rate        | 0.0003      |
|    loss                 | 381         |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00147     |
|    std                  | 0.681       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -14.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 228328     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.20200594 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.263      |
|    n_updates            | 3770       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.679      |
|    value_loss           | 0.49       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -14.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 228567     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.12448505 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.301      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.00882    |
|    std                  | 0.678      |
|    value_loss           | 0.447      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -13.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 228803     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.08196616 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.18       |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.679      |
|    value_loss           | 0.328      |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.89 +/- 0.08
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.16262504 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.283      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.00122    |
|    std                  | 0.678      |
|    value_loss           | 0.464      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -13.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 230844   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -13.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 231083     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.13071074 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.029      |
|    learning_rate        | 0.0003     |
|    loss                 | 458        |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.00121   |
|    std                  | 0.681      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -12.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 383        |
|    time_elapsed         | 231321     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.17698348 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.144      |
|    n_updates            | 3820       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.683      |
|    value_loss           | 0.369      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -12.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 231561     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.21088162 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.07      |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.201      |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.00731    |
|    std                  | 0.68       |
|    value_loss           | 0.691      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -12.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 231799     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.13016349 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.166      |
|    n_updates            | 3840       |
|    policy_gradient_loss | 0.00427    |
|    std                  | 0.68       |
|    value_loss           | 0.393      |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.84 +/- 0.14
Episode length: 3599.40 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.18634564 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.07      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.189      |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.682      |
|    value_loss           | 0.361      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -11.7    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 233839   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -11.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 234075      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.069576874 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.06       |
|    explained_variance   | -0.000992   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.96e+03    |
|    n_updates            | 3860        |
|    policy_gradient_loss | 0.00533     |
|    std                  | 0.679       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -10.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 234314     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.24268465 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.0357     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.223      |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0023     |
|    std                  | 0.679      |
|    value_loss           | 0.574      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -9.73      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 234554     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.09750979 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.311      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.678      |
|    value_loss           | 0.381      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -9.73      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 234792     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.15570498 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.186      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.00696    |
|    std                  | 0.674      |
|    value_loss           | 0.508      |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.89 +/- 0.01
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.07561669 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.108      |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.675      |
|    value_loss           | 0.344      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -8.44    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 236832   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -8.44      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 237069     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.05045222 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.00352    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.36       |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.00534   |
|    std                  | 0.674      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -7.46     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 393       |
|    time_elapsed         | 237306    |
|    total_timesteps      | 804864    |
| train/                  |           |
|    approx_kl            | 0.2574886 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.01     |
|    explained_variance   | 0.467     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.161     |
|    n_updates            | 3920      |
|    policy_gradient_loss | 0.0124    |
|    std                  | 0.676     |
|    value_loss           | 0.446     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -6.82      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 237543     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.14078578 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.01      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.216      |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.675      |
|    value_loss           | 0.619      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -6.82      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 237779     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.18462998 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.368      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0242     |
|    std                  | 0.675      |
|    value_loss           | 0.545      |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.84 +/- 0.09
Episode length: 3595.40 +/- 11.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.07788107 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.175      |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.677      |
|    value_loss           | 0.305      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -5.88    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 239821   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -5.88       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 397         |
|    time_elapsed         | 240058      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.064895526 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.02       |
|    explained_variance   | 0.00223     |
|    learning_rate        | 0.0003      |
|    loss                 | 138         |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.000844   |
|    std                  | 0.677       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -5.26     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 398       |
|    time_elapsed         | 240295    |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 0.5797764 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.03     |
|    explained_variance   | 0.2       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.321     |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.00872   |
|    std                  | 0.678     |
|    value_loss           | 0.479     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -4.74      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 240531     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.18860388 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.252      |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.677      |
|    value_loss           | 0.439      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -4.74      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 240768     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.10221072 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.335      |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.0098     |
|    std                  | 0.672      |
|    value_loss           | 0.427      |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.82 +/- 0.02
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.13324673 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.94      |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.175      |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.668      |
|    value_loss           | 0.483      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -4.06    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 242809   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -3.63      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 243046     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.06374084 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | -0.00088   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.35e+03   |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.00243   |
|    std                  | 0.669      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -3.63     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 403       |
|    time_elapsed         | 243283    |
|    total_timesteps      | 825344    |
| train/                  |           |
|    approx_kl            | 0.3918305 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.93     |
|    explained_variance   | -0.425    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.102     |
|    n_updates            | 4020      |
|    policy_gradient_loss | -0.0068   |
|    std                  | 0.671     |
|    value_loss           | 0.554     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -2.92      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 243521     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.40293592 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | 0.562      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.228      |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.671      |
|    value_loss           | 0.554      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -2.39       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 405         |
|    time_elapsed         | 243759      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.116371974 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.304       |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.0087      |
|    std                  | 0.671       |
|    value_loss           | 0.499       |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.14416951 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.168      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.671      |
|    value_loss           | 0.338      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -2.16    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 245797   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -1.4        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 407         |
|    time_elapsed         | 246035      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.058041707 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | -0.001      |
|    learning_rate        | 0.0003      |
|    loss                 | 273         |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.00812    |
|    std                  | 0.671       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -1.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 246272     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.20316094 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.91      |
|    explained_variance   | -0.0742    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.205      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.668      |
|    value_loss           | 0.509      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -0.789     |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 246512     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.14684777 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.91      |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.496      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.671      |
|    value_loss           | 0.549      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -0.389     |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 246749     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.09635055 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.183      |
|    n_updates            | 4090       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.674      |
|    value_loss           | 0.401      |
----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.88 +/- 0.03
Episode length: 3596.40 +/- 6.97
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.23821759 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.225      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.672      |
|    value_loss           | 0.458      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -0.152   |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 248790   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 0.326       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 249029      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.056044422 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | -0.00168    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00754    |
|    std                  | 0.671       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 0.326      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 249267     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.13955957 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | -0.913     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.146      |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.00212   |
|    std                  | 0.669      |
|    value_loss           | 0.611      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 0.776      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 414        |
|    time_elapsed         | 249504     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.17673555 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.235      |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.667      |
|    value_loss           | 0.462      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.22       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 249741     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.16444078 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.193      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.667      |
|    value_loss           | 0.531      |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.82 +/- 0.06
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 850000    |
| train/                  |           |
|    approx_kl            | 0.1554425 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.89     |
|    explained_variance   | 0.601     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.421     |
|    n_updates            | 4150      |
|    policy_gradient_loss | 0.00374   |
|    std                  | 0.666     |
|    value_loss           | 0.526     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.49     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 251780   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 2.09       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 252015     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.05664378 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | -0.000946  |
|    learning_rate        | 0.0003     |
|    loss                 | 94.2       |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.00537   |
|    std                  | 0.668      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 2.09       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 418        |
|    time_elapsed         | 252255     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.77413815 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.91      |
|    explained_variance   | -0.813     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.335      |
|    n_updates            | 4170       |
|    policy_gradient_loss | 0.00135    |
|    std                  | 0.668      |
|    value_loss           | 0.602      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 2.19       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 252494     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.10143438 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.327      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.664      |
|    value_loss           | 0.485      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.92 +/- 0.07
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.0931819 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.88     |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.201     |
|    n_updates            | 4190      |
|    policy_gradient_loss | 0.00613   |
|    std                  | 0.667     |
|    value_loss           | 0.471     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 2.52     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 254535   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 2.52       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 254773     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.10369377 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.00311    |
|    learning_rate        | 0.0003     |
|    loss                 | 182        |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.00375    |
|    std                  | 0.669      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 2.91       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 255012     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.21354806 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.45       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.226      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.00935    |
|    std                  | 0.666      |
|    value_loss           | 0.597      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 3.33       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 255253     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.23809813 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.304      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.00893    |
|    std                  | 0.663      |
|    value_loss           | 0.49       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 3.33      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 424       |
|    time_elapsed         | 255490    |
|    total_timesteps      | 868352    |
| train/                  |           |
|    approx_kl            | 0.1223554 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.82     |
|    explained_variance   | 0.666     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.109     |
|    n_updates            | 4230      |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.661     |
|    value_loss           | 0.421     |
---------------------------------------
Eval num_timesteps=870000, episode_reward=-99.85 +/- 0.08
Episode length: 3596.60 +/- 7.39
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 870000    |
| train/                  |           |
|    approx_kl            | 0.1844391 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.81     |
|    explained_variance   | 0.663     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.247     |
|    n_updates            | 4240      |
|    policy_gradient_loss | 0.016     |
|    std                  | 0.663     |
|    value_loss           | 0.439     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 3.62     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 257532   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 3.62       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 257772     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.05364213 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | -0.00236   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53e+03   |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.00111   |
|    std                  | 0.663      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 4.27      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 427       |
|    time_elapsed         | 258011    |
|    total_timesteps      | 874496    |
| train/                  |           |
|    approx_kl            | 1.2195834 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.81     |
|    explained_variance   | 0.0415    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.188     |
|    n_updates            | 4260      |
|    policy_gradient_loss | 0.00146   |
|    std                  | 0.66      |
|    value_loss           | 0.561     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 5.32       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 258249     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.66947603 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.78      |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.109      |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.66       |
|    value_loss           | 0.312      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 5.32        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 429         |
|    time_elapsed         | 258489      |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.113763005 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.77       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.129       |
|    n_updates            | 4280        |
|    policy_gradient_loss | 0.0147      |
|    std                  | 0.658       |
|    value_loss           | 0.307       |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.88 +/- 0.09
Episode length: 3596.40 +/- 5.99
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.11124256 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.162      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.656      |
|    value_loss           | 0.356      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 6.56     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 260530   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 6.56       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 260768     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.12419645 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.74      |
|    explained_variance   | 0.00106    |
|    learning_rate        | 0.0003     |
|    loss                 | 166        |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.00176   |
|    std                  | 0.657      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 7.36      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 261005    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 0.1312857 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.72     |
|    explained_variance   | 0.536     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.182     |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.654     |
|    value_loss           | 0.386     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 7.85       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 261243     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.20647809 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.71      |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.147      |
|    n_updates            | 4320       |
|    policy_gradient_loss | 0.0257     |
|    std                  | 0.655      |
|    value_loss           | 0.317      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 7.85       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 261481     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.20438936 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.7       |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.173      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.00865    |
|    std                  | 0.651      |
|    value_loss           | 0.33       |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.91 +/- 0.03
Episode length: 3599.80 +/- 1.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.09212965 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.155      |
|    n_updates            | 4340       |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.65       |
|    value_loss           | 0.273      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 8.7      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 263524   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 8.7         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 263762      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.044834763 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | -0.000289   |
|    learning_rate        | 0.0003      |
|    loss                 | 250         |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.00466    |
|    std                  | 0.652       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 9.05      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 437       |
|    time_elapsed         | 264000    |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 0.5416374 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.69     |
|    explained_variance   | 0.449     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.282     |
|    n_updates            | 4360      |
|    policy_gradient_loss | 0.00378   |
|    std                  | 0.651     |
|    value_loss           | 0.374     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 9.51        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 438         |
|    time_elapsed         | 264239      |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.069273695 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.66       |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.198       |
|    n_updates            | 4370        |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.646       |
|    value_loss           | 0.365       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 9.51       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 264478     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.30540583 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.151      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.647      |
|    value_loss           | 0.445      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.91 +/- 0.07
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 900000    |
| train/                  |           |
|    approx_kl            | 0.4017523 |
|    clip_fraction        | 0.415     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.64     |
|    explained_variance   | 0.727     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.138     |
|    n_updates            | 4390      |
|    policy_gradient_loss | 0.0159    |
|    std                  | 0.646     |
|    value_loss           | 0.328     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 9.91     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 266523   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 10.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 266764     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.06550996 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | -0.00162   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.03       |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.00337   |
|    std                  | 0.647      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 10.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 267004     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.38222834 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | 0.345      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.102      |
|    n_updates            | 4410       |
|    policy_gradient_loss | 0.00515    |
|    std                  | 0.648      |
|    value_loss           | 0.388      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 10.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 267245     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.13449699 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.101      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0267     |
|    std                  | 0.646      |
|    value_loss           | 0.319      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 11.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 267484     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.12549058 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.182      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.645      |
|    value_loss           | 0.315      |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.16464987 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.194      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.644      |
|    value_loss           | 0.249      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 11.7     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 269524   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 12.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 269765     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.06292166 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | -0.000529  |
|    learning_rate        | 0.0003     |
|    loss                 | 510        |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.00236   |
|    std                  | 0.645      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 12.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 270011     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.45534933 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | -0.415     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0832     |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.00157   |
|    std                  | 0.643      |
|    value_loss           | 0.428      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 12.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 270252     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.22858334 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.228      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.64       |
|    value_loss           | 0.304      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 13.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 270492     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.24089938 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.54      |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.125      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.637      |
|    value_loss           | 0.249      |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.94 +/- 0.05
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 920000    |
| train/                  |           |
|    approx_kl            | 0.3528982 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.54     |
|    explained_variance   | 0.794     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.134     |
|    n_updates            | 4490      |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.638     |
|    value_loss           | 0.247     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 14       |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 272535   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 14.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 451        |
|    time_elapsed         | 272775     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.17096695 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | -0.000515  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.49e+03   |
|    n_updates            | 4500       |
|    policy_gradient_loss | 0.0042     |
|    std                  | 0.641      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 14.6      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 452       |
|    time_elapsed         | 273014    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 0.5799484 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.57     |
|    explained_variance   | 0.395     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.149     |
|    n_updates            | 4510      |
|    policy_gradient_loss | 0.0109    |
|    std                  | 0.641     |
|    value_loss           | 0.466     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 15.2      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 453       |
|    time_elapsed         | 273255    |
|    total_timesteps      | 927744    |
| train/                  |           |
|    approx_kl            | 0.2654417 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.58     |
|    explained_variance   | 0.726     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.168     |
|    n_updates            | 4520      |
|    policy_gradient_loss | 0.0148    |
|    std                  | 0.641     |
|    value_loss           | 0.339     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 16         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 273494     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.17687592 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.187      |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.64       |
|    value_loss           | 0.376      |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.90 +/- 0.08
Episode length: 3598.80 +/- 3.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.24513395 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.23       |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.639      |
|    value_loss           | 0.388      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 16.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 275536   |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 16.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 456        |
|    time_elapsed         | 275778     |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.10241676 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | -0.000335  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.33e+03   |
|    n_updates            | 4550       |
|    policy_gradient_loss | 0.000902   |
|    std                  | 0.637      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 16.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 276019     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.20985556 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | 0.331      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.162      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.638      |
|    value_loss           | 0.364      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 17.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 276258     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.08445042 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.255      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.0279     |
|    std                  | 0.638      |
|    value_loss           | 0.407      |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.83 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.19220713 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.222      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.641      |
|    value_loss           | 0.406      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 18.5     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 278297   |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 18.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 460         |
|    time_elapsed         | 278537      |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.068035714 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.54       |
|    explained_variance   | -0.0006     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 4590        |
|    policy_gradient_loss | 0.00226     |
|    std                  | 0.641       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 19.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 278776     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.28333664 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | 0.255      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.124      |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.00781    |
|    std                  | 0.644      |
|    value_loss           | 0.468      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 20         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 279020     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.12185178 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.317      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.645      |
|    value_loss           | 0.406      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 20         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 279258     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.09075488 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.15       |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.642      |
|    value_loss           | 0.332      |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.88 +/- 0.07
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.07748863 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.642      |
|    value_loss           | 0.353      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 21       |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 281300   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 21         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 281539     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.08712217 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.00332    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.54       |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.00257   |
|    std                  | 0.641      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 21.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 281777     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.37185484 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.359      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.215      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.641      |
|    value_loss           | 0.475      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 22.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 282017     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.07607255 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.54      |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.64       |
|    value_loss           | 0.447      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 22.6      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 468       |
|    time_elapsed         | 282256    |
|    total_timesteps      | 958464    |
| train/                  |           |
|    approx_kl            | 0.3535364 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.51     |
|    explained_variance   | 0.668     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.163     |
|    n_updates            | 4670      |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.637     |
|    value_loss           | 0.406     |
---------------------------------------
Eval num_timesteps=960000, episode_reward=-99.82 +/- 0.12
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.26438826 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.48      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.222      |
|    n_updates            | 4680       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.634      |
|    value_loss           | 0.299      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 23.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 284301   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 23.8        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 284542      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.077573285 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.47       |
|    explained_variance   | 0.00209     |
|    learning_rate        | 0.0003      |
|    loss                 | 90.9        |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.00345     |
|    std                  | 0.634       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 23.9      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 471       |
|    time_elapsed         | 284780    |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 1.0378416 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.46     |
|    explained_variance   | 0.0959    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.161     |
|    n_updates            | 4700      |
|    policy_gradient_loss | 0.0178    |
|    std                  | 0.634     |
|    value_loss           | 0.459     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 22.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 285018     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.18203123 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.266      |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.635      |
|    value_loss           | 0.648      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 22.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 473         |
|    time_elapsed         | 285257      |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.113479815 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.47       |
|    explained_variance   | 0.57        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.304       |
|    n_updates            | 4720        |
|    policy_gradient_loss | 0.0363      |
|    std                  | 0.634       |
|    value_loss           | 0.577       |
-----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.07868591 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.544      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.338      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.633      |
|    value_loss           | 0.648      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 21.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 287299   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 21.8       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 287541     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.09422003 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.00328    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.14       |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.00271   |
|    std                  | 0.633      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 21.3      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 287783    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 0.6658659 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.46     |
|    explained_variance   | 0.15      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.286     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.00592   |
|    std                  | 0.63      |
|    value_loss           | 0.49      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 21.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 288023     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.22274634 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.42      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.225      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0293     |
|    std                  | 0.627      |
|    value_loss           | 0.454      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 21.4      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 478       |
|    time_elapsed         | 288263    |
|    total_timesteps      | 978944    |
| train/                  |           |
|    approx_kl            | 0.1951464 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.38     |
|    explained_variance   | 0.681     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.237     |
|    n_updates            | 4770      |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.625     |
|    value_loss           | 0.352     |
---------------------------------------
Eval num_timesteps=980000, episode_reward=-99.80 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.12875389 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.128      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.625      |
|    value_loss           | 0.302      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 21.2     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 290305   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 21.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 290545      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.045557234 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.38       |
|    explained_variance   | 0.000512    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.47e+03    |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.000186   |
|    std                  | 0.626       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 21.2      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 481       |
|    time_elapsed         | 290794    |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 1.6331841 |
|    clip_fraction        | 0.549     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.38     |
|    explained_variance   | -0.328    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.191     |
|    n_updates            | 4800      |
|    policy_gradient_loss | 0.021     |
|    std                  | 0.624     |
|    value_loss           | 0.401     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 20.8      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 482       |
|    time_elapsed         | 291037    |
|    total_timesteps      | 987136    |
| train/                  |           |
|    approx_kl            | 0.8656327 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.36     |
|    explained_variance   | 0.7       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.196     |
|    n_updates            | 4810      |
|    policy_gradient_loss | 0.0199    |
|    std                  | 0.625     |
|    value_loss           | 0.27      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 20.4      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 483       |
|    time_elapsed         | 291279    |
|    total_timesteps      | 989184    |
| train/                  |           |
|    approx_kl            | 0.4289063 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.37     |
|    explained_variance   | 0.66      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.191     |
|    n_updates            | 4820      |
|    policy_gradient_loss | 0.0286    |
|    std                  | 0.627     |
|    value_loss           | 0.332     |
---------------------------------------
Eval num_timesteps=990000, episode_reward=-99.84 +/- 0.09
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 990000    |
| train/                  |           |
|    approx_kl            | 0.7194714 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.38     |
|    explained_variance   | 0.694     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.193     |
|    n_updates            | 4830      |
|    policy_gradient_loss | 0.0361    |
|    std                  | 0.628     |
|    value_loss           | 0.264     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 20.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 293322   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 19.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 293565     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.14252001 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.4       |
|    explained_variance   | 0.00164    |
|    learning_rate        | 0.0003     |
|    loss                 | 113        |
|    n_updates            | 4840       |
|    policy_gradient_loss | 0.0061     |
|    std                  | 0.631      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 19.7      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 486       |
|    time_elapsed         | 293807    |
|    total_timesteps      | 995328    |
| train/                  |           |
|    approx_kl            | 2.7142005 |
|    clip_fraction        | 0.562     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.43     |
|    explained_variance   | 0.0163    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.167     |
|    n_updates            | 4850      |
|    policy_gradient_loss | 0.0313    |
|    std                  | 0.632     |
|    value_loss           | 0.561     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 18.8      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 294049    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.5820163 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.44     |
|    explained_variance   | 0.529     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.179     |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.0356    |
|    std                  | 0.634     |
|    value_loss           | 0.35      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | 17.9     |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 488      |
|    time_elapsed         | 294290   |
|    total_timesteps      | 999424   |
| train/                  |          |
|    approx_kl            | 2.092507 |
|    clip_fraction        | 0.473    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.44    |
|    explained_variance   | 0.612    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.107    |
|    n_updates            | 4870     |
|    policy_gradient_loss | 0.0327   |
|    std                  | 0.634    |
|    value_loss           | 0.316    |
--------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.83 +/- 0.07
Episode length: 3599.40 +/- 1.96
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 1000000  |
| train/                  |          |
|    approx_kl            | 1.16322  |
|    clip_fraction        | 0.493    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.42    |
|    explained_variance   | 0.629    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.143    |
|    n_updates            | 4880     |
|    policy_gradient_loss | 0.0411   |
|    std                  | 0.63     |
|    value_loss           | 0.302    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 18       |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 296335   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-24_14-12-14_llm_triton_qwen_14b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 10:15:52 < 0:00:00 , 9 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.953437  -99.842003  -99.801364  -99.820532  -99.831835]
 [-100.088734 -100.02957  -100.082169 -100.012579  -99.067502]
 [ -99.933062  -99.906893 -100.005303  -99.990268  -99.714386]
 [-100.003163  -99.931669  -99.825157  -99.839015  -99.807848]
 [ -99.879059  -99.949784  -99.952359  -99.949128  -99.95864 ]
 [ -99.929181  -99.75113   -99.872464  -99.908178  -99.746801]
 [ -99.867984  -99.955853  -99.964738  -99.926474  -99.833642]
 [ -99.93736   -99.989357  -99.9287    -99.78635   -99.935875]
 [ -99.88233   -99.942644  -99.992692  -99.808596  -99.842835]
 [ -99.805848  -99.848401  -99.790736  -99.891746  -99.843664]
 [ -99.83841   -99.760289  -99.833143  -99.967525  -99.798648]
 [ -99.792692  -99.796385  -99.959727  -99.768186  -99.885514]
 [ -99.880753  -99.866663  -99.861223  -99.935038  -99.903994]
 [ -99.883761  -99.793237  -99.926397  -99.893275  -99.991772]
 [ -99.949413  -99.844131  -99.855873  -99.841988  -99.871263]
 [ -99.92364   -99.9874    -99.88123   -99.923997  -99.950494]
 [ -99.907946  -99.95188   -99.972961  -99.893121  -99.966798]
 [ -99.956289  -99.924504  -99.821959 -100.009122  -99.850667]
 [ -99.904601  -99.979506  -99.844538  -99.900523  -99.940539]
 [ -99.846349  -99.832011  -99.760464  -99.954123  -99.861439]
 [ -99.876929  -99.931325  -99.759213  -99.837028  -99.815876]
 [ -99.997581  -99.829871  -99.876014  -99.9569    -99.905353]
 [ -99.840907  -99.853823  -99.898446  -99.836348  -99.857102]
 [ -99.843347  -99.911376  -99.91909   -99.847888  -99.877999]
 [ -99.915196 -100.019661  -99.851298  -99.937435  -99.906082]
 [ -99.902339 -100.001354  -99.896653  -99.929528 -100.005627]
 [ -99.895495  -99.985489  -99.931971  -99.851836  -99.880497]
 [ -99.969259  -99.902722  -99.915588  -99.956118  -99.92467 ]
 [ -99.898351  -99.799409  -99.951101  -99.906151  -99.822832]
 [ -99.880509  -99.764308  -99.932514  -99.795776 -100.003363]
 [ -99.952153  -99.916563  -99.839521  -99.979112  -99.867389]
 [ -99.948549  -99.865329  -99.785219  -99.84548   -99.810483]
 [ -99.82108   -99.825449  -99.853189  -99.864954  -99.813521]
 [ -99.831014  -99.83858   -99.832875  -99.944909  -99.874115]
 [ -99.839955  -99.850283  -99.902326  -99.87605   -99.864472]
 [ -99.89108   -99.819134  -99.834006  -99.781509  -99.847518]
 [ -99.885061  -99.827681  -99.864626  -99.917659  -99.836623]
 [ -99.836231  -99.688945  -99.898798  -99.860941  -99.820758]
 [ -99.801942  -99.819529 -100.043069  -99.966458  -99.932856]
 [ -99.730045  -99.827234  -99.840621  -99.888476  -99.827192]
 [ -99.797841  -99.898382  -99.744003  -99.818332  -99.818554]
 [ -99.844452  -99.856545  -99.86649   -99.740791  -99.877189]
 [ -99.827332  -99.856832  -99.884829  -99.913123  -99.712793]
 [ -99.733612  -99.897033  -99.818383  -99.719794  -99.841185]
 [-100.011516  -99.886066  -99.838112  -99.804608  -99.764986]
 [ -99.727165  -99.686809  -99.721831  -99.701689  -99.809717]
 [ -99.767967  -99.829649  -99.83065   -99.925451  -99.847788]
 [ -99.746433  -99.656104  -99.802034  -99.827946  -99.829279]
 [-100.034722  -99.802411  -99.863823  -99.707367  -99.889085]
 [ -99.916246  -99.905785  -99.887867  -99.749567  -99.897599]
 [ -99.816216  -99.977586  -99.621908  -99.779284  -99.736455]
 [ -99.807208  -99.769241  -99.815435  -99.81569   -99.861247]
 [ -99.864319  -99.897435  -99.880273  -99.852615  -99.885337]
 [ -99.743883  -99.515445  -99.85349   -99.915656  -99.851686]
 [ -99.80455   -99.753461 -100.002348  -99.779488  -99.994854]
 [ -99.716943  -99.8334    -99.740196  -99.810933  -99.936636]
 [ -99.904969  -99.704374  -99.707752  -99.738467  -99.62545 ]
 [ -99.853874  -99.834161  -99.783448  -99.792596  -99.791183]
 [ -99.786854  -99.870292  -99.789838  -99.845003  -99.812155]
 [ -99.788831  -99.840107  -99.766626  -99.904969  -99.788613]
 [ -99.76885   -99.829377  -99.709108  -99.922148  -99.902784]
 [ -99.819194  -99.690239  -99.76222   -99.792759  -99.907463]
 [ -99.766146  -99.685274  -99.786615  -99.900239  -99.891117]
 [ -99.859966  -99.932825  -99.81308   -99.933642  -99.807079]
 [ -99.800529  -99.677393  -99.689878  -99.882315  -99.863028]
 [ -99.741625  -99.803676  -99.743234  -99.634428  -99.867165]
 [ -99.605138  -99.720453  -99.849944  -99.759603  -99.828262]
 [ -99.803766  -99.770061  -99.765906  -99.898521  -99.75742 ]
 [ -99.742682  -99.834959  -99.901227  -99.728071 -100.005968]
 [ -99.955145  -99.844392  -99.845244  -99.787007  -99.868415]
 [ -99.798872  -99.871449  -99.898936  -99.704977  -99.629221]
 [ -99.863247  -99.817383  -99.66058   -99.803334  -99.792654]
 [ -99.776851  -99.636799  -99.902363  -99.890144  -99.928845]
 [ -99.781961  -99.780157  -99.807591  -99.751288  -99.832849]
 [ -99.875621  -99.734468  -99.999422  -99.728758  -99.860771]
 [ -99.861885  -99.816627  -99.79108   -99.810864  -99.81818 ]
 [ -99.835104  -99.954257  -99.755497  -99.870089  -99.911839]
 [ -99.901429  -99.938919  -99.775194  -99.845105 -100.01311 ]
 [ -99.573182  -99.941805  -99.972059  -99.826638  -99.90174 ]
 [ -99.879145  -99.878513  -99.881228  -99.916927  -99.896213]
 [ -99.909034  -99.92893   -99.748318  -99.704387  -99.910167]
 [ -99.822379  -99.813057  -99.817564  -99.856422  -99.80519 ]
 [ -99.773343  -99.828986  -99.863066  -99.838072  -99.831179]
 [ -99.935952  -99.893072  -99.844936  -99.850954  -99.859482]
 [ -99.88276   -99.830816  -99.823275  -99.694198  -99.853686]
 [ -99.892643  -99.826211 -100.011225  -99.989679  -99.855485]
 [ -99.906671  -99.834067  -99.891115  -99.698615  -99.921678]
 [ -99.78933   -99.997534  -99.795965  -99.847736  -99.98741 ]
 [ -99.918572  -99.872678  -99.895698  -99.901845  -99.962072]
 [ -99.949232  -99.990209  -99.831134  -99.945667  -99.827595]
 [ -99.909464  -99.821317  -99.89848   -99.905689  -99.978817]
 [ -99.932219  -99.937597  -99.932468  -99.873559 -100.018405]
 [-100.027767  -99.826796  -99.920489  -99.807039  -99.897351]
 [ -99.904826  -99.841154  -99.778409  -99.746695  -99.86387 ]
 [ -99.791682  -99.972994  -99.83539   -99.827286  -99.954063]
 [ -99.95262   -99.87802   -99.919365  -99.728657  -99.643374]
 [ -99.913291  -99.947105  -99.810063  -99.927226  -99.885487]
 [ -99.775006  -99.900958  -99.748222  -99.756638  -99.835334]
 [ -99.917754  -99.760926  -99.89085   -99.920613  -99.704639]
 [ -99.8305    -99.753636  -99.755649  -99.915206  -99.911625]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3600 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3589]
 [3601 3601 3601 3601 3601]
 [3600 3600 3601 3601 3601]
 [3601 3585 3601 3601 3598]
 [3601 3601 3601 3601 3586]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3589]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3601 3589 3601 3599 3601]
 [3601 3601 3601 3588 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3599 3601 3601 3600 3601]
 [3601 3601 3601 3583 3601]
 [3601 3598 3601 3601 3601]
 [3599 3601 3601 3601 3600]
 [3588 3601 3599 3601 3601]
 [3601 3601 3586 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3599 3601 3601 3591]
 [3601 3601 3600 3601 3595]
 [3601 3601 3601 3601 3599]
 [3601 3601 3599 3601 3599]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3591 3601 3601 3599 3601]
 [3601 3601 3601 3600 3601]
 [3601 3600 3601 3600 3601]
 [3601 3601 3601 3601 3588]
 [3601 3598 3601 3601 3601]
 [3601 3601 3600 3601 3599]
 [3601 3601 3598 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3592 3601]
 [3600 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3600 3600 3601 3601 3601]
 [3601 3601 3600 3598 3601]
 [3600 3601 3601 3601 3588]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3588 3598 3601 3601]
 [3601 3601 3601 3600 3599]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3592 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3592 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3581]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3592 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3596]
 [3601 3601 3601 3601 3601]
 [3601 3601 3597 3601 3597]
 [3601 3601 3601 3601 3601]
 [3573 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3583 3596 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3582 3601 3601 3601 3598]
 [3601 3601 3599 3596 3585]
 [3601 3598 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3593 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3586 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3597]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-24_14-12-14_llm_triton_qwen_14b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-24_14-12-14_llm_triton_qwen_14b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
