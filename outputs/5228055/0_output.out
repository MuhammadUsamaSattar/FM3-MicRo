####################
/var/spool/slurmd/job5228064/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_3B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-20_12-12-47_llm_triton_qwen_3b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and +9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 8    |
|    iterations      | 1    |
|    time_elapsed    | 240  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.14e+03    |
|    ep_rew_mean          | -188        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 2           |
|    time_elapsed         | 475         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012521716 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0422      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.72        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0211     |
|    std                  | 1           |
|    value_loss           | 5.53        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.14e+03     |
|    ep_rew_mean          | -188         |
| time/                   |              |
|    fps                  | 8            |
|    iterations           | 3            |
|    time_elapsed         | 711          |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0110491365 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.406        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.06         |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.0194      |
|    std                  | 1            |
|    value_loss           | 4.13         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.13e+03    |
|    ep_rew_mean          | -171        |
| time/                   |             |
|    fps                  | 8           |
|    iterations           | 4           |
|    time_elapsed         | 945         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011169286 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.431       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.58        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.021      |
|    std                  | 1           |
|    value_loss           | 4.92        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.85 +/- 0.03
Episode length: 3597.00 +/- 8.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.012683257 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.485       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.18        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0218     |
|    std                  | 1           |
|    value_loss           | 4.03        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -204     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2981     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -204        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 6           |
|    time_elapsed         | 3216        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.006494148 |
|    clip_fraction        | 0.0453      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | -0.00351    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.41        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0047     |
|    std                  | 1           |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.63e+03    |
|    ep_rew_mean          | -142        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3452        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.013409909 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | -0.0143     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.43        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0155     |
|    std                  | 1.01        |
|    value_loss           | 3.51        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.71e+03     |
|    ep_rew_mean          | -97.7        |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 8            |
|    time_elapsed         | 3687         |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0100720115 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.51         |
|    learning_rate        | 0.0003       |
|    loss                 | 2.01         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0178      |
|    std                  | 1.01         |
|    value_loss           | 3.52         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.71e+03    |
|    ep_rew_mean          | -97.7       |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 9           |
|    time_elapsed         | 3925        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.017821038 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.494       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0212     |
|    std                  | 1           |
|    value_loss           | 3.44        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.89 +/- 0.03
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.01305451 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.4      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.28       |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0208    |
|    std                  | 1          |
|    value_loss           | 3.76       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -123     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5960     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -123         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 6192         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0073184143 |
|    clip_fraction        | 0.0691       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.0238       |
|    learning_rate        | 0.0003       |
|    loss                 | 1.74e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00665     |
|    std                  | 1            |
|    value_loss           | 1.04e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.57e+03   |
|    ep_rew_mean          | -85.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 12         |
|    time_elapsed         | 6424       |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.01642014 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.536      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.24       |
|    n_updates            | 110        |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.995      |
|    value_loss           | 4.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.64e+03    |
|    ep_rew_mean          | -50         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6655        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.015640484 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.989       |
|    value_loss           | 3.69        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.64e+03    |
|    ep_rew_mean          | -50         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6884        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.018890973 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.25        |
|    learning_rate        | 0.0003      |
|    loss                 | 2           |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0253     |
|    std                  | 0.983       |
|    value_loss           | 3.89        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.87 +/- 0.06
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.018292103 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.487       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.65        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.976       |
|    value_loss           | 4.77        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -49.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8915     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -49.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 9143        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.012262058 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00289    |
|    learning_rate        | 0.0003      |
|    loss                 | 67.9        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00884    |
|    std                  | 0.973       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.55e+03 |
|    ep_rew_mean          | -15.4    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 17       |
|    time_elapsed         | 9373     |
|    total_timesteps      | 34816    |
| train/                  |          |
|    approx_kl            | 0.01939  |
|    clip_fraction        | 0.225    |
|    clip_range           | 0.2      |
|    entropy_loss         | -11.1    |
|    explained_variance   | -0.0171  |
|    learning_rate        | 0.0003   |
|    loss                 | 2.45     |
|    n_updates            | 160      |
|    policy_gradient_loss | -0.0173  |
|    std                  | 0.969    |
|    value_loss           | 4.78     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.6e+03     |
|    ep_rew_mean          | 16.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 9602        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.019137383 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.28        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.93        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.965       |
|    value_loss           | 3.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.6e+03     |
|    ep_rew_mean          | 16.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 9835        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.015684087 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.22        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.962       |
|    value_loss           | 3.28        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.90 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.022384953 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.953       |
|    value_loss           | 2.54        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 16.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11865    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | 16.4         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 12094        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0109235905 |
|    clip_fraction        | 0.129        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | -0.00111     |
|    learning_rate        | 0.0003       |
|    loss                 | 7.94         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00788     |
|    std                  | 0.953        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | 40.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 12323       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.021292612 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.0817      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.95        |
|    value_loss           | 3.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.58e+03    |
|    ep_rew_mean          | 66.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 12552       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.019465508 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.153       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00843    |
|    std                  | 0.947       |
|    value_loss           | 3.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.58e+03    |
|    ep_rew_mean          | 66.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 24          |
|    time_elapsed         | 12781       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.018019475 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0246     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.939       |
|    value_loss           | 3.77        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.86 +/- 0.04
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.021804985 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.939       |
|    value_loss           | 2.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 65.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14810    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 88.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 15040       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.015219068 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00184    |
|    learning_rate        | 0.0003      |
|    loss                 | 463         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00632    |
|    std                  | 0.941       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 88.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 27         |
|    time_elapsed         | 15270      |
|    total_timesteps      | 55296      |
| train/                  |            |
|    approx_kl            | 0.02032812 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.417      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.49       |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.939      |
|    value_loss           | 3.89       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.56e+03    |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 15500       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.020410871 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.935       |
|    value_loss           | 2.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.56e+03    |
|    ep_rew_mean          | 112         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 15730       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.016972726 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.26        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.929       |
|    value_loss           | 3.46        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.66 +/- 0.39
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.014368081 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.924       |
|    value_loss           | 5.77        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 108      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 17760    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17989       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.023451498 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00474    |
|    learning_rate        | 0.0003      |
|    loss                 | 899         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00672    |
|    std                  | 0.923       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 129        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 32         |
|    time_elapsed         | 18220      |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.02024314 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.286     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.964      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.00903   |
|    std                  | 0.921      |
|    value_loss           | 2.86       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.55e+03    |
|    ep_rew_mean          | 149         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 18449       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.022497455 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.0589      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.996       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00641    |
|    std                  | 0.92        |
|    value_loss           | 1.88        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.55e+03    |
|    ep_rew_mean          | 149         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 18678       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.019136298 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.465       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.921       |
|    value_loss           | 2.99        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.62 +/- 0.42
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.024027288 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.935       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.915       |
|    value_loss           | 2.63        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 144      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 20707    |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 161        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 36         |
|    time_elapsed         | 20935      |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.02211554 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.00167    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.68e+03   |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.00635   |
|    std                  | 0.915      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 161       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 37        |
|    time_elapsed         | 21165     |
|    total_timesteps      | 75776     |
| train/                  |           |
|    approx_kl            | 0.0201738 |
|    clip_fraction        | 0.253     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.6     |
|    explained_variance   | 0.354     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.63      |
|    n_updates            | 360       |
|    policy_gradient_loss | -0.0123   |
|    std                  | 0.916     |
|    value_loss           | 3.22      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.55e+03    |
|    ep_rew_mean          | 179         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 21394       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.023805529 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.00545    |
|    std                  | 0.916       |
|    value_loss           | 2.54        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.57e+03    |
|    ep_rew_mean          | 196         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 21621       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.023998722 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.547       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.917       |
|    value_loss           | 3.07        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.81 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.032577656 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.807       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00853    |
|    std                  | 0.911       |
|    value_loss           | 2.1         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 177      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 23650    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 194         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 23877       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.024585733 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000492   |
|    learning_rate        | 0.0003      |
|    loss                 | 144         |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00416    |
|    std                  | 0.912       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 194         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 24105       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.032662526 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.498      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41        |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0032     |
|    std                  | 0.907       |
|    value_loss           | 3.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | 211         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 24334       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.023306489 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.109       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12        |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00959    |
|    std                  | 0.905       |
|    value_loss           | 1.99        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.78 +/- 0.08
Episode length: 3600.00 +/- 1.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.025948957 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0747      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00627    |
|    std                  | 0.905       |
|    value_loss           | 2.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 208      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 26362    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 208         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 26589       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.029388916 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00125     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.87e+03    |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00391    |
|    std                  | 0.905       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 222        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 46         |
|    time_elapsed         | 26817      |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.03404671 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.0719    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02       |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.00218   |
|    std                  | 0.901      |
|    value_loss           | 1.94       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 222        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 47         |
|    time_elapsed         | 27045      |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.02544047 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.871      |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.00952   |
|    std                  | 0.897      |
|    value_loss           | 2.53       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | 237         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 27272       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.027740996 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.211       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 470         |
|    policy_gradient_loss | 0.00213     |
|    std                  | 0.89        |
|    value_loss           | 1.42        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.85 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.024990167 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.107       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.796       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00982    |
|    std                  | 0.885       |
|    value_loss           | 2.31        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 235      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 29301    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 235         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 29529       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.022754539 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0011      |
|    learning_rate        | 0.0003      |
|    loss                 | 10.5        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00468    |
|    std                  | 0.886       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 250         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 29755       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.025879256 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.064       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.75        |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00474    |
|    std                  | 0.883       |
|    value_loss           | 2.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.54e+03    |
|    ep_rew_mean          | 263         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 29982       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.037910666 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.111       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.872       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00577    |
|    std                  | 0.884       |
|    value_loss           | 2           |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.54e+03   |
|    ep_rew_mean          | 263        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 53         |
|    time_elapsed         | 30209      |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.03156253 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.274      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07       |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.882      |
|    value_loss           | 2.09       |
----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.81 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.030065028 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00912    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00642    |
|    std                  | 0.877       |
|    value_loss           | 2.61        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 261      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 32236    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 261         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 32462       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.029015874 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00327    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.2        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00744    |
|    std                  | 0.877       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 273        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 56         |
|    time_elapsed         | 32689      |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.03296794 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | -0.12      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.726      |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0029    |
|    std                  | 0.874      |
|    value_loss           | 1.92       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 287         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 32916       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.018427368 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.235       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.875       |
|    value_loss           | 3.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 287         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 33143       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.021278108 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0445      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57        |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00232    |
|    std                  | 0.873       |
|    value_loss           | 3.48        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.88 +/- 0.10
Episode length: 3600.40 +/- 0.80
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 120000   |
| train/                  |          |
|    approx_kl            | 0.037006 |
|    clip_fraction        | 0.288    |
|    clip_range           | 0.2      |
|    entropy_loss         | -10.2    |
|    explained_variance   | -0.0104  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.692    |
|    n_updates            | 580      |
|    policy_gradient_loss | -0.00137 |
|    std                  | 0.87     |
|    value_loss           | 1.66     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 286      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 35170    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 286         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 35396       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.032547526 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.000635    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24e+03    |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.000303   |
|    std                  | 0.87        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 300         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 35625       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.026280068 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0827      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.769       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00323    |
|    std                  | 0.871       |
|    value_loss           | 1.76        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 313        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 62         |
|    time_elapsed         | 35853      |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.03828492 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.201      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.773      |
|    n_updates            | 610        |
|    policy_gradient_loss | 0.00192    |
|    std                  | 0.867      |
|    value_loss           | 1.48       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 313        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 63         |
|    time_elapsed         | 36080      |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.03281091 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.185      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02       |
|    n_updates            | 620        |
|    policy_gradient_loss | 0.00362    |
|    std                  | 0.867      |
|    value_loss           | 1.86       |
----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.83 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.029093828 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.179       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00164    |
|    std                  | 0.864       |
|    value_loss           | 1.97        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 311      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 38107    |
|    total_timesteps | 131072   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 311       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 65        |
|    time_elapsed         | 38334     |
|    total_timesteps      | 133120    |
| train/                  |           |
|    approx_kl            | 0.0385653 |
|    clip_fraction        | 0.293     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | 0.000194  |
|    learning_rate        | 0.0003    |
|    loss                 | 5.78      |
|    n_updates            | 640       |
|    policy_gradient_loss | -0.00309  |
|    std                  | 0.864     |
|    value_loss           | 1.04e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 323         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 38560       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.034790657 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0325      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08        |
|    n_updates            | 650         |
|    policy_gradient_loss | 0.00222     |
|    std                  | 0.86        |
|    value_loss           | 2.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 335         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 38788       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.029305462 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.629       |
|    n_updates            | 660         |
|    policy_gradient_loss | 0.00218     |
|    std                  | 0.859       |
|    value_loss           | 1.77        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 335         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 39015       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.041433364 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.52       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28        |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.858       |
|    value_loss           | 4.13        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.77 +/- 0.04
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.030510256 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.59        |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.000912   |
|    std                  | 0.856       |
|    value_loss           | 1.66        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 331      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 41042    |
|    total_timesteps | 141312   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | 343        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 70         |
|    time_elapsed         | 41270      |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.03541094 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.0173     |
|    learning_rate        | 0.0003     |
|    loss                 | 173        |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.00958   |
|    std                  | 0.856      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | 343        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 71         |
|    time_elapsed         | 41497      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.04196228 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.991      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.00345   |
|    std                  | 0.857      |
|    value_loss           | 4.18       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 353         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 41724       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.037777055 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.000467   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.951       |
|    n_updates            | 710         |
|    policy_gradient_loss | 0.00358     |
|    std                  | 0.851       |
|    value_loss           | 2.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 353         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 41951       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.037579123 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.576       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12        |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00388    |
|    std                  | 0.851       |
|    value_loss           | 2.41        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.029111331 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.161       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.61        |
|    n_updates            | 730         |
|    policy_gradient_loss | 0.00169     |
|    std                  | 0.851       |
|    value_loss           | 1.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 350      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 43977    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 360         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 44204       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.029217955 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.00711     |
|    learning_rate        | 0.0003      |
|    loss                 | 14.7        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.851       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | 360        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 76         |
|    time_elapsed         | 44431      |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.03703781 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.022     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32       |
|    n_updates            | 750        |
|    policy_gradient_loss | 0.00367    |
|    std                  | 0.846      |
|    value_loss           | 2.57       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 369         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 44657       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.028036054 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 760         |
|    policy_gradient_loss | 0.00692     |
|    std                  | 0.85        |
|    value_loss           | 1.88        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 369         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 44885       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.028581534 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.194      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.762       |
|    n_updates            | 770         |
|    policy_gradient_loss | 0.00266     |
|    std                  | 0.843       |
|    value_loss           | 2.32        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.84 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.042226948 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.731       |
|    n_updates            | 780         |
|    policy_gradient_loss | 0.00138     |
|    std                  | 0.844       |
|    value_loss           | 1.78        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 366      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 46913    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 375         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 47139       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.030707285 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.0052      |
|    learning_rate        | 0.0003      |
|    loss                 | 83.7        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0073     |
|    std                  | 0.84        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 375         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 47366       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.024841096 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.66        |
|    n_updates            | 800         |
|    policy_gradient_loss | 0.00225     |
|    std                  | 0.835       |
|    value_loss           | 2.41        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 385         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 47593       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.044680327 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.994       |
|    n_updates            | 810         |
|    policy_gradient_loss | 0.00427     |
|    std                  | 0.828       |
|    value_loss           | 1.93        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 394         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 47819       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.034434102 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.826       |
|    n_updates            | 820         |
|    policy_gradient_loss | 0.00136     |
|    std                  | 0.834       |
|    value_loss           | 1.65        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.03298281 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.86      |
|    explained_variance   | 0.0458     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.926      |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.00275   |
|    std                  | 0.83       |
|    value_loss           | 1.88       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 382      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 49846    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 391         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 50076       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.030436384 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.00268    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.000297   |
|    std                  | 0.831       |
|    value_loss           | 927         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 391         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 50303       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.036608454 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.328       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.877       |
|    n_updates            | 850         |
|    policy_gradient_loss | 0.00104     |
|    std                  | 0.829       |
|    value_loss           | 2.39        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 400        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 87         |
|    time_elapsed         | 50529      |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.03968721 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 7.49e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19       |
|    n_updates            | 860        |
|    policy_gradient_loss | 0.00276    |
|    std                  | 0.827      |
|    value_loss           | 1.95       |
----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.85 +/- 0.03
Episode length: 3597.40 +/- 5.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.045025706 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.0473      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.947       |
|    n_updates            | 870         |
|    policy_gradient_loss | 0.00179     |
|    std                  | 0.822       |
|    value_loss           | 2.03        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 397      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 52559    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 397         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 52787       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.026822453 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | 0.00838     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.99e+03    |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00499    |
|    std                  | 0.824       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 405         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 53014       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.055504993 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | 0.00702     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 890         |
|    policy_gradient_loss | 0.00118     |
|    std                  | 0.82        |
|    value_loss           | 2.72        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 405         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 53240       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.048931323 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.0914      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12        |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.00673     |
|    std                  | 0.816       |
|    value_loss           | 2.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 413        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 92         |
|    time_elapsed         | 53466      |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.04230037 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.7       |
|    explained_variance   | 0.107      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01       |
|    n_updates            | 910        |
|    policy_gradient_loss | 0.00407    |
|    std                  | 0.816      |
|    value_loss           | 1.97       |
----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.84 +/- 0.07
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.047979742 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | -0.0269     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.86        |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00208    |
|    std                  | 0.817       |
|    value_loss           | 2.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 410      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 55494    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 410         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 55722       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.023750614 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.00397     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44e+03    |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00533    |
|    std                  | 0.818       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 417         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 55949       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.038488105 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.027       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.814       |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.00906     |
|    std                  | 0.816       |
|    value_loss           | 2.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 425         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 56178       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.048731644 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | 0.0624      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 950         |
|    policy_gradient_loss | 0.0013      |
|    std                  | 0.813       |
|    value_loss           | 2.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 425         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 56406       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.041660987 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3         |
|    n_updates            | 960         |
|    policy_gradient_loss | 0.00141     |
|    std                  | 0.815       |
|    value_loss           | 2.78        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.030503567 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.0928      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.935       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00132    |
|    std                  | 0.815       |
|    value_loss           | 1.86        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 421      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 58434    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 421         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 58661       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.027791796 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | 0.00261     |
|    learning_rate        | 0.0003      |
|    loss                 | 17          |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0034     |
|    std                  | 0.813       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 429         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 58887       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.032864425 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | -0.0641     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48        |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.812       |
|    value_loss           | 1.99        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 436         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 59113       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.037794366 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | -0.415      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.992       |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.00238    |
|    std                  | 0.81        |
|    value_loss           | 2.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 436         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 59339       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.027567828 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.131       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.801       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.805       |
|    value_loss           | 1.64        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.85 +/- 0.05
Episode length: 3598.20 +/- 3.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.029668473 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 1020        |
|    policy_gradient_loss | 0.00569     |
|    std                  | 0.804       |
|    value_loss           | 1.73        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 434      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 61365    |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 434        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 104        |
|    time_elapsed         | 61592      |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.02719134 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | -0.00193   |
|    learning_rate        | 0.0003     |
|    loss                 | 303        |
|    n_updates            | 1030       |
|    policy_gradient_loss | 0.00593    |
|    std                  | 0.805      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | 440        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 61820      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.04853359 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | 0.00339    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.38       |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.00802    |
|    std                  | 0.808      |
|    value_loss           | 1.94       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 447        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 62046      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.02822556 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.61      |
|    explained_variance   | 0.108      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.989      |
|    n_updates            | 1050       |
|    policy_gradient_loss | 5.26e-05   |
|    std                  | 0.808      |
|    value_loss           | 2.4        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.52e+03   |
|    ep_rew_mean          | 447        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 62272      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.03629272 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | 0.0395     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.559      |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.000164  |
|    std                  | 0.805      |
|    value_loss           | 1.7        |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.82 +/- 0.06
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.028022079 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.692       |
|    n_updates            | 1070        |
|    policy_gradient_loss | 0.00304     |
|    std                  | 0.801       |
|    value_loss           | 1.54        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 443      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 64300    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 443         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 64527       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.030082831 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | 0.0029      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.14e+03    |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00446    |
|    std                  | 0.803       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 450         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 64754       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.052949026 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -0.0399     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.586       |
|    n_updates            | 1090        |
|    policy_gradient_loss | 0.00675     |
|    std                  | 0.799       |
|    value_loss           | 1.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 457         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 64980       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.043112323 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.149       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.708       |
|    n_updates            | 1100        |
|    policy_gradient_loss | 0.00443     |
|    std                  | 0.795       |
|    value_loss           | 1.84        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 457         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 65206       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.035158068 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.15        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 1110        |
|    policy_gradient_loss | 0.00286     |
|    std                  | 0.798       |
|    value_loss           | 2.1         |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.035363168 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.196       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.887       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00409     |
|    std                  | 0.797       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 453      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 67233    |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | 459        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 114        |
|    time_elapsed         | 67458      |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.03432843 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.48      |
|    explained_variance   | 0.00443    |
|    learning_rate        | 0.0003     |
|    loss                 | 6.28       |
|    n_updates            | 1130       |
|    policy_gradient_loss | -0.00448   |
|    std                  | 0.796      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 459         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 67684       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.045049734 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -0.0798     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.977       |
|    n_updates            | 1140        |
|    policy_gradient_loss | 0.00995     |
|    std                  | 0.789       |
|    value_loss           | 1.96        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 466         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 67910       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.033862703 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.895       |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.792       |
|    value_loss           | 1.85        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 466         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 68135       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.046597466 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.117       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73        |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.0119      |
|    std                  | 0.788       |
|    value_loss           | 2.15        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.62 +/- 0.39
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.030117001 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.594       |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.00401     |
|    std                  | 0.785       |
|    value_loss           | 1.66        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 463      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 70165    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 469         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 70390       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.040710803 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -0.00291    |
|    learning_rate        | 0.0003      |
|    loss                 | 695         |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00319    |
|    std                  | 0.787       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 469         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 70615       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.043866612 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | -0.17       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.854       |
|    n_updates            | 1190        |
|    policy_gradient_loss | 0.00291     |
|    std                  | 0.787       |
|    value_loss           | 1.77        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 476         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 70840       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.048898228 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 1200        |
|    policy_gradient_loss | 0.00922     |
|    std                  | 0.78        |
|    value_loss           | 1.76        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | 484         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 71065       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.055665687 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.922       |
|    n_updates            | 1210        |
|    policy_gradient_loss | 0.00859     |
|    std                  | 0.779       |
|    value_loss           | 1.69        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.87 +/- 0.07
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.038738422 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | -0.139      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.931       |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00256     |
|    std                  | 0.778       |
|    value_loss           | 2.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 475      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 73093    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 488         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 73318       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.034961898 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | -0.000803   |
|    learning_rate        | 0.0003      |
|    loss                 | 440         |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00279    |
|    std                  | 0.777       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 488         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 73544       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.034556158 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | -0.422      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.687       |
|    n_updates            | 1240        |
|    policy_gradient_loss | 0.00206     |
|    std                  | 0.775       |
|    value_loss           | 2.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 500         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 73770       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.046934918 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.1         |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 1250        |
|    policy_gradient_loss | 0.00466     |
|    std                  | 0.773       |
|    value_loss           | 1.94        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.83 +/- 0.07
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.05655505 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.22      |
|    explained_variance   | -0.0159    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.628      |
|    n_updates            | 1260       |
|    policy_gradient_loss | 0.00392    |
|    std                  | 0.771      |
|    value_loss           | 1.64       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 512      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 75796    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 512         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 76021       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.042844318 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -0.00119    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+03     |
|    n_updates            | 1270        |
|    policy_gradient_loss | 0.00379     |
|    std                  | 0.771       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 523         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 76245       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.051723085 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | -0.15       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28        |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.769       |
|    value_loss           | 2.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 523         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 76469       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.039304264 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | 0.162       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54        |
|    n_updates            | 1290        |
|    policy_gradient_loss | 0.00372     |
|    std                  | 0.768       |
|    value_loss           | 2.37        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 533         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 76694       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.046362277 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.0795      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.982       |
|    n_updates            | 1300        |
|    policy_gradient_loss | 0.00765     |
|    std                  | 0.768       |
|    value_loss           | 1.72        |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.72 +/- 0.43
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.04598178 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | 0.0981     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.634      |
|    n_updates            | 1310       |
|    policy_gradient_loss | 0.00497    |
|    std                  | 0.764      |
|    value_loss           | 2.03       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 545      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 78719    |
|    total_timesteps | 270336   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 545        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 133        |
|    time_elapsed         | 78944      |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.02631747 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.13      |
|    explained_variance   | 0.0157     |
|    learning_rate        | 0.0003     |
|    loss                 | 753        |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.00278   |
|    std                  | 0.763      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 555        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 79168      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.04303388 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | -0.128     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.63       |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.767      |
|    value_loss           | 1.98       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 555        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 79393      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.07950367 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9        |
|    n_updates            | 1340       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.764      |
|    value_loss           | 4.18       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 564         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 79618       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.040550165 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.143       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.844       |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.76        |
|    value_loss           | 1.47        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.85 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.03313502 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15       |
|    n_updates            | 1360       |
|    policy_gradient_loss | -0.000424  |
|    std                  | 0.759      |
|    value_loss           | 2.73       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 573      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 81644    |
|    total_timesteps | 280576   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 573        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 138        |
|    time_elapsed         | 81870      |
|    total_timesteps      | 282624     |
| train/                  |            |
|    approx_kl            | 0.04678864 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | -0.00277   |
|    learning_rate        | 0.0003     |
|    loss                 | 621        |
|    n_updates            | 1370       |
|    policy_gradient_loss | -0.000661  |
|    std                  | 0.759      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 581         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 82094       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.053059764 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | -0.00575    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21        |
|    n_updates            | 1380        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.76        |
|    value_loss           | 1.83        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 589       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 140       |
|    time_elapsed         | 82318     |
|    total_timesteps      | 286720    |
| train/                  |           |
|    approx_kl            | 0.0353538 |
|    clip_fraction        | 0.348     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.07     |
|    explained_variance   | 0.0142    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.649     |
|    n_updates            | 1390      |
|    policy_gradient_loss | 0.0026    |
|    std                  | 0.757     |
|    value_loss           | 1.71      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 589       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 141       |
|    time_elapsed         | 82543     |
|    total_timesteps      | 288768    |
| train/                  |           |
|    approx_kl            | 0.0461838 |
|    clip_fraction        | 0.333     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.05     |
|    explained_variance   | 0.477     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.706     |
|    n_updates            | 1400      |
|    policy_gradient_loss | 0.00611   |
|    std                  | 0.756     |
|    value_loss           | 2.21      |
---------------------------------------
Eval num_timesteps=290000, episode_reward=-99.91 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.063129686 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | 0.0992      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.79        |
|    n_updates            | 1410        |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.749       |
|    value_loss           | 1.77        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 597      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 84569    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 597         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 84794       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.042695593 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.97       |
|    explained_variance   | -0.00107    |
|    learning_rate        | 0.0003      |
|    loss                 | 571         |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.749       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 605        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 85018      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.10152219 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | -0.0166    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.752      |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.000613  |
|    std                  | 0.748      |
|    value_loss           | 1.81       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 612         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 85243       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.061120376 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.125       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.743       |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.00628     |
|    std                  | 0.745       |
|    value_loss           | 1.62        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 612        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 85468      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.07268381 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | -0.145     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.631      |
|    n_updates            | 1450       |
|    policy_gradient_loss | 0.00436    |
|    std                  | 0.745      |
|    value_loss           | 1.75       |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.68 +/- 0.39
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.04391055 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.158      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.794      |
|    n_updates            | 1460       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.743      |
|    value_loss           | 1.56       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 620      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 87492    |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 620        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 148        |
|    time_elapsed         | 87716      |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.04405047 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.00113    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.95       |
|    n_updates            | 1470       |
|    policy_gradient_loss | 0.00438    |
|    std                  | 0.742      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 627        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 149        |
|    time_elapsed         | 87941      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.33816037 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.00692    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.629      |
|    n_updates            | 1480       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.744      |
|    value_loss           | 1.57       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 633         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 88166       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.057518512 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.08        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.653       |
|    n_updates            | 1490        |
|    policy_gradient_loss | 0.01        |
|    std                  | 0.743       |
|    value_loss           | 1.5         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 633         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 88390       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.032767866 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | 0.125       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.881       |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.00767     |
|    std                  | 0.743       |
|    value_loss           | 1.73        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.89 +/- 0.03
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.036707077 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.145       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.951       |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.741       |
|    value_loss           | 1.86        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 639      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 90415    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 646        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 153        |
|    time_elapsed         | 90639      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.04182194 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | -0.0035    |
|    learning_rate        | 0.0003     |
|    loss                 | 78         |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.000558  |
|    std                  | 0.742      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 646        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 90863      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.12564933 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | -0.00115   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09       |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.00933    |
|    std                  | 0.742      |
|    value_loss           | 1.76       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 652         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 91088       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.045742318 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.134       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.904       |
|    n_updates            | 1540        |
|    policy_gradient_loss | 0.0203      |
|    std                  | 0.742       |
|    value_loss           | 1.89        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 652        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 91313      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.07422201 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.864      |
|    n_updates            | 1550       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.741      |
|    value_loss           | 1.9        |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.71 +/- 0.39
Episode length: 3599.40 +/- 1.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.03995963 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.86      |
|    explained_variance   | 0.155      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.843      |
|    n_updates            | 1560       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.739      |
|    value_loss           | 1.66       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 658      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 93339    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 665         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 93564       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.051229425 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.00232     |
|    learning_rate        | 0.0003      |
|    loss                 | 719         |
|    n_updates            | 1570        |
|    policy_gradient_loss | 0.00145     |
|    std                  | 0.74        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 665        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 159        |
|    time_elapsed         | 93788      |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.34727466 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.85      |
|    explained_variance   | -0.0946    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13       |
|    n_updates            | 1580       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.737      |
|    value_loss           | 2.31       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 671         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 94014       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.052860633 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.82       |
|    explained_variance   | 0.049       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 1590        |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.734       |
|    value_loss           | 1.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 671         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 94237       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.052309968 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.583       |
|    n_updates            | 1600        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.732       |
|    value_loss           | 1.61        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.70 +/- 0.42
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.037529886 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.654       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00616     |
|    std                  | 0.736       |
|    value_loss           | 1.54        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 676      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 96262    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 682        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 96486      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.08507524 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.82      |
|    explained_variance   | -4.45e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 185        |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.000894  |
|    std                  | 0.737      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 682       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 164       |
|    time_elapsed         | 96710     |
|    total_timesteps      | 335872    |
| train/                  |           |
|    approx_kl            | 0.2168567 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.83     |
|    explained_variance   | 0.00126   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.991     |
|    n_updates            | 1630      |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.736     |
|    value_loss           | 2.04      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 687        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 165        |
|    time_elapsed         | 96935      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.06707469 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.82      |
|    explained_variance   | -0.000214  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.753      |
|    n_updates            | 1640       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.735      |
|    value_loss           | 1.62       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 692        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 97161      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.03936681 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.82      |
|    explained_variance   | 0.205      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.64       |
|    n_updates            | 1650       |
|    policy_gradient_loss | 0.00779    |
|    std                  | 0.736      |
|    value_loss           | 1.42       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.69 +/- 0.42
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.05859372 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.83      |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.869      |
|    n_updates            | 1660       |
|    policy_gradient_loss | 0.00421    |
|    std                  | 0.739      |
|    value_loss           | 2.18       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 692      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 99186    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 697         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 99411       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.044424668 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | -8.13e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+03    |
|    n_updates            | 1670        |
|    policy_gradient_loss | 0.00436     |
|    std                  | 0.74        |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 697         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 99635       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.089796856 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.85       |
|    explained_variance   | -0.0644     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.738       |
|    value_loss           | 1.69        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 701         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 99860       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.052336313 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16        |
|    n_updates            | 1690        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.734       |
|    value_loss           | 2.13        |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.80 +/- 0.04
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.053771824 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.741       |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.00145     |
|    std                  | 0.733       |
|    value_loss           | 1.99        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 705      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 101885   |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 705        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 172        |
|    time_elapsed         | 102109     |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.09910269 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | -0.00065   |
|    learning_rate        | 0.0003     |
|    loss                 | 53.1       |
|    n_updates            | 1710       |
|    policy_gradient_loss | 8.5e-06    |
|    std                  | 0.732      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 709        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 173        |
|    time_elapsed         | 102337     |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.07726203 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.71      |
|    explained_variance   | -0.313     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.882      |
|    n_updates            | 1720       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.726      |
|    value_loss           | 1.72       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 709        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 102563     |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.05744167 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.779      |
|    n_updates            | 1730       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.723      |
|    value_loss           | 1.45       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 714         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 102788      |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.043685257 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.123       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.851       |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.72        |
|    value_loss           | 1.65        |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.59 +/- 0.46
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.04647674 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.0979     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.81       |
|    n_updates            | 1750       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.718      |
|    value_loss           | 1.93       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 717      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 104814   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 717         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 105039      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.031487003 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.000899    |
|    learning_rate        | 0.0003      |
|    loss                 | 118         |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.00167     |
|    std                  | 0.719       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 721        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 105265     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.09306614 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.00581    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.31       |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.72       |
|    value_loss           | 2.19       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 724        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 105490     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.07987831 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.0191     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04       |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.0263     |
|    std                  | 0.721      |
|    value_loss           | 2.42       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 724         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 105715      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.054303683 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.723       |
|    value_loss           | 2.1         |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.70 +/- 0.45
Episode length: 3597.80 +/- 6.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.04466837 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5        |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.00726   |
|    std                  | 0.72       |
|    value_loss           | 3.54       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 725      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 107741   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 725         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 107965      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.046143685 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.000217    |
|    learning_rate        | 0.0003      |
|    loss                 | 11.8        |
|    n_updates            | 1810        |
|    policy_gradient_loss | 0.00635     |
|    std                  | 0.721       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 729       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 183       |
|    time_elapsed         | 108189    |
|    total_timesteps      | 374784    |
| train/                  |           |
|    approx_kl            | 0.1304717 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.61     |
|    explained_variance   | -0.000266 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.899     |
|    n_updates            | 1820      |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.72      |
|    value_loss           | 1.75      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 731         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 108413      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.051285706 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 1830        |
|    policy_gradient_loss | 0.00277     |
|    std                  | 0.721       |
|    value_loss           | 2.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 731         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 108638      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.066474445 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.0429      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.715       |
|    value_loss           | 2.04        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.84 +/- 0.13
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.041235797 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.106       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.935       |
|    n_updates            | 1850        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.719       |
|    value_loss           | 1.65        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 734      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 110662   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 734         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 110888      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.086860076 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | -0.000524   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+03    |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.00189     |
|    std                  | 0.719       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 737       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 188       |
|    time_elapsed         | 111112    |
|    total_timesteps      | 385024    |
| train/                  |           |
|    approx_kl            | 0.0767609 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.6      |
|    explained_variance   | 0.00288   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.903     |
|    n_updates            | 1870      |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.72      |
|    value_loss           | 2.23      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 739         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 111336      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.040837824 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | -0.0537     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.0183      |
|    std                  | 0.718       |
|    value_loss           | 2.06        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 739       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 190       |
|    time_elapsed         | 111561    |
|    total_timesteps      | 389120    |
| train/                  |           |
|    approx_kl            | 0.0573219 |
|    clip_fraction        | 0.342     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.56     |
|    explained_variance   | 0.638     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.19      |
|    n_updates            | 1890      |
|    policy_gradient_loss | 0.00789   |
|    std                  | 0.715     |
|    value_loss           | 2.48      |
---------------------------------------
Eval num_timesteps=390000, episode_reward=-99.79 +/- 0.07
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.07254042 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.53      |
|    explained_variance   | 0.0748     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14       |
|    n_updates            | 1900       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.714      |
|    value_loss           | 2.09       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 742      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 113588   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 742        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 113812     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.04147844 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.53      |
|    explained_variance   | -0.000255  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+03   |
|    n_updates            | 1910       |
|    policy_gradient_loss | 0.00592    |
|    std                  | 0.715      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 744         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 114037      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.066416584 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.00254     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 1920        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.713       |
|    value_loss           | 2.54        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 747        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 194        |
|    time_elapsed         | 114263     |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.09664882 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.51      |
|    explained_variance   | 0.171      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07       |
|    n_updates            | 1930       |
|    policy_gradient_loss | 0.00565    |
|    std                  | 0.712      |
|    value_loss           | 2.13       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | 747      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 195      |
|    time_elapsed         | 114488   |
|    total_timesteps      | 399360   |
| train/                  |          |
|    approx_kl            | 0.053549 |
|    clip_fraction        | 0.381    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.48    |
|    explained_variance   | 0.13     |
|    learning_rate        | 0.0003   |
|    loss                 | 0.757    |
|    n_updates            | 1940     |
|    policy_gradient_loss | 0.0142   |
|    std                  | 0.709    |
|    value_loss           | 1.53     |
--------------------------------------
Eval num_timesteps=400000, episode_reward=-99.74 +/- 0.04
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.04901261 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.46      |
|    explained_variance   | 0.136      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.692      |
|    n_updates            | 1950       |
|    policy_gradient_loss | 0.009      |
|    std                  | 0.707      |
|    value_loss           | 1.76       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 750      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 116514   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 753        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 116739     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.05244547 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.44      |
|    explained_variance   | 0.000169   |
|    learning_rate        | 0.0003     |
|    loss                 | 144        |
|    n_updates            | 1960       |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.707      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 753         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 116963      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.043593682 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | -0.193      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39        |
|    n_updates            | 1970        |
|    policy_gradient_loss | 0.000565    |
|    std                  | 0.705       |
|    value_loss           | 2.32        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 757        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 117188     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.05170233 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.0448     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.774      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.0058     |
|    std                  | 0.703      |
|    value_loss           | 1.79       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 757        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 117415     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.06137291 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | 0.231      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.926      |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.000195   |
|    std                  | 0.703      |
|    value_loss           | 1.88       |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.85 +/- 0.10
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 410000   |
| train/                  |          |
|    approx_kl            | 0.173335 |
|    clip_fraction        | 0.362    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.42    |
|    explained_variance   | 0.0042   |
|    learning_rate        | 0.0003   |
|    loss                 | 1.15     |
|    n_updates            | 2000     |
|    policy_gradient_loss | 0.0124   |
|    std                  | 0.705    |
|    value_loss           | 2.57     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 760      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 119440   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 763         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 119665      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.052871093 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | -0.00124    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+03    |
|    n_updates            | 2010        |
|    policy_gradient_loss | 0.00404     |
|    std                  | 0.705       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 763        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 119889     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.05366523 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.39      |
|    explained_variance   | 0.55       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.16       |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.000136  |
|    std                  | 0.699      |
|    value_loss           | 2.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 765        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 120113     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.05190264 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.35      |
|    explained_variance   | 0.0704     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.853      |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.698      |
|    value_loss           | 1.65       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 765        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 120338     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.04112778 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.33      |
|    explained_variance   | 0.154      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.935      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.695      |
|    value_loss           | 1.52       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.86 +/- 0.05
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.080112055 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.893       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.695       |
|    value_loss           | 1.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 769      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 122364   |
|    total_timesteps | 421888   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | 772      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 207      |
|    time_elapsed         | 122588   |
|    total_timesteps      | 423936   |
| train/                  |          |
|    approx_kl            | 0.040901 |
|    clip_fraction        | 0.364    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.32    |
|    explained_variance   | -0.0011  |
|    learning_rate        | 0.0003   |
|    loss                 | 1.57e+03 |
|    n_updates            | 2060     |
|    policy_gradient_loss | 0.00422  |
|    std                  | 0.695    |
|    value_loss           | 1.05e+03 |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 772        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 122813     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.06385028 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.32      |
|    explained_variance   | 0.00304    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.814      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.695      |
|    value_loss           | 1.8        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 776        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 123039     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.03485079 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.31      |
|    explained_variance   | 0.185      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.683      |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.692      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.82 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.036689624 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.868       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.688       |
|    value_loss           | 1.58        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 779      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 125064   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 779        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 211        |
|    time_elapsed         | 125289     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.06765433 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.25      |
|    explained_variance   | -0.000844  |
|    learning_rate        | 0.0003     |
|    loss                 | 6.22       |
|    n_updates            | 2100       |
|    policy_gradient_loss | 0.00315    |
|    std                  | 0.69       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 782         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 125514      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.042315416 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.00342     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.692       |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.00426     |
|    std                  | 0.693       |
|    value_loss           | 1.48        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 782         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 125738      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.031535678 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.000261    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.686       |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.000184   |
|    std                  | 0.693       |
|    value_loss           | 1.62        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 785         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 125962      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.087265015 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.079       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 2130        |
|    policy_gradient_loss | 0.00662     |
|    std                  | 0.692       |
|    value_loss           | 1.6         |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.86 +/- 0.07
Episode length: 3598.20 +/- 4.66
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.033142813 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | 0.633       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.723       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.00275     |
|    std                  | 0.69        |
|    value_loss           | 1.87        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 788      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 127987   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 788         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 128212      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.039600722 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.25       |
|    explained_variance   | -0.00125    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.16        |
|    n_updates            | 2150        |
|    policy_gradient_loss | 0.00425     |
|    std                  | 0.691       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 792        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 217        |
|    time_elapsed         | 128436     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.12601589 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.25      |
|    explained_variance   | 0.0639     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.82       |
|    n_updates            | 2160       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.689      |
|    value_loss           | 1.65       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 792        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 128659     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.06899047 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.22      |
|    explained_variance   | 0.203      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.642      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.687      |
|    value_loss           | 1.4        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 796         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 128883      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.039601505 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.749       |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.00969     |
|    std                  | 0.691       |
|    value_loss           | 1.69        |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.89 +/- 0.05
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.059497204 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.209       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.8         |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.0189      |
|    std                  | 0.692       |
|    value_loss           | 1.39        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 799      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 130908   |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 799        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 221        |
|    time_elapsed         | 131131     |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.07530639 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | 0.00018    |
|    learning_rate        | 0.0003     |
|    loss                 | 11.3       |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.00409   |
|    std                  | 0.694      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 802        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 131355     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.07207022 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.3       |
|    explained_variance   | 0.1        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.831      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.695      |
|    value_loss           | 1.7        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 805         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 131579      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.047147464 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.899       |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.695       |
|    value_loss           | 1.63        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 805        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 224        |
|    time_elapsed         | 131802     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.06940177 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.29      |
|    explained_variance   | 0.198      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.728      |
|    n_updates            | 2230       |
|    policy_gradient_loss | 0.00419    |
|    std                  | 0.694      |
|    value_loss           | 1.41       |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.86 +/- 0.06
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.05011657 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.29      |
|    explained_variance   | 0.173      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.642      |
|    n_updates            | 2240       |
|    policy_gradient_loss | 0.00861    |
|    std                  | 0.696      |
|    value_loss           | 1.5        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 808      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 133826   |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 808        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 226        |
|    time_elapsed         | 134050     |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.03587548 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.3       |
|    explained_variance   | 0.00085    |
|    learning_rate        | 0.0003     |
|    loss                 | 6.28       |
|    n_updates            | 2250       |
|    policy_gradient_loss | 0.00222    |
|    std                  | 0.697      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 812        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 134274     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.65268624 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | -0.00213   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.664      |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.694      |
|    value_loss           | 1.83       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 816        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 134499     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.46888843 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.25      |
|    explained_variance   | -0.348     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.388      |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.00963    |
|    std                  | 0.693      |
|    value_loss           | 1.19       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 816        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 134723     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.06572129 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.22      |
|    explained_variance   | -0.0178    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.785      |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.00216    |
|    std                  | 0.691      |
|    value_loss           | 1.83       |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.85 +/- 0.01
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.068059646 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | 0.164       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.716       |
|    n_updates            | 2290        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.69        |
|    value_loss           | 1.5         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 820      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 136749   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 820         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 136974      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.035957024 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.00076     |
|    learning_rate        | 0.0003      |
|    loss                 | 149         |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.00153    |
|    std                  | 0.687       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 824        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 137201     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.68583244 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.14      |
|    explained_variance   | 0.00999    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.632      |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.684      |
|    value_loss           | 1.57       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 826         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 137426      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.067123085 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 2320        |
|    policy_gradient_loss | 0.000315    |
|    std                  | 0.684       |
|    value_loss           | 2.98        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 826        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 137650     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.05431727 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.1       |
|    explained_variance   | 0.162      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.731      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.682      |
|    value_loss           | 1.7        |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.87 +/- 0.03
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.07440621 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.11      |
|    explained_variance   | 0.187      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.663      |
|    n_updates            | 2340       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.683      |
|    value_loss           | 1.51       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 830      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 139675   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 833         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 139900      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.053468175 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | -0.00312    |
|    learning_rate        | 0.0003      |
|    loss                 | 9.96        |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00241    |
|    std                  | 0.683       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 833        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 140124     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.06644498 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | -0.425     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.934      |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.00677    |
|    std                  | 0.685      |
|    value_loss           | 1.87       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 836        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 140349     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.12213805 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.11      |
|    explained_variance   | 0.000729   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.618      |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.00867    |
|    std                  | 0.683      |
|    value_loss           | 1.96       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 836        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 140574     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.07020418 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.735      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.681      |
|    value_loss           | 1.56       |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.86 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.044922344 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.06       |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.77        |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.0227      |
|    std                  | 0.68        |
|    value_loss           | 1.46        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 839      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 142599   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 843        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 142823     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.03542169 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | -0.003     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+03   |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.00338   |
|    std                  | 0.681      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 843        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 143048     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.06866862 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.675      |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.00777    |
|    std                  | 0.68       |
|    value_loss           | 1.49       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 846         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 143272      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.055558413 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.795       |
|    n_updates            | 2420        |
|    policy_gradient_loss | 0.00792     |
|    std                  | 0.677       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 846         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 143496      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.047897168 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8          |
|    explained_variance   | 0.479       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 2430        |
|    policy_gradient_loss | 0.00109     |
|    std                  | 0.674       |
|    value_loss           | 1.42        |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.04111287 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.97      |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.78       |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.672      |
|    value_loss           | 1.44       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 848      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 145520   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 851        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 246        |
|    time_elapsed         | 145744     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.04798398 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | -3.45e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 458        |
|    n_updates            | 2450       |
|    policy_gradient_loss | 0.00253    |
|    std                  | 0.675      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 851        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 145967     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.06255045 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | -0.562     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.833      |
|    n_updates            | 2460       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.673      |
|    value_loss           | 2.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 854         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 146190      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.043792084 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.96       |
|    explained_variance   | 0.0012      |
|    learning_rate        | 0.0003      |
|    loss                 | 1           |
|    n_updates            | 2470        |
|    policy_gradient_loss | 0.00532     |
|    std                  | 0.67        |
|    value_loss           | 1.92        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 857        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 249        |
|    time_elapsed         | 146413     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.88145244 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.0142     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.52       |
|    n_updates            | 2480       |
|    policy_gradient_loss | 0.00392    |
|    std                  | 0.671      |
|    value_loss           | 1.86       |
----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.86 +/- 0.05
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.13065669 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.244      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.35       |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.00483    |
|    std                  | 0.664      |
|    value_loss           | 2.31       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 856      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 148437   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 859         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 148661      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.049362175 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.00014     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.58e+03    |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.00226     |
|    std                  | 0.663       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 859         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 148886      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.088336036 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.032       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.6         |
|    n_updates            | 2510        |
|    policy_gradient_loss | 0.00216     |
|    std                  | 0.664       |
|    value_loss           | 1.9         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 862        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 149109     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.11867294 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.0444     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.668      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.00525    |
|    std                  | 0.664      |
|    value_loss           | 1.85       |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.84 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.08421078 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.0305     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27       |
|    n_updates            | 2530       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.663      |
|    value_loss           | 2.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 864      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 151133   |
|    total_timesteps | 520192   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 864        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 255        |
|    time_elapsed         | 151356     |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.05496364 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | -0.000555  |
|    learning_rate        | 0.0003     |
|    loss                 | 555        |
|    n_updates            | 2540       |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.667      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 868        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 151579     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.60695505 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.000487   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.668      |
|    n_updates            | 2550       |
|    policy_gradient_loss | 0.000816   |
|    std                  | 0.662      |
|    value_loss           | 1.68       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 868        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 151803     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.07610342 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.109      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.81       |
|    n_updates            | 2560       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.661      |
|    value_loss           | 1.84       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 870        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 152027     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.04433318 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | 0.0864     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.732      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.663      |
|    value_loss           | 1.81       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.86 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.115064174 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | 0.144       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.749       |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.0231      |
|    std                  | 0.664       |
|    value_loss           | 1.69        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 873      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 154054   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 873        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 154278     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.03744532 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.86      |
|    explained_variance   | 0.00196    |
|    learning_rate        | 0.0003     |
|    loss                 | 865        |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.00067   |
|    std                  | 0.663      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 876        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 154502     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.07670882 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | 0.00681    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.486      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.00918    |
|    std                  | 0.659      |
|    value_loss           | 1.64       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 876         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 154726      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.031104216 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.0979      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.766       |
|    n_updates            | 2610        |
|    policy_gradient_loss | 0.00553     |
|    std                  | 0.657       |
|    value_loss           | 1.64        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 878         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 154950      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.047039673 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | 0.0666      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.905       |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.00622     |
|    std                  | 0.656       |
|    value_loss           | 2.34        |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.07232628 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.0881     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.11       |
|    n_updates            | 2630       |
|    policy_gradient_loss | 0.00887    |
|    std                  | 0.649      |
|    value_loss           | 2.59       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 880      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 156977   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 880         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 157201      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.053011984 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.68       |
|    explained_variance   | -0.00225    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.8         |
|    n_updates            | 2640        |
|    policy_gradient_loss | 0.00931     |
|    std                  | 0.647       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 883        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 157426     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.41018102 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.00892    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.01       |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.647      |
|    value_loss           | 2.88       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 885        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 157651     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.22949322 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.0876     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05       |
|    n_updates            | 2660       |
|    policy_gradient_loss | 0.0052     |
|    std                  | 0.647      |
|    value_loss           | 2.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 885         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 157876      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.081910595 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | 0.116       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.807       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.648       |
|    value_loss           | 1.9         |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.81 +/- 0.07
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.058695484 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | 0.124       |
|    learning_rate        | 0.0003      |
|    loss                 | 1           |
|    n_updates            | 2680        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.647       |
|    value_loss           | 1.89        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 888      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 159900   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 888         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 160124      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.030189916 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | -0.00285    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.33        |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.647       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 891        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 160347     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.09868397 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.0028     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.69       |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.646      |
|    value_loss           | 1.63       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 894        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 160570     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.06811948 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | 0.129      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.751      |
|    n_updates            | 2710       |
|    policy_gradient_loss | 0.00999    |
|    std                  | 0.642      |
|    value_loss           | 2.08       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 894        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 160793     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.04411803 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.149      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.596      |
|    n_updates            | 2720       |
|    policy_gradient_loss | 0.00814    |
|    std                  | 0.644      |
|    value_loss           | 1.42       |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.049475774 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.986       |
|    n_updates            | 2730        |
|    policy_gradient_loss | 0.0105      |
|    std                  | 0.643       |
|    value_loss           | 1.44        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 897      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 162817   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 897         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 163041      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.053415693 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.62       |
|    explained_variance   | -0.00407    |
|    learning_rate        | 0.0003      |
|    loss                 | 30.7        |
|    n_updates            | 2740        |
|    policy_gradient_loss | 0.00527     |
|    std                  | 0.642       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 899         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 276         |
|    time_elapsed         | 163264      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.038236663 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.62       |
|    explained_variance   | -1.67e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53        |
|    n_updates            | 2750        |
|    policy_gradient_loss | 0.00535     |
|    std                  | 0.643       |
|    value_loss           | 3.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 902         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 163488      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.057649292 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.62       |
|    explained_variance   | 0.0328      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.00312     |
|    std                  | 0.642       |
|    value_loss           | 2.19        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 902        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 163711     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.04721134 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | -0.0172    |
|    learning_rate        | 0.0003     |
|    loss                 | 1          |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.00183    |
|    std                  | 0.638      |
|    value_loss           | 2.8        |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.80 +/- 0.02
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 570000    |
| train/                  |           |
|    approx_kl            | 0.0393091 |
|    clip_fraction        | 0.31      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.58     |
|    explained_variance   | 0.065     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.08      |
|    n_updates            | 2780      |
|    policy_gradient_loss | 0.00577   |
|    std                  | 0.639     |
|    value_loss           | 2.18      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 905      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 165736   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 906         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 165960      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.057191983 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | 0.000313    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.00192     |
|    std                  | 0.642       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 906        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 166183     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.08194986 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | -0.196     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9        |
|    n_updates            | 2800       |
|    policy_gradient_loss | 0.00501    |
|    std                  | 0.642      |
|    value_loss           | 5.82       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 909       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 282       |
|    time_elapsed         | 166406    |
|    total_timesteps      | 577536    |
| train/                  |           |
|    approx_kl            | 0.2014497 |
|    clip_fraction        | 0.355     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.6      |
|    explained_variance   | 0.0135    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.36      |
|    n_updates            | 2810      |
|    policy_gradient_loss | 0.00707   |
|    std                  | 0.638     |
|    value_loss           | 2.29      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 909        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 166629     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.04043545 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.122      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08       |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.637      |
|    value_loss           | 2.16       |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.05692917 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.54      |
|    explained_variance   | 0.109      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.968      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.00438    |
|    std                  | 0.632      |
|    value_loss           | 1.54       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 912      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 168654   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 915         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 168877      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.046144903 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.5        |
|    explained_variance   | 0.0128      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.2         |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.63        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 915       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 286       |
|    time_elapsed         | 169101    |
|    total_timesteps      | 585728    |
| train/                  |           |
|    approx_kl            | 0.5535818 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.47     |
|    explained_variance   | 0.375     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.13      |
|    n_updates            | 2850      |
|    policy_gradient_loss | 0.156     |
|    std                  | 0.628     |
|    value_loss           | 2.1       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 919       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 287       |
|    time_elapsed         | 169324    |
|    total_timesteps      | 587776    |
| train/                  |           |
|    approx_kl            | 0.3404281 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.44     |
|    explained_variance   | 0.00315   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.773     |
|    n_updates            | 2860      |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.625     |
|    value_loss           | 1.58      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 919        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 169548     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.08301015 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.41      |
|    explained_variance   | 0.144      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.501      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.00806    |
|    std                  | 0.623      |
|    value_loss           | 1.1        |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.83 +/- 0.05
Episode length: 3599.40 +/- 2.06
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 590000    |
| train/                  |           |
|    approx_kl            | 0.2594282 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.41     |
|    explained_variance   | 0.125     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.579     |
|    n_updates            | 2880      |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.624     |
|    value_loss           | 1.62      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 923      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 171574   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 927         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 171798      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.051163614 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.41       |
|    explained_variance   | -0.00258    |
|    learning_rate        | 0.0003      |
|    loss                 | 21.1        |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.00187     |
|    std                  | 0.624       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 927        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 172022     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.14527261 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.647      |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.0096     |
|    std                  | 0.618      |
|    value_loss           | 1.57       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 931       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 292       |
|    time_elapsed         | 172247    |
|    total_timesteps      | 598016    |
| train/                  |           |
|    approx_kl            | 0.6330195 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.34     |
|    explained_variance   | -0.0118   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.437     |
|    n_updates            | 2910      |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.619     |
|    value_loss           | 1.11      |
---------------------------------------
Eval num_timesteps=600000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.055578142 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.35       |
|    explained_variance   | -0.101      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.806       |
|    n_updates            | 2920        |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.62        |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 935      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 174271   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 935         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 174494      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.061448507 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.37       |
|    explained_variance   | 0.000421    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+03    |
|    n_updates            | 2930        |
|    policy_gradient_loss | 0.00214     |
|    std                  | 0.621       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 939        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 174717     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.15125598 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | 0.000148   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.702      |
|    n_updates            | 2940       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.619      |
|    value_loss           | 1.46       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 939       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 296       |
|    time_elapsed         | 174941    |
|    total_timesteps      | 606208    |
| train/                  |           |
|    approx_kl            | 0.7957971 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.36     |
|    explained_variance   | 0.0573    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.563     |
|    n_updates            | 2950      |
|    policy_gradient_loss | 0.011     |
|    std                  | 0.619     |
|    value_loss           | 1.29      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 175165     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.12959774 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | 0.00023    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06       |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.616      |
|    value_loss           | 1.6        |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.85 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.083033174 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.277       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.00605     |
|    std                  | 0.617       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 948      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 177189   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 948        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 177413     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.06725682 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | 0.000162   |
|    learning_rate        | 0.0003     |
|    loss                 | 239        |
|    n_updates            | 2980       |
|    policy_gradient_loss | 0.0097     |
|    std                  | 0.621      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 952         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 300         |
|    time_elapsed         | 177639      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.050022125 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | -0.0269     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.653       |
|    n_updates            | 2990        |
|    policy_gradient_loss | 0.00652     |
|    std                  | 0.618       |
|    value_loss           | 1.73        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 952        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 177862     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.04980716 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | -0.144     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.732      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.00312    |
|    std                  | 0.616      |
|    value_loss           | 1.36       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 957         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 178086      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.043801572 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.63        |
|    n_updates            | 3010        |
|    policy_gradient_loss | 0.00956     |
|    std                  | 0.615       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.057507597 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.182       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.931       |
|    n_updates            | 3020        |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.615       |
|    value_loss           | 1.36        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 962      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 180110   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 962         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 180335      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.042634446 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.000723    |
|    learning_rate        | 0.0003      |
|    loss                 | 24.9        |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.000825   |
|    std                  | 0.615       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 967         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 305         |
|    time_elapsed         | 180558      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.077416494 |
|    clip_fraction        | 0.467       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.3        |
|    explained_variance   | 0.00407     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.653       |
|    n_updates            | 3040        |
|    policy_gradient_loss | 0.0199      |
|    std                  | 0.617       |
|    value_loss           | 1.3         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 971       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 306       |
|    time_elapsed         | 180783    |
|    total_timesteps      | 626688    |
| train/                  |           |
|    approx_kl            | 0.0320269 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.28     |
|    explained_variance   | 0.214     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.581     |
|    n_updates            | 3050      |
|    policy_gradient_loss | 0.0111    |
|    std                  | 0.614     |
|    value_loss           | 1.29      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 971       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 307       |
|    time_elapsed         | 181006    |
|    total_timesteps      | 628736    |
| train/                  |           |
|    approx_kl            | 0.1933088 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.24     |
|    explained_variance   | 0.0305    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.692     |
|    n_updates            | 3060      |
|    policy_gradient_loss | 0.0148    |
|    std                  | 0.612     |
|    value_loss           | 1.48      |
---------------------------------------
Eval num_timesteps=630000, episode_reward=-99.81 +/- 0.03
Episode length: 3600.00 +/- 1.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.051092297 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.242       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.624       |
|    n_updates            | 3070        |
|    policy_gradient_loss | 0.0178      |
|    std                  | 0.611       |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 976      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 183031   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 976        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 183253     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.17100453 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | -0.000544  |
|    learning_rate        | 0.0003     |
|    loss                 | 2.91e+03   |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.611      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 981         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 310         |
|    time_elapsed         | 183477      |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.076858975 |
|    clip_fraction        | 0.464       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | 0.00101     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.71        |
|    n_updates            | 3090        |
|    policy_gradient_loss | 0.017       |
|    std                  | 0.606       |
|    value_loss           | 2.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 986         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 183700      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.069118924 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.0933      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.865       |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.602       |
|    value_loss           | 1.76        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 986        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 312        |
|    time_elapsed         | 183922     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.07827804 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | 0.126      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.552      |
|    n_updates            | 3110       |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.597      |
|    value_loss           | 1.34       |
----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.81 +/- 0.04
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.04699458 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7         |
|    explained_variance   | 0.0931     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.934      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.593      |
|    value_loss           | 1.59       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 991      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 185948   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 991        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 186171     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.11835921 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | -0.000632  |
|    learning_rate        | 0.0003     |
|    loss                 | 164        |
|    n_updates            | 3130       |
|    policy_gradient_loss | 0.00703    |
|    std                  | 0.594      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 996       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 315       |
|    time_elapsed         | 186394    |
|    total_timesteps      | 645120    |
| train/                  |           |
|    approx_kl            | 1.1939129 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.94     |
|    explained_variance   | 0.000661  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.647     |
|    n_updates            | 3140      |
|    policy_gradient_loss | 0.0223    |
|    std                  | 0.589     |
|    value_loss           | 1.45      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 186617     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.44616872 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.281      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.644      |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.59       |
|    value_loss           | 1.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 186842     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.06385724 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.588      |
|    value_loss           | 1.01       |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.84 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.09373054 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.122      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.793      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.588      |
|    value_loss           | 1.5        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 188867   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 319        |
|    time_elapsed         | 189091     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.17011967 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.000871   |
|    learning_rate        | 0.0003     |
|    loss                 | 308        |
|    n_updates            | 3180       |
|    policy_gradient_loss | 0.00715    |
|    std                  | 0.589      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.01e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 320       |
|    time_elapsed         | 189314    |
|    total_timesteps      | 655360    |
| train/                  |           |
|    approx_kl            | 1.4345856 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.88     |
|    explained_variance   | 0.0049    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.47      |
|    n_updates            | 3190      |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.586     |
|    value_loss           | 1.04      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 189537     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.05598271 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.138      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.648      |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.585      |
|    value_loss           | 1.4        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 189759     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.30071044 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.608      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.00515    |
|    std                  | 0.583      |
|    value_loss           | 1.52       |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.82 +/- 0.05
Episode length: 3599.40 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.08318213 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.0594     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.635      |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.583      |
|    value_loss           | 1.55       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 191782   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 192005     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.05730451 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.82      |
|    explained_variance   | 0.000724   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+03   |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.583      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 325       |
|    time_elapsed         | 192228    |
|    total_timesteps      | 665600    |
| train/                  |           |
|    approx_kl            | 0.5058835 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.8      |
|    explained_variance   | 0.0621    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.685     |
|    n_updates            | 3240      |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.581     |
|    value_loss           | 1.44      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 192451     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.09780148 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.75      |
|    explained_variance   | 0.146      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.799      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.579      |
|    value_loss           | 1.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 192674     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.20321566 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.72      |
|    explained_variance   | 0.138      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.758      |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.576      |
|    value_loss           | 1.29       |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.76 +/- 0.04
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.093600586 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.0236      |
|    std                  | 0.576       |
|    value_loss           | 1.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 194699   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 194921     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.05088578 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | 0.00379    |
|    learning_rate        | 0.0003     |
|    loss                 | 182        |
|    n_updates            | 3280       |
|    policy_gradient_loss | -0.000342  |
|    std                  | 0.577      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 330       |
|    time_elapsed         | 195148    |
|    total_timesteps      | 675840    |
| train/                  |           |
|    approx_kl            | 0.3687153 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.69     |
|    explained_variance   | 0.00231   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.409     |
|    n_updates            | 3290      |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.572     |
|    value_loss           | 1.32      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 331         |
|    time_elapsed         | 195372      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.033703275 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.65       |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.559       |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.0202      |
|    std                  | 0.573       |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 332       |
|    time_elapsed         | 195595    |
|    total_timesteps      | 679936    |
| train/                  |           |
|    approx_kl            | 0.1494694 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.65     |
|    explained_variance   | 0.145     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.566     |
|    n_updates            | 3310      |
|    policy_gradient_loss | 0.0156    |
|    std                  | 0.571     |
|    value_loss           | 1.19      |
---------------------------------------
Eval num_timesteps=680000, episode_reward=-99.85 +/- 0.06
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.03694597 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.59      |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.6        |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.00566    |
|    std                  | 0.566      |
|    value_loss           | 1.39       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 197620   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 197844     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.06703493 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | -5.72e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 176        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.00233    |
|    std                  | 0.569      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 198068     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.10455767 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.000838   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.375      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.566      |
|    value_loss           | 1.38       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 198292     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.11348045 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.568      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.84 +/- 0.05
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.058211025 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | -0.12       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.78        |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.566       |
|    value_loss           | 1.55        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 200317   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 200541      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.052553255 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | 0.000259    |
|    learning_rate        | 0.0003      |
|    loss                 | 787         |
|    n_updates            | 3370        |
|    policy_gradient_loss | 0.00547     |
|    std                  | 0.567       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 200765     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.06583169 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.00103    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.812      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.565      |
|    value_loss           | 1.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 200990     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.30854046 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | 0.00577    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.578      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.566      |
|    value_loss           | 1.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 201214      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.053313293 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.1         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.7         |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.566       |
|    value_loss           | 1.61        |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.84 +/- 0.02
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.065685265 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.796       |
|    n_updates            | 3410        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.565       |
|    value_loss           | 1.34        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 203238   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 203464      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.051129043 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | -0.000596   |
|    learning_rate        | 0.0003      |
|    loss                 | 851         |
|    n_updates            | 3420        |
|    policy_gradient_loss | 0.00518     |
|    std                  | 0.566       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.07e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 344       |
|    time_elapsed         | 203689    |
|    total_timesteps      | 704512    |
| train/                  |           |
|    approx_kl            | 0.1543896 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.57     |
|    explained_variance   | 0.0118    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.65      |
|    n_updates            | 3430      |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.566     |
|    value_loss           | 1.4       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 203913     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.11045405 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.136      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.82       |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0228     |
|    std                  | 0.564      |
|    value_loss           | 1.32       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 204137      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.085568905 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.53       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.6         |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.0185      |
|    std                  | 0.564       |
|    value_loss           | 1.16        |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.83 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.07191321 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.5       |
|    explained_variance   | 0.125      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.921      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.0302     |
|    std                  | 0.562      |
|    value_loss           | 1.71       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 206161   |
|    total_timesteps | 710656   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | 1.07e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 348      |
|    time_elapsed         | 206386   |
|    total_timesteps      | 712704   |
| train/                  |          |
|    approx_kl            | 0.11746  |
|    clip_fraction        | 0.501    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.5     |
|    explained_variance   | 0.000248 |
|    learning_rate        | 0.0003   |
|    loss                 | 348      |
|    n_updates            | 3470     |
|    policy_gradient_loss | 0.014    |
|    std                  | 0.564    |
|    value_loss           | 1.05e+03 |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.07e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 349       |
|    time_elapsed         | 206609    |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 0.5547035 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.51     |
|    explained_variance   | 0.00134   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.538     |
|    n_updates            | 3480      |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.564     |
|    value_loss           | 1.15      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 206833     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.12319435 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | 0.0385     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.401      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.026      |
|    std                  | 0.562      |
|    value_loss           | 1.19       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 207056     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.07664107 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.47      |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.759      |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.562      |
|    value_loss           | 1.44       |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.82 +/- 0.04
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.042484462 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.44       |
|    explained_variance   | 0.157       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.411       |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.02        |
|    std                  | 0.559       |
|    value_loss           | 1.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 209082   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 209305      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.098159276 |
|    clip_fraction        | 0.503       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.43       |
|    explained_variance   | 0.000544    |
|    learning_rate        | 0.0003      |
|    loss                 | 42.2        |
|    n_updates            | 3520        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.561       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.08e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 209529    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 1.2594393 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.44     |
|    explained_variance   | 0.000286  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.596     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.0433    |
|    std                  | 0.558     |
|    value_loss           | 1.24      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 209751     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.07749745 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.41      |
|    explained_variance   | 0.217      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.725      |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0433     |
|    std                  | 0.556      |
|    value_loss           | 1.28       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 209974     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.77097875 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.187      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.696      |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.0326     |
|    std                  | 0.555      |
|    value_loss           | 1.3        |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.74 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.082618445 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.186       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.514       |
|    n_updates            | 3560        |
|    policy_gradient_loss | 0.0333      |
|    std                  | 0.553       |
|    value_loss           | 0.961       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 211997   |
|    total_timesteps | 731136   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 358       |
|    time_elapsed         | 212221    |
|    total_timesteps      | 733184    |
| train/                  |           |
|    approx_kl            | 0.2167273 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.34     |
|    explained_variance   | 0.00149   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.18e+03  |
|    n_updates            | 3570      |
|    policy_gradient_loss | 0.00839   |
|    std                  | 0.555     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 359       |
|    time_elapsed         | 212444    |
|    total_timesteps      | 735232    |
| train/                  |           |
|    approx_kl            | 1.1895387 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.33     |
|    explained_variance   | 0.00011   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.81      |
|    n_updates            | 3580      |
|    policy_gradient_loss | 0.0454    |
|    std                  | 0.552     |
|    value_loss           | 1.68      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 212667     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.14725953 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.3       |
|    explained_variance   | -0.105     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.851      |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.0355     |
|    std                  | 0.551      |
|    value_loss           | 1.77       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 212890     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.23864068 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 5.6e-06    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.815      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0242     |
|    std                  | 0.548      |
|    value_loss           | 1.6        |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.82 +/- 0.02
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 740000   |
| train/                  |          |
|    approx_kl            | 2.381124 |
|    clip_fraction        | 0.496    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.21    |
|    explained_variance   | 1.88e-05 |
|    learning_rate        | 0.0003   |
|    loss                 | 0.744    |
|    n_updates            | 3610     |
|    policy_gradient_loss | 0.0101   |
|    std                  | 0.544    |
|    value_loss           | 1.63     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 214914   |
|    total_timesteps | 741376   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 363       |
|    time_elapsed         | 215137    |
|    total_timesteps      | 743424    |
| train/                  |           |
|    approx_kl            | 0.071656  |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.17     |
|    explained_variance   | -1.11e-05 |
|    learning_rate        | 0.0003    |
|    loss                 | 1.05e+03  |
|    n_updates            | 3620      |
|    policy_gradient_loss | 0.00836   |
|    std                  | 0.542     |
|    value_loss           | 1.06e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 364       |
|    time_elapsed         | 215360    |
|    total_timesteps      | 745472    |
| train/                  |           |
|    approx_kl            | 0.7205639 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.16     |
|    explained_variance   | 0.0171    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.34      |
|    n_updates            | 3630      |
|    policy_gradient_loss | 0.0186    |
|    std                  | 0.543     |
|    value_loss           | 1.89      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 365       |
|    time_elapsed         | 215582    |
|    total_timesteps      | 747520    |
| train/                  |           |
|    approx_kl            | 0.7869907 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.14     |
|    explained_variance   | 4.41e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 1.85      |
|    n_updates            | 3640      |
|    policy_gradient_loss | 0.0278    |
|    std                  | 0.54      |
|    value_loss           | 2.45      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 215805      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.055977475 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.12       |
|    explained_variance   | 0.0205      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.874       |
|    n_updates            | 3650        |
|    policy_gradient_loss | 0.0195      |
|    std                  | 0.538       |
|    value_loss           | 2.21        |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.81 +/- 0.05
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.26591706 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.0624     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.641      |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.535      |
|    value_loss           | 1.46       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 217830   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 368         |
|    time_elapsed         | 218053      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.107888445 |
|    clip_fraction        | 0.529       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.06       |
|    explained_variance   | 0.000899    |
|    learning_rate        | 0.0003      |
|    loss                 | 167         |
|    n_updates            | 3670        |
|    policy_gradient_loss | 0.0198      |
|    std                  | 0.536       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 218276     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.18178278 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.00265    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.612      |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.538      |
|    value_loss           | 1.34       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 218498     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.25376448 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.09      |
|    explained_variance   | 1.19e-07   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.712      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.538      |
|    value_loss           | 1.77       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 218720     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.21133082 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.07      |
|    explained_variance   | -0.886     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.645      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.0879     |
|    std                  | 0.535      |
|    value_loss           | 1.75       |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.79 +/- 0.04
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 760000    |
| train/                  |           |
|    approx_kl            | 1.5263939 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.06     |
|    explained_variance   | 2.32e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 1.01      |
|    n_updates            | 3710      |
|    policy_gradient_loss | 0.0236    |
|    std                  | 0.534     |
|    value_loss           | 1.66      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 220743   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 220965     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.91721743 |
|    clip_fraction        | 0.528      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.04      |
|    explained_variance   | -6.79e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 208        |
|    n_updates            | 3720       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.533      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.12e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 374       |
|    time_elapsed         | 221187    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 0.3799348 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.01     |
|    explained_variance   | 2.56e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.758     |
|    n_updates            | 3730      |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.529     |
|    value_loss           | 1.84      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 221409     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.97077906 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.000111   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.786      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.531      |
|    value_loss           | 1.27       |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.81 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.07324506 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.0954     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.622      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.53       |
|    value_loss           | 1.39       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 223433   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 223655      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.044174016 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.96       |
|    explained_variance   | -0.000372   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.5         |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00493     |
|    std                  | 0.528       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.13e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 378       |
|    time_elapsed         | 223877    |
|    total_timesteps      | 774144    |
| train/                  |           |
|    approx_kl            | 1.3027676 |
|    clip_fraction        | 0.536     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.94     |
|    explained_variance   | 0.000127  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.538     |
|    n_updates            | 3770      |
|    policy_gradient_loss | 0.0309    |
|    std                  | 0.526     |
|    value_loss           | 1.09      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 224099     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.27444872 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | 0.000104   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.873      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.0288     |
|    std                  | 0.525      |
|    value_loss           | 1.84       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.13e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 380       |
|    time_elapsed         | 224323    |
|    total_timesteps      | 778240    |
| train/                  |           |
|    approx_kl            | 1.5309777 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.87     |
|    explained_variance   | -0.000525 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.677     |
|    n_updates            | 3790      |
|    policy_gradient_loss | 0.00688   |
|    std                  | 0.521     |
|    value_loss           | 1.34      |
---------------------------------------
Eval num_timesteps=780000, episode_reward=-99.80 +/- 0.06
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.25990865 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | -0.174     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.813      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.00921    |
|    std                  | 0.522      |
|    value_loss           | 1.6        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 226347   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 226570     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.14913262 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.85      |
|    explained_variance   | -0.000645  |
|    learning_rate        | 0.0003     |
|    loss                 | 29         |
|    n_updates            | 3810       |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.521      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.14e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 383       |
|    time_elapsed         | 226793    |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 0.9075371 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.86     |
|    explained_variance   | 1.55e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.44      |
|    n_updates            | 3820      |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.524     |
|    value_loss           | 1.32      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.14e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 384       |
|    time_elapsed         | 227016    |
|    total_timesteps      | 786432    |
| train/                  |           |
|    approx_kl            | 1.7895279 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.88     |
|    explained_variance   | -0.0876   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.985     |
|    n_updates            | 3830      |
|    policy_gradient_loss | 0.0229    |
|    std                  | 0.524     |
|    value_loss           | 1.61      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 385       |
|    time_elapsed         | 227238    |
|    total_timesteps      | 788480    |
| train/                  |           |
|    approx_kl            | 1.4833856 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.86     |
|    explained_variance   | -1.18e-05 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.774     |
|    n_updates            | 3840      |
|    policy_gradient_loss | 0.0292    |
|    std                  | 0.523     |
|    value_loss           | 1.22      |
---------------------------------------
Eval num_timesteps=790000, episode_reward=-99.79 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 790000    |
| train/                  |           |
|    approx_kl            | 2.562677  |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.85     |
|    explained_variance   | -0.000818 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.726     |
|    n_updates            | 3850      |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.522     |
|    value_loss           | 1.34      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 229262   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 387        |
|    time_elapsed         | 229484     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.18138304 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | -0.00147   |
|    learning_rate        | 0.0003     |
|    loss                 | 40         |
|    n_updates            | 3860       |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.521      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 388       |
|    time_elapsed         | 229707    |
|    total_timesteps      | 794624    |
| train/                  |           |
|    approx_kl            | 0.4675775 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.84     |
|    explained_variance   | -0.000887 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.591     |
|    n_updates            | 3870      |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.522     |
|    value_loss           | 1.4       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | 1.16e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 389      |
|    time_elapsed         | 229929   |
|    total_timesteps      | 796672   |
| train/                  |          |
|    approx_kl            | 2.374157 |
|    clip_fraction        | 0.434    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.86    |
|    explained_variance   | 0.0683   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.664    |
|    n_updates            | 3880     |
|    policy_gradient_loss | 0.0088   |
|    std                  | 0.523    |
|    value_loss           | 1.39     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 230152     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.15965575 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.83      |
|    explained_variance   | 0.246      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.589      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.519      |
|    value_loss           | 1.25       |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.81 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.11226074 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.141      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.967      |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.0307     |
|    std                  | 0.518      |
|    value_loss           | 1.95       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 232176   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 232398     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.09551288 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.8       |
|    explained_variance   | 0.0046     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.63       |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.00431    |
|    std                  | 0.52       |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.16e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 393       |
|    time_elapsed         | 232621    |
|    total_timesteps      | 804864    |
| train/                  |           |
|    approx_kl            | 0.3331452 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.82     |
|    explained_variance   | 2.5e-05   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.52      |
|    n_updates            | 3920      |
|    policy_gradient_loss | 0.0278    |
|    std                  | 0.523     |
|    value_loss           | 2.1       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 232844     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.31221282 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.82      |
|    explained_variance   | -0.357     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.774      |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.521      |
|    value_loss           | 1.78       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.16e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 395       |
|    time_elapsed         | 233067    |
|    total_timesteps      | 808960    |
| train/                  |           |
|    approx_kl            | 1.0148382 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.77     |
|    explained_variance   | 0.0364    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.742     |
|    n_updates            | 3940      |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.517     |
|    value_loss           | 1.71      |
---------------------------------------
Eval num_timesteps=810000, episode_reward=-99.80 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.54973716 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.72      |
|    explained_variance   | 0.215      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0355     |
|    std                  | 0.515      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 235090   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 235312     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.07301748 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.72      |
|    explained_variance   | 0.00323    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.94e+03   |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.00163   |
|    std                  | 0.516      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.17e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 398       |
|    time_elapsed         | 235534    |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 0.9659679 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.72     |
|    explained_variance   | -5.36e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.96      |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.0158    |
|    std                  | 0.515     |
|    value_loss           | 1.71      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 235758     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.73219025 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.7       |
|    explained_variance   | 0.0878     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.594      |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.0272     |
|    std                  | 0.512      |
|    value_loss           | 1.15       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 400         |
|    time_elapsed         | 235981      |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.076476276 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.822       |
|    n_updates            | 3990        |
|    policy_gradient_loss | 0.0286      |
|    std                  | 0.512       |
|    value_loss           | 1.47        |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.81 +/- 0.04
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 820000    |
| train/                  |           |
|    approx_kl            | 0.5807785 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.66     |
|    explained_variance   | 0.126     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.893     |
|    n_updates            | 4000      |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.512     |
|    value_loss           | 1.49      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 238004   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 238225      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.063853085 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.68       |
|    explained_variance   | -0.00225    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00155    |
|    std                  | 0.514       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 403       |
|    time_elapsed         | 238447    |
|    total_timesteps      | 825344    |
| train/                  |           |
|    approx_kl            | 0.5914664 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.69     |
|    explained_variance   | -3.46e-06 |
|    learning_rate        | 0.0003    |
|    loss                 | 0.776     |
|    n_updates            | 4020      |
|    policy_gradient_loss | 0.0268    |
|    std                  | 0.513     |
|    value_loss           | 1.46      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 404       |
|    time_elapsed         | 238671    |
|    total_timesteps      | 827392    |
| train/                  |           |
|    approx_kl            | 1.3478606 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.65     |
|    explained_variance   | 0.0341    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.737     |
|    n_updates            | 4030      |
|    policy_gradient_loss | 0.017     |
|    std                  | 0.51      |
|    value_loss           | 2.01      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 405         |
|    time_elapsed         | 238894      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.118772075 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.63       |
|    explained_variance   | 0.098       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.0229      |
|    std                  | 0.511       |
|    value_loss           | 1.58        |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.82 +/- 0.06
Episode length: 3599.40 +/- 2.73
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.12575907 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.6       |
|    explained_variance   | 0.174      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.646      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.508      |
|    value_loss           | 1.35       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 240917   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 241140     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.07139057 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.58      |
|    explained_variance   | 0.00326    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.3        |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.00575    |
|    std                  | 0.508      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 241364     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.53315794 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.55      |
|    explained_variance   | -0.351     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.594      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.507      |
|    value_loss           | 1.74       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 409       |
|    time_elapsed         | 241587    |
|    total_timesteps      | 837632    |
| train/                  |           |
|    approx_kl            | 0.7308427 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.54     |
|    explained_variance   | 0.0482    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.937     |
|    n_updates            | 4080      |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.506     |
|    value_loss           | 1.74      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 241810     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.14030436 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.5       |
|    explained_variance   | -0.135     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.793      |
|    n_updates            | 4090       |
|    policy_gradient_loss | 0.0267     |
|    std                  | 0.502      |
|    value_loss           | 1.88       |
----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.80 +/- 0.03
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.13308586 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.48      |
|    explained_variance   | 0.147      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.794      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0266     |
|    std                  | 0.503      |
|    value_loss           | 1.91       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 243834   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 244057     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.06420004 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.49      |
|    explained_variance   | 0.000646   |
|    learning_rate        | 0.0003     |
|    loss                 | 20.6       |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.00188    |
|    std                  | 0.504      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 244278     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.88540447 |
|    clip_fraction        | 0.507      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.101      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03       |
|    n_updates            | 4120       |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.5        |
|    value_loss           | 2          |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 414        |
|    time_elapsed         | 244500     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.19178359 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.43      |
|    explained_variance   | 0.000484   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.882      |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.0258     |
|    std                  | 0.499      |
|    value_loss           | 2.24       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 244722     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.11443967 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.43      |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.798      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.0325     |
|    std                  | 0.5        |
|    value_loss           | 1.87       |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.80 +/- 0.02
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.14738357 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.45      |
|    explained_variance   | 0.28       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.7        |
|    n_updates            | 4150       |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.501      |
|    value_loss           | 1.31       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 246746   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 246968      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.064800285 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.46       |
|    explained_variance   | 0.00358     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.37        |
|    n_updates            | 4160        |
|    policy_gradient_loss | 0.00646     |
|    std                  | 0.501       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 418        |
|    time_elapsed         | 247189     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.47025582 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.0277     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.57       |
|    n_updates            | 4170       |
|    policy_gradient_loss | 0.0252     |
|    std                  | 0.501      |
|    value_loss           | 2.91       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 247411     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.23155591 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.44      |
|    explained_variance   | 1.57e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1          |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.5        |
|    value_loss           | 2.38       |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.86 +/- 0.09
Episode length: 3600.00 +/- 2.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.6116298 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.42     |
|    explained_variance   | 0.18      |
|    learning_rate        | 0.0003    |
|    loss                 | 1.23      |
|    n_updates            | 4190      |
|    policy_gradient_loss | 0.0265    |
|    std                  | 0.497     |
|    value_loss           | 1.9       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 249435   |
|    total_timesteps | 860160   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.19e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 421       |
|    time_elapsed         | 249658    |
|    total_timesteps      | 862208    |
| train/                  |           |
|    approx_kl            | 0.6034279 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.41     |
|    explained_variance   | 0.0512    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.98      |
|    n_updates            | 4200      |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.498     |
|    value_loss           | 557       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.19e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 422       |
|    time_elapsed         | 249880    |
|    total_timesteps      | 864256    |
| train/                  |           |
|    approx_kl            | 2.6334538 |
|    clip_fraction        | 0.513     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.43     |
|    explained_variance   | 3.35e-05  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.611     |
|    n_updates            | 4210      |
|    policy_gradient_loss | 0.0272    |
|    std                  | 0.499     |
|    value_loss           | 1.47      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.5e+03  |
|    ep_rew_mean          | 1.19e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 423      |
|    time_elapsed         | 250101   |
|    total_timesteps      | 866304   |
| train/                  |          |
|    approx_kl            | 2.052787 |
|    clip_fraction        | 0.473    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.44    |
|    explained_variance   | 2.38e-06 |
|    learning_rate        | 0.0003   |
|    loss                 | 0.88     |
|    n_updates            | 4220     |
|    policy_gradient_loss | 0.0293   |
|    std                  | 0.499    |
|    value_loss           | 1.57     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 424       |
|    time_elapsed         | 250324    |
|    total_timesteps      | 868352    |
| train/                  |           |
|    approx_kl            | 1.7707865 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.44     |
|    explained_variance   | 6.56e-06  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.742     |
|    n_updates            | 4230      |
|    policy_gradient_loss | 0.0197    |
|    std                  | 0.498     |
|    value_loss           | 1.34      |
---------------------------------------
Eval num_timesteps=870000, episode_reward=-99.83 +/- 0.01
Episode length: 3598.40 +/- 5.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 870000    |
| train/                  |           |
|    approx_kl            | 1.1132042 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.43     |
|    explained_variance   | -1.88     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.29      |
|    n_updates            | 4240      |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.499     |
|    value_loss           | 12.7      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 252349   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 426         |
|    time_elapsed         | 252572      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.069721825 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.45       |
|    explained_variance   | 1.88e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 790         |
|    n_updates            | 4250        |
|    policy_gradient_loss | 0.00799     |
|    std                  | 0.501       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 252794     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.08540364 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.45      |
|    explained_variance   | 4.83e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.88       |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.5        |
|    value_loss           | 6.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 253017     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.34194812 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.43      |
|    explained_variance   | -1.02      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.07       |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.499      |
|    value_loss           | 4.81       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 253239     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.49208662 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.12       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.664      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.496      |
|    value_loss           | 1.62       |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.80 +/- 0.06
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.46451455 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.175      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.864      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.0299     |
|    std                  | 0.494      |
|    value_loss           | 1.45       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 255263   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 255484     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.20383298 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.34      |
|    explained_variance   | -0.00499   |
|    learning_rate        | 0.0003     |
|    loss                 | 42.5       |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.00592    |
|    std                  | 0.495      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 255706    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 1.3704075 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.33     |
|    explained_variance   | 0.00749   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.604     |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.493     |
|    value_loss           | 1.55      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 255929     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.07298639 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | -0.345     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.42       |
|    n_updates            | 4320       |
|    policy_gradient_loss | 0.0429     |
|    std                  | 0.495      |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 434       |
|    time_elapsed         | 256152    |
|    total_timesteps      | 888832    |
| train/                  |           |
|    approx_kl            | 0.6785461 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.35     |
|    explained_variance   | -0.453    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.885     |
|    n_updates            | 4330      |
|    policy_gradient_loss | 0.0299    |
|    std                  | 0.496     |
|    value_loss           | 1.76      |
---------------------------------------
Eval num_timesteps=890000, episode_reward=-99.81 +/- 0.02
Episode length: 3600.00 +/- 1.55
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 890000    |
| train/                  |           |
|    approx_kl            | 1.0284377 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.36     |
|    explained_variance   | 0.226     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.633     |
|    n_updates            | 4340      |
|    policy_gradient_loss | 0.0211    |
|    std                  | 0.495     |
|    value_loss           | 1.5       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 258177   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 258400     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.15326573 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.34      |
|    explained_variance   | 0.00406    |
|    learning_rate        | 0.0003     |
|    loss                 | 131        |
|    n_updates            | 4350       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.493      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 437       |
|    time_elapsed         | 258623    |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 3.5162833 |
|    clip_fraction        | 0.535     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.31     |
|    explained_variance   | 0.000506  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.397     |
|    n_updates            | 4360      |
|    policy_gradient_loss | 0.0245    |
|    std                  | 0.492     |
|    value_loss           | 1.39      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 258845     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.50902003 |
|    clip_fraction        | 0.514      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | 0.108      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.701      |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.0317     |
|    std                  | 0.493      |
|    value_loss           | 1.33       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 259068     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.08741568 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | 0.0649     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.764      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.493      |
|    value_loss           | 1.57       |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.82 +/- 0.04
Episode length: 3599.20 +/- 3.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.42717946 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | 0.114      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13       |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.0371     |
|    std                  | 0.493      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 261092   |
|    total_timesteps | 901120   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 441       |
|    time_elapsed         | 261315    |
|    total_timesteps      | 903168    |
| train/                  |           |
|    approx_kl            | 0.3290169 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.33     |
|    explained_variance   | 0.00698   |
|    learning_rate        | 0.0003    |
|    loss                 | 35.4      |
|    n_updates            | 4400      |
|    policy_gradient_loss | 0.00679   |
|    std                  | 0.494     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 261537     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.15141028 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | -4.74e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.738      |
|    n_updates            | 4410       |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.497      |
|    value_loss           | 1.73       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 443       |
|    time_elapsed         | 261759    |
|    total_timesteps      | 907264    |
| train/                  |           |
|    approx_kl            | 0.9044552 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.39     |
|    explained_variance   | -0.625    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.432     |
|    n_updates            | 4420      |
|    policy_gradient_loss | 0.016     |
|    std                  | 0.498     |
|    value_loss           | 1.83      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 444         |
|    time_elapsed         | 261982      |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.077308804 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.39       |
|    explained_variance   | 0.133       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.631       |
|    n_updates            | 4430        |
|    policy_gradient_loss | 0.0214      |
|    std                  | 0.498       |
|    value_loss           | 1.35        |
-----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.87 +/- 0.03
Episode length: 3597.40 +/- 6.22
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.44441852 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.205      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.666      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0717     |
|    std                  | 0.497      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 264006   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 264229     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.22152719 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.000238   |
|    learning_rate        | 0.0003     |
|    loss                 | 9.2        |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.497      |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 447       |
|    time_elapsed         | 264450    |
|    total_timesteps      | 915456    |
| train/                  |           |
|    approx_kl            | 0.6909609 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.38     |
|    explained_variance   | -0.0396   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.462     |
|    n_updates            | 4460      |
|    policy_gradient_loss | 0.0263    |
|    std                  | 0.495     |
|    value_loss           | 1.34      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 264673     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.30302197 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.36      |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.568      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0306     |
|    std                  | 0.495      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 264894     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.11157019 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.36      |
|    explained_variance   | -0.15      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.497      |
|    value_loss           | 1.01       |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.86 +/- 0.06
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.069585845 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.37       |
|    explained_variance   | 0.17        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.59        |
|    n_updates            | 4490        |
|    policy_gradient_loss | 0.0288      |
|    std                  | 0.496       |
|    value_loss           | 1.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 266917   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 451        |
|    time_elapsed         | 267139     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.09446019 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.0384     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.936      |
|    n_updates            | 4500       |
|    policy_gradient_loss | 0.00614    |
|    std                  | 0.496      |
|    value_loss           | 881        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 452        |
|    time_elapsed         | 267360     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.22874722 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | 0.0121     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.43       |
|    n_updates            | 4510       |
|    policy_gradient_loss | 0.0346     |
|    std                  | 0.495      |
|    value_loss           | 1.36       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 453       |
|    time_elapsed         | 267581    |
|    total_timesteps      | 927744    |
| train/                  |           |
|    approx_kl            | 0.6242316 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.37     |
|    explained_variance   | 0.221     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.405     |
|    n_updates            | 4520      |
|    policy_gradient_loss | 0.0325    |
|    std                  | 0.496     |
|    value_loss           | 0.904     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 267803     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.17590612 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | -1.29      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.674      |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.497      |
|    value_loss           | 14         |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.80 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.22510123 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.614      |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0422     |
|    std                  | 0.498      |
|    value_loss           | 1.09       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 269827   |
|    total_timesteps | 931840   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | 1.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 456       |
|    time_elapsed         | 270047    |
|    total_timesteps      | 933888    |
| train/                  |           |
|    approx_kl            | 0.2673273 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.41     |
|    explained_variance   | 0.00297   |
|    learning_rate        | 0.0003    |
|    loss                 | 313       |
|    n_updates            | 4550      |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.499     |
|    value_loss           | 946       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 270269     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.20345429 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | -0.324     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.518      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.00222    |
|    std                  | 0.497      |
|    value_loss           | 1.56       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 270490     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.14192215 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | 0.199      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.601      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.497      |
|    value_loss           | 0.991      |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.84 +/- 0.07
Episode length: 3597.20 +/- 7.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.14869528 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | -0.208     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.516      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.496      |
|    value_loss           | 1.49       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 272511   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 272732     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.14965019 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | -0.00235   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25e+03   |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.496      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 272953     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.05512301 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.00744    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.781      |
|    n_updates            | 4600       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.497      |
|    value_loss           | 1.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 1.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 462         |
|    time_elapsed         | 273174      |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.106185675 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.39       |
|    explained_variance   | -0.27       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.594       |
|    n_updates            | 4610        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.495       |
|    value_loss           | 1.65        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 273396     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.07422671 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.115      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.798      |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.497      |
|    value_loss           | 1.64       |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.79 +/- 0.05
Episode length: 3599.80 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.05637591 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.41      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.23       |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.498      |
|    value_loss           | 2.31       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 275419   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 275641     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.39804292 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.41      |
|    explained_variance   | 0.0458     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.18e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.497      |
|    value_loss           | 494        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 1.24e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 466       |
|    time_elapsed         | 275864    |
|    total_timesteps      | 954368    |
| train/                  |           |
|    approx_kl            | 1.5602801 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.41     |
|    explained_variance   | -3.34     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.693     |
|    n_updates            | 4650      |
|    policy_gradient_loss | 0.00452   |
|    std                  | 0.497     |
|    value_loss           | 2.69      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 276087     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.06577222 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | -0.0139    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.699      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.496      |
|    value_loss           | 1.92       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 1.24e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 468       |
|    time_elapsed         | 276308    |
|    total_timesteps      | 958464    |
| train/                  |           |
|    approx_kl            | 0.4916397 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.38     |
|    explained_variance   | 0.0553    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.57      |
|    n_updates            | 4670      |
|    policy_gradient_loss | 0.0442    |
|    std                  | 0.495     |
|    value_loss           | 2.28      |
---------------------------------------
Eval num_timesteps=960000, episode_reward=-99.83 +/- 0.06
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.10312168 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.0397     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.893      |
|    n_updates            | 4680       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.495      |
|    value_loss           | 2.24       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 278330   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 278552     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.08856024 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.0031     |
|    learning_rate        | 0.0003     |
|    loss                 | 54.2       |
|    n_updates            | 4690       |
|    policy_gradient_loss | 0.00728    |
|    std                  | 0.496      |
|    value_loss           | 1.03e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 1.25e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 471       |
|    time_elapsed         | 278775    |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 1.0473442 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.4      |
|    explained_variance   | 0.00223   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.28      |
|    n_updates            | 4700      |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.497     |
|    value_loss           | 3.28      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 278998     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.06971494 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.41      |
|    explained_variance   | -0.0869    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.662      |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.498      |
|    value_loss           | 1.69       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 279219     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.04877052 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.4       |
|    explained_variance   | 0.349      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.678      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.497      |
|    value_loss           | 1.23       |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.79 +/- 0.07
Episode length: 3598.40 +/- 3.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.047851138 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.41       |
|    explained_variance   | 0.372       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.604       |
|    n_updates            | 4730        |
|    policy_gradient_loss | 0.0188      |
|    std                  | 0.498       |
|    value_loss           | 1.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 281242   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 281464      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.071306095 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.42       |
|    explained_variance   | 0.007       |
|    learning_rate        | 0.0003      |
|    loss                 | 946         |
|    n_updates            | 4740        |
|    policy_gradient_loss | 0.0152      |
|    std                  | 0.499       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 1.25e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 281686    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 0.9015262 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.42     |
|    explained_variance   | 0.00988   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.498     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0271    |
|    std                  | 0.498     |
|    value_loss           | 1.33      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 1.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 477         |
|    time_elapsed         | 281907      |
|    total_timesteps      | 976896      |
| train/                  |             |
|    approx_kl            | 0.122228846 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.41       |
|    explained_variance   | -0.369      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 4760        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.497       |
|    value_loss           | 2.79        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 282129     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.14503369 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.149      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.642      |
|    n_updates            | 4770       |
|    policy_gradient_loss | 0.0367     |
|    std                  | 0.496      |
|    value_loss           | 1.48       |
----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.76 +/- 0.02
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 980000   |
| train/                  |          |
|    approx_kl            | 0.121269 |
|    clip_fraction        | 0.485    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.35    |
|    explained_variance   | 0.184    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.561    |
|    n_updates            | 4780     |
|    policy_gradient_loss | 0.0417   |
|    std                  | 0.493    |
|    value_loss           | 1.43     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 284151   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 284373     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.08064449 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.33      |
|    explained_variance   | 0.00955    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.27       |
|    n_updates            | 4790       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.492      |
|    value_loss           | 930        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 1.25e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 481       |
|    time_elapsed         | 284595    |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 0.7140889 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.32     |
|    explained_variance   | 0.00357   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.839     |
|    n_updates            | 4800      |
|    policy_gradient_loss | 0.0252    |
|    std                  | 0.493     |
|    value_loss           | 1.56      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 284816     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.21676356 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.33      |
|    explained_variance   | -1.6       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.659      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.495      |
|    value_loss           | 3.49       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.53e+03    |
|    ep_rew_mean          | 1.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 483         |
|    time_elapsed         | 285038      |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.090872124 |
|    clip_fraction        | 0.47        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.31       |
|    explained_variance   | -0.304      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 4820        |
|    policy_gradient_loss | 0.0284      |
|    std                  | 0.492       |
|    value_loss           | 1.34        |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.79 +/- 0.06
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.10511097 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.3       |
|    explained_variance   | 0.242      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.468      |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.494      |
|    value_loss           | 1.16       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 287061   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 1.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 287285      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.058260664 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.33       |
|    explained_variance   | 0.0614      |
|    learning_rate        | 0.0003      |
|    loss                 | 19.3        |
|    n_updates            | 4840        |
|    policy_gradient_loss | 0.00992     |
|    std                  | 0.496       |
|    value_loss           | 871         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.53e+03  |
|    ep_rew_mean          | 1.26e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 486       |
|    time_elapsed         | 287507    |
|    total_timesteps      | 995328    |
| train/                  |           |
|    approx_kl            | 1.3267233 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.34     |
|    explained_variance   | 0.0338    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.63      |
|    n_updates            | 4850      |
|    policy_gradient_loss | 0.0287    |
|    std                  | 0.497     |
|    value_loss           | 1.25      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 287729     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.17599006 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.34      |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.455      |
|    n_updates            | 4860       |
|    policy_gradient_loss | 0.0506     |
|    std                  | 0.495      |
|    value_loss           | 0.965      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.53e+03   |
|    ep_rew_mean          | 1.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 287953     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.15021935 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.3       |
|    explained_variance   | -0.56      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.694      |
|    n_updates            | 4870       |
|    policy_gradient_loss | 0.0356     |
|    std                  | 0.494      |
|    value_loss           | 4.46       |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.80 +/- 0.03
Episode length: 3597.80 +/- 6.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.19947723 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.27      |
|    explained_variance   | 0.235      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.551      |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.493      |
|    value_loss           | 1.16       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 289978   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-20_12-12-47_llm_triton_qwen_3b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 8:30:11 < 0:00:00 , 9 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.830948  -99.798778  -99.871943  -99.866871  -99.889768]
 [ -99.846527  -99.884799  -99.929625  -99.922906  -99.885958]
 [ -99.951801  -99.8166    -99.785995  -99.892932  -99.922918]
 [ -99.91822   -99.94072   -99.879709  -99.911605  -99.849553]
 [ -99.88031   -99.887956  -99.850119  -99.782193  -99.890921]
 [ -99.914772  -99.789004  -98.883059  -99.935739  -99.794101]
 [ -98.780685  -99.897747  -99.766987  -99.829583  -99.831439]
 [ -99.839504  -99.858351  -99.799945  -99.766271  -99.77826 ]
 [ -99.838656  -99.81858   -99.669978  -99.688651  -99.863606]
 [ -99.76165   -99.902139  -99.918019  -99.886502  -99.774031]
 [ -99.818266  -99.776281  -99.855167  -99.804298  -99.783918]
 [ -99.795571  -99.92095   -99.732601  -99.939364  -99.992163]
 [ -99.789033  -99.873818  -99.8982    -99.784885  -99.811718]
 [ -99.738997  -99.843943  -99.748906  -99.741709  -99.795454]
 [ -99.852017  -99.852585  -99.771585  -99.800263  -99.958221]
 [ -99.781975  -99.837476  -99.821059  -99.825954  -99.949673]
 [ -99.826097  -99.857996  -99.845388  -99.78311   -99.843928]
 [ -99.887224  -99.865909  -99.856301  -99.858327  -99.797556]
 [ -99.915051  -99.927655  -99.775691  -99.764753  -99.806992]
 [ -99.795828  -99.88151   -99.915694  -99.77666   -99.87688 ]
 [ -99.828654  -99.945408  -99.799307  -99.86134   -99.817696]
 [ -99.747742  -99.898758  -99.816784  -99.761317  -99.864116]
 [ -99.903987  -99.748561  -99.872531  -99.822232  -99.905858]
 [ -99.803723  -99.831405  -99.806186  -98.82923   -99.81612 ]
 [ -99.790493  -99.905728  -99.799018  -99.89312   -99.960152]
 [ -99.80148   -99.75251   -99.905301  -99.921602  -99.783727]
 [ -99.9412    -99.97709   -99.937463  -99.862124  -98.862503]
 [ -99.876541  -99.80942   -99.871291  -99.875141  -99.810091]
 [ -99.971589  -99.952006  -99.931882  -99.873185  -99.834203]
 [ -98.921354  -99.973992  -99.799569  -99.899515  -99.823547]
 [ -99.939771  -99.84709   -99.881558  -99.903056  -99.898465]
 [ -99.935329  -98.928204  -99.911977  -99.859956  -99.907452]
 [ -99.849185  -99.881268  -98.877163  -99.964525  -99.943167]
 [ -99.883543  -98.86388   -99.892496  -99.897789  -99.932319]
 [ -99.845654  -99.734272  -99.789213  -99.851087  -99.770571]
 [ -98.685128  -99.754348  -99.817408  -99.940157  -99.750195]
 [ -99.966969  -99.889882  -99.893479  -98.793292  -99.936954]
 [-100.01667   -99.844994  -99.665094  -99.952376  -99.734702]
 [ -99.741619  -99.748013  -99.850567  -99.719742  -99.888362]
 [ -99.803515  -99.675047  -99.727657  -99.743702  -99.769251]
 [ -99.883919  -99.799605  -99.962358  -99.675933  -99.90773 ]
 [ -99.846027  -99.911892  -99.84912   -99.783765  -99.907326]
 [ -99.777469  -99.856186  -99.812664  -99.848281  -99.802283]
 [ -99.787952  -99.881848  -99.988309  -99.86809   -99.791376]
 [ -99.950544  -99.885519  -99.943785  -99.872249  -99.803844]
 [ -99.96241   -99.875306  -99.864943  -99.77259   -99.846032]
 [ -99.837801  -99.860421  -99.868929  -99.828518  -99.849914]
 [ -99.850369  -99.832443  -99.914234  -99.902287  -99.872091]
 [ -99.770475  -99.899123  -99.840664  -99.935423  -99.870342]
 [ -99.912374  -99.776907  -99.807788  -99.828837  -99.901075]
 [ -99.959364  -99.836297  -99.8327    -99.817842  -99.864613]
 [ -99.898949  -99.786584  -99.882048  -99.803307  -99.816879]
 [ -99.91613   -99.899508  -99.818347  -99.784234  -99.897778]
 [ -99.816548  -99.796457  -99.854834  -99.834798  -99.935578]
 [ -99.860259  -99.736753  -99.91049   -99.776585  -99.764647]
 [ -99.877636  -99.867639  -99.873196  -99.865202  -99.755569]
 [ -99.814526  -99.819434  -99.812202  -99.769564  -99.785744]
 [ -99.803699  -99.827734  -99.763971  -99.794757  -99.899245]
 [ -99.768299  -99.82444   -99.848808  -99.821729  -99.910115]
 [ -99.85432   -99.758984  -99.866103  -99.833702  -99.959416]
 [ -99.847561  -99.830282  -99.888987  -99.882565  -99.803728]
 [ -99.777274  -99.806597  -99.871782  -99.89385   -99.882596]
 [ -99.775026  -99.812926  -99.81112   -99.857636  -99.769467]
 [ -99.798273  -99.812941  -99.747777  -99.857704  -99.832415]
 [ -99.805532  -99.829517  -99.796309  -99.813259  -99.954345]
 [ -99.907602  -99.844852  -99.760135  -99.781033  -99.805414]
 [ -99.742707  -99.735817  -99.82514   -99.781853  -99.728445]
 [ -99.788794  -99.835749  -99.810563  -99.863864  -99.948243]
 [ -99.828535  -99.877253  -99.756608  -99.835952  -99.909775]
 [ -99.833502  -99.832258  -99.846224  -99.801417  -99.862058]
 [ -99.891816  -99.873372  -99.813683  -99.842977  -99.751236]
 [ -99.809582  -99.842934  -99.743064  -99.827744  -99.878467]
 [ -99.706886  -99.719672  -99.778027  -99.770106  -99.744608]
 [ -99.838486  -99.7944    -99.831948  -99.848796  -99.794532]
 [ -99.817171  -99.796708  -99.879761  -99.831396  -99.741259]
 [ -99.83384   -99.79024   -99.752253  -99.841247  -99.732296]
 [ -99.782526  -99.842931  -99.735571  -99.843937  -99.8556  ]
 [ -99.843488  -99.72829   -99.81661   -99.732833  -99.884652]
 [ -99.777153  -99.870248  -99.747578  -99.823917  -99.748043]
 [ -99.739865  -99.7955    -99.891966  -99.80876   -99.799417]
 [ -99.83452   -99.815722  -99.816258  -99.714758  -99.829283]
 [ -99.84014   -99.836724  -99.7465    -99.786852  -99.829921]
 [ -99.894618  -99.891804  -99.784266  -99.750352  -99.778965]
 [ -99.806553  -99.828737  -99.78121   -99.751314  -99.838313]
 [ -99.774717  -99.799919  -99.787661  -99.798695  -99.836457]
 [ -99.940605  -99.756694  -99.954973  -99.884129  -99.755006]
 [ -99.846644  -99.840258  -99.836389  -99.805928  -99.836201]
 [ -99.875817  -99.715734  -99.843873  -99.823313  -99.766088]
 [ -99.796507  -99.809105  -99.850231  -99.817691  -99.790815]
 [ -99.818235  -99.863577  -99.753521  -99.837759  -99.825235]
 [ -99.842089  -99.910155  -99.869344  -99.837392  -99.881011]
 [ -99.940062  -99.791172  -99.845834  -99.928819  -99.796838]
 [ -99.82372   -99.859339  -99.776579  -99.826759  -99.738095]
 [ -99.827438  -99.79272   -99.889421  -99.743119  -99.925841]
 [ -99.718451  -99.837588  -99.752201  -99.818218  -99.842614]
 [ -99.854894  -99.749995  -99.832419  -99.768187  -99.919564]
 [ -99.703922  -99.813438  -99.741088  -99.906623  -99.789579]
 [ -99.797419  -99.746015  -99.778364  -99.752977  -99.744937]
 [ -99.842695  -99.868389  -99.748598  -99.711073  -99.758484]
 [ -99.832189  -99.840934  -99.821084  -99.772577  -99.752686]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3581 3601]
 [3601 3601 3584 3601 3601]
 [3601 3594 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3600 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3599 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3598 3586 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3597 3591 3601 3601 3601]
 [3601 3601 3601 3601 3583]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3600]
 [3601 3601 3601 3601 3601]
 [3601 3601 3583 3601 3601]
 [3601 3599 3597 3601 3599]
 [3601 3601 3601 3601 3600]
 [3601 3583 3601 3601 3601]
 [3601 3601 3592 3601 3601]
 [3601 3601 3598 3601 3601]
 [3585 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3587 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3596 3601 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3601 3599 3589 3601 3601]
 [3598 3601 3601 3601 3600]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3601 3601 3600]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3597]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3598 3596]
 [3601 3601 3600 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3600 3601 3601 3601 3597]
 [3601 3601 3601 3586 3601]
 [3601 3601 3601 3601 3601]
 [3601 3597 3597 3601 3601]
 [3586 3601 3601 3601 3601]
 [3601 3601 3601 3592 3601]
 [3598 3597 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3592]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3588 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3600 3601 3594 3601]
 [3601 3601 3601 3601 3598]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3596]
 [3601 3601 3601 3588 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3600 3597 3601]
 [3601 3592 3601 3601 3601]
 [3600 3600 3601 3601 3585]
 [3601 3601 3601 3597 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3583 3601 3601]
 [3601 3599 3597 3601 3601]
 [3600 3601 3601 3601 3600]
 [3593 3601 3601 3596 3601]
 [3601 3601 3601 3601 3601]
 [3601 3596 3601 3601 3601]
 [3601 3585 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-20_12-12-47_llm_triton_qwen_3b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-20_12-12-47_llm_triton_qwen_3b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/model
