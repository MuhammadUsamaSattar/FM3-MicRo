####################
/var/spool/slurmd/job5248569/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_7B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 9
 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 3
 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 1
 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (20.75, -250.00).
 What is the reward score?
 
 Response: -8
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 213  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | -683        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 419         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.010631271 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.02        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.995       |
|    value_loss           | 20.1        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.59e+03     |
|    ep_rew_mean          | -683         |
| time/                   |              |
|    fps                  | 9            |
|    iterations           | 3            |
|    time_elapsed         | 624          |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0097079845 |
|    clip_fraction        | 0.111        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.438        |
|    learning_rate        | 0.0003       |
|    loss                 | 7.62         |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.0188      |
|    std                  | 0.993        |
|    value_loss           | 22.4         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.59e+03     |
|    ep_rew_mean          | -637         |
| time/                   |              |
|    fps                  | 9            |
|    iterations           | 4            |
|    time_elapsed         | 830          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0073894784 |
|    clip_fraction        | 0.079        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.594        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.27         |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.0155      |
|    std                  | 0.993        |
|    value_loss           | 12.3         |
------------------------------------------
Eval num_timesteps=10000, episode_reward=-100.04 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009725276 |
|    clip_fraction        | 0.0942      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.98        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.989       |
|    value_loss           | 7.42        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -702     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2836     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -702        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3041        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.002936205 |
|    clip_fraction        | 0.00635     |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0093      |
|    learning_rate        | 0.0003      |
|    loss                 | 177         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00294    |
|    std                  | 0.989       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -656        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3247        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008169927 |
|    clip_fraction        | 0.0746      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.443       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.59        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.988       |
|    value_loss           | 8.81        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.4e+03    |
|    ep_rew_mean          | -656       |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 8          |
|    time_elapsed         | 3452       |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.00821324 |
|    clip_fraction        | 0.0869     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.34       |
|    n_updates            | 70         |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.988      |
|    value_loss           | 5.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.44e+03    |
|    ep_rew_mean          | -586        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3657        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.010582766 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.367       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6         |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.989       |
|    value_loss           | 3.69        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.98 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.009148765 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.985       |
|    value_loss           | 3.04        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -598     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5664     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -598         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 5869         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0042168936 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.000373     |
|    learning_rate        | 0.0003       |
|    loss                 | 23.6         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00401     |
|    std                  | 0.985        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -525        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6074        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.011857821 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8         |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.986       |
|    value_loss           | 3.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -525        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6280        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.015828043 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.99        |
|    value_loss           | 2.59        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -488        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6485        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.013497441 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.96        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.983       |
|    value_loss           | 2.9         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.89 +/- 0.16
Episode length: 3595.80 +/- 8.13
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.015216634 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.485       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.09        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.98        |
|    value_loss           | 3.46        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -490     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8497     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -490        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 8703        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.007966006 |
|    clip_fraction        | 0.0602      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00276     |
|    learning_rate        | 0.0003      |
|    loss                 | 342         |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00506    |
|    std                  | 0.98        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -440        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 8909        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.020473614 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.76        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.00967    |
|    std                  | 0.976       |
|    value_loss           | 3.77        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -440        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9114        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.026681256 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.972       |
|    value_loss           | 2.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | -393        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9319        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.013818841 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.59        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00956    |
|    std                  | 0.966       |
|    value_loss           | 2.01        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.86 +/- 0.15
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.016766515 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.71        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.96        |
|    value_loss           | 1.66        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -392     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11326    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -392        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 11531       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.005716824 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.000598    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.62        |
|    n_updates            | 200         |
|    policy_gradient_loss | 0.00183     |
|    std                  | 0.96        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -350        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11739       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.020094253 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.006      |
|    std                  | 0.954       |
|    value_loss           | 1.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -350        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11945       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.018548049 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.953       |
|    value_loss           | 2.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -311        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12151       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.017449258 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.473       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.553       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00617    |
|    std                  | 0.944       |
|    value_loss           | 1.42        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.82 +/- 0.15
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.020505998 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.282       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.831       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00828    |
|    std                  | 0.933       |
|    value_loss           | 1.87        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -310     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14158    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -310        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 14363       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.024142042 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00116     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.47        |
|    n_updates            | 250         |
|    policy_gradient_loss | 0.000371    |
|    std                  | 0.933       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -272        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14569       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.027118286 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.28        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.954       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.000193   |
|    std                  | 0.932       |
|    value_loss           | 1.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -235        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14774       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.016607605 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.318       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.688       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.927       |
|    value_loss           | 1.59        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -235        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14979       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.023089422 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.357       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0072     |
|    std                  | 0.925       |
|    value_loss           | 1.91        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.89 +/- 0.11
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.020967439 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.433       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.633       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.918       |
|    value_loss           | 1.6         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -233     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16991    |
|    total_timesteps | 61440    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -233       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 31         |
|    time_elapsed         | 17198      |
|    total_timesteps      | 63488      |
| train/                  |            |
|    approx_kl            | 0.01567613 |
|    clip_fraction        | 0.164      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.000912   |
|    learning_rate        | 0.0003     |
|    loss                 | 18.5       |
|    n_updates            | 300        |
|    policy_gradient_loss | -0.00505   |
|    std                  | 0.918      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -199        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17404       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.019070238 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.227       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.916       |
|    value_loss           | 1.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -168        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17609       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.019429365 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.629       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00749    |
|    std                  | 0.911       |
|    value_loss           | 1.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -168        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17815       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.023219628 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.463       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.775       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.906       |
|    value_loss           | 1.35        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.82 +/- 0.10
Episode length: 3598.80 +/- 4.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.022900833 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.471       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.732       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.898       |
|    value_loss           | 1.49        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -164     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19826    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20033       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.026981272 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000873   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00758    |
|    std                  | 0.898       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20238       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.036214866 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00639    |
|    std                  | 0.893       |
|    value_loss           | 1.68        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | -107       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 38         |
|    time_elapsed         | 20443      |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.02417481 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.45       |
|    n_updates            | 370        |
|    policy_gradient_loss | -0.00994   |
|    std                  | 0.894      |
|    value_loss           | 3.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -107        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20649       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.026204899 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.92        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.892       |
|    value_loss           | 3.69        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.91 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.026839927 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.402       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.727       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0036     |
|    std                  | 0.887       |
|    value_loss           | 1.58        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -107     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22655    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -78.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22861       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.023864537 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.000964   |
|    learning_rate        | 0.0003      |
|    loss                 | 22.6        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00223    |
|    std                  | 0.886       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -78.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23066       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.023916215 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.287       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.708       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00312    |
|    std                  | 0.884       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -53.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23274       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.026935533 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.452       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00667    |
|    std                  | 0.879       |
|    value_loss           | 1.36        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.88 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.023707477 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.52        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.562       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00673    |
|    std                  | 0.876       |
|    value_loss           | 1.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -51.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25283    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -51.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25490       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.023018459 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00122     |
|    learning_rate        | 0.0003      |
|    loss                 | 167         |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.000928   |
|    std                  | 0.875       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -25.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25696       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.022915512 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.405       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.871       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00235    |
|    std                  | 0.868       |
|    value_loss           | 1.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -25.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25901       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.026384644 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.785       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00167    |
|    std                  | 0.865       |
|    value_loss           | 1.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -0.598      |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26107       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.020027578 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.613       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00683    |
|    std                  | 0.865       |
|    value_loss           | 1.39        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.91 +/- 0.04
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.028317912 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01        |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00948    |
|    std                  | 0.859       |
|    value_loss           | 4.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 0.129    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28117    |
|    total_timesteps | 100352   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 0.129      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 50         |
|    time_elapsed         | 28324      |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.02995236 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.00244   |
|    learning_rate        | 0.0003     |
|    loss                 | 859        |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.00547   |
|    std                  | 0.859      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 21.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28529       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.035009645 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.195       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 500         |
|    policy_gradient_loss | 0.00322     |
|    std                  | 0.857       |
|    value_loss           | 1.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 21.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28734       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.031198436 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0486     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.55        |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0005     |
|    std                  | 0.857       |
|    value_loss           | 1.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 43.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28940       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.030167058 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.418       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.698       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00389    |
|    std                  | 0.853       |
|    value_loss           | 1.64        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.67 +/- 0.18
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.024831057 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.85        |
|    value_loss           | 4.72        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 39.7     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30949    |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 39.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 55         |
|    time_elapsed         | 31154      |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.02894685 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.000543  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.88       |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.00351   |
|    std                  | 0.847      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 59.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 56         |
|    time_elapsed         | 31360      |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.04150684 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.97      |
|    explained_variance   | 0.262      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.859      |
|    n_updates            | 550        |
|    policy_gradient_loss | 0.00205    |
|    std                  | 0.842      |
|    value_loss           | 1.55       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 59.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31565       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.026955603 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.85        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00479    |
|    std                  | 0.838       |
|    value_loss           | 1.37        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 79.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31771       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.029709492 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.476       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.605       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.000267   |
|    std                  | 0.839       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.92 +/- 0.05
Episode length: 3598.80 +/- 3.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.026798796 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.45        |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.837       |
|    value_loss           | 5.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 75.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33780    |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 75.3       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 60         |
|    time_elapsed         | 33987      |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.02669571 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | 0.00163    |
|    learning_rate        | 0.0003     |
|    loss                 | 7.15       |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.00465   |
|    std                  | 0.837      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 95          |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34192       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.029220764 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.75        |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.0043      |
|    std                  | 0.834       |
|    value_loss           | 1.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 95          |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34398       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.028373603 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.89        |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00873    |
|    std                  | 0.832       |
|    value_loss           | 4.98        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 113        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 63         |
|    time_elapsed         | 34603      |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.04620722 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 620        |
|    policy_gradient_loss | 0.000207   |
|    std                  | 0.829      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.00 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 130000     |
| train/                  |            |
|    approx_kl            | 0.03176716 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.861      |
|    n_updates            | 630        |
|    policy_gradient_loss | 0.00384    |
|    std                  | 0.825      |
|    value_loss           | 1.67       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 115      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36612    |
|    total_timesteps | 131072   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 115        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 65         |
|    time_elapsed         | 36818      |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.02408012 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | 0.0677     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.79       |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.00711   |
|    std                  | 0.824      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 130        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 66         |
|    time_elapsed         | 37024      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.18322134 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.75      |
|    explained_variance   | 0.113      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.879      |
|    n_updates            | 650        |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.823      |
|    value_loss           | 1.56       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37229       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.042357072 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53        |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.818       |
|    value_loss           | 6.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37434       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.121558584 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | 0.418       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.701       |
|    n_updates            | 670         |
|    policy_gradient_loss | 0.0021      |
|    std                  | 0.813       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.93 +/- 0.03
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.039686866 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.63       |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.673       |
|    n_updates            | 680         |
|    policy_gradient_loss | 0.00366     |
|    std                  | 0.811       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 146      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39440    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39646       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.023502527 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | 0.00287     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.88        |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00436    |
|    std                  | 0.811       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 163         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39851       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.037399996 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.871       |
|    n_updates            | 700         |
|    policy_gradient_loss | 0.00136     |
|    std                  | 0.806       |
|    value_loss           | 1.95        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 180        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 72         |
|    time_elapsed         | 40057      |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.06327412 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.55      |
|    explained_variance   | 0.361      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.614      |
|    n_updates            | 710        |
|    policy_gradient_loss | -0.000221  |
|    std                  | 0.804      |
|    value_loss           | 1.58       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 180        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 73         |
|    time_elapsed         | 40262      |
|    total_timesteps      | 149504     |
| train/                  |            |
|    approx_kl            | 0.03333179 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.53      |
|    explained_variance   | 0.119      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.731      |
|    n_updates            | 720        |
|    policy_gradient_loss | -0.00362   |
|    std                  | 0.804      |
|    value_loss           | 1.52       |
----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.85 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.046049267 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 0.431       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.888       |
|    n_updates            | 730         |
|    policy_gradient_loss | 0.00696     |
|    std                  | 0.803       |
|    value_loss           | 1.42        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 181      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42268    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 196         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42473       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.027005797 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.0611      |
|    learning_rate        | 0.0003      |
|    loss                 | 382         |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00685    |
|    std                  | 0.803       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 196         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42679       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.042912714 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.755       |
|    n_updates            | 750         |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.805       |
|    value_loss           | 1.45        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 213         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42884       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.051930573 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.549       |
|    n_updates            | 760         |
|    policy_gradient_loss | 0.0088      |
|    std                  | 0.8         |
|    value_loss           | 1.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 213         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43091       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.036429927 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.391       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 770         |
|    policy_gradient_loss | 0.00342     |
|    std                  | 0.797       |
|    value_loss           | 1.61        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.88 +/- 0.06
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 160000     |
| train/                  |            |
|    approx_kl            | 0.06669568 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.534      |
|    n_updates            | 780        |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.794      |
|    value_loss           | 1.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 214      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45097    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 231         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45302       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.025108475 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | -0.00253    |
|    learning_rate        | 0.0003      |
|    loss                 | 107         |
|    n_updates            | 790         |
|    policy_gradient_loss | 0.000358    |
|    std                  | 0.792       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 231         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45508       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.034197733 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.828       |
|    n_updates            | 800         |
|    policy_gradient_loss | 0.00215     |
|    std                  | 0.788       |
|    value_loss           | 2.33        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 245         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45713       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.038532257 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | 0.766       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.777       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00567    |
|    std                  | 0.784       |
|    value_loss           | 5.39        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 245        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 83         |
|    time_elapsed         | 45919      |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.04646934 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.503      |
|    n_updates            | 820        |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.78       |
|    value_loss           | 1.23       |
----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.94 +/- 0.03
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.050737195 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.421       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.918       |
|    n_updates            | 830         |
|    policy_gradient_loss | 0.0083      |
|    std                  | 0.775       |
|    value_loss           | 1.53        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 247      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47925    |
|    total_timesteps | 172032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 263        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 85         |
|    time_elapsed         | 48130      |
|    total_timesteps      | 174080     |
| train/                  |            |
|    approx_kl            | 0.04724802 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.2       |
|    explained_variance   | 0.00253    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.66       |
|    n_updates            | 840        |
|    policy_gradient_loss | 0.00413    |
|    std                  | 0.774      |
|    value_loss           | 926        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 263         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48336       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.038406424 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.16       |
|    explained_variance   | 0.99        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00354    |
|    std                  | 0.768       |
|    value_loss           | 2.33        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 273         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48541       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.045185365 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | 0.617       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.38        |
|    n_updates            | 860         |
|    policy_gradient_loss | 0.000373    |
|    std                  | 0.768       |
|    value_loss           | 6.19        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.94 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.046434738 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | 0.246       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.769       |
|    n_updates            | 870         |
|    policy_gradient_loss | 0.00624     |
|    std                  | 0.764       |
|    value_loss           | 1.72        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 275      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50551    |
|    total_timesteps | 180224   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 275        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 89         |
|    time_elapsed         | 50756      |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.03975364 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.09      |
|    explained_variance   | 0.00256    |
|    learning_rate        | 0.0003     |
|    loss                 | 517        |
|    n_updates            | 880        |
|    policy_gradient_loss | 7.63e-05   |
|    std                  | 0.764      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 289        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 50961      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.07748736 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.0871     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.607      |
|    n_updates            | 890        |
|    policy_gradient_loss | 0.00914    |
|    std                  | 0.766      |
|    value_loss           | 1.4        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 289         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51167       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.022678208 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.958       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.766       |
|    value_loss           | 7.3         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 301      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 92       |
|    time_elapsed         | 51372    |
|    total_timesteps      | 188416   |
| train/                  |          |
|    approx_kl            | 0.395678 |
|    clip_fraction        | 0.363    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.12    |
|    explained_variance   | 0.359    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.584    |
|    n_updates            | 910      |
|    policy_gradient_loss | 0.0215   |
|    std                  | 0.77     |
|    value_loss           | 1.43     |
--------------------------------------
Eval num_timesteps=190000, episode_reward=-99.85 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.042969454 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.546       |
|    n_updates            | 920         |
|    policy_gradient_loss | 0.00893     |
|    std                  | 0.762       |
|    value_loss           | 1.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 303      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53378    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 303        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 94         |
|    time_elapsed         | 53584      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.05259916 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | -0.000604  |
|    learning_rate        | 0.0003     |
|    loss                 | 356        |
|    n_updates            | 930        |
|    policy_gradient_loss | 0.0029     |
|    std                  | 0.763      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 317         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53789       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.076845065 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.911       |
|    n_updates            | 940         |
|    policy_gradient_loss | 0.0176      |
|    std                  | 0.756       |
|    value_loss           | 1.76        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 317         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 53994       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.047812104 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | 0.438       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.487       |
|    n_updates            | 950         |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.755       |
|    value_loss           | 1.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 331        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 54200      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.05626813 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | 0.463      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.567      |
|    n_updates            | 960        |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.751      |
|    value_loss           | 1.22       |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.88 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.03567589 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.417      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.72       |
|    n_updates            | 970        |
|    policy_gradient_loss | 0.00426    |
|    std                  | 0.744      |
|    value_loss           | 1.37       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 333      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56206    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 333         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56412       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.022260008 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.0186      |
|    learning_rate        | 0.0003      |
|    loss                 | 539         |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00893    |
|    std                  | 0.743       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 346        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 100        |
|    time_elapsed         | 56618      |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.09069995 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.00983    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.675      |
|    n_updates            | 990        |
|    policy_gradient_loss | 0.00168    |
|    std                  | 0.741      |
|    value_loss           | 1.46       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 346         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56823       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.026702147 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.82       |
|    explained_variance   | 0.826       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0014     |
|    std                  | 0.739       |
|    value_loss           | 5.54        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 359        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 102        |
|    time_elapsed         | 57028      |
|    total_timesteps      | 208896     |
| train/                  |            |
|    approx_kl            | 0.46416354 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.79      |
|    explained_variance   | 0.413      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.628      |
|    n_updates            | 1010       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.736      |
|    value_loss           | 1.27       |
----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.81 +/- 0.15
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 210000    |
| train/                  |           |
|    approx_kl            | 0.0536817 |
|    clip_fraction        | 0.251     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.76     |
|    explained_variance   | 0.886     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.76      |
|    n_updates            | 1020      |
|    policy_gradient_loss | -0.000374 |
|    std                  | 0.734     |
|    value_loss           | 4.96      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 359      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59034    |
|    total_timesteps | 210944   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 359       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 104       |
|    time_elapsed         | 59240     |
|    total_timesteps      | 212992    |
| train/                  |           |
|    approx_kl            | 0.0757635 |
|    clip_fraction        | 0.224     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.76     |
|    explained_variance   | 0.161     |
|    learning_rate        | 0.0003    |
|    loss                 | 63.4      |
|    n_updates            | 1030      |
|    policy_gradient_loss | -0.00985  |
|    std                  | 0.736     |
|    value_loss           | 1.06e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 367       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 105       |
|    time_elapsed         | 59446     |
|    total_timesteps      | 215040    |
| train/                  |           |
|    approx_kl            | 0.7589103 |
|    clip_fraction        | 0.462     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.72     |
|    explained_variance   | 0.0335    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.629     |
|    n_updates            | 1040      |
|    policy_gradient_loss | 0.0319    |
|    std                  | 0.728     |
|    value_loss           | 1.61      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 367        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 59652      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.07065413 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.02       |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.00254   |
|    std                  | 0.726      |
|    value_loss           | 6.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 376        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 59857      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.06591396 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.361      |
|    n_updates            | 1060       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.725      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.86 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.12463562 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.42       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.621      |
|    n_updates            | 1070       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.722      |
|    value_loss           | 1.09       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 377      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61863    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 377         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62069       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.024548173 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.000896    |
|    learning_rate        | 0.0003      |
|    loss                 | 683         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.000879   |
|    std                  | 0.722       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 388        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 62274      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.32806528 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | -0.095     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.399      |
|    n_updates            | 1090       |
|    policy_gradient_loss | 0.00956    |
|    std                  | 0.721      |
|    value_loss           | 1.43       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 399        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 111        |
|    time_elapsed         | 62479      |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.10204454 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.391      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.489      |
|    n_updates            | 1100       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.72       |
|    value_loss           | 1.22       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 399       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 112       |
|    time_elapsed         | 62685     |
|    total_timesteps      | 229376    |
| train/                  |           |
|    approx_kl            | 0.1595217 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.56     |
|    explained_variance   | 0.357     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.763     |
|    n_updates            | 1110      |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.716     |
|    value_loss           | 1.34      |
---------------------------------------
Eval num_timesteps=230000, episode_reward=-99.69 +/- 0.12
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 230000    |
| train/                  |           |
|    approx_kl            | 0.4105511 |
|    clip_fraction        | 0.359     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.51     |
|    explained_variance   | 0.419     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.64      |
|    n_updates            | 1120      |
|    policy_gradient_loss | 0.0123    |
|    std                  | 0.713     |
|    value_loss           | 1.17      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 398      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64691    |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 398        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 114        |
|    time_elapsed         | 64896      |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.04247827 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.5       |
|    explained_variance   | 0.0589     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.19       |
|    n_updates            | 1130       |
|    policy_gradient_loss | 2.13e-05   |
|    std                  | 0.713      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 406       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 115       |
|    time_elapsed         | 65101     |
|    total_timesteps      | 235520    |
| train/                  |           |
|    approx_kl            | 0.2974925 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.5      |
|    explained_variance   | 0.00344   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.672     |
|    n_updates            | 1140      |
|    policy_gradient_loss | 0.0213    |
|    std                  | 0.714     |
|    value_loss           | 1.26      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 416        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 116        |
|    time_elapsed         | 65307      |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.44390976 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.31       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.843      |
|    n_updates            | 1150       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.711      |
|    value_loss           | 1.49       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 416       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 117       |
|    time_elapsed         | 65512     |
|    total_timesteps      | 239616    |
| train/                  |           |
|    approx_kl            | 0.6467134 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.48     |
|    explained_variance   | 0.0152    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.504     |
|    n_updates            | 1160      |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.713     |
|    value_loss           | 1.16      |
---------------------------------------
Eval num_timesteps=240000, episode_reward=-99.93 +/- 0.01
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.066065386 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.471       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.709       |
|    value_loss           | 1.06        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 414      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67518    |
|    total_timesteps | 241664   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 422        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 119        |
|    time_elapsed         | 67724      |
|    total_timesteps      | 243712     |
| train/                  |            |
|    approx_kl            | 0.04623977 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | -0.00198   |
|    learning_rate        | 0.0003     |
|    loss                 | 15.2       |
|    n_updates            | 1180       |
|    policy_gradient_loss | -0.00437   |
|    std                  | 0.709      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 422        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 120        |
|    time_elapsed         | 67929      |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.03041961 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.521      |
|    n_updates            | 1190       |
|    policy_gradient_loss | -0.0013    |
|    std                  | 0.704      |
|    value_loss           | 1.77       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 427         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68134       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.056321517 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09        |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.706       |
|    value_loss           | 5.47        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 427        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 122        |
|    time_elapsed         | 68340      |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.12874562 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.43      |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17       |
|    n_updates            | 1210       |
|    policy_gradient_loss | 0.00207    |
|    std                  | 0.707      |
|    value_loss           | 2.54       |
----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.88 +/- 0.07
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.059473123 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | 0.363       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.671       |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.707       |
|    value_loss           | 1.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 425      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70346    |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 433        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 124        |
|    time_elapsed         | 70551      |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.31126624 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.43      |
|    explained_variance   | 0.00101    |
|    learning_rate        | 0.0003     |
|    loss                 | 813        |
|    n_updates            | 1230       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.706      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 433        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 125        |
|    time_elapsed         | 70756      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.60119903 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.726      |
|    n_updates            | 1240       |
|    policy_gradient_loss | 0.00557    |
|    std                  | 0.704      |
|    value_loss           | 2.91       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 441         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70964       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.062984474 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.886       |
|    n_updates            | 1250        |
|    policy_gradient_loss | 0.0171      |
|    std                  | 0.701       |
|    value_loss           | 1.26        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.89 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.15520963 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.496      |
|    n_updates            | 1260       |
|    policy_gradient_loss | 0.00247    |
|    std                  | 0.7        |
|    value_loss           | 3.41       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 440      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72970    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 440        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 128        |
|    time_elapsed         | 73175      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.26385728 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | 0.00366    |
|    learning_rate        | 0.0003     |
|    loss                 | 157        |
|    n_updates            | 1270       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.702      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 448      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 129      |
|    time_elapsed         | 73381    |
|    total_timesteps      | 264192   |
| train/                  |          |
|    approx_kl            | 0.562589 |
|    clip_fraction        | 0.404    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.39    |
|    explained_variance   | -0.0166  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.572    |
|    n_updates            | 1280     |
|    policy_gradient_loss | 0.0205   |
|    std                  | 0.703    |
|    value_loss           | 1.36     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 448       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 130       |
|    time_elapsed         | 73586     |
|    total_timesteps      | 266240    |
| train/                  |           |
|    approx_kl            | 0.7067326 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.37     |
|    explained_variance   | 0.277     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.43      |
|    n_updates            | 1290      |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.7       |
|    value_loss           | 1.7       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 456       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 131       |
|    time_elapsed         | 73791     |
|    total_timesteps      | 268288    |
| train/                  |           |
|    approx_kl            | 0.3704677 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.36     |
|    explained_variance   | 0.441     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.392     |
|    n_updates            | 1300      |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.7       |
|    value_loss           | 1.09      |
---------------------------------------
Eval num_timesteps=270000, episode_reward=-99.89 +/- 0.05
Episode length: 3597.00 +/- 7.51
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 270000    |
| train/                  |           |
|    approx_kl            | 0.0820799 |
|    clip_fraction        | 0.334     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.32     |
|    explained_variance   | 0.29      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.692     |
|    n_updates            | 1310      |
|    policy_gradient_loss | 0.0158    |
|    std                  | 0.694     |
|    value_loss           | 1.49      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 454      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75798    |
|    total_timesteps | 270336   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 454       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 133       |
|    time_elapsed         | 76003     |
|    total_timesteps      | 272384    |
| train/                  |           |
|    approx_kl            | 0.0940831 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.29     |
|    explained_variance   | 0.00116   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.58      |
|    n_updates            | 1320      |
|    policy_gradient_loss | 0.00885   |
|    std                  | 0.694     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 462        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76208      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.31167534 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.28      |
|    explained_variance   | 0.000859   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.66       |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.692      |
|    value_loss           | 1.83       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 462       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 135       |
|    time_elapsed         | 76414     |
|    total_timesteps      | 276480    |
| train/                  |           |
|    approx_kl            | 0.3404444 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.26     |
|    explained_variance   | 0.39      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.718     |
|    n_updates            | 1340      |
|    policy_gradient_loss | 0.0708    |
|    std                  | 0.691     |
|    value_loss           | 1.38      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 470        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 136        |
|    time_elapsed         | 76619      |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.33221412 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.26      |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.504      |
|    n_updates            | 1350       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.691      |
|    value_loss           | 1.3        |
----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.84 +/- 0.05
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.16019295 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.23      |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.744      |
|    n_updates            | 1360       |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.688      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 469      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78625    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 469         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78833       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.033420786 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | 0.000946    |
|    learning_rate        | 0.0003      |
|    loss                 | 25          |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00385    |
|    std                  | 0.688       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 476       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 139       |
|    time_elapsed         | 79039     |
|    total_timesteps      | 284672    |
| train/                  |           |
|    approx_kl            | 1.0589569 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.2      |
|    explained_variance   | 0.0535    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.642     |
|    n_updates            | 1380      |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.684     |
|    value_loss           | 1.5       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 476        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 140        |
|    time_elapsed         | 79244      |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.41872305 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.832      |
|    n_updates            | 1390       |
|    policy_gradient_loss | 0.0333     |
|    std                  | 0.683      |
|    value_loss           | 1.39       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 483         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 141         |
|    time_elapsed         | 79450       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.091330186 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.14       |
|    explained_variance   | 0.41        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.696       |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.0218      |
|    std                  | 0.68        |
|    value_loss           | 1.33        |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.89 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.042889655 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.391       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.581       |
|    n_updates            | 1410        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.676       |
|    value_loss           | 1.16        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 481      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81456    |
|    total_timesteps | 290816   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 481        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 143        |
|    time_elapsed         | 81661      |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.11243194 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.000267   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02e+03   |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.0043    |
|    std                  | 0.674      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 488        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 81866      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.12504987 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.0424     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.458      |
|    n_updates            | 1430       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.672      |
|    value_loss           | 1.19       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 488         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82072       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.042065173 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.426       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.653       |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.0206      |
|    std                  | 0.673       |
|    value_loss           | 1.27        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 494       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 146       |
|    time_elapsed         | 82277     |
|    total_timesteps      | 299008    |
| train/                  |           |
|    approx_kl            | 1.1047695 |
|    clip_fraction        | 0.326     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.03     |
|    explained_variance   | 0.483     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.502     |
|    n_updates            | 1450      |
|    policy_gradient_loss | 0.0171    |
|    std                  | 0.669     |
|    value_loss           | 1.04      |
---------------------------------------
Eval num_timesteps=300000, episode_reward=-99.89 +/- 0.05
Episode length: 3596.20 +/- 8.18
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 300000    |
| train/                  |           |
|    approx_kl            | 1.4093814 |
|    clip_fraction        | 0.347     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.01     |
|    explained_variance   | 0.427     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.869     |
|    n_updates            | 1460      |
|    policy_gradient_loss | 0.0203    |
|    std                  | 0.668     |
|    value_loss           | 1.36      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 494      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84283    |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 494        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 148        |
|    time_elapsed         | 84489      |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.08940987 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.01      |
|    explained_variance   | -0.00077   |
|    learning_rate        | 0.0003     |
|    loss                 | 93.7       |
|    n_updates            | 1470       |
|    policy_gradient_loss | 0.00293    |
|    std                  | 0.67       |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 500       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 149       |
|    time_elapsed         | 84694     |
|    total_timesteps      | 305152    |
| train/                  |           |
|    approx_kl            | 2.2013993 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.06     |
|    explained_variance   | 0.0106    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.539     |
|    n_updates            | 1480      |
|    policy_gradient_loss | 0.0266    |
|    std                  | 0.672     |
|    value_loss           | 1.53      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 507        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 150        |
|    time_elapsed         | 84900      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.23822105 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.429      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.62       |
|    n_updates            | 1490       |
|    policy_gradient_loss | 0.0279     |
|    std                  | 0.673      |
|    value_loss           | 1.18       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 507         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 85105       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.039424613 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.591       |
|    n_updates            | 1500        |
|    policy_gradient_loss | 0.00771     |
|    std                  | 0.676       |
|    value_loss           | 1.25        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.87 +/- 0.05
Episode length: 3597.60 +/- 5.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.05902635 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.506      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.691      |
|    n_updates            | 1510       |
|    policy_gradient_loss | 0.00804    |
|    std                  | 0.668      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 506      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87111    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 506        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 153        |
|    time_elapsed         | 87317      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.04902858 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.0277     |
|    learning_rate        | 0.0003     |
|    loss                 | 153        |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.000132  |
|    std                  | 0.668      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 512        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 154        |
|    time_elapsed         | 87522      |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.29520166 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.242      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.884      |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.673      |
|    value_loss           | 1.47       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 519         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 87727       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.032236084 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.66        |
|    n_updates            | 1540        |
|    policy_gradient_loss | 0.0063      |
|    std                  | 0.673       |
|    value_loss           | 1.48        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 519        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 87933      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.03079032 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.8        |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.00677   |
|    std                  | 0.673      |
|    value_loss           | 4.02       |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.87 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.08282784 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.04      |
|    explained_variance   | 0.436      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.545      |
|    n_updates            | 1560       |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.671      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 518      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89939    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 518         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90144       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.064885065 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | -0.000981   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 1570        |
|    policy_gradient_loss | 0.000223    |
|    std                  | 0.673       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 524       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 159       |
|    time_elapsed         | 90351     |
|    total_timesteps      | 325632    |
| train/                  |           |
|    approx_kl            | 1.3062272 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.04     |
|    explained_variance   | -0.033    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.559     |
|    n_updates            | 1580      |
|    policy_gradient_loss | 0.00675   |
|    std                  | 0.672     |
|    value_loss           | 1.2       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 529       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 160       |
|    time_elapsed         | 90558     |
|    total_timesteps      | 327680    |
| train/                  |           |
|    approx_kl            | 0.2928313 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.02     |
|    explained_variance   | 0.42      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.626     |
|    n_updates            | 1590      |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.669     |
|    value_loss           | 1.21      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 529      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 161      |
|    time_elapsed         | 90763    |
|    total_timesteps      | 329728   |
| train/                  |          |
|    approx_kl            | 0.466234 |
|    clip_fraction        | 0.36     |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.98    |
|    explained_variance   | 0.0999   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.641    |
|    n_updates            | 1600     |
|    policy_gradient_loss | 0.00847  |
|    std                  | 0.668    |
|    value_loss           | 1.43     |
--------------------------------------
Eval num_timesteps=330000, episode_reward=-99.85 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.17724898 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 1610       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.671      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 526      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92769    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 531        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 92975      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.05872257 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | -0.000966  |
|    learning_rate        | 0.0003     |
|    loss                 | 856        |
|    n_updates            | 1620       |
|    policy_gradient_loss | 0.00147    |
|    std                  | 0.671      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 531        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 164        |
|    time_elapsed         | 93180      |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.06681712 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | -0.0518    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.766      |
|    n_updates            | 1630       |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.669      |
|    value_loss           | 1.76       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 547        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 165        |
|    time_elapsed         | 93385      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.13485448 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.654      |
|    n_updates            | 1640       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.67       |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 547        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 93591      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.06667773 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.292      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.511      |
|    n_updates            | 1650       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.667      |
|    value_loss           | 1.27       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.87 +/- 0.04
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.11960642 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.94      |
|    explained_variance   | 0.412      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.627      |
|    n_updates            | 1660       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.664      |
|    value_loss           | 1.19       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 555      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95597    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 574        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 168        |
|    time_elapsed         | 95802      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.04051453 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | -0.00187   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.96       |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.00129    |
|    std                  | 0.663      |
|    value_loss           | 1.03e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 574       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 169       |
|    time_elapsed         | 96007     |
|    total_timesteps      | 346112    |
| train/                  |           |
|    approx_kl            | 0.8970946 |
|    clip_fraction        | 0.355     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.9      |
|    explained_variance   | 0.598     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.448     |
|    n_updates            | 1680      |
|    policy_gradient_loss | -0.00928  |
|    std                  | 0.662     |
|    value_loss           | 1.62      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 590        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 170        |
|    time_elapsed         | 96213      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.07138746 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 1690       |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.658      |
|    value_loss           | 0.921      |
----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.88 +/- 0.04
Episode length: 3596.80 +/- 6.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.06905824 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | 0.369      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.708      |
|    n_updates            | 1700       |
|    policy_gradient_loss | 0.00499    |
|    std                  | 0.657      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 596      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98219    |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 596        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 172        |
|    time_elapsed         | 98425      |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.09884611 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.000394   |
|    learning_rate        | 0.0003     |
|    loss                 | 51.5       |
|    n_updates            | 1710       |
|    policy_gradient_loss | 0.00546    |
|    std                  | 0.655      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 614       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 173       |
|    time_elapsed         | 98631     |
|    total_timesteps      | 354304    |
| train/                  |           |
|    approx_kl            | 0.5112781 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.82     |
|    explained_variance   | 0.00201   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.784     |
|    n_updates            | 1720      |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.654     |
|    value_loss           | 1.57      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 614      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 174      |
|    time_elapsed         | 98836    |
|    total_timesteps      | 356352   |
| train/                  |          |
|    approx_kl            | 1.303108 |
|    clip_fraction        | 0.362    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.78    |
|    explained_variance   | 0.268    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.754    |
|    n_updates            | 1730     |
|    policy_gradient_loss | 0.045    |
|    std                  | 0.65     |
|    value_loss           | 1.12     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 626      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 175      |
|    time_elapsed         | 99042    |
|    total_timesteps      | 358400   |
| train/                  |          |
|    approx_kl            | 0.149528 |
|    clip_fraction        | 0.342    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.75    |
|    explained_variance   | 0.487    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.467    |
|    n_updates            | 1740     |
|    policy_gradient_loss | 0.0196   |
|    std                  | 0.648    |
|    value_loss           | 0.956    |
--------------------------------------
Eval num_timesteps=360000, episode_reward=-99.82 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.13389878 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 0.386      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.675      |
|    n_updates            | 1750       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.645      |
|    value_loss           | 1.22       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 632      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101048   |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 632        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 177        |
|    time_elapsed         | 101253     |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.05266419 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.71      |
|    explained_variance   | -6.27e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 510        |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.00289   |
|    std                  | 0.645      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 648        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 101459     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.33704728 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.0684     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.203      |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.636      |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 648        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 101664     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.15411934 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | 0.376      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.324      |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.00716    |
|    std                  | 0.638      |
|    value_loss           | 0.87       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 658        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 180        |
|    time_elapsed         | 101870     |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.25570482 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | 0.463      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.571      |
|    n_updates            | 1790       |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.636      |
|    value_loss           | 1.04       |
----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.90 +/- 0.06
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.067394435 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.56       |
|    explained_variance   | 0.478       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.482       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.00484     |
|    std                  | 0.632       |
|    value_loss           | 0.962       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 661      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103876   |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 661        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 182        |
|    time_elapsed         | 104081     |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.09849329 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | 0.00149    |
|    learning_rate        | 0.0003     |
|    loss                 | 637        |
|    n_updates            | 1810       |
|    policy_gradient_loss | 0.00825    |
|    std                  | 0.631      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 675        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 183        |
|    time_elapsed         | 104286     |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.18169543 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | 0.0123     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.0308     |
|    std                  | 0.627      |
|    value_loss           | 1.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 675        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 104492     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.03841492 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.46      |
|    explained_variance   | 0.476      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.352      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.624      |
|    value_loss           | 0.996      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 685        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 104697     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.18134093 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.43      |
|    explained_variance   | 0.441      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.569      |
|    n_updates            | 1840       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.623      |
|    value_loss           | 1.08       |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.91 +/- 0.03
Episode length: 3597.00 +/- 6.07
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.19278279 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.464      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.541      |
|    n_updates            | 1850       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.625      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 687      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106703   |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 687        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 187        |
|    time_elapsed         | 106910     |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.15164834 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.46      |
|    explained_variance   | 0.00182    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+03   |
|    n_updates            | 1860       |
|    policy_gradient_loss | -0.00337   |
|    std                  | 0.626      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 701       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 188       |
|    time_elapsed         | 107116    |
|    total_timesteps      | 385024    |
| train/                  |           |
|    approx_kl            | 0.3431459 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.45     |
|    explained_variance   | 0.03      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.835     |
|    n_updates            | 1870      |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.623     |
|    value_loss           | 1.42      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 701        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 189        |
|    time_elapsed         | 107321     |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.35808057 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.41      |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 1880       |
|    policy_gradient_loss | 0.00645    |
|    std                  | 0.62       |
|    value_loss           | 1.62       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 709        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 107527     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.30597264 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.69       |
|    n_updates            | 1890       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.619      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.88 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.041596267 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | 0.509       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 1900        |
|    policy_gradient_loss | 0.00858     |
|    std                  | 0.614       |
|    value_loss           | 1.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 709      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109533   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 709        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 109738     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.06661099 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | -0.00127   |
|    learning_rate        | 0.0003     |
|    loss                 | 299        |
|    n_updates            | 1910       |
|    policy_gradient_loss | 0.00505    |
|    std                  | 0.615      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 722        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 193        |
|    time_elapsed         | 109944     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.62250406 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | 0.00724    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.382      |
|    n_updates            | 1920       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.614      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 729        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 194        |
|    time_elapsed         | 110150     |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.20882878 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.648      |
|    n_updates            | 1930       |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.614      |
|    value_loss           | 1.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 729         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110355      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.050686434 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.42        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.518       |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.611       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.65 +/- 0.12
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 400000    |
| train/                  |           |
|    approx_kl            | 0.6721771 |
|    clip_fraction        | 0.348     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.28     |
|    explained_variance   | 0.467     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.37      |
|    n_updates            | 1950      |
|    policy_gradient_loss | 0.033     |
|    std                  | 0.613     |
|    value_loss           | 1.05      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 728      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112361   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 728        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 112567     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.15159565 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.3       |
|    explained_variance   | -0.000657  |
|    learning_rate        | 0.0003     |
|    loss                 | 9.08       |
|    n_updates            | 1960       |
|    policy_gradient_loss | 0.00276    |
|    std                  | 0.614      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 741       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 198       |
|    time_elapsed         | 112772    |
|    total_timesteps      | 405504    |
| train/                  |           |
|    approx_kl            | 1.8223002 |
|    clip_fraction        | 0.584     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.29     |
|    explained_variance   | 0.00134   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.521     |
|    n_updates            | 1970      |
|    policy_gradient_loss | 0.0893    |
|    std                  | 0.611     |
|    value_loss           | 1.48      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 747        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 112978     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07760599 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.27      |
|    explained_variance   | 0.399      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.466      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.61       |
|    value_loss           | 1.13       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 747        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 113183     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.50490904 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | 0.38       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.537      |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.0325     |
|    std                  | 0.609      |
|    value_loss           | 1.47       |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.80 +/- 0.12
Episode length: 3597.00 +/- 6.54
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.81234086 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.586      |
|    n_updates            | 2000       |
|    policy_gradient_loss | 0.294      |
|    std                  | 0.609      |
|    value_loss           | 0.841      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 747      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115189   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 759        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 115395     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.21230534 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | -0.000515  |
|    learning_rate        | 0.0003     |
|    loss                 | 26.5       |
|    n_updates            | 2010       |
|    policy_gradient_loss | 0.00812    |
|    std                  | 0.61       |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 759       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 203       |
|    time_elapsed         | 115600    |
|    total_timesteps      | 415744    |
| train/                  |           |
|    approx_kl            | 1.9489517 |
|    clip_fraction        | 0.321     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.27     |
|    explained_variance   | 0.943     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.562     |
|    n_updates            | 2020      |
|    policy_gradient_loss | 0.0454    |
|    std                  | 0.612     |
|    value_loss           | 1.37      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 764       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 204       |
|    time_elapsed         | 115805    |
|    total_timesteps      | 417792    |
| train/                  |           |
|    approx_kl            | 0.6339186 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.26     |
|    explained_variance   | -0.116    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.531     |
|    n_updates            | 2030      |
|    policy_gradient_loss | -0.000935 |
|    std                  | 0.609     |
|    value_loss           | 1.69      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 764        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 116011     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.05519413 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | 0.312      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.489      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.00167    |
|    std                  | 0.61       |
|    value_loss           | 1.61       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.85 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.100473985 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.478       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.614       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.0373      |
|    std                  | 0.605       |
|    value_loss           | 1.1         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 762      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118017   |
|    total_timesteps | 421888   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 774      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 207      |
|    time_elapsed         | 118223   |
|    total_timesteps      | 423936   |
| train/                  |          |
|    approx_kl            | 0.086604 |
|    clip_fraction        | 0.362    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.21    |
|    explained_variance   | 0.00023  |
|    learning_rate        | 0.0003   |
|    loss                 | 456      |
|    n_updates            | 2060     |
|    policy_gradient_loss | 0.006    |
|    std                  | 0.606    |
|    value_loss           | 1.05e+03 |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 774       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 208       |
|    time_elapsed         | 118428    |
|    total_timesteps      | 425984    |
| train/                  |           |
|    approx_kl            | 0.3976133 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.22     |
|    explained_variance   | 0.0146    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.685     |
|    n_updates            | 2070      |
|    policy_gradient_loss | 0.00177   |
|    std                  | 0.606     |
|    value_loss           | 1.26      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 779        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 118634     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.07195665 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.717      |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.606      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.89 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.36749387 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.812      |
|    n_updates            | 2090       |
|    policy_gradient_loss | 0.00312    |
|    std                  | 0.604      |
|    value_loss           | 1.7        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 777      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120640   |
|    total_timesteps | 430080   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 777        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 211        |
|    time_elapsed         | 120845     |
|    total_timesteps      | 432128     |
| train/                  |            |
|    approx_kl            | 0.01607288 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -0.00113   |
|    learning_rate        | 0.0003     |
|    loss                 | 101        |
|    n_updates            | 2100       |
|    policy_gradient_loss | -0.000958  |
|    std                  | 0.604      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 789        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 212        |
|    time_elapsed         | 121051     |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.40635663 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | 0.0596     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.747      |
|    n_updates            | 2110       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.6        |
|    value_loss           | 1.39       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 789         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121256      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.094092816 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.464       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.52        |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.0153      |
|    std                  | 0.604       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 794       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 214       |
|    time_elapsed         | 121461    |
|    total_timesteps      | 438272    |
| train/                  |           |
|    approx_kl            | 0.2450665 |
|    clip_fraction        | 0.346     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.19     |
|    explained_variance   | 0.522     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.567     |
|    n_updates            | 2130      |
|    policy_gradient_loss | 0.0147    |
|    std                  | 0.605     |
|    value_loss           | 0.938     |
---------------------------------------
Eval num_timesteps=440000, episode_reward=-99.93 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.30340594 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.557      |
|    n_updates            | 2140       |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.606      |
|    value_loss           | 1.25       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 792      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123467   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 792         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123673      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.014944392 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 0.0106      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.73        |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00213    |
|    std                  | 0.606       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 804       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 217       |
|    time_elapsed         | 123878    |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 0.1463966 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.17     |
|    explained_variance   | 0.369     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.481     |
|    n_updates            | 2160      |
|    policy_gradient_loss | 0.0372    |
|    std                  | 0.602     |
|    value_loss           | 1.3       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 804        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 124083     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.45709077 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.496      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.0649     |
|    std                  | 0.601      |
|    value_loss           | 0.992      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 809       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 219       |
|    time_elapsed         | 124289    |
|    total_timesteps      | 448512    |
| train/                  |           |
|    approx_kl            | 0.4678504 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.14     |
|    explained_variance   | 0.535     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.441     |
|    n_updates            | 2180      |
|    policy_gradient_loss | 0.0293    |
|    std                  | 0.601     |
|    value_loss           | 0.915     |
---------------------------------------
Eval num_timesteps=450000, episode_reward=-99.90 +/- 0.04
Episode length: 3599.60 +/- 2.33
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.057660278 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | 0.272       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.808       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.601       |
|    value_loss           | 1.42        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 806      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126295   |
|    total_timesteps | 450560   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 806       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 221       |
|    time_elapsed         | 126500    |
|    total_timesteps      | 452608    |
| train/                  |           |
|    approx_kl            | 0.0951156 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.13     |
|    explained_variance   | -6.35e-05 |
|    learning_rate        | 0.0003    |
|    loss                 | 506       |
|    n_updates            | 2200      |
|    policy_gradient_loss | 0.00863   |
|    std                  | 0.602     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 819       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 222       |
|    time_elapsed         | 126706    |
|    total_timesteps      | 454656    |
| train/                  |           |
|    approx_kl            | 1.8035781 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.14     |
|    explained_variance   | 0.00449   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.463     |
|    n_updates            | 2210      |
|    policy_gradient_loss | 0.00826   |
|    std                  | 0.602     |
|    value_loss           | 1.12      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 819        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 126911     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.19313297 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.1       |
|    explained_variance   | 0.461      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.6        |
|    n_updates            | 2220       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.598      |
|    value_loss           | 1.35       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 823       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 224       |
|    time_elapsed         | 127117    |
|    total_timesteps      | 458752    |
| train/                  |           |
|    approx_kl            | 0.1287423 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.09     |
|    explained_variance   | 0.498     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.478     |
|    n_updates            | 2230      |
|    policy_gradient_loss | 0.0279    |
|    std                  | 0.601     |
|    value_loss           | 0.969     |
---------------------------------------
Eval num_timesteps=460000, episode_reward=-99.92 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.09342828 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.511      |
|    n_updates            | 2240       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.599      |
|    value_loss           | 1.29       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 820      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129123   |
|    total_timesteps | 460800   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 820       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 226       |
|    time_elapsed         | 129328    |
|    total_timesteps      | 462848    |
| train/                  |           |
|    approx_kl            | 0.0765807 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.08     |
|    explained_variance   | -0.00195  |
|    learning_rate        | 0.0003    |
|    loss                 | 189       |
|    n_updates            | 2250      |
|    policy_gradient_loss | 0.00124   |
|    std                  | 0.6       |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 830       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 227       |
|    time_elapsed         | 129533    |
|    total_timesteps      | 464896    |
| train/                  |           |
|    approx_kl            | 1.6415083 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.09     |
|    explained_variance   | -0.0135   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.49      |
|    n_updates            | 2260      |
|    policy_gradient_loss | 0.0193    |
|    std                  | 0.6       |
|    value_loss           | 1.15      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 830        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 129739     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.09433232 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.658      |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.00121    |
|    std                  | 0.599      |
|    value_loss           | 1.54       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 833        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 129944     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.03832368 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.08      |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.458      |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.597      |
|    value_loss           | 1.07       |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.88 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.37982857 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.516      |
|    n_updates            | 2290       |
|    policy_gradient_loss | 0.00642    |
|    std                  | 0.597      |
|    value_loss           | 2.48       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 829      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131950   |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 829        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 231        |
|    time_elapsed         | 132156     |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.32278317 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.08      |
|    explained_variance   | 0.00283    |
|    learning_rate        | 0.0003     |
|    loss                 | 787        |
|    n_updates            | 2300       |
|    policy_gradient_loss | 0.0051     |
|    std                  | 0.601      |
|    value_loss           | 1.04e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 839      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 232      |
|    time_elapsed         | 132361   |
|    total_timesteps      | 475136   |
| train/                  |          |
|    approx_kl            | 2.417186 |
|    clip_fraction        | 0.402    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.12    |
|    explained_variance   | 0.0861   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.32     |
|    n_updates            | 2310     |
|    policy_gradient_loss | 0.000567 |
|    std                  | 0.601    |
|    value_loss           | 1.3      |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 839        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 132566     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.06671943 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | 0.447      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.687      |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.074      |
|    std                  | 0.6        |
|    value_loss           | 1.24       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 843       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 234       |
|    time_elapsed         | 132772    |
|    total_timesteps      | 479232    |
| train/                  |           |
|    approx_kl            | 0.5556575 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.07     |
|    explained_variance   | 0.484     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.379     |
|    n_updates            | 2330      |
|    policy_gradient_loss | 0.0305    |
|    std                  | 0.597     |
|    value_loss           | 1.07      |
---------------------------------------
Eval num_timesteps=480000, episode_reward=-99.78 +/- 0.10
Episode length: 3597.20 +/- 7.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.12217143 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.465      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.393      |
|    n_updates            | 2340       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.597      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 838      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134778   |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 838        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 236        |
|    time_elapsed         | 134984     |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.08717674 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.04      |
|    explained_variance   | 0.000339   |
|    learning_rate        | 0.0003     |
|    loss                 | 258        |
|    n_updates            | 2350       |
|    policy_gradient_loss | 0.00137    |
|    std                  | 0.597      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 849       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 237       |
|    time_elapsed         | 135189    |
|    total_timesteps      | 485376    |
| train/                  |           |
|    approx_kl            | 0.6443494 |
|    clip_fraction        | 0.311     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.04     |
|    explained_variance   | 0.0793    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.82      |
|    n_updates            | 2360      |
|    policy_gradient_loss | 0.00309   |
|    std                  | 0.597     |
|    value_loss           | 1.55      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 852        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 135395     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.41939074 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.03      |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.708      |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.595      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 852       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 239       |
|    time_elapsed         | 135600    |
|    total_timesteps      | 489472    |
| train/                  |           |
|    approx_kl            | 0.5465894 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7        |
|    explained_variance   | 0.42      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.666     |
|    n_updates            | 2380      |
|    policy_gradient_loss | 0.0177    |
|    std                  | 0.594     |
|    value_loss           | 1.38      |
---------------------------------------
Eval num_timesteps=490000, episode_reward=-99.66 +/- 0.19
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.32314268 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.683      |
|    n_updates            | 2390       |
|    policy_gradient_loss | 0.0369     |
|    std                  | 0.591      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 847      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137606   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 847        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 137812     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.09089348 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.000379   |
|    learning_rate        | 0.0003     |
|    loss                 | 750        |
|    n_updates            | 2400       |
|    policy_gradient_loss | 0.00443    |
|    std                  | 0.593      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 856        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 138017     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.17223871 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.99      |
|    explained_variance   | 0.0931     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.482      |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.592      |
|    value_loss           | 1.13       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 858        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 138222     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.14324106 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.28       |
|    n_updates            | 2420       |
|    policy_gradient_loss | -0.00395   |
|    std                  | 0.591      |
|    value_loss           | 2.68       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 858        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138428     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.16240509 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.347      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.822      |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.59       |
|    value_loss           | 1.45       |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.91 +/- 0.04
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 500000    |
| train/                  |           |
|    approx_kl            | 0.2351784 |
|    clip_fraction        | 0.385     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.91     |
|    explained_variance   | 0.445     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.622     |
|    n_updates            | 2440      |
|    policy_gradient_loss | 0.0339    |
|    std                  | 0.587     |
|    value_loss           | 1.32      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 853      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140434   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 862         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 140639      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.022938708 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | 0.0014      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.08        |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00102    |
|    std                  | 0.586       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 862       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 247       |
|    time_elapsed         | 140844    |
|    total_timesteps      | 505856    |
| train/                  |           |
|    approx_kl            | 0.8894108 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.87     |
|    explained_variance   | 0.295     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.772     |
|    n_updates            | 2460      |
|    policy_gradient_loss | 0.023     |
|    std                  | 0.585     |
|    value_loss           | 1.48      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 863       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 248       |
|    time_elapsed         | 141050    |
|    total_timesteps      | 507904    |
| train/                  |           |
|    approx_kl            | 0.5326194 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.87     |
|    explained_variance   | 0.398     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.712     |
|    n_updates            | 2470      |
|    policy_gradient_loss | 0.0521    |
|    std                  | 0.586     |
|    value_loss           | 1.44      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 863       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 249       |
|    time_elapsed         | 141255    |
|    total_timesteps      | 509952    |
| train/                  |           |
|    approx_kl            | 0.6055121 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.86     |
|    explained_variance   | 0.445     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.815     |
|    n_updates            | 2480      |
|    policy_gradient_loss | 0.0505    |
|    std                  | 0.584     |
|    value_loss           | 1.49      |
---------------------------------------
Eval num_timesteps=510000, episode_reward=-99.92 +/- 0.04
Episode length: 3595.80 +/- 7.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.41291505 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.82      |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.663      |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.0414     |
|    std                  | 0.581      |
|    value_loss           | 1.34       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 860      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143261   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 868        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 143467     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.20882425 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.00175    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.74e+03   |
|    n_updates            | 2500       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.583      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 868        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 143672     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.21216796 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.8       |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.757      |
|    n_updates            | 2510       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.58       |
|    value_loss           | 1.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 869        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 143877     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.26673105 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.74      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.703      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.575      |
|    value_loss           | 1.5        |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.92 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.049365036 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.994       |
|    n_updates            | 2530        |
|    policy_gradient_loss | 0.00898     |
|    std                  | 0.573       |
|    value_loss           | 2.23        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 863      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145883   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 863         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146089      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.093839385 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.68       |
|    explained_variance   | 0.00228     |
|    learning_rate        | 0.0003      |
|    loss                 | 152         |
|    n_updates            | 2540        |
|    policy_gradient_loss | 0.00413     |
|    std                  | 0.573       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 871       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 256       |
|    time_elapsed         | 146294    |
|    total_timesteps      | 524288    |
| train/                  |           |
|    approx_kl            | 0.9250828 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.66     |
|    explained_variance   | 0.00349   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.796     |
|    n_updates            | 2550      |
|    policy_gradient_loss | 0.0287    |
|    std                  | 0.57      |
|    value_loss           | 1.78      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 871       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 257       |
|    time_elapsed         | 146499    |
|    total_timesteps      | 526336    |
| train/                  |           |
|    approx_kl            | 0.2118757 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.61     |
|    explained_variance   | 0.347     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.588     |
|    n_updates            | 2560      |
|    policy_gradient_loss | 0.0227    |
|    std                  | 0.568     |
|    value_loss           | 1.94      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 871        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 146705     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.19391844 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.36       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.811      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.032      |
|    std                  | 0.567      |
|    value_loss           | 1.81       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.73 +/- 0.14
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.10910822 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | 0.35       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.962      |
|    n_updates            | 2580       |
|    policy_gradient_loss | 0.0264     |
|    std                  | 0.565      |
|    value_loss           | 2.04       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 864      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148711   |
|    total_timesteps | 530432   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 864       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 260       |
|    time_elapsed         | 148916    |
|    total_timesteps      | 532480    |
| train/                  |           |
|    approx_kl            | 0.1318754 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.55     |
|    explained_variance   | 0.00106   |
|    learning_rate        | 0.0003    |
|    loss                 | 444       |
|    n_updates            | 2590      |
|    policy_gradient_loss | 0.0197    |
|    std                  | 0.564     |
|    value_loss           | 1.05e+03  |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 871      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 261      |
|    time_elapsed         | 149122   |
|    total_timesteps      | 534528   |
| train/                  |          |
|    approx_kl            | 1.391337 |
|    clip_fraction        | 0.504    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.54    |
|    explained_variance   | -0.167   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.589    |
|    n_updates            | 2600     |
|    policy_gradient_loss | 0.0274   |
|    std                  | 0.565    |
|    value_loss           | 1.33     |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 871      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 262      |
|    time_elapsed         | 149327   |
|    total_timesteps      | 536576   |
| train/                  |          |
|    approx_kl            | 0.895836 |
|    clip_fraction        | 0.382    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.55    |
|    explained_variance   | 0.392    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.822    |
|    n_updates            | 2610     |
|    policy_gradient_loss | 0.0316   |
|    std                  | 0.566    |
|    value_loss           | 1.96     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 869         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 149534      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.057332084 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.55       |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.996       |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.0158      |
|    std                  | 0.565       |
|    value_loss           | 1.88        |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.93 +/- 0.04
Episode length: 3599.80 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.15252262 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.391      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.37       |
|    n_updates            | 2630       |
|    policy_gradient_loss | 0.0461     |
|    std                  | 0.566      |
|    value_loss           | 1.93       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 861      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151540   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 861        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 265        |
|    time_elapsed         | 151746     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.10141541 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.56      |
|    explained_variance   | -0.000117  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.22e+03   |
|    n_updates            | 2640       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.565      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 868       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 266       |
|    time_elapsed         | 151951    |
|    total_timesteps      | 544768    |
| train/                  |           |
|    approx_kl            | 2.6868718 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.52     |
|    explained_variance   | -0.0309   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.671     |
|    n_updates            | 2650      |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.561     |
|    value_loss           | 2.28      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 868       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 267       |
|    time_elapsed         | 152157    |
|    total_timesteps      | 546816    |
| train/                  |           |
|    approx_kl            | 0.5537126 |
|    clip_fraction        | 0.334     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.5      |
|    explained_variance   | 0.382     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.37      |
|    n_updates            | 2660      |
|    policy_gradient_loss | 0.00663   |
|    std                  | 0.561     |
|    value_loss           | 2.57      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 869         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 152362      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.050435603 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.47       |
|    explained_variance   | 0.406       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.874       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0136      |
|    std                  | 0.558       |
|    value_loss           | 2.13        |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.89 +/- 0.01
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.24629942 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.45      |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.29       |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.557      |
|    value_loss           | 2.9        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 863      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154368   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 863        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 270        |
|    time_elapsed         | 154573     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.03140659 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.45      |
|    explained_variance   | 0.00142    |
|    learning_rate        | 0.0003     |
|    loss                 | 15         |
|    n_updates            | 2690       |
|    policy_gradient_loss | 0.00271    |
|    std                  | 0.559      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 870       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 271       |
|    time_elapsed         | 154779    |
|    total_timesteps      | 555008    |
| train/                  |           |
|    approx_kl            | 1.1447797 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.48     |
|    explained_variance   | 0.0258    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.863     |
|    n_updates            | 2700      |
|    policy_gradient_loss | 0.00221   |
|    std                  | 0.56      |
|    value_loss           | 2.26      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 870       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 272       |
|    time_elapsed         | 154984    |
|    total_timesteps      | 557056    |
| train/                  |           |
|    approx_kl            | 0.0675394 |
|    clip_fraction        | 0.337     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.45     |
|    explained_variance   | 0.395     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.16      |
|    n_updates            | 2710      |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.556     |
|    value_loss           | 2.03      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 870         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 273         |
|    time_elapsed         | 155190      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.038344115 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.46       |
|    explained_variance   | 0.402       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.896       |
|    n_updates            | 2720        |
|    policy_gradient_loss | 0.0244      |
|    std                  | 0.56        |
|    value_loss           | 1.83        |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.96 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.17660958 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.45      |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.816      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.0242     |
|    std                  | 0.557      |
|    value_loss           | 1.56       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 864      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157196   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 864        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 157401     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.05459439 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | -0.00119   |
|    learning_rate        | 0.0003     |
|    loss                 | 135        |
|    n_updates            | 2740       |
|    policy_gradient_loss | 0.00598    |
|    std                  | 0.557      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 871        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 157607     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.31912166 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | -0.219     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.86       |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.556      |
|    value_loss           | 1.68       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 874       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 277       |
|    time_elapsed         | 157812    |
|    total_timesteps      | 567296    |
| train/                  |           |
|    approx_kl            | 0.7683989 |
|    clip_fraction        | 0.321     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.43     |
|    explained_variance   | 0.344     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.986     |
|    n_updates            | 2760      |
|    policy_gradient_loss | 0.00801   |
|    std                  | 0.557     |
|    value_loss           | 2.14      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 874      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 278      |
|    time_elapsed         | 158017   |
|    total_timesteps      | 569344   |
| train/                  |          |
|    approx_kl            | 0.228508 |
|    clip_fraction        | 0.38     |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.43    |
|    explained_variance   | 0.481    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.566    |
|    n_updates            | 2770     |
|    policy_gradient_loss | 0.0329   |
|    std                  | 0.556    |
|    value_loss           | 1.25     |
--------------------------------------
Eval num_timesteps=570000, episode_reward=-99.94 +/- 0.04
Episode length: 3597.40 +/- 6.71
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 570000    |
| train/                  |           |
|    approx_kl            | 1.1025023 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.43     |
|    explained_variance   | 0.433     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.921     |
|    n_updates            | 2780      |
|    policy_gradient_loss | 0.049     |
|    std                  | 0.557     |
|    value_loss           | 1.47      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 867      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160023   |
|    total_timesteps | 571392   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 867        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 280        |
|    time_elapsed         | 160229     |
|    total_timesteps      | 573440     |
| train/                  |            |
|    approx_kl            | 0.07594536 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0.00167    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.49e+03   |
|    n_updates            | 2790       |
|    policy_gradient_loss | 0.00648    |
|    std                  | 0.556      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 876       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 281       |
|    time_elapsed         | 160434    |
|    total_timesteps      | 575488    |
| train/                  |           |
|    approx_kl            | 0.6406699 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.4      |
|    explained_variance   | 0.131     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.655     |
|    n_updates            | 2800      |
|    policy_gradient_loss | 0.0299    |
|    std                  | 0.555     |
|    value_loss           | 1.5       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 878        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 160640     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.38346022 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.39      |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.449      |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.124      |
|    std                  | 0.555      |
|    value_loss           | 0.927      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 878        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 160845     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.18219711 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.41      |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.773      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.557      |
|    value_loss           | 1.48       |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.88 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.75514764 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.441      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.772      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.0336     |
|    std                  | 0.557      |
|    value_loss           | 1.45       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 874      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162851   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 884        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 285        |
|    time_elapsed         | 163057     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.19462109 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.000359   |
|    learning_rate        | 0.0003     |
|    loss                 | 213        |
|    n_updates            | 2840       |
|    policy_gradient_loss | 0.00972    |
|    std                  | 0.558      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 884       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 286       |
|    time_elapsed         | 163262    |
|    total_timesteps      | 585728    |
| train/                  |           |
|    approx_kl            | 2.8067267 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.44     |
|    explained_variance   | -0.0147   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.708     |
|    n_updates            | 2850      |
|    policy_gradient_loss | 0.0059    |
|    std                  | 0.558     |
|    value_loss           | 1.42      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 885        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163468     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.17754206 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0238     |
|    std                  | 0.556      |
|    value_loss           | 1.18       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 885        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 163673     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.15483016 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.87       |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0259     |
|    std                  | 0.557      |
|    value_loss           | 1.16       |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.70 +/- 0.18
Episode length: 3596.80 +/- 8.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.17952089 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.639      |
|    n_updates            | 2880       |
|    policy_gradient_loss | 0.0262     |
|    std                  | 0.558      |
|    value_loss           | 1.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 879      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165679   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 887         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 165884      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.060877997 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.44       |
|    explained_variance   | -0.00045    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.99e+03    |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.0014      |
|    std                  | 0.559       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 887      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 291      |
|    time_elapsed         | 166090   |
|    total_timesteps      | 595968   |
| train/                  |          |
|    approx_kl            | 1.462023 |
|    clip_fraction        | 0.413    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.46    |
|    explained_variance   | 0.0248   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.649    |
|    n_updates            | 2900     |
|    policy_gradient_loss | 0.00813  |
|    std                  | 0.562    |
|    value_loss           | 1.41     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 889        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 166295     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.43573642 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.47      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.505      |
|    n_updates            | 2910       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.562      |
|    value_loss           | 1.34       |
----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.87 +/- 0.06
Episode length: 3597.80 +/- 5.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.26006934 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.5       |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.796      |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.564      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 883      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168301   |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 883        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 294        |
|    time_elapsed         | 168507     |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.11562936 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.51      |
|    explained_variance   | -0.00128   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+03   |
|    n_updates            | 2930       |
|    policy_gradient_loss | 0.00824    |
|    std                  | 0.566      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 891      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 295      |
|    time_elapsed         | 168712   |
|    total_timesteps      | 604160   |
| train/                  |          |
|    approx_kl            | 5.072772 |
|    clip_fraction        | 0.502    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.57    |
|    explained_variance   | -0.0609  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.632    |
|    n_updates            | 2940     |
|    policy_gradient_loss | 0.00786  |
|    std                  | 0.568    |
|    value_loss           | 1.65     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 891        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 168917     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.73165536 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.54      |
|    explained_variance   | 0.399      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04       |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.00301    |
|    std                  | 0.565      |
|    value_loss           | 2.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 892        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 169123     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.03868341 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.5       |
|    explained_variance   | 0.447      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.658      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.00258    |
|    std                  | 0.562      |
|    value_loss           | 1.38       |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.040890552 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.48       |
|    explained_variance   | 0.675       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.00869     |
|    std                  | 0.562       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 884      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171130   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 884         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 171335      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.011128226 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.48       |
|    explained_variance   | -0.000444   |
|    learning_rate        | 0.0003      |
|    loss                 | 271         |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00497    |
|    std                  | 0.562       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 892        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171541     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.08289583 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.48      |
|    explained_variance   | 0.2        |
|    learning_rate        | 0.0003     |
|    loss                 | 0.562      |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.00477    |
|    std                  | 0.563      |
|    value_loss           | 1.58       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 892         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 171747      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.045555685 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.49       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.00363     |
|    std                  | 0.563       |
|    value_loss           | 1.77        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 893        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 171953     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.14556128 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.5       |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.537      |
|    n_updates            | 3010       |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.564      |
|    value_loss           | 1.3        |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.52 +/- 0.81
Episode length: 3599.80 +/- 1.47
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 620000    |
| train/                  |           |
|    approx_kl            | 1.1224574 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.5      |
|    explained_variance   | 0.568     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.77      |
|    n_updates            | 3020      |
|    policy_gradient_loss | 0.0206    |
|    std                  | 0.564     |
|    value_loss           | 1.29      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 886      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 173959   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 886        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 174165     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.26029262 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | 0.00232    |
|    learning_rate        | 0.0003     |
|    loss                 | 59.8       |
|    n_updates            | 3030       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.562      |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 895       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 174370    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 3.8981953 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.46     |
|    explained_variance   | -0.0112   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.645     |
|    n_updates            | 3040      |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.561     |
|    value_loss           | 1.8       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 895        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 174576     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.71224463 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.46      |
|    explained_variance   | 0.422      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.903      |
|    n_updates            | 3050       |
|    policy_gradient_loss | 0.0272     |
|    std                  | 0.562      |
|    value_loss           | 1.4        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 897       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 307       |
|    time_elapsed         | 174781    |
|    total_timesteps      | 628736    |
| train/                  |           |
|    approx_kl            | 1.0209236 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.45     |
|    explained_variance   | 0.485     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.373     |
|    n_updates            | 3060      |
|    policy_gradient_loss | 0.0318    |
|    std                  | 0.561     |
|    value_loss           | 1.11      |
---------------------------------------
Eval num_timesteps=630000, episode_reward=-99.90 +/- 0.05
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.05213075 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.44      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.805      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.56       |
|    value_loss           | 1.53       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 890      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176787   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 890        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 176992     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.10532581 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.41      |
|    explained_variance   | -0.00078   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.51e+03   |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00522    |
|    std                  | 0.559      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 898      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 310      |
|    time_elapsed         | 177198   |
|    total_timesteps      | 634880   |
| train/                  |          |
|    approx_kl            | 3.79355  |
|    clip_fraction        | 0.395    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.39    |
|    explained_variance   | -0.0115  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.692    |
|    n_updates            | 3090     |
|    policy_gradient_loss | 0.0118   |
|    std                  | 0.557    |
|    value_loss           | 1.52     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 898         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 177403      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.056310162 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.34       |
|    explained_variance   | 0.361       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.854       |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.551       |
|    value_loss           | 2           |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 898       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 312       |
|    time_elapsed         | 177609    |
|    total_timesteps      | 638976    |
| train/                  |           |
|    approx_kl            | 0.7940018 |
|    clip_fraction        | 0.328     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.29     |
|    explained_variance   | 0.394     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.902     |
|    n_updates            | 3110      |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.55      |
|    value_loss           | 2.05      |
---------------------------------------
Eval num_timesteps=640000, episode_reward=-99.93 +/- 0.05
Episode length: 3597.60 +/- 5.43
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.15240398 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.38       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.96       |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.55       |
|    value_loss           | 2.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 891      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179618   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 891         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 179825      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.017376918 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.29       |
|    explained_variance   | 4.71e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 763         |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00125    |
|    std                  | 0.551       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 898        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 315        |
|    time_elapsed         | 180031     |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.16625711 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.29      |
|    explained_variance   | 0.308      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.63       |
|    n_updates            | 3140       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.551      |
|    value_loss           | 2.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 898        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 180236     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.31247383 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 0.273      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03       |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.549      |
|    value_loss           | 2.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 898        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 180442     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.25213677 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.21      |
|    explained_variance   | 0.391      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53       |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.027      |
|    std                  | 0.546      |
|    value_loss           | 2.22       |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.92 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 650000    |
| train/                  |           |
|    approx_kl            | 0.4940152 |
|    clip_fraction        | 0.309     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.15     |
|    explained_variance   | 0.379     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.966     |
|    n_updates            | 3170      |
|    policy_gradient_loss | 0.0096    |
|    std                  | 0.541     |
|    value_loss           | 2.31      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 891      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182447   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 891        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 319        |
|    time_elapsed         | 182653     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.30281597 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.12      |
|    explained_variance   | 0.000897   |
|    learning_rate        | 0.0003     |
|    loss                 | 9.34       |
|    n_updates            | 3180       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.54       |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 899       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 320       |
|    time_elapsed         | 182859    |
|    total_timesteps      | 655360    |
| train/                  |           |
|    approx_kl            | 3.1136293 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.08     |
|    explained_variance   | -0.000298 |
|    learning_rate        | 0.0003    |
|    loss                 | 1.45      |
|    n_updates            | 3190      |
|    policy_gradient_loss | 0.0251    |
|    std                  | 0.536     |
|    value_loss           | 2.31      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 897        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 183064     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.08015469 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.04      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08       |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.00272   |
|    std                  | 0.536      |
|    value_loss           | 3.13       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 897        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183270     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.06353317 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.364      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.29       |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.536      |
|    value_loss           | 2.79       |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.69 +/- 0.14
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.05596464 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.04      |
|    explained_variance   | 0.332      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.2        |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.0311     |
|    std                  | 0.538      |
|    value_loss           | 2.94       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 889      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185276   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 889         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 185481      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.023699835 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.05       |
|    explained_variance   | 0.00223     |
|    learning_rate        | 0.0003      |
|    loss                 | 10.4        |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.000701   |
|    std                  | 0.538       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 896       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 325       |
|    time_elapsed         | 185686    |
|    total_timesteps      | 665600    |
| train/                  |           |
|    approx_kl            | 1.4491758 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.05     |
|    explained_variance   | -0.0249   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.47      |
|    n_updates            | 3240      |
|    policy_gradient_loss | 0.00722   |
|    std                  | 0.537     |
|    value_loss           | 2.49      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 898         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 326         |
|    time_elapsed         | 185892      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.064059585 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.25        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 3250        |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.537       |
|    value_loss           | 2.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 898         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 327         |
|    time_elapsed         | 186097      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.092356786 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.788       |
|    n_updates            | 3260        |
|    policy_gradient_loss | 0.0492      |
|    std                  | 0.538       |
|    value_loss           | 2.14        |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.79 +/- 0.19
Episode length: 3595.00 +/- 8.65
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 670000   |
| train/                  |          |
|    approx_kl            | 0.517665 |
|    clip_fraction        | 0.376    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.04    |
|    explained_variance   | 0.348    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.889    |
|    n_updates            | 3270     |
|    policy_gradient_loss | 0.0206   |
|    std                  | 0.535    |
|    value_loss           | 1.97     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 893      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188105   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 904        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 188311     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.24437073 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | -0.000383  |
|    learning_rate        | 0.0003     |
|    loss                 | 7.18       |
|    n_updates            | 3280       |
|    policy_gradient_loss | 0.00743    |
|    std                  | 0.537      |
|    value_loss           | 1.07e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 904       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 330       |
|    time_elapsed         | 188516    |
|    total_timesteps      | 675840    |
| train/                  |           |
|    approx_kl            | 1.2087339 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.05     |
|    explained_variance   | 0.611     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.26      |
|    n_updates            | 3290      |
|    policy_gradient_loss | 0.00724   |
|    std                  | 0.537     |
|    value_loss           | 2.07      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 908        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188721     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.06548618 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.394      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.561      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.539      |
|    value_loss           | 1.49       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 908        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 188927     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.08789932 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.07      |
|    explained_variance   | 0.393      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.624      |
|    n_updates            | 3310       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.537      |
|    value_loss           | 1.36       |
----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.91 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.15319537 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.331      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.826      |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.54       |
|    value_loss           | 1.69       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 903      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190933   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 913        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 191138     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.09169866 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.09      |
|    explained_variance   | 0.00245    |
|    learning_rate        | 0.0003     |
|    loss                 | 393        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.539      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 913        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 191344     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.40248922 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.06      |
|    explained_variance   | 0.0464     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.892      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.243      |
|    std                  | 0.537      |
|    value_loss           | 2.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 915        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 191549     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.03242396 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.863      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.000326   |
|    std                  | 0.537      |
|    value_loss           | 1.98       |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.91 +/- 0.04
Episode length: 3596.00 +/- 10.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 690000    |
| train/                  |           |
|    approx_kl            | 0.1416947 |
|    clip_fraction        | 0.265     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.04     |
|    explained_variance   | 0.332     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.625     |
|    n_updates            | 3360      |
|    policy_gradient_loss | 0.00759   |
|    std                  | 0.535     |
|    value_loss           | 1.74      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 910      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193555   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 910         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 193761      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.050772414 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.03       |
|    explained_variance   | 0.00012     |
|    learning_rate        | 0.0003      |
|    loss                 | 19.1        |
|    n_updates            | 3370        |
|    policy_gradient_loss | 0.00032     |
|    std                  | 0.536       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 917      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 339      |
|    time_elapsed         | 193966   |
|    total_timesteps      | 694272   |
| train/                  |          |
|    approx_kl            | 4.66512  |
|    clip_fraction        | 0.431    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.99    |
|    explained_variance   | 0.00274  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.718    |
|    n_updates            | 3380     |
|    policy_gradient_loss | -0.00629 |
|    std                  | 0.529    |
|    value_loss           | 1.7      |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 917         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 194171      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.024866354 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.94       |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16        |
|    n_updates            | 3390        |
|    policy_gradient_loss | 0.00475     |
|    std                  | 0.529       |
|    value_loss           | 2.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 915         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 194377      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.060786508 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.92       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.31        |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.0204      |
|    std                  | 0.528       |
|    value_loss           | 2.4         |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.85 +/- 0.04
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.036154646 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.9        |
|    explained_variance   | 0.21        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3         |
|    n_updates            | 3410        |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.526       |
|    value_loss           | 1.92        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 906      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196385   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 906         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 196590      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.056431036 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.88       |
|    explained_variance   | -0.000388   |
|    learning_rate        | 0.0003      |
|    loss                 | 12.6        |
|    n_updates            | 3420        |
|    policy_gradient_loss | 0.00756     |
|    std                  | 0.525       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 913       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 344       |
|    time_elapsed         | 196796    |
|    total_timesteps      | 704512    |
| train/                  |           |
|    approx_kl            | 2.8517609 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.85     |
|    explained_variance   | 0.0399    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.969     |
|    n_updates            | 3430      |
|    policy_gradient_loss | 0.0236    |
|    std                  | 0.523     |
|    value_loss           | 2.05      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 913        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 197001     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.05430196 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.639      |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.521      |
|    value_loss           | 2          |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 914       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 346       |
|    time_elapsed         | 197206    |
|    total_timesteps      | 708608    |
| train/                  |           |
|    approx_kl            | 0.2881164 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.79     |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.27      |
|    n_updates            | 3450      |
|    policy_gradient_loss | 0.0152    |
|    std                  | 0.52      |
|    value_loss           | 2.13      |
---------------------------------------
Eval num_timesteps=710000, episode_reward=-99.89 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.048524812 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.76       |
|    explained_variance   | 0.0996      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41        |
|    n_updates            | 3460        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.519       |
|    value_loss           | 2.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 908      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199212   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 908         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 199418      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.011968651 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.75       |
|    explained_variance   | 0.00145     |
|    learning_rate        | 0.0003      |
|    loss                 | 773         |
|    n_updates            | 3470        |
|    policy_gradient_loss | -0.00173    |
|    std                  | 0.519       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 917       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 349       |
|    time_elapsed         | 199624    |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 1.7759311 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.71     |
|    explained_variance   | 0.345     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.825     |
|    n_updates            | 3480      |
|    policy_gradient_loss | 0.0281    |
|    std                  | 0.514     |
|    value_loss           | 1.75      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 917        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 199831     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.32619157 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.66      |
|    explained_variance   | 0.394      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.939      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.0323     |
|    std                  | 0.513      |
|    value_loss           | 2.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 918        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 200036     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.86509717 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.63      |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.24       |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.512      |
|    value_loss           | 1.83       |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.88 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.051353212 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.62       |
|    explained_variance   | 0.379       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11        |
|    n_updates            | 3510        |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.509       |
|    value_loss           | 1.94        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 912      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202042   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 912        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 202247     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.41261238 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.59      |
|    explained_variance   | 0.00169    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.36       |
|    n_updates            | 3520       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.508      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 921       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 202453    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 1.4331167 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.59     |
|    explained_variance   | 0.00206   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.907     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.028     |
|    std                  | 0.509     |
|    value_loss           | 2.24      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 921        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 202658     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.24389741 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.59      |
|    explained_variance   | 0.369      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.76       |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.509      |
|    value_loss           | 1.99       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 923        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 202864     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.14241621 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.58      |
|    explained_variance   | 0.386      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05       |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.508      |
|    value_loss           | 1.69       |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.86 +/- 0.07
Episode length: 3596.60 +/- 8.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.07061358 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.54      |
|    explained_variance   | 0.352      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.992      |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.00945    |
|    std                  | 0.505      |
|    value_loss           | 1.99       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 918      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204871   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 918        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 358        |
|    time_elapsed         | 205077     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.09624547 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.51      |
|    explained_variance   | -0.00166   |
|    learning_rate        | 0.0003     |
|    loss                 | 838        |
|    n_updates            | 3570       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.504      |
|    value_loss           | 1.07e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 929       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 359       |
|    time_elapsed         | 205282    |
|    total_timesteps      | 735232    |
| train/                  |           |
|    approx_kl            | 0.2588422 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.49     |
|    explained_variance   | 0.00391   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.06      |
|    n_updates            | 3580      |
|    policy_gradient_loss | 0.0152    |
|    std                  | 0.502     |
|    value_loss           | 2.1       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 932        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 205488     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.13127598 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.47      |
|    explained_variance   | 0.319      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.824      |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.00873    |
|    std                  | 0.502      |
|    value_loss           | 1.87       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 932        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 205693     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.21077164 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.871      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.501      |
|    value_loss           | 1.39       |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.98 +/- 0.03
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.05050578 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.44      |
|    explained_variance   | 0.345      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06       |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.498      |
|    value_loss           | 1.87       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 927      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207699   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 927         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 207904      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.032968633 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.42       |
|    explained_variance   | 0.00219     |
|    learning_rate        | 0.0003      |
|    loss                 | 51.6        |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.000575   |
|    std                  | 0.499       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 937       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 364       |
|    time_elapsed         | 208110    |
|    total_timesteps      | 745472    |
| train/                  |           |
|    approx_kl            | 1.5357721 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.4      |
|    explained_variance   | 0.0273    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.91      |
|    n_updates            | 3630      |
|    policy_gradient_loss | 0.03      |
|    std                  | 0.497     |
|    value_loss           | 1.76      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 939       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 365       |
|    time_elapsed         | 208315    |
|    total_timesteps      | 747520    |
| train/                  |           |
|    approx_kl            | 1.8844409 |
|    clip_fraction        | 0.355     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.4      |
|    explained_variance   | 0.504     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.702     |
|    n_updates            | 3640      |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.497     |
|    value_loss           | 1.57      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 939        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 208521     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.08296947 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.355      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.724      |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.00956    |
|    std                  | 0.494      |
|    value_loss           | 1.52       |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.91 +/- 0.03
Episode length: 3595.60 +/- 10.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.15769833 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.51       |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.492      |
|    value_loss           | 1.03       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 934      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210527   |
|    total_timesteps | 751616   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 942       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 368       |
|    time_elapsed         | 210732    |
|    total_timesteps      | 753664    |
| train/                  |           |
|    approx_kl            | 0.1809393 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.34     |
|    explained_variance   | 0.00123   |
|    learning_rate        | 0.0003    |
|    loss                 | 12.8      |
|    n_updates            | 3670      |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.493     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 942       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 369       |
|    time_elapsed         | 210937    |
|    total_timesteps      | 755712    |
| train/                  |           |
|    approx_kl            | 4.2396374 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.36     |
|    explained_variance   | 0.116     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.664     |
|    n_updates            | 3680      |
|    policy_gradient_loss | 0.00862   |
|    std                  | 0.492     |
|    value_loss           | 1.33      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 943        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 211143     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.38831267 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.995      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.0288     |
|    std                  | 0.493      |
|    value_loss           | 1.32       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 943        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 211349     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.13032366 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.352      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.708      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.491      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.93 +/- 0.05
Episode length: 3598.40 +/- 5.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 760000    |
| train/                  |           |
|    approx_kl            | 1.9646156 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.36     |
|    explained_variance   | 0.533     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.418     |
|    n_updates            | 3710      |
|    policy_gradient_loss | 0.0236    |
|    std                  | 0.492     |
|    value_loss           | 1.02      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 936      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213357   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 213562     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.15861726 |
|    clip_fraction        | 0.225      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.36      |
|    explained_variance   | -0.000192  |
|    learning_rate        | 0.0003     |
|    loss                 | 6.97       |
|    n_updates            | 3720       |
|    policy_gradient_loss | 0.00487    |
|    std                  | 0.492      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 944       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 374       |
|    time_elapsed         | 213767    |
|    total_timesteps      | 765952    |
| train/                  |           |
|    approx_kl            | 1.6782761 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.35     |
|    explained_variance   | 0.255     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.59      |
|    n_updates            | 3730      |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.491     |
|    value_loss           | 1.39      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 213973     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.24811839 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.945      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.489      |
|    value_loss           | 1.51       |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.91 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.120763935 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.29       |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.797       |
|    n_updates            | 3750        |
|    policy_gradient_loss | 0.0262      |
|    std                  | 0.489       |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 215979   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 937         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216185      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.014849841 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.29       |
|    explained_variance   | -0.000643   |
|    learning_rate        | 0.0003      |
|    loss                 | 842         |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.000237   |
|    std                  | 0.489       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 216390     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.28260982 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.27      |
|    explained_variance   | 0.446      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.831      |
|    n_updates            | 3770       |
|    policy_gradient_loss | 0.0357     |
|    std                  | 0.486      |
|    value_loss           | 1.23       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 216597     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.19218436 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.26      |
|    explained_variance   | 0.278      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.785      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.487      |
|    value_loss           | 1.58       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 945      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 380      |
|    time_elapsed         | 216803   |
|    total_timesteps      | 778240   |
| train/                  |          |
|    approx_kl            | 0.150361 |
|    clip_fraction        | 0.411    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.24    |
|    explained_variance   | 0.395    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.679    |
|    n_updates            | 3790     |
|    policy_gradient_loss | 0.0334   |
|    std                  | 0.487    |
|    value_loss           | 1.61     |
--------------------------------------
Eval num_timesteps=780000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.12202287 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.23      |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.856      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.0384     |
|    std                  | 0.486      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 938      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218809   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 938        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 219014     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.19981152 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.23      |
|    explained_variance   | 0.000291   |
|    learning_rate        | 0.0003     |
|    loss                 | 10.3       |
|    n_updates            | 3810       |
|    policy_gradient_loss | 0.00206    |
|    std                  | 0.486      |
|    value_loss           | 1.04e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 946      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 383      |
|    time_elapsed         | 219220   |
|    total_timesteps      | 784384   |
| train/                  |          |
|    approx_kl            | 3.225965 |
|    clip_fraction        | 0.484    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.24    |
|    explained_variance   | 0.0254   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.44     |
|    n_updates            | 3820     |
|    policy_gradient_loss | 0.0153   |
|    std                  | 0.488    |
|    value_loss           | 1.42     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 946        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 219425     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.72800434 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.23      |
|    explained_variance   | 0.491      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.609      |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.0278     |
|    std                  | 0.486      |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 946        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 219631     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.36070973 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.23      |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.619      |
|    n_updates            | 3840       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.486      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.92 +/- 0.04
Episode length: 3597.40 +/- 7.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 790000    |
| train/                  |           |
|    approx_kl            | 1.3696856 |
|    clip_fraction        | 0.294     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.22     |
|    explained_variance   | 0.4       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.804     |
|    n_updates            | 3850      |
|    policy_gradient_loss | 0.0267    |
|    std                  | 0.487     |
|    value_loss           | 1.37      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 938      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221637   |
|    total_timesteps | 790528   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 938       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 387       |
|    time_elapsed         | 221843    |
|    total_timesteps      | 792576    |
| train/                  |           |
|    approx_kl            | 0.2685889 |
|    clip_fraction        | 0.259     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.22     |
|    explained_variance   | 0.00148   |
|    learning_rate        | 0.0003    |
|    loss                 | 637       |
|    n_updates            | 3860      |
|    policy_gradient_loss | 0.000858  |
|    std                  | 0.486     |
|    value_loss           | 1.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 222048     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.23803246 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.2       |
|    explained_variance   | 0.472      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.52       |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.484      |
|    value_loss           | 0.95       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 222253     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.22443342 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.19      |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.751      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.486      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 944       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 390       |
|    time_elapsed         | 222459    |
|    total_timesteps      | 798720    |
| train/                  |           |
|    approx_kl            | 1.0846138 |
|    clip_fraction        | 0.321     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.19     |
|    explained_variance   | 0.439     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.522     |
|    n_updates            | 3890      |
|    policy_gradient_loss | 0.0171    |
|    std                  | 0.484     |
|    value_loss           | 1.03      |
---------------------------------------
Eval num_timesteps=800000, episode_reward=-99.92 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.10823642 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.15      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.647      |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.481      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224468   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 937        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 224675     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.41317934 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.12      |
|    explained_variance   | 0.00113    |
|    learning_rate        | 0.0003     |
|    loss                 | 41.5       |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.0025     |
|    std                  | 0.48       |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 944       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 393       |
|    time_elapsed         | 224881    |
|    total_timesteps      | 804864    |
| train/                  |           |
|    approx_kl            | 0.5301282 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.11     |
|    explained_variance   | 0.00104   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.634     |
|    n_updates            | 3920      |
|    policy_gradient_loss | 0.00365   |
|    std                  | 0.48      |
|    value_loss           | 1.38      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 225086     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.25402242 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.709      |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.00962    |
|    std                  | 0.48       |
|    value_loss           | 1.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 225291     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.81354517 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.11      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.582      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0435     |
|    std                  | 0.48       |
|    value_loss           | 1.21       |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.88 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.03366202 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.669      |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.479      |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227298   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 937         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 397         |
|    time_elapsed         | 227503      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.021205384 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.09       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.16e+03    |
|    n_updates            | 3960        |
|    policy_gradient_loss | 0.00295     |
|    std                  | 0.479       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 943        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 227708     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.53107345 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.08      |
|    explained_variance   | 0.395      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.625      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.478      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 943       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 399       |
|    time_elapsed         | 227914    |
|    total_timesteps      | 817152    |
| train/                  |           |
|    approx_kl            | 3.8851647 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.06     |
|    explained_variance   | 0.492     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.446     |
|    n_updates            | 3980      |
|    policy_gradient_loss | 0.0519    |
|    std                  | 0.478     |
|    value_loss           | 0.946     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 942       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 400       |
|    time_elapsed         | 228119    |
|    total_timesteps      | 819200    |
| train/                  |           |
|    approx_kl            | 1.9611471 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.06     |
|    explained_variance   | 0.464     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.706     |
|    n_updates            | 3990      |
|    policy_gradient_loss | 0.0306    |
|    std                  | 0.478     |
|    value_loss           | 1.18      |
---------------------------------------
Eval num_timesteps=820000, episode_reward=-99.50 +/- 0.85
Episode length: 3597.20 +/- 6.21
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 820000    |
| train/                  |           |
|    approx_kl            | 0.9829395 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.02     |
|    explained_variance   | 0.268     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.716     |
|    n_updates            | 4000      |
|    policy_gradient_loss | 0.0241    |
|    std                  | 0.476     |
|    value_loss           | 1.24      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 935      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230125   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 935        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 230331     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.49375504 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.01      |
|    explained_variance   | 0.00356    |
|    learning_rate        | 0.0003     |
|    loss                 | 23         |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.00724    |
|    std                  | 0.476      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 943         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 403         |
|    time_elapsed         | 230536      |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.073755056 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.98       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.609       |
|    n_updates            | 4020        |
|    policy_gradient_loss | 0.0343      |
|    std                  | 0.474       |
|    value_loss           | 1.32        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 230741     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.27438596 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.97      |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.16       |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0522     |
|    std                  | 0.475      |
|    value_loss           | 2.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 230947     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.08941767 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.95      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.677      |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.474      |
|    value_loss           | 2.82       |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.89 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.32911953 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.94      |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.581      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.474      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 936      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 232955   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 936        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233160     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.36276346 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.93      |
|    explained_variance   | -0.000351  |
|    learning_rate        | 0.0003     |
|    loss                 | 24.4       |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.0087     |
|    std                  | 0.474      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 944       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 408       |
|    time_elapsed         | 233366    |
|    total_timesteps      | 835584    |
| train/                  |           |
|    approx_kl            | 3.7418928 |
|    clip_fraction        | 0.532     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.93     |
|    explained_variance   | 0.00504   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.598     |
|    n_updates            | 4070      |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.472     |
|    value_loss           | 1.25      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 233571     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.17043819 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.89      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.776      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.471      |
|    value_loss           | 1.5        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 944       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 410       |
|    time_elapsed         | 233777    |
|    total_timesteps      | 839680    |
| train/                  |           |
|    approx_kl            | 0.3667683 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.86     |
|    explained_variance   | 0.336     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.899     |
|    n_updates            | 4090      |
|    policy_gradient_loss | 0.0247    |
|    std                  | 0.471     |
|    value_loss           | 1.55      |
---------------------------------------
Eval num_timesteps=840000, episode_reward=-99.87 +/- 0.05
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 840000    |
| train/                  |           |
|    approx_kl            | 0.6340046 |
|    clip_fraction        | 0.312     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.84     |
|    explained_variance   | 0.381     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.735     |
|    n_updates            | 4100      |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.469     |
|    value_loss           | 1.52      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235783   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 944        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 235988     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.67145216 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.82      |
|    explained_variance   | 0.000151   |
|    learning_rate        | 0.0003     |
|    loss                 | 85.5       |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.468      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 944       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 413       |
|    time_elapsed         | 236193    |
|    total_timesteps      | 845824    |
| train/                  |           |
|    approx_kl            | 1.7473803 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.79     |
|    explained_variance   | 0.0227    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.715     |
|    n_updates            | 4120      |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.467     |
|    value_loss           | 1.65      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 945       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 414       |
|    time_elapsed         | 236399    |
|    total_timesteps      | 847872    |
| train/                  |           |
|    approx_kl            | 0.3178871 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.77     |
|    explained_variance   | 0.473     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.513     |
|    n_updates            | 4130      |
|    policy_gradient_loss | 0.0251    |
|    std                  | 0.469     |
|    value_loss           | 1.25      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 945       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 415       |
|    time_elapsed         | 236604    |
|    total_timesteps      | 849920    |
| train/                  |           |
|    approx_kl            | 0.5269024 |
|    clip_fraction        | 0.332     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.77     |
|    explained_variance   | 0.496     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.662     |
|    n_updates            | 4140      |
|    policy_gradient_loss | 0.0553    |
|    std                  | 0.468     |
|    value_loss           | 1.22      |
---------------------------------------
Eval num_timesteps=850000, episode_reward=-99.88 +/- 0.04
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.041594423 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.75       |
|    explained_variance   | 0.46        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.507       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.0227      |
|    std                  | 0.467       |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238610   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 238816     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.04993073 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.75      |
|    explained_variance   | -0.00152   |
|    learning_rate        | 0.0003     |
|    loss                 | 805        |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.00744    |
|    std                  | 0.467      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 945       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 239021    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 0.3315035 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.74     |
|    explained_variance   | 0.35      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.739     |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.467     |
|    value_loss           | 1.44      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 945       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 419       |
|    time_elapsed         | 239226    |
|    total_timesteps      | 858112    |
| train/                  |           |
|    approx_kl            | 0.0740906 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.74     |
|    explained_variance   | 0.53      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.574     |
|    n_updates            | 4180      |
|    policy_gradient_loss | 0.0319    |
|    std                  | 0.466     |
|    value_loss           | 0.927     |
---------------------------------------
Eval num_timesteps=860000, episode_reward=-99.92 +/- 0.02
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.8657372 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.74     |
|    explained_variance   | 0.299     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.426     |
|    n_updates            | 4190      |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.465     |
|    value_loss           | 1.13      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 937      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241235   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 937        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 241441     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.08711692 |
|    clip_fraction        | 0.172      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.72      |
|    explained_variance   | 0.000542   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.93e+03   |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.000162   |
|    std                  | 0.464      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 241647     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.09022578 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.73      |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.584      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.465      |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 241852     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.12794282 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.71      |
|    explained_variance   | 0.51       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.385      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.463      |
|    value_loss           | 1.1        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 945        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 242058     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.15930754 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.67      |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.562      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0325     |
|    std                  | 0.46       |
|    value_loss           | 1.21       |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.88 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.14121269 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.66      |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.596      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.461      |
|    value_loss           | 1.04       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 940      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244064   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 940         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 426         |
|    time_elapsed         | 244269      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.025853738 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.67       |
|    explained_variance   | -6.82e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 125         |
|    n_updates            | 4250        |
|    policy_gradient_loss | 0.00287     |
|    std                  | 0.461       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 948       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 427       |
|    time_elapsed         | 244474    |
|    total_timesteps      | 874496    |
| train/                  |           |
|    approx_kl            | 0.8713933 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.66     |
|    explained_variance   | 0.0121    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.421     |
|    n_updates            | 4260      |
|    policy_gradient_loss | 0.032     |
|    std                  | 0.46      |
|    value_loss           | 1.02      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 948         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 428         |
|    time_elapsed         | 244680      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.116490304 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.61       |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.578       |
|    n_updates            | 4270        |
|    policy_gradient_loss | 0.0332      |
|    std                  | 0.457       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 949       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 429       |
|    time_elapsed         | 244885    |
|    total_timesteps      | 878592    |
| train/                  |           |
|    approx_kl            | 0.2600634 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.61     |
|    explained_variance   | 0.487     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.627     |
|    n_updates            | 4280      |
|    policy_gradient_loss | 0.0301    |
|    std                  | 0.459     |
|    value_loss           | 1.06      |
---------------------------------------
Eval num_timesteps=880000, episode_reward=-99.90 +/- 0.04
Episode length: 3596.60 +/- 8.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.06272613 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.63      |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.607      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.00943    |
|    std                  | 0.46       |
|    value_loss           | 0.933      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 943      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246891   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 943         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 247097      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.082863346 |
|    clip_fraction        | 0.513       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.61       |
|    explained_variance   | -0.000215   |
|    learning_rate        | 0.0003      |
|    loss                 | 871         |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.00988     |
|    std                  | 0.458       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 951        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 432        |
|    time_elapsed         | 247302     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.22468954 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.58      |
|    explained_variance   | 0.227      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.494      |
|    n_updates            | 4310       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.457      |
|    value_loss           | 0.976      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 951       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 433       |
|    time_elapsed         | 247507    |
|    total_timesteps      | 886784    |
| train/                  |           |
|    approx_kl            | 0.3491448 |
|    clip_fraction        | 0.339     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.56     |
|    explained_variance   | 0.49      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.602     |
|    n_updates            | 4320      |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.456     |
|    value_loss           | 1.04      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 952        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 247713     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.08640883 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.53      |
|    explained_variance   | 0.424      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.919      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.027      |
|    std                  | 0.454      |
|    value_loss           | 1.33       |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.90 +/- 0.04
Episode length: 3598.60 +/- 4.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.13730747 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.49      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.793      |
|    n_updates            | 4340       |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.453      |
|    value_loss           | 1.21       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 945      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249720   |
|    total_timesteps | 890880   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 945       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 436       |
|    time_elapsed         | 249925    |
|    total_timesteps      | 892928    |
| train/                  |           |
|    approx_kl            | 0.3050364 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.49     |
|    explained_variance   | -0.000841 |
|    learning_rate        | 0.0003    |
|    loss                 | 35.6      |
|    n_updates            | 4350      |
|    policy_gradient_loss | 0.0139    |
|    std                  | 0.454     |
|    value_loss           | 1.04e+03  |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 952      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 437      |
|    time_elapsed         | 250131   |
|    total_timesteps      | 894976   |
| train/                  |          |
|    approx_kl            | 3.943821 |
|    clip_fraction        | 0.421    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.47    |
|    explained_variance   | 0.0336   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.523    |
|    n_updates            | 4360     |
|    policy_gradient_loss | 0.000346 |
|    std                  | 0.452    |
|    value_loss           | 1.18     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 952        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 250336     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.05827366 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.45      |
|    explained_variance   | 0.474      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.451      |
|    value_loss           | 1.51       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 953      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 439      |
|    time_elapsed         | 250542   |
|    total_timesteps      | 899072   |
| train/                  |          |
|    approx_kl            | 0.269638 |
|    clip_fraction        | 0.326    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.46    |
|    explained_variance   | 0.463    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.632    |
|    n_updates            | 4380     |
|    policy_gradient_loss | 0.0198   |
|    std                  | 0.453    |
|    value_loss           | 1.32     |
--------------------------------------
Eval num_timesteps=900000, episode_reward=-99.89 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.11333454 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.45      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.698      |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.146      |
|    std                  | 0.451      |
|    value_loss           | 1.33       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 947      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252547   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 947        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 252753     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.16639104 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.44      |
|    explained_variance   | -0.000338  |
|    learning_rate        | 0.0003     |
|    loss                 | 8.48       |
|    n_updates            | 4400       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.453      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 956       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 442       |
|    time_elapsed         | 252959    |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 2.4489286 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.45     |
|    explained_variance   | 0.0154    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.559     |
|    n_updates            | 4410      |
|    policy_gradient_loss | 0.00743   |
|    std                  | 0.451     |
|    value_loss           | 1.22      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 958        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 253165     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.03467098 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.44      |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.38       |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.00852   |
|    std                  | 0.452      |
|    value_loss           | 6.13       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 958        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 253370     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.05733511 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.43      |
|    explained_variance   | 0.385      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.659      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.45       |
|    value_loss           | 1.46       |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.86 +/- 0.08
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.16510323 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.4       |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.514      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.45       |
|    value_loss           | 1.18       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 952      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255376   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 952        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 255582     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.22821665 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.39      |
|    explained_variance   | 0.00815    |
|    learning_rate        | 0.0003     |
|    loss                 | 62.5       |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.00417    |
|    std                  | 0.45       |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 961       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 447       |
|    time_elapsed         | 255787    |
|    total_timesteps      | 915456    |
| train/                  |           |
|    approx_kl            | 2.7606199 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.37     |
|    explained_variance   | 0.27      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.553     |
|    n_updates            | 4460      |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.446     |
|    value_loss           | 1.41      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 962       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 448       |
|    time_elapsed         | 255992    |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 0.5348838 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.32     |
|    explained_variance   | 0.5       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.587     |
|    n_updates            | 4470      |
|    policy_gradient_loss | 0.0462    |
|    std                  | 0.446     |
|    value_loss           | 1.11      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 962         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 449         |
|    time_elapsed         | 256198      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.051069126 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.32       |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.715       |
|    n_updates            | 4480        |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.446       |
|    value_loss           | 3.49        |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.90 +/- 0.01
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 920000    |
| train/                  |           |
|    approx_kl            | 0.0475832 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.3      |
|    explained_variance   | 0.496     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.486     |
|    n_updates            | 4490      |
|    policy_gradient_loss | 0.0373    |
|    std                  | 0.445     |
|    value_loss           | 1.02      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 955      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258206   |
|    total_timesteps | 921600   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 964       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 451       |
|    time_elapsed         | 258411    |
|    total_timesteps      | 923648    |
| train/                  |           |
|    approx_kl            | 0.5914403 |
|    clip_fraction        | 0.326     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.29     |
|    explained_variance   | 0.0932    |
|    learning_rate        | 0.0003    |
|    loss                 | 13.1      |
|    n_updates            | 4500      |
|    policy_gradient_loss | 0.00114   |
|    std                  | 0.445     |
|    value_loss           | 1.05e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 964       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 452       |
|    time_elapsed         | 258616    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 0.9066922 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.27     |
|    explained_variance   | 0.309     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.511     |
|    n_updates            | 4510      |
|    policy_gradient_loss | 0.0256    |
|    std                  | 0.444     |
|    value_loss           | 1.4       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 966       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 453       |
|    time_elapsed         | 258822    |
|    total_timesteps      | 927744    |
| train/                  |           |
|    approx_kl            | 1.5110825 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.26     |
|    explained_variance   | 0.582     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.516     |
|    n_updates            | 4520      |
|    policy_gradient_loss | 0.0328    |
|    std                  | 0.443     |
|    value_loss           | 0.809     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 966        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 259027     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.04499927 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.22      |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.558      |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.443      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.90 +/- 0.06
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.053263623 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.19       |
|    explained_variance   | 0.512       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.415       |
|    n_updates            | 4540        |
|    policy_gradient_loss | 0.0336      |
|    std                  | 0.44        |
|    value_loss           | 0.931       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 960      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261033   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 969         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261239      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.123491004 |
|    clip_fraction        | 0.539       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.15       |
|    explained_variance   | -0.00432    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.81        |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.439       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 969      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 457      |
|    time_elapsed         | 261444   |
|    total_timesteps      | 935936   |
| train/                  |          |
|    approx_kl            | 2.085063 |
|    clip_fraction        | 0.477    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.11    |
|    explained_variance   | 0.00506  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.546    |
|    n_updates            | 4560     |
|    policy_gradient_loss | 0.0162   |
|    std                  | 0.437    |
|    value_loss           | 1.87     |
--------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 972       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 458       |
|    time_elapsed         | 261649    |
|    total_timesteps      | 937984    |
| train/                  |           |
|    approx_kl            | 1.0026727 |
|    clip_fraction        | 0.367     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.09     |
|    explained_variance   | 0.296     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.877     |
|    n_updates            | 4570      |
|    policy_gradient_loss | 0.128     |
|    std                  | 0.436     |
|    value_loss           | 2.14      |
---------------------------------------
Eval num_timesteps=940000, episode_reward=-99.92 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.21114857 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.07      |
|    explained_variance   | 0.282      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.844      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0278     |
|    std                  | 0.435      |
|    value_loss           | 2.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 967      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263655   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 967        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 263861     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.11836417 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.05      |
|    explained_variance   | -4.9e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 572        |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.00951    |
|    std                  | 0.435      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 977      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 461      |
|    time_elapsed         | 264066   |
|    total_timesteps      | 944128   |
| train/                  |          |
|    approx_kl            | 4.166368 |
|    clip_fraction        | 0.401    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.04    |
|    explained_variance   | 0.00267  |
|    learning_rate        | 0.0003   |
|    loss                 | 1.11     |
|    n_updates            | 4600     |
|    policy_gradient_loss | 0.0317   |
|    std                  | 0.433    |
|    value_loss           | 2.38     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 977        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264271     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.40522692 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.01      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.00489    |
|    std                  | 0.432      |
|    value_loss           | 2.44       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 980        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 264477     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.09212472 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.01      |
|    explained_variance   | 0.506      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.517      |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.433      |
|    value_loss           | 1.2        |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.91 +/- 0.06
Episode length: 3598.80 +/- 4.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.20429385 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.99      |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.875      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.431      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 976      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266483   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 976        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 266688     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.11997181 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.98      |
|    explained_variance   | -0.0003    |
|    learning_rate        | 0.0003     |
|    loss                 | 99.1       |
|    n_updates            | 4640       |
|    policy_gradient_loss | 0.00824    |
|    std                  | 0.432      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 987      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 466      |
|    time_elapsed         | 266894   |
|    total_timesteps      | 954368   |
| train/                  |          |
|    approx_kl            | 3.253973 |
|    clip_fraction        | 0.402    |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.99    |
|    explained_variance   | 0.00339  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.74     |
|    n_updates            | 4650     |
|    policy_gradient_loss | 0.00168  |
|    std                  | 0.432    |
|    value_loss           | 2.23     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 987        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 267099     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.63017803 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.197      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.601      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.432      |
|    value_loss           | 1.48       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 990        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 468        |
|    time_elapsed         | 267304     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.22040464 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.94      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.615      |
|    n_updates            | 4670       |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.428      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.93 +/- 0.03
Episode length: 3598.80 +/- 4.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 960000    |
| train/                  |           |
|    approx_kl            | 1.1211818 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.9      |
|    explained_variance   | 0.446     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.622     |
|    n_updates            | 4680      |
|    policy_gradient_loss | 0.0397    |
|    std                  | 0.427     |
|    value_loss           | 1.6       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 985      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269310   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 985         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 269516      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.056249026 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.00651     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.89        |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.00392     |
|    std                  | 0.427       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 996        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 471        |
|    time_elapsed         | 269721     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.16124174 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.88      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.682      |
|    n_updates            | 4700       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.426      |
|    value_loss           | 1.43       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 996       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 472       |
|    time_elapsed         | 269927    |
|    total_timesteps      | 966656    |
| train/                  |           |
|    approx_kl            | 0.9306722 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.86     |
|    explained_variance   | 0.384     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.502     |
|    n_updates            | 4710      |
|    policy_gradient_loss | 0.0302    |
|    std                  | 0.427     |
|    value_loss           | 1.56      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 999       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 473       |
|    time_elapsed         | 270132    |
|    total_timesteps      | 968704    |
| train/                  |           |
|    approx_kl            | 0.1383261 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.85     |
|    explained_variance   | 0.4       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.446     |
|    n_updates            | 4720      |
|    policy_gradient_loss | 0.0392    |
|    std                  | 0.426     |
|    value_loss           | 1.72      |
---------------------------------------
Eval num_timesteps=970000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 970000    |
| train/                  |           |
|    approx_kl            | 0.1372559 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.82     |
|    explained_variance   | 0.45      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.7       |
|    n_updates            | 4730      |
|    policy_gradient_loss | 0.0243    |
|    std                  | 0.426     |
|    value_loss           | 1.51      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 995      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272138   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 995        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 272344     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.17771876 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.82      |
|    explained_variance   | 0.000855   |
|    learning_rate        | 0.0003     |
|    loss                 | 173        |
|    n_updates            | 4740       |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.424      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.01e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 272552    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 4.5209665 |
|    clip_fraction        | 0.52      |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.81     |
|    explained_variance   | 0.0394    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.842     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0206    |
|    std                  | 0.425     |
|    value_loss           | 1.99      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 272758     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.21661662 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.82      |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.634      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.041      |
|    std                  | 0.426      |
|    value_loss           | 1.62       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.01e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 478      |
|    time_elapsed         | 272963   |
|    total_timesteps      | 978944   |
| train/                  |          |
|    approx_kl            | 0.602554 |
|    clip_fraction        | 0.376    |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.79    |
|    explained_variance   | 0.471    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.924    |
|    n_updates            | 4770     |
|    policy_gradient_loss | 0.0231   |
|    std                  | 0.423    |
|    value_loss           | 1.72     |
--------------------------------------
Eval num_timesteps=980000, episode_reward=-99.91 +/- 0.02
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 980000    |
| train/                  |           |
|    approx_kl            | 2.8982875 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.77     |
|    explained_variance   | 0.491     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.578     |
|    n_updates            | 4780      |
|    policy_gradient_loss | 0.0296    |
|    std                  | 0.423     |
|    value_loss           | 1.08      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 274969   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275174      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.123451054 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.78       |
|    explained_variance   | 4.42e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 24.9        |
|    n_updates            | 4790        |
|    policy_gradient_loss | 0.00858     |
|    std                  | 0.423       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 481       |
|    time_elapsed         | 275380    |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 1.3559595 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.77     |
|    explained_variance   | 0.234     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.565     |
|    n_updates            | 4800      |
|    policy_gradient_loss | 0.00748   |
|    std                  | 0.423     |
|    value_loss           | 1.36      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275585     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.12384862 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.75      |
|    explained_variance   | 0.459      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.731      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.0271     |
|    std                  | 0.423      |
|    value_loss           | 1.55       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 483       |
|    time_elapsed         | 275791    |
|    total_timesteps      | 989184    |
| train/                  |           |
|    approx_kl            | 1.2976784 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.74     |
|    explained_variance   | 0.483     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.535     |
|    n_updates            | 4820      |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.422     |
|    value_loss           | 1.43      |
---------------------------------------
Eval num_timesteps=990000, episode_reward=-99.95 +/- 0.04
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.22045682 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.72      |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.58       |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.421      |
|    value_loss           | 3.98       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277797   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 278002     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.14687794 |
|    clip_fraction        | 0.158      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.116      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.49e+03   |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.00156   |
|    std                  | 0.421      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 278207     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.13196674 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.218      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.681      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.0241     |
|    std                  | 0.421      |
|    value_loss           | 1.44       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 278413    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.5680298 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.71     |
|    explained_variance   | 0.493     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.6       |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.0378    |
|    std                  | 0.422     |
|    value_loss           | 1.2       |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.04e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 488      |
|    time_elapsed         | 278618   |
|    total_timesteps      | 999424   |
| train/                  |          |
|    approx_kl            | 0.647174 |
|    clip_fraction        | 0.448    |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.71    |
|    explained_variance   | 0.527    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.893    |
|    n_updates            | 4870     |
|    policy_gradient_loss | 0.0495   |
|    std                  | 0.421    |
|    value_loss           | 1.17     |
--------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.93 +/- 0.05
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 1000000  |
| train/                  |          |
|    approx_kl            | 1.354841 |
|    clip_fraction        | 0.409    |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.71    |
|    explained_variance   | 0.423    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.554    |
|    n_updates            | 4880     |
|    policy_gradient_loss | 0.0388   |
|    std                  | 0.421    |
|    value_loss           | 1.42     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280625   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 3 days, 5:54:29 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-100.06099  -100.059127 -100.103003 -100.047243  -99.921053]
 [ -99.93736   -99.929124 -100.030884 -100.056152  -99.969819]
 [ -99.748221  -99.788692  -99.817722  -99.87582  -100.198234]
 [ -99.756915  -99.778244  -99.692829 -100.064363 -100.009689]
 [-100.004477  -99.780665  -99.97554   -99.693619  -99.642375]
 [-100.002384 -100.004321  -99.929753  -99.763962  -99.743684]
 [ -99.904713  -99.911827  -99.709631  -99.887827  -99.706586]
 [ -99.932497  -99.963674  -99.961275  -99.852515  -99.848578]
 [ -99.907428  -99.890687  -99.846662  -99.921038  -99.852052]
 [ -99.876848  -99.928511  -99.92638   -99.957367  -99.861737]
 [ -99.86784   -99.909674  -99.491558  -99.607963  -99.490128]
 [ -99.99149   -99.904742  -99.925864  -99.922732  -99.833763]
 [ -99.840511  -99.898817  -99.857092  -99.909926  -99.874893]
 [ -99.921593  -99.8911    -99.950647  -99.965069  -99.925708]
 [ -99.856267  -99.870507  -99.839547  -99.852384  -99.834179]
 [ -99.929161  -99.803035  -99.816352  -99.928281  -99.904914]
 [ -99.907963  -99.981025  -99.907723  -99.93241   -99.953732]
 [ -99.947877  -99.885983  -99.907712  -99.978378  -99.968079]
 [ -99.799219  -99.824997  -99.864314  -99.921527  -99.848252]
 [ -99.911879  -99.860434  -99.814621  -99.939288  -99.890328]
 [ -99.914627  -99.900609  -99.82851   -99.505939  -99.894676]
 [ -99.813252  -99.852643  -99.84915   -99.849331  -99.924108]
 [ -99.571763  -99.819323  -99.594766  -99.623265  -99.863912]
 [ -99.913227  -99.942933  -99.932997  -99.941805  -99.923055]
 [ -99.965768  -99.931286  -99.755012  -99.884778  -99.855485]
 [ -99.891487  -99.899542  -99.82669   -99.924363  -99.924634]
 [ -99.855961  -99.896869  -99.888466  -99.811449  -99.978247]
 [ -99.841869  -99.819186  -99.769797  -99.871345  -99.919315]
 [ -99.994359  -99.933898  -99.806609  -99.815725  -99.880746]
 [ -99.935685  -99.898671  -99.812164  -99.853486  -99.95015 ]
 [ -99.932356  -99.806012  -99.822181  -99.879674  -99.899218]
 [ -99.888457  -99.92811   -99.839949  -99.866865  -99.847267]
 [ -99.825282  -99.843927  -99.910834  -99.806588  -99.88641 ]
 [ -99.902095  -99.810948  -99.847429  -99.906073  -99.882619]
 [ -99.814269  -99.852314  -99.900135  -99.917474  -99.92928 ]
 [ -99.799771  -99.889763  -99.830157  -99.797255  -99.789462]
 [ -99.933075  -99.988653  -99.922013  -99.840274  -99.834543]
 [ -99.930763  -99.85561   -99.915128  -99.928958  -99.897919]
 [ -99.885227  -99.880577  -99.91882   -99.861748  -99.854485]
 [ -99.618029  -99.884816  -99.568985  -99.584903  -99.602669]
 [ -99.746883  -99.718979  -99.911637  -99.967295  -99.635558]
 [ -99.768888  -99.824747  -99.896911  -99.865226  -99.888334]
 [ -99.849489  -99.862006  -99.908039  -99.906175  -99.919436]
 [ -99.976229  -99.911691  -99.9704    -99.849355  -99.939794]
 [ -99.867001  -99.904694  -99.891495  -99.856204  -99.970763]
 [ -99.907667  -99.91488   -99.946422  -99.895086  -99.927518]
 [ -99.91848   -99.913083  -99.895349  -99.860623  -99.829494]
 [ -99.857138  -99.87203   -99.848414  -99.642434  -99.664203]
 [ -99.687006  -99.835765  -99.888476  -99.457142  -99.432939]
 [ -99.91877   -99.957572  -99.830073  -99.923807  -99.91072 ]
 [ -99.940001  -99.903328  -99.935033  -99.963336  -99.853711]
 [ -99.848106  -99.860833  -99.965548  -99.926115  -99.988952]
 [ -99.581335  -99.611133  -99.847434  -99.937676  -99.65    ]
 [-100.001135  -99.938132  -99.870806  -99.926336  -99.896362]
 [ -99.889026  -99.89926   -99.8746    -99.885245  -99.915387]
 [-100.010988  -99.949652  -99.896373  -99.968336  -99.950856]
 [ -99.891238  -99.984185  -99.890752  -99.990322  -99.919218]
 [ -99.902087  -99.833238  -99.843473  -99.877813  -99.923132]
 [ -99.831555  -99.646443  -99.524836  -99.524132  -99.97791 ]
 [ -99.877151  -99.937012  -99.808599  -99.936875  -99.80327 ]
 [ -99.83444   -99.914713  -99.860734  -99.893163  -99.911594]
 [ -97.902863  -99.941651  -99.881014  -99.93599   -99.958218]
 [ -99.971748  -99.892467  -99.866427  -99.824663  -99.926878]
 [ -99.989642  -99.939281  -99.852069  -99.972429  -99.898465]
 [ -99.931369  -99.96409   -99.886769  -99.955747  -99.84401 ]
 [ -99.5854    -99.818296  -99.89393   -99.607823  -99.549093]
 [ -99.485056 -100.012328  -99.812054  -99.958968  -99.665965]
 [ -99.984856  -99.853082  -99.878672  -99.883845  -99.925298]
 [ -99.902043  -99.949809  -99.853023  -99.911972  -99.957245]
 [ -99.877616  -99.838416  -99.770207  -99.867185  -99.877625]
 [ -99.911268  -99.7959    -99.931051  -99.862822  -99.943767]
 [ -99.922858  -99.862537  -99.810561  -99.945223  -99.87411 ]
 [ -99.919968  -99.928582  -99.859649  -99.745344  -99.867524]
 [ -99.978967 -100.029377  -99.949676 -100.009781  -99.950594]
 [ -99.920174  -99.906324  -99.958663  -99.866319  -99.898439]
 [ -99.883649  -99.971374  -99.983897  -99.936192  -99.867541]
 [ -99.850432  -99.909493  -99.868436  -99.932006  -99.972264]
 [ -99.927074  -99.855173  -99.909761  -99.857594  -99.844324]
 [ -99.880275  -99.94738   -99.936444  -99.874226  -99.958537]
 [ -99.943296  -99.961812  -99.870017  -99.892762  -99.929424]
 [ -99.844608  -99.939925  -99.846369  -99.912007  -99.868545]
 [ -99.967488  -99.960291  -97.810331  -99.90197   -99.858316]
 [ -99.874804  -99.885645  -99.95395   -99.855332  -99.894749]
 [ -99.93152   -99.791966  -99.905132  -99.898477  -99.818166]
 [ -99.870017  -99.938865  -99.846836  -99.891437  -99.828163]
 [ -99.941315  -99.944241  -99.929631  -99.904405  -99.904098]
 [ -99.898096  -99.892173  -99.887061  -99.924771  -99.813551]
 [ -99.826339  -99.914635  -99.934     -99.935625  -99.871721]
 [ -99.926654  -99.949206  -99.821091  -99.896987  -99.884793]
 [ -99.942469  -99.878018  -99.850428  -99.888329  -99.875653]
 [ -99.754112  -99.818602  -99.871819  -99.888052  -99.985792]
 [ -99.912387  -99.902447  -99.910147  -99.875371  -99.885632]
 [ -99.941471  -99.823813  -99.988323  -99.834182  -99.892464]
 [ -99.879509  -99.919531  -99.90877   -99.929545  -99.958313]
 [ -99.970237  -99.824005  -99.95842   -99.945856  -99.857894]
 [ -99.901764  -99.889007  -99.943512  -99.943273  -99.963958]
 [ -99.827594  -99.957794  -99.905617  -99.949829  -99.866177]
 [ -99.91446   -99.897871  -99.911991  -99.939366  -99.866995]
 [ -99.979055  -99.95153   -99.906384  -99.909651  -99.996236]
 [ -99.946373  -99.958661  -99.858355  -99.986706  -99.88255 ]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3596 3580 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3596 3601 3601 3601]
 [3601 3601 3601 3601 3590]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3582 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3593 3601 3601 3601]
 [3600 3601 3601 3597 3601]
 [3601 3601 3601 3586 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3583 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3601 3585]
 [3601 3601 3601 3601 3601]
 [3582 3601 3600 3601 3601]
 [3601 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3580 3598 3601 3601 3601]
 [3601 3601 3601 3586 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3584 3598 3601 3601]
 [3597 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3599 3601 3601 3599 3585]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3600 3584 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3595]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3600 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3593 3601 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3601 3595]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3600 3584]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3598 3601 3588 3601]
 [3601 3601 3601 3601 3598]
 [3598 3598 3601 3601 3601]
 [3601 3583 3601 3601 3601]
 [3598 3601 3601 3601 3587]
 [3601 3601 3601 3601 3601]
 [3588 3601 3601 3601 3601]
 [3597 3598 3601 3601 3578]
 [3601 3601 3601 3601 3599]
 [3576 3601 3601 3601 3601]
 [3601 3601 3601 3582 3601]
 [3601 3601 3600 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3579 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3575 3601 3601 3601 3600]
 [3601 3601 3601 3588 3601]
 [3601 3601 3599 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3583 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3585 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3579 3601 3601 3601 3601]
 [3601 3601 3601 3589 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3599 3601 3601 3601 3601]
 [3590 3601 3601 3601 3601]
 [3601 3601 3601 3590 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3588 3601 3601 3601]
 [3601 3601 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
