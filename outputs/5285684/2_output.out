####################
/var/spool/slurmd/job5285684/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --num-eval 100 --reward-type sparse --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-23_15-57-24_sparse_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 205  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.56e+03    |
|    ep_rew_mean          | -99         |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 413         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011944724 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.175       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0409      |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.996       |
|    value_loss           | 0.254       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.56e+03    |
|    ep_rew_mean          | -99         |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 619         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.011596952 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.074       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0115      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.991       |
|    value_loss           | 0.0848      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.57e+03   |
|    ep_rew_mean          | -99.5      |
| time/                   |            |
|    fps                  | 9          |
|    iterations           | 4          |
|    time_elapsed         | 825        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.01201058 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.141      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00527   |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.988      |
|    value_loss           | 0.0339     |
----------------------------------------
Eval num_timesteps=10000, episode_reward=-100.05 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.012957105 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.275      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0359     |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.985       |
|    value_loss           | 0.0136      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2832     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3039        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.002835053 |
|    clip_fraction        | 0.012       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.000175   |
|    learning_rate        | 0.0003      |
|    loss                 | 652         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00305    |
|    std                  | 0.985       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.39e+03    |
|    ep_rew_mean          | -219        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3245        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.012478759 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.295      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0907      |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.982       |
|    value_loss           | 0.267       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.39e+03    |
|    ep_rew_mean          | -219        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3451        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.017165635 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.398      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00964    |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0292     |
|    std                  | 0.981       |
|    value_loss           | 0.148       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.43e+03    |
|    ep_rew_mean          | -195        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3658        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.016455475 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.429      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00611     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0236     |
|    std                  | 0.978       |
|    value_loss           | 0.0423      |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.96 +/- 0.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.016284544 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.571      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0295     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0261     |
|    std                  | 0.976       |
|    value_loss           | 0.0116      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5665     |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 5871        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.004362149 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.000141   |
|    learning_rate        | 0.0003      |
|    loss                 | 49.6        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00191    |
|    std                  | 0.978       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -237        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6077        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.015744407 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.204       |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.974       |
|    value_loss           | 0.477       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.37e+03   |
|    ep_rew_mean          | -237       |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 13         |
|    time_elapsed         | 6283       |
|    total_timesteps      | 26624      |
| train/                  |            |
|    approx_kl            | 0.01630206 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.129      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0491     |
|    n_updates            | 120        |
|    policy_gradient_loss | -0.0254    |
|    std                  | 0.974      |
|    value_loss           | 0.204      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.39e+03    |
|    ep_rew_mean          | -220        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6489        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.018539334 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -1.71       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0295     |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.969       |
|    value_loss           | 0.0134      |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.88 +/- 0.03
Episode length: 3596.40 +/- 8.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.015575779 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -2.93       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000556    |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.965       |
|    value_loss           | 0.00579     |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8497     |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -260         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 8703         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0077472627 |
|    clip_fraction        | 0.0712       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -0.000533    |
|    learning_rate        | 0.0003       |
|    loss                 | 1.33e+03     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00612     |
|    std                  | 0.965        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -244        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 8909        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.014945731 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -1.87       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0192      |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.962       |
|    value_loss           | 0.167       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -244        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9116        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.018235244 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0168      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.961       |
|    value_loss           | 0.0516      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | -230        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9322        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.018143047 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00681    |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.962       |
|    value_loss           | 0.0489      |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.92 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.018418673 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.519       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0159      |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.96        |
|    value_loss           | 0.0208      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11329    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -259         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 11535        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0060654236 |
|    clip_fraction        | 0.0736       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.00305      |
|    learning_rate        | 0.0003       |
|    loss                 | 11.3         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00658     |
|    std                  | 0.96         |
|    value_loss           | 1.03e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | -247       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 22         |
|    time_elapsed         | 11744      |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.01756425 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.0791    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.199      |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.958      |
|    value_loss           | 0.438      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11951       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.021664977 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.173      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0353      |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.949       |
|    value_loss           | 0.0785      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -237        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12157       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.021442767 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.322       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00533    |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.95        |
|    value_loss           | 0.0287      |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.88 +/- 0.09
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.026892796 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.247      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0432     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.937       |
|    value_loss           | 0.017       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14164    |
|    total_timesteps | 51200    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -259       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 26         |
|    time_elapsed         | 14370      |
|    total_timesteps      | 53248      |
| train/                  |            |
|    approx_kl            | 0.00892807 |
|    clip_fraction        | 0.0729     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.0003    |
|    learning_rate        | 0.0003     |
|    loss                 | 212        |
|    n_updates            | 250        |
|    policy_gradient_loss | -0.00525   |
|    std                  | 0.937      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -249        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14576       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.021095905 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.896      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0565      |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.941       |
|    value_loss           | 0.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14782       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.023983723 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0805     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00605     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0276     |
|    std                  | 0.941       |
|    value_loss           | 0.0668      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14989       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.024204643 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.175      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0355     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0281     |
|    std                  | 0.943       |
|    value_loss           | 0.0233      |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.86 +/- 0.11
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.020733342 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.265       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0029     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.945       |
|    value_loss           | 0.0217      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16996    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17202       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.010540299 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000551   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.04        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00483    |
|    std                  | 0.944       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -251        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17409       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.019304613 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -3.51       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0614      |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.941       |
|    value_loss           | 0.271       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -243        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17615       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.024593502 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.331       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0103      |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.939       |
|    value_loss           | 0.0283      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -243        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17821       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.019562189 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.397       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0368     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.936       |
|    value_loss           | 0.0156      |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.90 +/- 0.07
Episode length: 3600.00 +/- 1.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.02037862 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.426      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00273   |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.939      |
|    value_loss           | 0.0083     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19828    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20037       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.008071164 |
|    clip_fraction        | 0.0742      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.000367   |
|    learning_rate        | 0.0003      |
|    loss                 | 46.3        |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.939       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20244       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.021216981 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -1.38       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0195      |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.938       |
|    value_loss           | 0.131       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | -246       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 38         |
|    time_elapsed         | 20450      |
|    total_timesteps      | 77824      |
| train/                  |            |
|    approx_kl            | 0.02316362 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -1.31      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00479    |
|    n_updates            | 370        |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.933      |
|    value_loss           | 0.0226     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -246        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20657       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.018641155 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -1.37       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00835    |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.931       |
|    value_loss           | 0.0131      |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.95 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.01751503 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -3.47      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0297    |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.928      |
|    value_loss           | 0.00536    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22663    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22870       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.011693783 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -5.19e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+03    |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00388    |
|    std                  | 0.928       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23076       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.024327748 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.842      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0642      |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.932       |
|    value_loss           | 0.305       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23282       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.029287662 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0118     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.025      |
|    std                  | 0.925       |
|    value_loss           | 0.0446      |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-100.03 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.025596028 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.874      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0127      |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.923       |
|    value_loss           | 0.0468      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -259     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25289    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25495       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.013110461 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000146   |
|    learning_rate        | 0.0003      |
|    loss                 | 10.9        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00798    |
|    std                  | 0.924       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25702       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.027908728 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.379      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0894      |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.924       |
|    value_loss           | 0.272       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25908       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.030373365 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.585      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0252     |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0252     |
|    std                  | 0.917       |
|    value_loss           | 0.0682      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -248        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26114       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.022228858 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -1.96       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0128     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.923       |
|    value_loss           | 0.0124      |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.84 +/- 0.07
Episode length: 3597.40 +/- 5.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.020900354 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -2.75       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0278     |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.922       |
|    value_loss           | 0.00409     |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28121    |
|    total_timesteps | 100352   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -260       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 50         |
|    time_elapsed         | 28328      |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.01332869 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -8.37e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 968        |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.00552   |
|    std                  | 0.922      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28534       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.018730905 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -5.53       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0107      |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.922       |
|    value_loss           | 0.0478      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28740       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.021900728 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0364     |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.918       |
|    value_loss           | 0.0243      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | -250       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 53         |
|    time_elapsed         | 28946      |
|    total_timesteps      | 108544     |
| train/                  |            |
|    approx_kl            | 0.02326265 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.615     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.023     |
|    n_updates            | 520        |
|    policy_gradient_loss | -0.0197    |
|    std                  | 0.916      |
|    value_loss           | 0.00916    |
----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.95 +/- 0.07
Episode length: 3593.20 +/- 9.81
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.022794914 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.336      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0159     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.913       |
|    value_loss           | 0.00436     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30955    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31161       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.015349516 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -6.68e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 50.1        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.914       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31367       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.025540031 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.813      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.142       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.913       |
|    value_loss           | 0.415       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31573       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.026919432 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0388     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0147      |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.91        |
|    value_loss           | 0.089       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -250        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31779       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.027028758 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00168     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00786    |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.911       |
|    value_loss           | 0.0174      |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-100.04 +/- 0.11
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.024435949 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -1.06       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0113     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.909       |
|    value_loss           | 0.00641     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33785    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 33991       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.008807445 |
|    clip_fraction        | 0.083       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.000921    |
|    learning_rate        | 0.0003      |
|    loss                 | 456         |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00912    |
|    std                  | 0.909       |
|    value_loss           | 1.01e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -255       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 61         |
|    time_elapsed         | 34197      |
|    total_timesteps      | 124928     |
| train/                  |            |
|    approx_kl            | 0.02514135 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -1.02      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.913      |
|    value_loss           | 0.503      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | -255      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 62        |
|    time_elapsed         | 34403     |
|    total_timesteps      | 126976    |
| train/                  |           |
|    approx_kl            | 0.0347702 |
|    clip_fraction        | 0.276     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.6     |
|    explained_variance   | -1.14     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.0725    |
|    n_updates            | 610       |
|    policy_gradient_loss | -0.0158   |
|    std                  | 0.914     |
|    value_loss           | 0.418     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -251        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34609       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.026933078 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.498      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00339     |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.915       |
|    value_loss           | 0.0156      |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.93 +/- 0.05
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.024629075 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.305      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0185     |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.908       |
|    value_loss           | 0.0497      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36615    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 36821       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.012266076 |
|    clip_fraction        | 0.0933      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000697   |
|    learning_rate        | 0.0003      |
|    loss                 | 11.4        |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0057     |
|    std                  | 0.909       |
|    value_loss           | 1.01e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -256        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 37028       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.020554615 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -1.07       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0571      |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.908       |
|    value_loss           | 0.312       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37234       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.025396917 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0142      |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.907       |
|    value_loss           | 0.0959      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | -252       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 68         |
|    time_elapsed         | 37440      |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.02864406 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0176    |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.904      |
|    value_loss           | 0.0543     |
----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.94 +/- 0.02
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.030437283 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.336       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0155     |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.902       |
|    value_loss           | 0.0246      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39447    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39653       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.009426545 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000595    |
|    learning_rate        | 0.0003      |
|    loss                 | 75.8        |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.902       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 71         |
|    time_elapsed         | 39859      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.02108052 |
|    clip_fraction        | 0.162      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.141     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.675      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.9        |
|    value_loss           | 1.51       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -252       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 72         |
|    time_elapsed         | 40066      |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.01766549 |
|    clip_fraction        | 0.174      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.0406    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0961     |
|    n_updates            | 710        |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.894      |
|    value_loss           | 0.397      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40272       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.029062144 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0655      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0868      |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.892       |
|    value_loss           | 0.15        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-100.00 +/- 0.04
Episode length: 3543.40 +/- 13.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.54e+03    |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.031836055 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00201     |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.894       |
|    value_loss           | 0.0927      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42279    |
|    total_timesteps | 151552   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 75         |
|    time_elapsed         | 42491      |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.02017596 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -3.15e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+03   |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.00432   |
|    std                  | 0.895      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 76         |
|    time_elapsed         | 42701      |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.02894058 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -1.77      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00262   |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.896      |
|    value_loss           | 0.0534     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -253       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 77         |
|    time_elapsed         | 42907      |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.01923954 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -3.72      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0065    |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.00868   |
|    std                  | 0.897      |
|    value_loss           | 0.00541    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43113       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.023920694 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.832      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0568     |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.897       |
|    value_loss           | 0.00537     |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.96 +/- 0.03
Episode length: 3595.20 +/- 9.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.022852262 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -1.8        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0206      |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00983    |
|    std                  | 0.902       |
|    value_loss           | 0.00212     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45120    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -256        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45326       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.010270655 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -1.12e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.11e+03    |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00234    |
|    std                  | 0.902       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 81         |
|    time_elapsed         | 45532      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.02135053 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -4.76      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0226    |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.00921   |
|    std                  | 0.903      |
|    value_loss           | 0.0424     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45738       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.018122146 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -2.41       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0333     |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.906       |
|    value_loss           | 0.00842     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45945       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.029991228 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0713     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00891    |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.905       |
|    value_loss           | 0.0117      |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.90 +/- 0.10
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.03991992 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.323      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0574    |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.907      |
|    value_loss           | 0.0152     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47951    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48158       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.019453043 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000735    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.222       |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00688    |
|    std                  | 0.905       |
|    value_loss           | 916         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48366       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.029436491 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.952      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0419      |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.895       |
|    value_loss           | 0.0935      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48572       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.034838967 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.274      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0224     |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.891       |
|    value_loss           | 0.0348      |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.94 +/- 0.04
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.025514893 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.19       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0508     |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0267     |
|    std                  | 0.887       |
|    value_loss           | 0.0117      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50579    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50785       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.011781588 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1e-05      |
|    learning_rate        | 0.0003      |
|    loss                 | 15.3        |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00683    |
|    std                  | 0.888       |
|    value_loss           | 1e+03       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 50991       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.021575034 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.162       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.285       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.884       |
|    value_loss           | 0.644       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51198       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.037309334 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0107     |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.88        |
|    value_loss           | 0.114       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -254       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 92         |
|    time_elapsed         | 51404      |
|    total_timesteps      | 188416     |
| train/                  |            |
|    approx_kl            | 0.03547963 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.195      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0647     |
|    n_updates            | 910        |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.885      |
|    value_loss           | 0.137      |
----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.89 +/- 0.02
Episode length: 3596.20 +/- 7.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.023799552 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.2         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00973     |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00777    |
|    std                  | 0.885       |
|    value_loss           | 0.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53411    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53617       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.012214776 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -4.77e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 169         |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00576    |
|    std                  | 0.885       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53823       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.021386802 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -3.63       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00341     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.892       |
|    value_loss           | 0.0489      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 96         |
|    time_elapsed         | 54029      |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.03183846 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.226      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0276     |
|    n_updates            | 950        |
|    policy_gradient_loss | -0.0224    |
|    std                  | 0.887      |
|    value_loss           | 0.00776    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54235       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.038559355 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.562      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0324     |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.897       |
|    value_loss           | 0.0219      |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.88 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 200000     |
| train/                  |            |
|    approx_kl            | 0.02548859 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0264    |
|    n_updates            | 970        |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.9        |
|    value_loss           | 0.00454    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56242    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56448       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.011720616 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000242    |
|    learning_rate        | 0.0003      |
|    loss                 | 88.7        |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00434    |
|    std                  | 0.899       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 100        |
|    time_elapsed         | 56655      |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.02383398 |
|    clip_fraction        | 0.228      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.581      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0265     |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.902      |
|    value_loss           | 0.148      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 101        |
|    time_elapsed         | 56861      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.02030207 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00863    |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.905      |
|    value_loss           | 0.0829     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -254        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57067       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.026649762 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.463       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0112     |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.905       |
|    value_loss           | 0.118       |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.91 +/- 0.07
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 210000     |
| train/                  |            |
|    approx_kl            | 0.02780268 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.202      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0251    |
|    n_updates            | 1020       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.901      |
|    value_loss           | 0.0501     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59074    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59280       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.018627465 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000403    |
|    learning_rate        | 0.0003      |
|    loss                 | 559         |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.000356   |
|    std                  | 0.901       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59486       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.032936238 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.273       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.904       |
|    value_loss           | 0.331       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 59692       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.041368894 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0337      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.048       |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.9         |
|    value_loss           | 0.0793      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 59897       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.026179543 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.606      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0224     |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.899       |
|    value_loss           | 0.0182      |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.91 +/- 0.07
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.025410306 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.186      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0392     |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.901       |
|    value_loss           | 0.00544     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61904    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62110       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.012937369 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000519    |
|    learning_rate        | 0.0003      |
|    loss                 | 842         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00844    |
|    std                  | 0.901       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 62316       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.025588023 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.49        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.254       |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.894       |
|    value_loss           | 0.743       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62522       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.025168898 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.145       |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.894       |
|    value_loss           | 0.335       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -255       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 62729      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.02910602 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0358     |
|    n_updates            | 1110       |
|    policy_gradient_loss | -0.0153    |
|    std                  | 0.895      |
|    value_loss           | 0.164      |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.87 +/- 0.06
Episode length: 3597.00 +/- 7.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.025824621 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.457       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0364      |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.891       |
|    value_loss           | 0.0254      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64735    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64941       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.013350201 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00073    |
|    learning_rate        | 0.0003      |
|    loss                 | 851         |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00494    |
|    std                  | 0.89        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65148       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.019109968 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.17       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0286     |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.888       |
|    value_loss           | 0.0427      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -255       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 116        |
|    time_elapsed         | 65354      |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.03324607 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.14       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0268    |
|    n_updates            | 1150       |
|    policy_gradient_loss | -0.0255    |
|    std                  | 0.891      |
|    value_loss           | 0.0178     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65560       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.020626035 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0103     |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.882       |
|    value_loss           | 0.0213      |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.83 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.025575228 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.394       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0093     |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.878       |
|    value_loss           | 0.0106      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67567    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67773       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.011407241 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0009     |
|    learning_rate        | 0.0003      |
|    loss                 | 948         |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00715    |
|    std                  | 0.879       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67979       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.023409463 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.714       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0392      |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.88        |
|    value_loss           | 0.142       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68185       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.028396295 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0281      |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.877       |
|    value_loss           | 0.047       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68392       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.025313502 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000402    |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.876       |
|    value_loss           | 0.0409      |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.82 +/- 0.11
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.023955777 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -1.27       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00248    |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.871       |
|    value_loss           | 0.0131      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70400    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70606       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.017268647 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000711   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.97e+03    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00528    |
|    std                  | 0.87        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 125        |
|    time_elapsed         | 70812      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.02117904 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.241     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00232   |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.00986   |
|    std                  | 0.867      |
|    value_loss           | 0.093      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -255        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 71019       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.027449612 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0166     |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.863       |
|    value_loss           | 0.0642      |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.88 +/- 0.04
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.02782122 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0141     |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.867      |
|    value_loss           | 0.0184     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 73025    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73232       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.014861689 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00591     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.67        |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00768    |
|    std                  | 0.867       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 73438       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.031269923 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.409       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.418       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.864       |
|    value_loss           | 0.941       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 130        |
|    time_elapsed         | 73644      |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.03356264 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.191      |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.00955   |
|    std                  | 0.863      |
|    value_loss           | 0.282      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -256        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 73850       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.034863114 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0753      |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.869       |
|    value_loss           | 0.156       |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.86 +/- 0.08
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.029096555 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00971     |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.865       |
|    value_loss           | 0.0566      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75857    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 76063       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.017877512 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.00386    |
|    learning_rate        | 0.0003      |
|    loss                 | 655         |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00817    |
|    std                  | 0.865       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76270      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.03854043 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.0554    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00639    |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.00996   |
|    std                  | 0.865      |
|    value_loss           | 0.156      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76476       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.047083177 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0349      |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.857       |
|    value_loss           | 0.0546      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 136        |
|    time_elapsed         | 76682      |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.03319874 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.439      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0414     |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.851      |
|    value_loss           | 0.0369     |
----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.86 +/- 0.05
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.032808322 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.44        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00889    |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.855       |
|    value_loss           | 0.018       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78688    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78894       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.010070585 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.002       |
|    learning_rate        | 0.0003      |
|    loss                 | 15          |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00599    |
|    std                  | 0.854       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 79100       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.034087528 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0377      |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.852       |
|    value_loss           | 0.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79306       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.041599248 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.88       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0271     |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00914    |
|    std                  | 0.852       |
|    value_loss           | 0.00874     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 79512      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.03497564 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0165    |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.851      |
|    value_loss           | 0.0132     |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.94 +/- 0.04
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.02747992 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.98      |
|    explained_variance   | -2.35      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.025     |
|    n_updates            | 1410       |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.848      |
|    value_loss           | 0.00584    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81518    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 81724       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.014855457 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -0.000593   |
|    learning_rate        | 0.0003      |
|    loss                 | 115         |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0074     |
|    std                  | 0.847       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 81930      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.02337426 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -6.18      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.046      |
|    n_updates            | 1430       |
|    policy_gradient_loss | 0.0033     |
|    std                  | 0.854      |
|    value_loss           | 0.0104     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82136       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.027951248 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -4.83       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0105     |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.856       |
|    value_loss           | 0.0125      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -256        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82342       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.036382098 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -2.05       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00795    |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.00176    |
|    std                  | 0.854       |
|    value_loss           | 0.00322     |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.95 +/- 0.04
Episode length: 3597.80 +/- 5.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 300000     |
| train/                  |            |
|    approx_kl            | 0.03715547 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -2.64      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0415    |
|    n_updates            | 1460       |
|    policy_gradient_loss | -0.00758   |
|    std                  | 0.853      |
|    value_loss           | 0.00352    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -260     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84348    |
|    total_timesteps | 301056   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -260         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 148          |
|    time_elapsed         | 84554        |
|    total_timesteps      | 303104       |
| train/                  |              |
|    approx_kl            | 0.0149125885 |
|    clip_fraction        | 0.167        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10          |
|    explained_variance   | -0.000166    |
|    learning_rate        | 0.0003       |
|    loss                 | 119          |
|    n_updates            | 1470         |
|    policy_gradient_loss | -0.00965     |
|    std                  | 0.854        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84760       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.022857836 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -6.17       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0422      |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.00944    |
|    std                  | 0.855       |
|    value_loss           | 0.131       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -256        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 84966       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.024798386 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -2.08       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0189     |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.00974    |
|    std                  | 0.852       |
|    value_loss           | 0.00949     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.3e+03    |
|    ep_rew_mean          | -243       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85172      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.02939017 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.98      |
|    explained_variance   | -0.361     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.000521   |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.847      |
|    value_loss           | 0.0115     |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.54 +/- 0.77
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.025128424 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.00308     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0281     |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.841       |
|    value_loss           | 502         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87179    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -246        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87385       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.017877154 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 3.76e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41e+03    |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00698    |
|    std                  | 0.841       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -245        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 87625       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.019380298 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -9.55       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00429    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.836       |
|    value_loss           | 0.0344      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -243        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 87871       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.037295327 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -0.931      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.028      |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.831       |
|    value_loss           | 0.0164      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -243        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 88077       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.022826448 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -2.03       |
|    learning_rate        | 0.0003      |
|    loss                 | -6.79e-05   |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.827       |
|    value_loss           | 0.0147      |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.93 +/- 0.03
Episode length: 3354.20 +/- 96.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.35e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.022243429 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | -1.67       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0106      |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00593    |
|    std                  | 0.824       |
|    value_loss           | 0.00396     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -247     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 90132    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -245        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90396       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.013460228 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | 3.36e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 9.2         |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00413    |
|    std                  | 0.824       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -244        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90664       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.027531978 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | -4.45       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0207     |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.824       |
|    value_loss           | 0.0323      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -244        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 90918       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.025418136 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | -0.197      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0188      |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.00602    |
|    std                  | 0.828       |
|    value_loss           | 0.00869     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.29e+03    |
|    ep_rew_mean          | -242        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 91127       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.014263784 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.115      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00916     |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00352    |
|    std                  | 0.826       |
|    value_loss           | 0.0103      |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.94 +/- 0.04
Episode length: 3598.60 +/- 3.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.025803413 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | -0.0361     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0299     |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00541    |
|    std                  | 0.836       |
|    value_loss           | 0.00678     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -247     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 93133    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -247       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 93339      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.01621484 |
|    clip_fraction        | 0.155      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | -1.97e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 114        |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.0044    |
|    std                  | 0.836      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93545       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.026241107 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -1.77       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0114     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.836       |
|    value_loss           | 0.0562      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -242        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93754       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.027769681 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.492      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0198      |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.843       |
|    value_loss           | 0.00764     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -242        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 93964       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.020415591 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -1.91       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00223    |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.84        |
|    value_loss           | 0.00922     |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.88 +/- 0.04
Episode length: 3259.20 +/- 74.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.26e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.028033372 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -0.17       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0143      |
|    n_updates            | 1660        |
|    policy_gradient_loss | 0.000111    |
|    std                  | 0.845       |
|    value_loss           | 0.00565     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -247     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 96003    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 96237       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.010367867 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 1.57e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 91.2        |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.000344   |
|    std                  | 0.846       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 96449       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.028567433 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -1.75       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0266     |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.848       |
|    value_loss           | 0.0302      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -242        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 96673       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.023878159 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.0477     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00217    |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.00214    |
|    std                  | 0.861       |
|    value_loss           | 0.0135      |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.82 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.023490854 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -1.11       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00577    |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.00841    |
|    std                  | 0.859       |
|    value_loss           | 0.0134      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98698    |
|    total_timesteps | 350208   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.23e+03   |
|    ep_rew_mean          | -246       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 172        |
|    time_elapsed         | 98908      |
|    total_timesteps      | 352256     |
| train/                  |            |
|    approx_kl            | 0.02015954 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 2.11e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.73e+03   |
|    n_updates            | 1710       |
|    policy_gradient_loss | -0.00817   |
|    std                  | 0.859      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 99115       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.030963816 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -3.84       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0162     |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00844    |
|    std                  | 0.862       |
|    value_loss           | 0.0358      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 99321       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.026356034 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.317      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00942     |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.863       |
|    value_loss           | 0.0203      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.24e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 99532      |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.03260636 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.159     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0147    |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.00587   |
|    std                  | 0.868      |
|    value_loss           | 0.00808    |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.94 +/- 0.04
Episode length: 3561.80 +/- 37.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.56e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.028069844 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.0981     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0139      |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.00346    |
|    std                  | 0.872       |
|    value_loss           | 0.016       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101548   |
|    total_timesteps | 360448   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.23e+03     |
|    ep_rew_mean          | -246         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 177          |
|    time_elapsed         | 101754       |
|    total_timesteps      | 362496       |
| train/                  |              |
|    approx_kl            | 0.0111449845 |
|    clip_fraction        | 0.206        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.2        |
|    explained_variance   | 7.51e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 739          |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00551     |
|    std                  | 0.871        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 101960      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.024270417 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -14.1       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0182     |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.00421    |
|    std                  | 0.87        |
|    value_loss           | 0.025       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 102166      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.024388116 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -1.92       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0472     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.869       |
|    value_loss           | 0.0187      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 102372      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.017338254 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.582      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.013       |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00834    |
|    std                  | 0.868       |
|    value_loss           | 0.00824     |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.96 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.033243082 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.0932     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0357     |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00252    |
|    std                  | 0.869       |
|    value_loss           | 0.00658     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 104378   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -246        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104584      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.015431835 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -6.79e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 48.4        |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00961    |
|    std                  | 0.87        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 104793      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.025989598 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -8.4        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0361      |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.00484    |
|    std                  | 0.865       |
|    value_loss           | 0.0301      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 105000      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.036946416 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.14       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0234     |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.00479    |
|    std                  | 0.864       |
|    value_loss           | 0.0159      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 105206      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.019276947 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -1          |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000284   |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.00282    |
|    std                  | 0.865       |
|    value_loss           | 0.00895     |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.85 +/- 0.09
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.03456314 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.224     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0306    |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.00948   |
|    std                  | 0.862      |
|    value_loss           | 0.00651    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 107212   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -246        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 107418      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.015060576 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 4.73e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 202         |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00393    |
|    std                  | 0.863       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.24e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 107624     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.02322064 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -2.96      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0188     |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.00644   |
|    std                  | 0.856      |
|    value_loss           | 0.0821     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107830      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.021226302 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -2.16       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0133     |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.00139    |
|    std                  | 0.855       |
|    value_loss           | 0.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 190         |
|    time_elapsed         | 108036      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.029076058 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.31       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0184     |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.00649    |
|    std                  | 0.855       |
|    value_loss           | 0.00453     |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.89 +/- 0.11
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.02541124 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -1.97      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00712   |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.00518   |
|    std                  | 0.849      |
|    value_loss           | 0.00517    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 110042   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -246        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 110248      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.011299338 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | -8.23e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.08        |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0022     |
|    std                  | 0.849       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 110461      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.016438361 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -5.39       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00896    |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.00312    |
|    std                  | 0.851       |
|    value_loss           | 0.0644      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110666      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.024911996 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.69       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0287     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.848       |
|    value_loss           | 0.026       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110876      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.026728824 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -2.35       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00278    |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00769    |
|    std                  | 0.847       |
|    value_loss           | 0.00621     |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.97 +/- 0.03
Episode length: 3592.40 +/- 10.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.03358829 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | -0.194     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0197     |
|    n_updates            | 1950       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.842      |
|    value_loss           | 0.00707    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -246     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112883   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.23e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 113107     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.01305933 |
|    clip_fraction        | 0.147      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | -2.23e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 212        |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.00432   |
|    std                  | 0.843      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 113321      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.018665824 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -6.12       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0331      |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.842       |
|    value_loss           | 0.0621      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 199         |
|    time_elapsed         | 113579      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.022606442 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -0.644      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0288     |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.00349    |
|    std                  | 0.842       |
|    value_loss           | 0.00982     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 200         |
|    time_elapsed         | 113895      |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.021634849 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.724      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0251     |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.838       |
|    value_loss           | 0.0293      |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.86 +/- 0.11
Episode length: 3072.60 +/- 246.99
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.07e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 410000     |
| train/                  |            |
|    approx_kl            | 0.02130232 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | -0.637     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00928    |
|    n_updates            | 2000       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.834      |
|    value_loss           | 0.0114     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.2e+03  |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115988   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.19e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 116288      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.013642886 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -5.48e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00836    |
|    std                  | 0.834       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 203         |
|    time_elapsed         | 116557      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.020356055 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -0.95       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0187      |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00755    |
|    std                  | 0.831       |
|    value_loss           | 0.0805      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 116804      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.026545476 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -1.02       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00962    |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0083     |
|    std                  | 0.832       |
|    value_loss           | 0.0133      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.18e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 117011      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.021810401 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.173      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00187     |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00894    |
|    std                  | 0.836       |
|    value_loss           | 0.0207      |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.98 +/- 0.04
Episode length: 3269.00 +/- 293.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.27e+03   |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.02552292 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.85      |
|    explained_variance   | -3.43      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00551    |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.00544   |
|    std                  | 0.833      |
|    value_loss           | 0.00758    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 119018   |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 207        |
|    time_elapsed         | 119224     |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.01530741 |
|    clip_fraction        | 0.161      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | -7.87e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 7.4        |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.00631   |
|    std                  | 0.833      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 208         |
|    time_elapsed         | 119430      |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.021243308 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -5.57       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00312     |
|    n_updates            | 2070        |
|    policy_gradient_loss | -0.00849    |
|    std                  | 0.834       |
|    value_loss           | 0.0702      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 119636      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.032618515 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -1.68       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0115     |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.839       |
|    value_loss           | 0.00953     |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.93 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.03127616 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | -4.88      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.046     |
|    n_updates            | 2090       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.837      |
|    value_loss           | 0.00523    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 121642   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 121848      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.014963137 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.000331    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.29        |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00719    |
|    std                  | 0.838       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 212        |
|    time_elapsed         | 122055     |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.01732997 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | -6.42      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.031     |
|    n_updates            | 2110       |
|    policy_gradient_loss | -0.00535   |
|    std                  | 0.843      |
|    value_loss           | 0.0262     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 122260      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.029513005 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -8.83       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0244     |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.838       |
|    value_loss           | 0.0133      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 122466      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.029484317 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -20.1       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0162     |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.00425    |
|    std                  | 0.84        |
|    value_loss           | 0.0113      |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.85 +/- 0.14
Episode length: 3596.20 +/- 9.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.03499028 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | -9.25      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0213    |
|    n_updates            | 2140       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.843      |
|    value_loss           | 0.00925    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 124473   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 124680      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.016790677 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.000141   |
|    learning_rate        | 0.0003      |
|    loss                 | 444         |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00694    |
|    std                  | 0.843       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 217         |
|    time_elapsed         | 124887      |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.028995994 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | -2.35       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00636    |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.00448    |
|    std                  | 0.843       |
|    value_loss           | 0.0804      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 218         |
|    time_elapsed         | 125092      |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.025355246 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.946      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0265      |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.843       |
|    value_loss           | 0.0234      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 125298      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.025202801 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.67       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0243     |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.843       |
|    value_loss           | 0.0361      |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.81 +/- 0.05
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.03054374 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.89      |
|    explained_variance   | -1.16      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0274    |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.84       |
|    value_loss           | 0.0125     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 127305   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 127510      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.021513335 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -0.00052    |
|    learning_rate        | 0.0003      |
|    loss                 | 419         |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00943    |
|    std                  | 0.84        |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 127716      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.023609051 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -1.97       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00519     |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.838       |
|    value_loss           | 0.351       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 127922      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.033112153 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.0117      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0462      |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.835       |
|    value_loss           | 0.231       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 128128      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.032503456 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.139       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00969    |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.827       |
|    value_loss           | 0.117       |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.86 +/- 0.06
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.029484574 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | -7.76       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0311     |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.827       |
|    value_loss           | 0.0188      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 130137   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 130345      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.010061989 |
|    clip_fraction        | 0.115       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -5.1e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 225         |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.00375    |
|    std                  | 0.827       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 130551      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.027998533 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -1.72       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0533      |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.826       |
|    value_loss           | 0.0542      |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.16e+03  |
|    ep_rew_mean          | -241      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 228       |
|    time_elapsed         | 130757    |
|    total_timesteps      | 466944    |
| train/                  |           |
|    approx_kl            | 0.0277063 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.7      |
|    explained_variance   | -2.65     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0263   |
|    n_updates            | 2270      |
|    policy_gradient_loss | -0.0113   |
|    std                  | 0.819     |
|    value_loss           | 0.00635   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | -236       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 130963     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.02229887 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.68      |
|    explained_variance   | -8.49      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0384    |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.82       |
|    value_loss           | 0.00805    |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.86 +/- 0.09
Episode length: 3596.40 +/- 9.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.028006207 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | -2.59       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00653    |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.00906    |
|    std                  | 0.826       |
|    value_loss           | 0.00283     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 132970   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 133178      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.016880652 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -7.92e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.04        |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.827       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 232         |
|    time_elapsed         | 133383      |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.027692717 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -1.96       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0807      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.826       |
|    value_loss           | 0.132       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 133589      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.026019204 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -1.41       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0246     |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.826       |
|    value_loss           | 0.0543      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 234         |
|    time_elapsed         | 133795      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.029446356 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | -1.96       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0314     |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.832       |
|    value_loss           | 0.0121      |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.82 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.03215392 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | -10.2      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0173    |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.833      |
|    value_loss           | 0.013      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 135801   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 136007      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.020030748 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 5.89e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.83        |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00863    |
|    std                  | 0.833       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 237         |
|    time_elapsed         | 136216      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.038276564 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -1.27       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0943      |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.0258     |
|    std                  | 0.831       |
|    value_loss           | 0.388       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 136424      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.029387368 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -1.17       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0165     |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.833       |
|    value_loss           | 0.0904      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 239         |
|    time_elapsed         | 136630      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.028222179 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -2.08       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00242     |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.833       |
|    value_loss           | 0.0306      |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.80 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.028669007 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -1.4        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0649     |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.832       |
|    value_loss           | 0.023       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 138637   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 241         |
|    time_elapsed         | 138842      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.023584675 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.000181    |
|    learning_rate        | 0.0003      |
|    loss                 | 338         |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0066     |
|    std                  | 0.833       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 139048     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.02731511 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | -0.0248    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.209      |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.828      |
|    value_loss           | 0.523      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 139254      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.029946357 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | -0.419      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0207      |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.825       |
|    value_loss           | 0.166       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 139460      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.026816674 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | 0.0903      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00352    |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.819       |
|    value_loss           | 0.0239      |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.84 +/- 0.02
Episode length: 3596.20 +/- 9.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.032227993 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | -1.14       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0138     |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.815       |
|    value_loss           | 0.0245      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 141468   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 141676      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.021628305 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | -0.000244   |
|    learning_rate        | 0.0003      |
|    loss                 | 270         |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00562    |
|    std                  | 0.815       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 141882      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.025343653 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.091       |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.814       |
|    value_loss           | 0.277       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | -236       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 248        |
|    time_elapsed         | 142088     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.02462549 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | -0.246     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0145     |
|    n_updates            | 2470       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.812      |
|    value_loss           | 0.0822     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 142293      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.035049543 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | 0.0188      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0183     |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.82        |
|    value_loss           | 0.0426      |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.82 +/- 0.06
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.03914938 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.67      |
|    explained_variance   | -0.121     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00592   |
|    n_updates            | 2490       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.821      |
|    value_loss           | 0.0527     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -240     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 144301   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -240        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 144509      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.013739651 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | -0.000633   |
|    learning_rate        | 0.0003      |
|    loss                 | 57.6        |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00745    |
|    std                  | 0.82        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -240        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 144715      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.030927194 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | -1.13       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0494      |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.815       |
|    value_loss           | 0.238       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 144920      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.035290748 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | -0.263      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0512      |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.813       |
|    value_loss           | 0.0662      |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.82 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.033340942 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | -0.492      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00993    |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.812       |
|    value_loss           | 0.0254      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -240     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 146927   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -240        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 147133      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.015601866 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.0011      |
|    learning_rate        | 0.0003      |
|    loss                 | 25.2        |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.811       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 256         |
|    time_elapsed         | 147339      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.026785946 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | -0.085      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.281       |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.813       |
|    value_loss           | 0.713       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 147544      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.045338422 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.0309      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0624      |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.812       |
|    value_loss           | 0.187       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 147750      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.032426514 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.55       |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0266      |
|    n_updates            | 2570        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.807       |
|    value_loss           | 0.0685      |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=-98.77 +/- 2.40
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.8       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.038973697 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.48       |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0182      |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.8         |
|    value_loss           | 0.0253      |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 149761   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 149969      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.015888274 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | -1.31e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.01        |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.00359    |
|    std                  | 0.801       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 150174      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.026644643 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | -6.58       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0177      |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.00379    |
|    std                  | 0.799       |
|    value_loss           | 0.0284      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 262        |
|    time_elapsed         | 150380     |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.02070878 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | -2.19      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0097    |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.796      |
|    value_loss           | 0.00709    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 150586      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.027809717 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -3.06       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00112     |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.00538    |
|    std                  | 0.797       |
|    value_loss           | 0.00636     |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.98 +/- 0.03
Episode length: 3596.60 +/- 7.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.035713375 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | -1.26       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0226     |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.792       |
|    value_loss           | 0.0137      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 152593   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 152801      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.018008124 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | 2.8e-06     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.19        |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.00211    |
|    std                  | 0.793       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 266         |
|    time_elapsed         | 153007      |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.034495648 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.104       |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.792       |
|    value_loss           | 0.179       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 153212      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.037308298 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.681       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0337      |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.00991    |
|    std                  | 0.791       |
|    value_loss           | 0.0561      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | -236       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 153418     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.03792629 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.35      |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0197     |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.00757   |
|    std                  | 0.787      |
|    value_loss           | 0.018      |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.87 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.023799174 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | -7.95       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0171     |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.783       |
|    value_loss           | 0.00139     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 155425   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 155634      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.015934024 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | -5.35e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00379    |
|    std                  | 0.783       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 271         |
|    time_elapsed         | 155841      |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.043004412 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.26       |
|    explained_variance   | -4.51       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0367     |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.0018     |
|    std                  | 0.777       |
|    value_loss           | 0.0761      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 156048      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.028812855 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | -0.864      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0227     |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.779       |
|    value_loss           | 0.0311      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 273         |
|    time_elapsed         | 156253      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.031335384 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0174      |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.777       |
|    value_loss           | 0.00329     |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.91 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.03812751 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | -2.12      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0256    |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0217    |
|    std                  | 0.772      |
|    value_loss           | 0.00695    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 158260   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 158466      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.013611598 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.000469    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.08        |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00169    |
|    std                  | 0.773       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 276         |
|    time_elapsed         | 158672      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.034034833 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -4.47       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00234    |
|    n_updates            | 2750        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.77        |
|    value_loss           | 0.0614      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 158878      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.031410705 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.16       |
|    explained_variance   | -7.79       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0149     |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.768       |
|    value_loss           | 0.00411     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 159083      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.029455226 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | -2.04       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0388     |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.77        |
|    value_loss           | 0.00561     |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.89 +/- 0.02
Episode length: 3594.60 +/- 9.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.03349577 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | -11.1      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0243    |
|    n_updates            | 2780       |
|    policy_gradient_loss | -0.00559   |
|    std                  | 0.772      |
|    value_loss           | 0.00144    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 161091   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 161299      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.019300625 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | 5.13e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.1        |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.00578    |
|    std                  | 0.772       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.16e+03  |
|    ep_rew_mean          | -241      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 281       |
|    time_elapsed         | 161505    |
|    total_timesteps      | 575488    |
| train/                  |           |
|    approx_kl            | 0.0276567 |
|    clip_fraction        | 0.276     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.17     |
|    explained_variance   | -0.245    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.069     |
|    n_updates            | 2800      |
|    policy_gradient_loss | -0.00741  |
|    std                  | 0.768     |
|    value_loss           | 0.0686    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 161711      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.033100344 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.16       |
|    explained_variance   | -0.972      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0406     |
|    n_updates            | 2810        |
|    policy_gradient_loss | -0.00895    |
|    std                  | 0.769       |
|    value_loss           | 0.0115      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | -236       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 161917     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.03920734 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | -1.19      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0596     |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.00774   |
|    std                  | 0.768      |
|    value_loss           | 0.00397    |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.70 +/- 0.41
Episode length: 3595.80 +/- 6.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.028381353 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | -0.704      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0346     |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.765       |
|    value_loss           | 0.00639     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 163925   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 164133      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.016896434 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | -8.46e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.96e+03    |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.000759   |
|    std                  | 0.766       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 164339     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.02709129 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | -5.44      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0235    |
|    n_updates            | 2850       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.771      |
|    value_loss           | 0.0607     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | -236       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 164545     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.02117006 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | -0.949     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0065     |
|    n_updates            | 2860       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.774      |
|    value_loss           | 0.0194     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 288         |
|    time_elapsed         | 164751      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.021508273 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | -1.67       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0233     |
|    n_updates            | 2870        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.773       |
|    value_loss           | 0.00921     |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.96 +/- 0.05
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.018555803 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -0.00549    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0138      |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.00484    |
|    std                  | 0.772       |
|    value_loss           | 0.00422     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 166758   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 166966      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.018408764 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -0.000126   |
|    learning_rate        | 0.0003      |
|    loss                 | 65.7        |
|    n_updates            | 2890        |
|    policy_gradient_loss | -0.000942   |
|    std                  | 0.772       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 291         |
|    time_elapsed         | 167172      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.028166268 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -7.96       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0103     |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.00181    |
|    std                  | 0.776       |
|    value_loss           | 0.0216      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 292         |
|    time_elapsed         | 167379      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.024209656 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | -0.136      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0246     |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.778       |
|    value_loss           | 0.0059      |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.88 +/- 0.09
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.04900217 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.22      |
|    explained_variance   | -0.533     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0267    |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.773      |
|    value_loss           | 0.0163     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 169386   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 169593      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.022710726 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 8.1e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.12        |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.00685    |
|    std                  | 0.773       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 295         |
|    time_elapsed         | 169798      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.029086702 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -1.95       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0168     |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.00123    |
|    std                  | 0.774       |
|    value_loss           | 0.0222      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 170007     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.07116741 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.2       |
|    explained_variance   | -0.0401    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0187    |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.0223    |
|    std                  | 0.771      |
|    value_loss           | 0.0651     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.17e+03   |
|    ep_rew_mean          | -236       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 170213     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.03307974 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | -1.33      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0129    |
|    n_updates            | 2960       |
|    policy_gradient_loss | -0.0153    |
|    std                  | 0.766      |
|    value_loss           | 0.0131     |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.93 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.04528171 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.14      |
|    explained_variance   | -1.13      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0281    |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.769      |
|    value_loss           | 0.0154     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 172220   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 172427      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.015432012 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.000125    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.35        |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.768       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.16e+03   |
|    ep_rew_mean          | -241       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 172633     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.03832172 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.17      |
|    explained_variance   | -0.6       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0679     |
|    n_updates            | 2990       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.773      |
|    value_loss           | 0.167      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 172838      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.042486157 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -0.729      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0115      |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.772       |
|    value_loss           | 0.0532      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.17e+03    |
|    ep_rew_mean          | -236        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 173044      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.038283646 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | -1.49       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0172     |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.773       |
|    value_loss           | 0.0292      |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.84 +/- 0.04
Episode length: 3597.80 +/- 6.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.03857403 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | -3.91      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0109     |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.772      |
|    value_loss           | 0.0103     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.16e+03 |
|    ep_rew_mean     | -241     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 175051   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 175259      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.019728288 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -4.21e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.00535    |
|    std                  | 0.771       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.16e+03  |
|    ep_rew_mean          | -241      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 175465    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 0.0290233 |
|    clip_fraction        | 0.253     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.16     |
|    explained_variance   | -4.59     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.00551  |
|    n_updates            | 3040      |
|    policy_gradient_loss | -0.0113   |
|    std                  | 0.769     |
|    value_loss           | 0.131     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.16e+03    |
|    ep_rew_mean          | -241        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 306         |
|    time_elapsed         | 175672      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.028871132 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -2.23       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0168     |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.772       |
|    value_loss           | 0.0284      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.2e+03    |
|    ep_rew_mean          | -252       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 175878     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.04159213 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.17      |
|    explained_variance   | -1.59      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0264    |
|    n_updates            | 3060       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.77       |
|    value_loss           | 0.0139     |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.93 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.03134016 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | -6.61      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0355    |
|    n_updates            | 3070       |
|    policy_gradient_loss | -0.024     |
|    std                  | 0.771      |
|    value_loss           | 0.00459    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.2e+03  |
|    ep_rew_mean     | -252     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 177884   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 178091      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.022207184 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.000113    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.04e+03    |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.772       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.2e+03    |
|    ep_rew_mean          | -252       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 178301     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.03453786 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | -1.25      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0727     |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.77       |
|    value_loss           | 0.209      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.2e+03     |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 178507      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.027283974 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | -0.0588     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0245     |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.774       |
|    value_loss           | 0.0538      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 178713      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.031378813 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -0.648      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0204     |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.774       |
|    value_loss           | 0.0156      |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.90 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.030878985 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -1.06       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00371     |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.769       |
|    value_loss           | 0.00532     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.2e+03  |
|    ep_rew_mean     | -252     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 180720   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.2e+03    |
|    ep_rew_mean          | -252       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 180926     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.02042593 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | -6.35e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 8.32       |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.00347   |
|    std                  | 0.77       |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 315         |
|    time_elapsed         | 181132      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.033262413 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -0.0539     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0542      |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.772       |
|    value_loss           | 0.0662      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 181337      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.024746869 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -0.81       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0108     |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.0024     |
|    std                  | 0.769       |
|    value_loss           | 0.0119      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.22e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 317         |
|    time_elapsed         | 181543      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.036359154 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.0456      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00209     |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.763       |
|    value_loss           | 0.0123      |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.94 +/- 0.04
Episode length: 3595.80 +/- 10.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.04615899 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | -0.745     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00901   |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0056     |
|    std                  | 0.761      |
|    value_loss           | 0.00492    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.21e+03 |
|    ep_rew_mean     | -256     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 183550   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.21e+03    |
|    ep_rew_mean          | -256        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 183758      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.009718522 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | -0.000175   |
|    learning_rate        | 0.0003      |
|    loss                 | 871         |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.00577    |
|    std                  | 0.762       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 320         |
|    time_elapsed         | 183964      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.021408493 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | 0.0551      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.101       |
|    n_updates            | 3190        |
|    policy_gradient_loss | -0.00381    |
|    std                  | 0.765       |
|    value_loss           | 0.392       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 184170      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.027935937 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | -0.0237     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00737    |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.00458    |
|    std                  | 0.766       |
|    value_loss           | 0.075       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 322         |
|    time_elapsed         | 184376      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.029986762 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | -1.05       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0281      |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.00763    |
|    std                  | 0.761       |
|    value_loss           | 0.00813     |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.90 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.036426947 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | -1.7        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0304     |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.756       |
|    value_loss           | 0.00532     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.23e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 186387   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.23e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 186595      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.014879194 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | -0.000218   |
|    learning_rate        | 0.0003      |
|    loss                 | 23.8        |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.00216    |
|    std                  | 0.756       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.24e+03   |
|    ep_rew_mean          | -252       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 186801     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.04955723 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.27       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0972     |
|    n_updates            | 3240       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.758      |
|    value_loss           | 0.239      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 326         |
|    time_elapsed         | 187007      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.028858466 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0067     |
|    n_updates            | 3250        |
|    policy_gradient_loss | -0.00288    |
|    std                  | 0.756       |
|    value_loss           | 0.111       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -252        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 327         |
|    time_elapsed         | 187213      |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.030061787 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0167      |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.00454    |
|    std                  | 0.755       |
|    value_loss           | 0.0511      |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.10 +/- 1.66
Episode length: 3593.40 +/- 15.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.04670889 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | 0.523      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0122     |
|    n_updates            | 3270       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.752      |
|    value_loss           | 0.0539     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.24e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 189221   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 189429      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.017312158 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | -0.00132    |
|    learning_rate        | 0.0003      |
|    loss                 | 12.9        |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.00737    |
|    std                  | 0.752       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.24e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 330         |
|    time_elapsed         | 189635      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.022430446 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0206     |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.753       |
|    value_loss           | 0.0393      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.27e+03   |
|    ep_rew_mean          | -253       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 189840     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.03808365 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.02      |
|    explained_variance   | 0.225      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0072    |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.758      |
|    value_loss           | 0.014      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.27e+03   |
|    ep_rew_mean          | -253       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 190046     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.02949123 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.05      |
|    explained_variance   | -0.154     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0512    |
|    n_updates            | 3310       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.758      |
|    value_loss           | 0.0177     |
----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.96 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.02462986 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | -0.159     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0193     |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.755      |
|    value_loss           | 0.00676    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 192053   |
|    total_timesteps | 681984   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.26e+03  |
|    ep_rew_mean          | -257      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 334       |
|    time_elapsed         | 192263    |
|    total_timesteps      | 684032    |
| train/                  |           |
|    approx_kl            | 0.0127877 |
|    clip_fraction        | 0.146     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.02     |
|    explained_variance   | 0.00106   |
|    learning_rate        | 0.0003    |
|    loss                 | 451       |
|    n_updates            | 3330      |
|    policy_gradient_loss | -0.00905  |
|    std                  | 0.755     |
|    value_loss           | 1.02e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 335         |
|    time_elapsed         | 192471      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.031732827 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.054       |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.00959    |
|    std                  | 0.755       |
|    value_loss           | 0.163       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 336         |
|    time_elapsed         | 192677      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.037326172 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | -1.31       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0324     |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.00499    |
|    std                  | 0.756       |
|    value_loss           | 0.000829    |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.94 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.023363601 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | 0.153       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.000442   |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.00705    |
|    std                  | 0.753       |
|    value_loss           | 0.0502      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 194683   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 194889      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.008608114 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | -5.39e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 551         |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00296    |
|    std                  | 0.753       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 339         |
|    time_elapsed         | 195095      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.030383285 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | -0.582      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0123      |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.755       |
|    value_loss           | 0.0292      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 195301      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.025701556 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | -0.82       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0775      |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.753       |
|    value_loss           | 0.105       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 195507      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.028621064 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.465       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0239     |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.00989    |
|    std                  | 0.753       |
|    value_loss           | 0.00638     |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.94 +/- 0.05
Episode length: 3594.60 +/- 12.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.020477485 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | 0.231       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0184      |
|    n_updates            | 3410        |
|    policy_gradient_loss | -0.00232    |
|    std                  | 0.751       |
|    value_loss           | 0.00366     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 197515   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 197723     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.02147343 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.98      |
|    explained_variance   | -0.000123  |
|    learning_rate        | 0.0003     |
|    loss                 | 4.66       |
|    n_updates            | 3420       |
|    policy_gradient_loss | -0.00322   |
|    std                  | 0.752      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 344         |
|    time_elapsed         | 197929      |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.022503756 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | -0.0375     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0178     |
|    n_updates            | 3430        |
|    policy_gradient_loss | -4.92e-05   |
|    std                  | 0.755       |
|    value_loss           | 0.0101      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 198135     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.02431598 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | -0.071     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0162    |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.000366  |
|    std                  | 0.759      |
|    value_loss           | 0.00946    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.27e+03   |
|    ep_rew_mean          | -253       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 346        |
|    time_elapsed         | 198341     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.03815186 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | -3.71      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0163    |
|    n_updates            | 3450       |
|    policy_gradient_loss | -0.00302   |
|    std                  | 0.761      |
|    value_loss           | 0.00657    |
----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.89 +/- 0.09
Episode length: 3594.60 +/- 8.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.027296875 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | -2.76       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0233     |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.76        |
|    value_loss           | 0.00474     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 200348   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 200556     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.01109301 |
|    clip_fraction        | 0.148      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | -3.46e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 102        |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.005     |
|    std                  | 0.76       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 349         |
|    time_elapsed         | 200762      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.019963231 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | -0.772      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0133      |
|    n_updates            | 3480        |
|    policy_gradient_loss | 0.0027      |
|    std                  | 0.759       |
|    value_loss           | 0.0129      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 350         |
|    time_elapsed         | 200968      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.022205949 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -0.194      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0149      |
|    n_updates            | 3490        |
|    policy_gradient_loss | 0.000705    |
|    std                  | 0.763       |
|    value_loss           | 0.00944     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 351         |
|    time_elapsed         | 201174      |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.019036971 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | -0.0237     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0201     |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.763       |
|    value_loss           | 0.00503     |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.95 +/- 0.07
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.029409457 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | -0.904      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0242     |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.00339    |
|    std                  | 0.766       |
|    value_loss           | 0.00412     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.26e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 203181   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 203387      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.012954824 |
|    clip_fraction        | 0.146       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 2.78e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 103         |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00431    |
|    std                  | 0.766       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.26e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 354         |
|    time_elapsed         | 203593      |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.027497236 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.443       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0715      |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.00694    |
|    std                  | 0.76        |
|    value_loss           | 0.464       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.26e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 203799     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.03170658 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | -0.414     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0265    |
|    n_updates            | 3540       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.757      |
|    value_loss           | 0.117      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 356         |
|    time_elapsed         | 204007      |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.025765032 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.4         |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0296     |
|    n_updates            | 3550        |
|    policy_gradient_loss | -0.00693    |
|    std                  | 0.756       |
|    value_loss           | 0.0189      |
-----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.98 +/- 0.04
Episode length: 3558.40 +/- 69.88
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.56e+03    |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.029823102 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | -0.271      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0239     |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.753       |
|    value_loss           | 0.0102      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.27e+03 |
|    ep_rew_mean     | -257     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 206016   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.27e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 206223      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.009306876 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 6.47e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 63.3        |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.000828   |
|    std                  | 0.754       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.27e+03   |
|    ep_rew_mean          | -257       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 359        |
|    time_elapsed         | 206429     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.01905723 |
|    clip_fraction        | 0.182      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.02      |
|    explained_variance   | -3.58      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00446   |
|    n_updates            | 3580       |
|    policy_gradient_loss | -0.00253   |
|    std                  | 0.753      |
|    value_loss           | 0.0205     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 206635      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.026835075 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | -0.782      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0146     |
|    n_updates            | 3590        |
|    policy_gradient_loss | -0.00411    |
|    std                  | 0.761       |
|    value_loss           | 0.0103      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.28e+03    |
|    ep_rew_mean          | -257        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 206840      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.024729531 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | -2.87       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0211     |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.00407    |
|    std                  | 0.758       |
|    value_loss           | 0.00633     |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.92 +/- 0.08
Episode length: 3550.00 +/- 52.17
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.55e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.01710412 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | -0.366     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.021     |
|    n_updates            | 3610       |
|    policy_gradient_loss | -0.0024    |
|    std                  | 0.763      |
|    value_loss           | 0.00362    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.3e+03  |
|    ep_rew_mean     | -258     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 208848   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.3e+03     |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 209056      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.016986905 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 1.2e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 16.9        |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.00456    |
|    std                  | 0.764       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.31e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 364         |
|    time_elapsed         | 209262      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.023107931 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | -1          |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0497     |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.00448    |
|    std                  | 0.76        |
|    value_loss           | 0.0295      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.32e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 209468     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.03178436 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | -0.0713    |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0175    |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.0163    |
|    std                  | 0.758      |
|    value_loss           | 0.0218     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.32e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 209674      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.036835857 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | -0.0531     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0111     |
|    n_updates            | 3650        |
|    policy_gradient_loss | -0.000221   |
|    std                  | 0.759       |
|    value_loss           | 0.0124      |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.91 +/- 0.12
Episode length: 3454.40 +/- 193.84
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.45e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.03190864 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.09      |
|    explained_variance   | -0.564     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00715   |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.00437   |
|    std                  | 0.762      |
|    value_loss           | 0.00682    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.32e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 211682   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 211889     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.01991117 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | -6.2e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.56       |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.00279   |
|    std                  | 0.762      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 369         |
|    time_elapsed         | 212095      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.034864135 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0713      |
|    n_updates            | 3680        |
|    policy_gradient_loss | -0.00735    |
|    std                  | 0.76        |
|    value_loss           | 0.0964      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 212301      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.033159282 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -1.07       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0395      |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.00482    |
|    std                  | 0.761       |
|    value_loss           | 0.0204      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 212507     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.03262034 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0202    |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.758      |
|    value_loss           | 0.017      |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.95 +/- 0.07
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.027082603 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.769       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0243     |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.00638    |
|    std                  | 0.758       |
|    value_loss           | 0.00656     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 214514   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 214722      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.012464449 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | -0.00144    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.03        |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00401    |
|    std                  | 0.758       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 214928     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.04342845 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.445      |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.00255    |
|    std                  | 0.759      |
|    value_loss           | 0.455      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 375         |
|    time_elapsed         | 215133      |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.036154814 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0763      |
|    n_updates            | 3740        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.757       |
|    value_loss           | 0.213       |
-----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.89 +/- 0.09
Episode length: 3595.60 +/- 10.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.026152167 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.167       |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.00732    |
|    std                  | 0.761       |
|    value_loss           | 0.246       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 217141   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 217349      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.015567081 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.00216     |
|    learning_rate        | 0.0003      |
|    loss                 | 369         |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.761       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 378         |
|    time_elapsed         | 217555      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.024351852 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | -0.0526     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0599      |
|    n_updates            | 3770        |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.761       |
|    value_loss           | 0.135       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 217761     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.02681102 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | 0.228      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0118     |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.00876   |
|    std                  | 0.759      |
|    value_loss           | 0.0283     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | -258      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 380       |
|    time_elapsed         | 217967    |
|    total_timesteps      | 778240    |
| train/                  |           |
|    approx_kl            | 0.0257011 |
|    clip_fraction        | 0.285     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.06     |
|    explained_variance   | 0.716     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0378   |
|    n_updates            | 3790      |
|    policy_gradient_loss | -0.00306  |
|    std                  | 0.759     |
|    value_loss           | 0.0139    |
---------------------------------------
Eval num_timesteps=780000, episode_reward=-99.94 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.036154356 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -0.0743     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.033      |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.762       |
|    value_loss           | 0.0105      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 219973   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 220179      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.021537084 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.000422    |
|    learning_rate        | 0.0003      |
|    loss                 | 441         |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.00392    |
|    std                  | 0.763       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | -258      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 383       |
|    time_elapsed         | 220385    |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 0.0203913 |
|    clip_fraction        | 0.212     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.13     |
|    explained_variance   | -7.17     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.00184   |
|    n_updates            | 3820      |
|    policy_gradient_loss | -0.0021   |
|    std                  | 0.766     |
|    value_loss           | 0.0288    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 220590      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.020909589 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | -1.8        |
|    learning_rate        | 0.0003      |
|    loss                 | -0.031      |
|    n_updates            | 3830        |
|    policy_gradient_loss | -0.00974    |
|    std                  | 0.767       |
|    value_loss           | 0.0104      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 220799     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.02302379 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.11      |
|    explained_variance   | 0.445      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0094     |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.00575   |
|    std                  | 0.76       |
|    value_loss           | 0.00576    |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.91 +/- 0.09
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.02585465 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.08      |
|    explained_variance   | -0.352     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0229    |
|    n_updates            | 3850       |
|    policy_gradient_loss | -0.00277   |
|    std                  | 0.761      |
|    value_loss           | 0.00616    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 222806   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 223012      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.018269246 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | -3.3e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 44.4        |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.00438    |
|    std                  | 0.762       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 388         |
|    time_elapsed         | 223217      |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.034730967 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.00306     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00551     |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.00215    |
|    std                  | 0.764       |
|    value_loss           | 0.00976     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 389         |
|    time_elapsed         | 223428      |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.029181924 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | -0.618      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.011      |
|    n_updates            | 3880        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.766       |
|    value_loss           | 0.0172      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 223635     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.01833882 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.16      |
|    explained_variance   | -0.00088   |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0067    |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.00149   |
|    std                  | 0.769      |
|    value_loss           | 0.0117     |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.96 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.037080303 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -6.96       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0118      |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.77        |
|    value_loss           | 0.0101      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 225641   |
|    total_timesteps | 800768   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -263         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 392          |
|    time_elapsed         | 225847       |
|    total_timesteps      | 802816       |
| train/                  |              |
|    approx_kl            | 0.0149808675 |
|    clip_fraction        | 0.194        |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.19        |
|    explained_variance   | -1.66e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 503          |
|    n_updates            | 3910         |
|    policy_gradient_loss | -0.0064      |
|    std                  | 0.772        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 393         |
|    time_elapsed         | 226053      |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.018311527 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | -23.2       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00288    |
|    n_updates            | 3920        |
|    policy_gradient_loss | -0.00552    |
|    std                  | 0.771       |
|    value_loss           | 0.0335      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 226259      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.030589186 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 2.32e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0148      |
|    n_updates            | 3930        |
|    policy_gradient_loss | 0.000571    |
|    std                  | 0.776       |
|    value_loss           | 0.00934     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 395         |
|    time_elapsed         | 226465      |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.021429071 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.26       |
|    explained_variance   | -0.301      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0625      |
|    n_updates            | 3940        |
|    policy_gradient_loss | 0.00315     |
|    std                  | 0.78        |
|    value_loss           | 0.00554     |
-----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.92 +/- 0.04
Episode length: 3593.80 +/- 14.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.024074282 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | -1.2e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0244     |
|    n_updates            | 3950        |
|    policy_gradient_loss | -0.00187    |
|    std                  | 0.783       |
|    value_loss           | 0.00474     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 228472   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 397         |
|    time_elapsed         | 228680      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.016410008 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 1.85e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.3         |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.00107    |
|    std                  | 0.783       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 398         |
|    time_elapsed         | 228886      |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.032086402 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | -0.00644    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0074      |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.00582    |
|    std                  | 0.784       |
|    value_loss           | 0.014       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 399         |
|    time_elapsed         | 229091      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.030663367 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | -3.37       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0188     |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.786       |
|    value_loss           | 0.0161      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 229297     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.03285125 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | -0.0803    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.056      |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0058    |
|    std                  | 0.785      |
|    value_loss           | 0.00757    |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.94 +/- 0.04
Episode length: 3591.40 +/- 19.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.018795121 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | -2.53       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0206      |
|    n_updates            | 4000        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.783       |
|    value_loss           | 0.0056      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 231305   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -263       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 231512     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.01693745 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.31      |
|    explained_variance   | 0          |
|    learning_rate        | 0.0003     |
|    loss                 | 452        |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.00153   |
|    std                  | 0.784      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 403         |
|    time_elapsed         | 231718      |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.025336122 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | -2.9e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0205     |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.00419    |
|    std                  | 0.791       |
|    value_loss           | 0.0142      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 404         |
|    time_elapsed         | 231924      |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.029084831 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.645       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0271     |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.787       |
|    value_loss           | 0.0197      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 232130     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.01745559 |
|    clip_fraction        | 0.157      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.00926   |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.794      |
|    value_loss           | 0.0076     |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.70 +/- 0.40
Episode length: 3204.80 +/- 224.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.2e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.023460798 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00297     |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.794       |
|    value_loss           | 0.0115      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 234138   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 407         |
|    time_elapsed         | 234345      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.017097078 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | -1.63e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.2         |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.00551    |
|    std                  | 0.794       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 408         |
|    time_elapsed         | 234551      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.035455994 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | -0.294      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00929    |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.00583    |
|    std                  | 0.801       |
|    value_loss           | 0.0177      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 409         |
|    time_elapsed         | 234756      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.026351029 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0341     |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.801       |
|    value_loss           | 0.0598      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 410         |
|    time_elapsed         | 234962      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.027184835 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | -0.141      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.027      |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.00964    |
|    std                  | 0.806       |
|    value_loss           | 0.0186      |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.95 +/- 0.08
Episode length: 3533.80 +/- 107.77
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.53e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.035618447 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -0.186      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000408    |
|    n_updates            | 4100        |
|    policy_gradient_loss | -0.00327    |
|    std                  | 0.8         |
|    value_loss           | 0.00529     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 236970   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 237178      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.019636549 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 1.11e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 46.1        |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00428    |
|    std                  | 0.8         |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 413         |
|    time_elapsed         | 237384      |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.034453705 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0393     |
|    n_updates            | 4120        |
|    policy_gradient_loss | -0.00784    |
|    std                  | 0.8         |
|    value_loss           | 0.0334      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 414         |
|    time_elapsed         | 237590      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.035275407 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0601      |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.798       |
|    value_loss           | 0.0303      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 415         |
|    time_elapsed         | 237796      |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.038897175 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | -2.21       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0141     |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.00463    |
|    std                  | 0.802       |
|    value_loss           | 0.0106      |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.91 +/- 0.09
Episode length: 3594.20 +/- 13.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.030132974 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | -0.0815     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00201     |
|    n_updates            | 4150        |
|    policy_gradient_loss | -0.000948   |
|    std                  | 0.802       |
|    value_loss           | 0.00514     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 239804   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 240013      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.016967718 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | 2.57e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 420         |
|    n_updates            | 4160        |
|    policy_gradient_loss | -0.00375    |
|    std                  | 0.8         |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 418         |
|    time_elapsed         | 240218      |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.019805504 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | -1.06       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0118     |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.8         |
|    value_loss           | 0.0728      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 419         |
|    time_elapsed         | 240427      |
|    total_timesteps      | 858112      |
| train/                  |             |
|    approx_kl            | 0.044181064 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | -0.204      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0251      |
|    n_updates            | 4180        |
|    policy_gradient_loss | -0.00359    |
|    std                  | 0.804       |
|    value_loss           | 0.015       |
-----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.84 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.024959229 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | -2.32       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0231     |
|    n_updates            | 4190        |
|    policy_gradient_loss | -0.00449    |
|    std                  | 0.809       |
|    value_loss           | 0.0127      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 242434   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -263       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 242640     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.01895899 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | -3.58e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 566        |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.00164   |
|    std                  | 0.81       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 422         |
|    time_elapsed         | 242850      |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.023415562 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | -0.0124     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0132      |
|    n_updates            | 4210        |
|    policy_gradient_loss | -0.00469    |
|    std                  | 0.808       |
|    value_loss           | 0.0299      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 423         |
|    time_elapsed         | 243059      |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.020813668 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | -0.00201    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0156      |
|    n_updates            | 4220        |
|    policy_gradient_loss | 0.00107     |
|    std                  | 0.812       |
|    value_loss           | 0.0289      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 424         |
|    time_elapsed         | 243265      |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.027881686 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | -0.00115    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0209      |
|    n_updates            | 4230        |
|    policy_gradient_loss | 0.00387     |
|    std                  | 0.816       |
|    value_loss           | 0.0126      |
-----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.90 +/- 0.05
Episode length: 3593.20 +/- 15.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.027138192 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | -0.798      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0198     |
|    n_updates            | 4240        |
|    policy_gradient_loss | -0.000119   |
|    std                  | 0.823       |
|    value_loss           | 0.00861     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 245273   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 426         |
|    time_elapsed         | 245480      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.014159322 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -8.13e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 20.7        |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.00327    |
|    std                  | 0.825       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 427         |
|    time_elapsed         | 245686      |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.028248142 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | -0.0578     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0062     |
|    n_updates            | 4260        |
|    policy_gradient_loss | -0.000664   |
|    std                  | 0.823       |
|    value_loss           | 0.0244      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 428         |
|    time_elapsed         | 245892      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.015959647 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.0127     |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00495    |
|    n_updates            | 4270        |
|    policy_gradient_loss | -0.00097    |
|    std                  | 0.834       |
|    value_loss           | 0.0183      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 246098     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.02014511 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | -0.00715   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0109     |
|    n_updates            | 4280       |
|    policy_gradient_loss | -0.000538  |
|    std                  | 0.835      |
|    value_loss           | 0.00991    |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.92 +/- 0.03
Episode length: 3594.00 +/- 14.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.02299771 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | -15.2      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0156    |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.835      |
|    value_loss           | 0.0306     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 248106   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 248314      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.011235811 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 1.07e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.3         |
|    n_updates            | 4300        |
|    policy_gradient_loss | 0.000466    |
|    std                  | 0.836       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 432         |
|    time_elapsed         | 248520      |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.018206155 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -4.77e-07   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0159      |
|    n_updates            | 4310        |
|    policy_gradient_loss | 0.00218     |
|    std                  | 0.841       |
|    value_loss           | 0.038       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 433        |
|    time_elapsed         | 248725     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.03446078 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0303    |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.0019    |
|    std                  | 0.845      |
|    value_loss           | 0.0501     |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 248931     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.02856369 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.94      |
|    explained_variance   | -0.0402    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0293     |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.000585  |
|    std                  | 0.845      |
|    value_loss           | 0.012      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.96 +/- 0.04
Episode length: 3594.20 +/- 13.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.030196434 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.561       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.000118    |
|    n_updates            | 4340        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.845       |
|    value_loss           | 0.0132      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 250939   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 251147      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.018632472 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.00191     |
|    learning_rate        | 0.0003      |
|    loss                 | 535         |
|    n_updates            | 4350        |
|    policy_gradient_loss | 0.000808    |
|    std                  | 0.844       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 251353     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.02030305 |
|    clip_fraction        | 0.168      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | -0.814     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.00248    |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.00821    |
|    std                  | 0.84       |
|    value_loss           | 0.0337     |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | -258      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 438       |
|    time_elapsed         | 251563    |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.0239832 |
|    clip_fraction        | 0.187     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.88     |
|    explained_variance   | 0.572     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0405   |
|    n_updates            | 4370      |
|    policy_gradient_loss | -0.0163   |
|    std                  | 0.838     |
|    value_loss           | 0.0294    |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 439         |
|    time_elapsed         | 251770      |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.025283903 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.000618   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00528     |
|    n_updates            | 4380        |
|    policy_gradient_loss | 0.000157    |
|    std                  | 0.842       |
|    value_loss           | 0.023       |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.88 +/- 0.03
Episode length: 3585.40 +/- 19.15
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.04245135 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.287      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0149     |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.841      |
|    value_loss           | 0.0579     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 253778   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 253986      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.020827275 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.00512     |
|    learning_rate        | 0.0003      |
|    loss                 | 536         |
|    n_updates            | 4400        |
|    policy_gradient_loss | -0.00969    |
|    std                  | 0.843       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 442         |
|    time_elapsed         | 254192      |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.027197395 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | -0.0153     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0216      |
|    n_updates            | 4410        |
|    policy_gradient_loss | 0.00426     |
|    std                  | 0.846       |
|    value_loss           | 0.0621      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 443         |
|    time_elapsed         | 254398      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.024083182 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0251      |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.842       |
|    value_loss           | 0.0648      |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | -258      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 444       |
|    time_elapsed         | 254604    |
|    total_timesteps      | 909312    |
| train/                  |           |
|    approx_kl            | 0.0240955 |
|    clip_fraction        | 0.184     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.91     |
|    explained_variance   | 0.751     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0262   |
|    n_updates            | 4430      |
|    policy_gradient_loss | -0.0211   |
|    std                  | 0.842     |
|    value_loss           | 0.0429    |
---------------------------------------
Eval num_timesteps=910000, episode_reward=-99.89 +/- 0.05
Episode length: 3551.40 +/- 48.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.55e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.024613127 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -0.86       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0181      |
|    n_updates            | 4440        |
|    policy_gradient_loss | -0.00525    |
|    std                  | 0.839       |
|    value_loss           | 0.016       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 256612   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 256821      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.013734741 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.014       |
|    learning_rate        | 0.0003      |
|    loss                 | 199         |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.00458    |
|    std                  | 0.839       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 447         |
|    time_elapsed         | 257027      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.029930623 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.596      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0254     |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.00953    |
|    std                  | 0.84        |
|    value_loss           | 0.00777     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 448         |
|    time_elapsed         | 257237      |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.027912768 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -4.06       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00786    |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.841       |
|    value_loss           | 0.00267     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 449         |
|    time_elapsed         | 257444      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.030572703 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.115       |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.84        |
|    value_loss           | 0.464       |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.84 +/- 0.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.028501792 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -0.173      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00156     |
|    n_updates            | 4490        |
|    policy_gradient_loss | -0.000184   |
|    std                  | 0.84        |
|    value_loss           | 0.0743      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 259451   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 259657      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.022734808 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.000269    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.25        |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.00155    |
|    std                  | 0.84        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 259863      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.025332129 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -1.51       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00337     |
|    n_updates            | 4510        |
|    policy_gradient_loss | -0.00706    |
|    std                  | 0.841       |
|    value_loss           | 0.178       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 453         |
|    time_elapsed         | 260068      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.039511137 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -0.0472     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00893     |
|    n_updates            | 4520        |
|    policy_gradient_loss | -0.00779    |
|    std                  | 0.848       |
|    value_loss           | 0.0652      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 260274     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.02423999 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0132    |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.847      |
|    value_loss           | 0.0473     |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.88 +/- 0.07
Episode length: 3585.60 +/- 19.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.02075424 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | -4.13      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0214     |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.00614   |
|    std                  | 0.848      |
|    value_loss           | 0.00118    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 262281   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 262490      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.009904421 |
|    clip_fraction        | 0.0994      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | -0.0403     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.9         |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.848       |
|    value_loss           | 978         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 457         |
|    time_elapsed         | 262696      |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.022706198 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | -10.7       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.018      |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.00644    |
|    std                  | 0.845       |
|    value_loss           | 0.0662      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -258       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 262907     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.02696028 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0073     |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.842      |
|    value_loss           | 0.0107     |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.88 +/- 0.07
Episode length: 3594.20 +/- 13.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.018456236 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0166      |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.00593    |
|    std                  | 0.844       |
|    value_loss           | 0.217       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 264917   |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 460         |
|    time_elapsed         | 265124      |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.014580652 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | -0.0309     |
|    learning_rate        | 0.0003      |
|    loss                 | 14.5        |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.00385    |
|    std                  | 0.846       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 461         |
|    time_elapsed         | 265335      |
|    total_timesteps      | 944128      |
| train/                  |             |
|    approx_kl            | 0.027713574 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.448       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0745      |
|    n_updates            | 4600        |
|    policy_gradient_loss | -0.00973    |
|    std                  | 0.844       |
|    value_loss           | 0.181       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 462         |
|    time_elapsed         | 265545      |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.021662623 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00535     |
|    n_updates            | 4610        |
|    policy_gradient_loss | -0.00501    |
|    std                  | 0.843       |
|    value_loss           | 0.0934      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -258        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 265753      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.024002496 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | -5.01       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0195     |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.00444    |
|    std                  | 0.847       |
|    value_loss           | 0.0724      |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.91 +/- 0.04
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.029853975 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00362     |
|    n_updates            | 4630        |
|    policy_gradient_loss | -0.00997    |
|    std                  | 0.846       |
|    value_loss           | 0.0461      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 267761   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 267968      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.019731851 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | -0.00119    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.3         |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.00409    |
|    std                  | 0.846       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 466         |
|    time_elapsed         | 268174      |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.040789172 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -1.37       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0249      |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.00195    |
|    std                  | 0.844       |
|    value_loss           | 0.0454      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 467         |
|    time_elapsed         | 268380      |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.035081103 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.39        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00498     |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.000732   |
|    std                  | 0.847       |
|    value_loss           | 0.0231      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 268586      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.026185384 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.874      |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0205     |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.00978    |
|    std                  | 0.851       |
|    value_loss           | 0.0144      |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.79 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.018854126 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0463     |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.85        |
|    value_loss           | 0.0404      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 270592   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -263       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 270798     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.01484563 |
|    clip_fraction        | 0.108      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.97      |
|    explained_variance   | -0.0147    |
|    learning_rate        | 0.0003     |
|    loss                 | 969        |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.00193   |
|    std                  | 0.85       |
|    value_loss           | 1.03e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 271007      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.018248236 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -0.329      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00391     |
|    n_updates            | 4700        |
|    policy_gradient_loss | 0.00215     |
|    std                  | 0.851       |
|    value_loss           | 0.0753      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -259       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 271216     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.02892968 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0165     |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.00707   |
|    std                  | 0.848      |
|    value_loss           | 0.0626     |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 473         |
|    time_elapsed         | 271421      |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.027914818 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | -2.56       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.042      |
|    n_updates            | 4720        |
|    policy_gradient_loss | -0.00509    |
|    std                  | 0.847       |
|    value_loss           | 0.0157      |
-----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.86 +/- 0.07
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.03075567 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | -2.1       |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0294    |
|    n_updates            | 4730       |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.85       |
|    value_loss           | 0.0144     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 273428   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 273634      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.011146424 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.0274      |
|    learning_rate        | 0.0003      |
|    loss                 | 123         |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.00471    |
|    std                  | 0.848       |
|    value_loss           | 958         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 476         |
|    time_elapsed         | 273840      |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.018138835 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | -19.7       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0158      |
|    n_updates            | 4750        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.843       |
|    value_loss           | 0.0187      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -259       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 274045     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.02066018 |
|    clip_fraction        | 0.196      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.0319     |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.00852   |
|    std                  | 0.844      |
|    value_loss           | 0.482      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 478         |
|    time_elapsed         | 274251      |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.031398788 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.384      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.053       |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.848       |
|    value_loss           | 0.311       |
-----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.87 +/- 0.07
Episode length: 3593.40 +/- 15.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.021438409 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -2.31       |
|    learning_rate        | 0.0003      |
|    loss                 | -0.0294     |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.00563    |
|    std                  | 0.848       |
|    value_loss           | 0.246       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 276259   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | -263       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 276468     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.00845281 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | 0.0361     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.38       |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.000242  |
|    std                  | 0.848      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 481         |
|    time_elapsed         | 276674      |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.023270117 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0681      |
|    n_updates            | 4800        |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.846       |
|    value_loss           | 0.435       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 482         |
|    time_elapsed         | 276880      |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.018330773 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0485      |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.847       |
|    value_loss           | 0.312       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 483         |
|    time_elapsed         | 277085      |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.028412817 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.00851    |
|    learning_rate        | 0.0003      |
|    loss                 | -0.00391    |
|    n_updates            | 4820        |
|    policy_gradient_loss | 0.00137     |
|    std                  | 0.856       |
|    value_loss           | 0.0886      |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.94 +/- 0.05
Episode length: 3593.80 +/- 14.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.025873296 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -1.68       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00196     |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.00363    |
|    std                  | 0.862       |
|    value_loss           | 0.0654      |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 279093   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -263        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 279302      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.015280936 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0002     |
|    learning_rate        | 0.0003      |
|    loss                 | 728         |
|    n_updates            | 4840        |
|    policy_gradient_loss | -0.0011     |
|    std                  | 0.862       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 486         |
|    time_elapsed         | 279508      |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.021568662 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0           |
|    learning_rate        | 0.0003      |
|    loss                 | 0.0415      |
|    n_updates            | 4850        |
|    policy_gradient_loss | 0.00201     |
|    std                  | 0.873       |
|    value_loss           | 0.0786      |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | -259        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 487         |
|    time_elapsed         | 279714      |
|    total_timesteps      | 997376      |
| train/                  |             |
|    approx_kl            | 0.025177298 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.00214     |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.00497    |
|    std                  | 0.872       |
|    value_loss           | 0.0574      |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | -259       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 279924     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.02905383 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -1.16      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0189    |
|    n_updates            | 4870       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.871      |
|    value_loss           | 0.0159     |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.99 +/- 0.12
Episode length: 3486.20 +/- 187.19
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.49e+03   |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.02379848 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.123     |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0178    |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.00211   |
|    std                  | 0.872      |
|    value_loss           | 0.0137     |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -263     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 281947   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-23_15-57-24_sparse_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 6:16:40 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-100.083556 -100.022836 -100.012894 -100.014783 -100.106672]
 [-100.113833 -100.0028    -99.870921  -99.990903  -99.846537]
 [ -99.914606  -99.833107  -99.905203  -99.891666  -99.835402]
 [ -99.872509  -99.964139  -99.853379  -99.991877  -99.906979]
 [ -99.966955  -99.81448  -100.014675  -99.833887  -99.783685]
 [ -99.869347  -99.917143  -99.766549 -100.031989  -99.736642]
 [ -99.902622  -99.927294  -99.961219  -99.936283  -99.773071]
 [ -99.901767  -99.994554  -99.998617  -99.897677  -99.959407]
 [-100.016848 -100.059626 -100.049927 -100.023765 -100.021014]
 [ -99.725961  -99.926891  -99.785981  -99.864622  -99.889773]
 [ -99.981577  -99.839585  -99.946797 -100.069245  -99.925825]
 [-100.211861  -99.923441  -99.985128 -100.102821  -99.962184]
 [ -99.905517 -100.017819  -99.953324  -99.852268  -99.918206]
 [ -99.966918  -99.913714  -99.940632  -99.911246  -99.942539]
 [-100.004142  -99.925996 -100.01757  -100.003606 -100.036037]
 [ -99.934513 -100.021426  -99.953812  -99.978562  -99.927127]
 [ -99.834875 -100.05646   -99.840537  -99.977543  -99.811417]
 [ -99.865965  -99.959612  -99.953741  -99.964822  -99.97878 ]
 [ -99.903002  -99.883876  -99.92158   -99.884562  -99.857291]
 [ -99.917678  -99.812132  -99.909763  -99.831569  -99.926874]
 [ -99.834686  -99.945719 -100.017729  -99.872796  -99.87247 ]
 [ -99.924233  -99.910846 -100.040993  -99.831734  -99.854126]
 [ -99.750293  -99.860263  -99.938456  -99.884825  -99.90355 ]
 [ -99.756209  -99.81497   -99.848978  -99.891991  -99.86032 ]
 [ -99.668675  -99.940751  -99.810068  -99.749984  -99.939129]
 [ -99.897199  -99.892593  -99.924222  -99.817035  -99.883082]
 [ -99.912193  -99.731118  -99.938375  -99.920168  -99.791195]
 [ -99.935737  -99.87672   -99.875087  -99.841084  -99.789364]
 [ -99.933587  -99.888279  -99.989476  -99.89887   -99.975452]
 [ -99.973722  -99.970079  -99.882785  -99.982775  -99.931868]
 [ -99.867148  -99.940997  -99.977004  -97.99629   -99.920423]
 [ -99.920702  -99.944223  -99.887092  -99.950056  -99.970472]
 [ -99.926068 -100.000697  -99.948409  -99.953798  -99.876133]
 [ -99.913691  -99.927293  -99.861079  -99.891708  -99.822881]
 [ -99.884818  -99.945086  -99.773877  -99.718618  -99.787509]
 [-100.007634  -99.886924  -99.931018  -99.973482  -99.901191]
 [ -99.931932  -99.976515  -99.964279  -99.974316  -99.950719]
 [ -99.748043  -99.871257  -99.75169   -99.908406  -99.989786]
 [ -99.706171 -100.001041  -99.802616  -99.968705  -99.950142]
 [ -99.959052  -99.980866  -99.939573 -100.02213   -99.92894 ]
 [ -99.783679  -99.953282  -99.751454  -99.793432 -100.030196]
 [ -99.976226 -100.015732 -100.037416  -99.941104  -99.948926]
 [ -99.970239  -99.906264  -99.952601  -99.917643  -99.919616]
 [-100.024323  -99.800254  -99.684107  -99.720554 -100.010294]
 [ -99.851347  -99.797683  -99.885856  -99.786473  -99.74238 ]
 [ -99.827904  -99.860962  -99.768032  -99.896076  -99.942731]
 [ -99.838207  -99.923814  -99.760305  -99.982584  -99.774934]
 [ -99.868006  -99.829315  -99.797144  -99.776008  -99.824752]
 [ -99.806364  -99.862293  -99.73636   -99.810239  -99.802501]
 [ -99.828122  -99.807409  -99.862498  -99.856182  -99.861253]
 [ -99.756156  -99.855851  -99.744726  -99.893597  -99.839859]
 [ -99.851784  -99.792831  -99.876423  -99.830761  -99.753463]
 [ -99.95798   -93.981492  -99.976184  -99.955171  -99.986408]
 [-100.011585 -100.01868   -99.933867  -99.962212  -99.989542]
 [ -99.808572  -99.890058  -99.900412  -99.85845   -99.870118]
 [ -99.928996  -99.86426   -99.865278  -99.934838  -99.979109]
 [ -99.912498  -99.855643  -99.866397  -99.900645  -99.916705]
 [ -99.85974   -99.962743  -99.933203  -98.881439  -99.868903]
 [-100.01712   -99.924019  -99.939014 -100.009207  -99.890871]
 [ -99.855861  -99.97428   -99.889596  -99.710887  -99.947436]
 [ -99.899679  -99.903867  -99.963729  -99.957156  -99.91921 ]
 [ -99.826591  -99.905304  -99.784405  -99.817963  -99.84954 ]
 [ -99.88891   -99.880632  -99.966225  -99.906758  -99.990865]
 [ -99.88243   -99.869796  -99.98197   -99.860165  -99.902833]
 [ -99.918607  -99.910315  -99.927088  -99.917296 -100.018048]
 [ -99.855377  -99.845085  -99.969884  -99.857313  -99.984301]
 [ -99.955546  -95.778691  -99.854253  -99.916402  -99.977295]
 [ -99.974615 -100.010142  -99.869324  -99.924801 -100.003771]
 [-100.029373  -99.977961  -99.883042  -99.845421  -99.946451]
 [ -99.961413  -99.99468   -99.980891  -99.858883  -99.909505]
 [-100.024395  -99.909206  -99.952798  -99.778832  -99.797208]
 [-100.015605  -99.987104  -99.942882  -99.976009  -99.808323]
 [ -99.933354  -99.974936  -99.933177 -100.01825  -100.044641]
 [ -99.971843  -99.915694 -100.008195  -99.782399  -99.931737]
 [ -99.915792 -100.031629  -99.810141 -100.045445  -99.727488]
 [ -99.807693 -100.014094  -99.956902  -99.998413  -99.981181]
 [ -99.968749  -99.905727  -99.759889  -99.809033  -99.997871]
 [ -99.953519  -99.957347  -99.950272  -99.893183  -99.94976 ]
 [ -99.741811  -99.989739  -99.996574  -99.873973  -99.939194]
 [ -99.932336 -100.013201  -99.971392  -99.894043 -100.012307]
 [ -99.938478  -99.890861  -99.948009  -99.859316  -99.973133]
 [ -99.9785    -99.88587   -99.917832  -99.996256  -99.901655]
 [-100.004782  -98.919795  -99.842174  -99.923861  -99.803184]
 [ -99.982324  -99.98763   -99.997695  -99.7937    -99.964169]
 [ -99.983033  -99.908992  -99.743391  -99.945621  -99.985519]
 [ -99.788311  -99.944341  -99.726634  -99.909941  -99.822251]
 [ -99.876589  -99.853404  -99.866479  -99.990984  -99.93566 ]
 [ -99.946701  -99.869     -99.939678  -99.93765   -99.894695]
 [ -99.991224  -99.987701  -99.967639  -99.873931  -99.961226]
 [ -99.902018  -99.824722  -99.892464  -99.851346  -99.915243]
 [ -99.863106  -99.861596  -99.851686  -99.995055  -99.883273]
 [ -99.780607  -99.741481  -99.943524  -99.969438  -99.755448]
 [ -99.96075   -99.961591  -99.820545  -99.799143  -99.881118]
 [ -99.908759  -99.877292  -99.884972  -99.984963  -99.76549 ]
 [ -99.890805  -99.878132  -99.978892  -99.873534  -99.910493]
 [ -99.75341   -99.758     -99.863347  -99.766132  -99.790266]
 [ -99.822837  -99.990246  -99.835239  -99.868018  -99.781843]
 [ -99.778111  -99.860003  -99.969818  -99.950709  -99.814113]
 [-100.017995  -99.916211  -99.902505  -99.977254  -99.876836]
 [-100.209695  -99.977626  -99.911552  -99.993893  -99.846186]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3580 3601]
 [3601 3600 3601 3601 3601]
 [3596 3601 3601 3601 3601]
 [3601 3583 3601 3601 3601]
 [3599 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3598 3586 3601]
 [3601 3601 3578 3601 3585]
 [3601 3601 3601 3601 3601]
 [3593 3601 3601 3601 3601]
 [3601 3601 3601 3594 3601]
 [3539 3556 3536 3524 3562]
 [3601 3601 3601 3576 3597]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3582 3596 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3595 3601 3601 3601]
 [3600 3601 3601 3601 3582]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3596 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3589]
 [3601 3596 3601 3601 3601]
 [3586 3601 3601 3601 3600]
 [3601 3601 3601 3592 3601]
 [3518 3264 3409 3307 3273]
 [3596 3601 3601 3601 3594]
 [3371 3315 3234 3160 3216]
 [3601 3601 3601 3601 3601]
 [3503 3601 3561 3543 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3588]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3582 3577]
 [2926 2896 2903 3093 3545]
 [3080 3207 2856 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3577]
 [3601 3600 3601 3601 3601]
 [3598 3601 3601 3601 3600]
 [3601 3601 3601 3578 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3577 3601 3601 3601]
 [3601 3601 3601 3601 3582]
 [3601 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3582 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3578 3592 3601 3601 3601]
 [3601 3584 3601 3599 3594]
 [3601 3601 3601 3582 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3585 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3575 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3563 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3570 3600 3601 3601]
 [3601 3601 3601 3588 3582]
 [3587 3601 3601 3601 3601]
 [3601 3421 3568 3601 3601]
 [3601 3563 3521 3464 3601]
 [3601 3350 3119 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3601 3574]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3565 3601 3601 3601]
 [3601 3553 3601 3601 3601]
 [3537 2922 3077 3097 3391]
 [3601 3601 3543 3323 3601]
 [3601 3601 3567 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3562 3601 3601 3601]
 [3566 3601 3601 3601 3601]
 [3601 3601 3601 3567 3601]
 [3601 3564 3601 3601 3560]
 [3601 3561 3515 3479 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3569 3601 3556]
 [3601 3601 3601 3567 3601]
 [3601 3601 3585 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3563 3601 3601 3601]
 [3601 3601 3565 3601 3601]
 [3114 3566 3601 3601 3549]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-23_15-57-24_sparse_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-23_15-57-24_sparse_1000000-steps_5-obs_ep-time-360.0/model
