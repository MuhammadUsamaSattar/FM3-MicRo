####################
/var/spool/slurmd/job5304883/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_14B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_1_example_explanation.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-24_14-26-37_llm_triton_qwen_14b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 1
 
 Explanation (Do not generate this in your output): The particle started at (17.25, -160.50) and ended at (16.50, -159.75), while the goal was at (5.75, -57.00). The distance to the goal at starting position was 104.13 while the distance at ending position was 103.31. Since, 103.31 < 104.13, the particle moved closer to the goal the score should be positive. But the magnitude of reduction in distance isn't very high so the magnitude should be low. Therfore, a score of 1 seems appropriate.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 6    |
|    iterations      | 1    |
|    time_elapsed    | 306  |
|    total_timesteps | 2048 |
-----------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.4e+03    |
|    ep_rew_mean          | -291       |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 2          |
|    time_elapsed         | 621        |
|    total_timesteps      | 4096       |
| train/                  |            |
|    approx_kl            | 0.00926424 |
|    clip_fraction        | 0.11       |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | -0.222     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.23       |
|    n_updates            | 10         |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.996      |
|    value_loss           | 3.88       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.38e+03    |
|    ep_rew_mean          | -299        |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 3           |
|    time_elapsed         | 939         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010153582 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.257       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.723       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.996       |
|    value_loss           | 3.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.39e+03    |
|    ep_rew_mean          | -299        |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 4           |
|    time_elapsed         | 1232        |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.008993534 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.308       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.736       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.992       |
|    value_loss           | 2.43        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.41 +/- 0.20
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 10000      |
| train/                  |            |
|    approx_kl            | 0.01033557 |
|    clip_fraction        | 0.0967     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.577      |
|    n_updates            | 40         |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.991      |
|    value_loss           | 1.99       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -343     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 3341     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -343         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 6            |
|    time_elapsed         | 3643         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0013641504 |
|    clip_fraction        | 0.000732     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00649     |
|    learning_rate        | 0.0003       |
|    loss                 | 29.3         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00264     |
|    std                  | 0.991        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.07e+03    |
|    ep_rew_mean          | -320        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 7           |
|    time_elapsed         | 3942        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.009441746 |
|    clip_fraction        | 0.094       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.48       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.733       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.99        |
|    value_loss           | 4.76        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.13e+03    |
|    ep_rew_mean          | -309        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 8           |
|    time_elapsed         | 4240        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.008902973 |
|    clip_fraction        | 0.0868      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.422      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.719       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.986       |
|    value_loss           | 1.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.17e+03    |
|    ep_rew_mean          | -295        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 9           |
|    time_elapsed         | 4536        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.011188716 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.104      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.34        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.988       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.32 +/- 0.06
Episode length: 3599.80 +/- 1.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.010732186 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0603     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.434       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.985       |
|    value_loss           | 1.2         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -306     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 6659     |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -294        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 6962        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.004504512 |
|    clip_fraction        | 0.0222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.000489    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.61e+03    |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.0053     |
|    std                  | 0.985       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -294        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 12          |
|    time_elapsed         | 7285        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.010719044 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -1.01       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.46        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.981       |
|    value_loss           | 3.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -278        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 7601        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.014483922 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00744     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.9         |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.981       |
|    value_loss           | 7.82        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.08e+03    |
|    ep_rew_mean          | -270        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 7923        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014388017 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.056       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.682       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.98        |
|    value_loss           | 4.36        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.03 +/- 0.19
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99       |
| time/                   |           |
|    total_timesteps      | 30000     |
| train/                  |           |
|    approx_kl            | 0.0178959 |
|    clip_fraction        | 0.224     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.2     |
|    explained_variance   | 0.0224    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.535     |
|    n_updates            | 140       |
|    policy_gradient_loss | -0.0286   |
|    std                  | 0.975     |
|    value_loss           | 1.17      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.92e+03 |
|    ep_rew_mean     | -199     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 10031    |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.92e+03    |
|    ep_rew_mean          | -199        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 10349       |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.009678252 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00144    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.18e+03    |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00341    |
|    std                  | 0.975       |
|    value_loss           | 5.57e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.94e+03   |
|    ep_rew_mean          | -197       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 17         |
|    time_elapsed         | 10652      |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.01903143 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | -1.56      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06       |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.026     |
|    std                  | 0.979      |
|    value_loss           | 1.97       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.97e+03    |
|    ep_rew_mean          | -192        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 10962       |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.023270557 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.0768     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.498       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0261     |
|    std                  | 0.97        |
|    value_loss           | 1.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.99e+03    |
|    ep_rew_mean          | -186        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 11293       |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.021090236 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0267      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0286     |
|    std                  | 0.966       |
|    value_loss           | 4.48        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-95.72 +/- 1.27
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -95.7       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.023466298 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0589      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.897       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0255     |
|    std                  | 0.965       |
|    value_loss           | 3.38        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.9e+03  |
|    ep_rew_mean     | -194     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 13424    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.92e+03    |
|    ep_rew_mean          | -185        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 13739       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.022243712 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00323     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73e+03    |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00712    |
|    std                  | 0.959       |
|    value_loss           | 1e+03       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.92e+03    |
|    ep_rew_mean          | -132        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 14063       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.024217762 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.238      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0256     |
|    std                  | 0.954       |
|    value_loss           | 3.88        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.93e+03    |
|    ep_rew_mean          | -123        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 14380       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.020986993 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.000251    |
|    learning_rate        | 0.0003      |
|    loss                 | 199         |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00847    |
|    std                  | 0.954       |
|    value_loss           | 4.44e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.9e+03    |
|    ep_rew_mean          | -76.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 24         |
|    time_elapsed         | 14711      |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.03029913 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.187     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.785      |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0309    |
|    std                  | 0.949      |
|    value_loss           | 1.98       |
----------------------------------------
Eval num_timesteps=50000, episode_reward=-21.53 +/- 6.39
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -21.5       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.011249489 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.000102    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.34        |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.948       |
|    value_loss           | 4.41e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.81e+03 |
|    ep_rew_mean     | -45.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 16856    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.83e+03     |
|    ep_rew_mean          | -40          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 17170        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0054312674 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | -0.0031      |
|    learning_rate        | 0.0003       |
|    loss                 | 5.64e+03     |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00564     |
|    std                  | 0.947        |
|    value_loss           | 5.5e+03      |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.84e+03    |
|    ep_rew_mean          | -35.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 17515       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.018167427 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.312      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0315     |
|    std                  | 0.941       |
|    value_loss           | 4.37        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.79e+03   |
|    ep_rew_mean          | 1.86       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 28         |
|    time_elapsed         | 17842      |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.02251276 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.0176    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03       |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0275    |
|    std                  | 0.933      |
|    value_loss           | 8.7        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.75e+03    |
|    ep_rew_mean          | 73.6        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 18192       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.008775648 |
|    clip_fraction        | 0.0976      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.000552    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.89e+03    |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.932       |
|    value_loss           | 4.42e+03    |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=248.66 +/- 60.34
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 249         |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.010000937 |
|    clip_fraction        | 0.0797      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00117     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.83e+03    |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00825    |
|    std                  | 0.931       |
|    value_loss           | 5.75e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.69e+03 |
|    ep_rew_mean     | 95.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 20318    |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.67e+03     |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 31           |
|    time_elapsed         | 20628        |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0023973456 |
|    clip_fraction        | 0.00259      |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.00182      |
|    learning_rate        | 0.0003       |
|    loss                 | 140          |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00463     |
|    std                  | 0.931        |
|    value_loss           | 5.32e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.67e+03     |
|    ep_rew_mean          | 129          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 32           |
|    time_elapsed         | 20959        |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0075328485 |
|    clip_fraction        | 0.0577       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.000596     |
|    learning_rate        | 0.0003       |
|    loss                 | 9.24e+03     |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00657     |
|    std                  | 0.929        |
|    value_loss           | 4.32e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.68e+03   |
|    ep_rew_mean          | 133        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 33         |
|    time_elapsed         | 21295      |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.02696133 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.168     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.67       |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.0332    |
|    std                  | 0.921      |
|    value_loss           | 5.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.66e+03   |
|    ep_rew_mean          | 163        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 34         |
|    time_elapsed         | 21624      |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.02001795 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.0066    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.47       |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0277    |
|    std                  | 0.914      |
|    value_loss           | 8.63       |
----------------------------------------
Eval num_timesteps=70000, episode_reward=585.25 +/- 448.68
Episode length: 2952.00 +/- 1124.42
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.95e+03    |
|    mean_reward          | 585         |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.010679141 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000471   |
|    learning_rate        | 0.0003      |
|    loss                 | 663         |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00755    |
|    std                  | 0.912       |
|    value_loss           | 4.45e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.67e+03 |
|    ep_rew_mean     | 159      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 23423    |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | 217        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 36         |
|    time_elapsed         | 23756      |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.01656862 |
|    clip_fraction        | 0.164      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.00311   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.34       |
|    n_updates            | 350        |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.91       |
|    value_loss           | 702        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.65e+03   |
|    ep_rew_mean          | 238        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 37         |
|    time_elapsed         | 24067      |
|    total_timesteps      | 75776      |
| train/                  |            |
|    approx_kl            | 0.00910611 |
|    clip_fraction        | 0.078      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -7.14e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 27.7       |
|    n_updates            | 360        |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.91       |
|    value_loss           | 8.5e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.52e+03    |
|    ep_rew_mean          | 348         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 24443       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.011894466 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 4.37e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 77.9        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.909       |
|    value_loss           | 4.23e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.47e+03     |
|    ep_rew_mean          | 394          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 39           |
|    time_elapsed         | 24797        |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0060005505 |
|    clip_fraction        | 0.0277       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.6        |
|    explained_variance   | 0.000994     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.31e+04     |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.011       |
|    std                  | 0.909        |
|    value_loss           | 2.49e+04     |
------------------------------------------
Eval num_timesteps=80000, episode_reward=1154.39 +/- 102.65
Episode length: 1309.40 +/- 863.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.31e+03   |
|    mean_reward          | 1.15e+03   |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.00844782 |
|    clip_fraction        | 0.106      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.00103    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.82e+03   |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.906      |
|    value_loss           | 1.21e+04   |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.39e+03 |
|    ep_rew_mean     | 436      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 25795    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.38e+03    |
|    ep_rew_mean          | 450         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 26126       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.009331919 |
|    clip_fraction        | 0.0673      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.000692   |
|    learning_rate        | 0.0003      |
|    loss                 | 200         |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.905       |
|    value_loss           | 1.62e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.39e+03    |
|    ep_rew_mean          | 453         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 26463       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.013123251 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.000348    |
|    learning_rate        | 0.0003      |
|    loss                 | 657         |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.899       |
|    value_loss           | 4.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.39e+03    |
|    ep_rew_mean          | 482         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 26803       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.024622293 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.232      |
|    learning_rate        | 0.0003      |
|    loss                 | 14.5        |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0231     |
|    std                  | 0.896       |
|    value_loss           | 33.9        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=1089.91 +/- 31.92
Episode length: 728.60 +/- 368.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 729         |
|    mean_reward          | 1.09e+03    |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.015958887 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.000373   |
|    learning_rate        | 0.0003      |
|    loss                 | 36.9        |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.895       |
|    value_loss           | 8.21e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.38e+03 |
|    ep_rew_mean     | 493      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 27499    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.31e+03    |
|    ep_rew_mean          | 539         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 27845       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.013338843 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00163     |
|    learning_rate        | 0.0003      |
|    loss                 | 436         |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.894       |
|    value_loss           | 4.05e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1.27e+03     |
|    ep_rew_mean          | 574          |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 46           |
|    time_elapsed         | 28197        |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0072733946 |
|    clip_fraction        | 0.0507       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.00403      |
|    learning_rate        | 0.0003       |
|    loss                 | 625          |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.0106      |
|    std                  | 0.892        |
|    value_loss           | 1.95e+04     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.26e+03    |
|    ep_rew_mean          | 592         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 28540       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.012636772 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.002      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.43e+04    |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.89        |
|    value_loss           | 1.53e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.24e+03    |
|    ep_rew_mean          | 619         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 28873       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.023326613 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.000796    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11e+03    |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.887       |
|    value_loss           | 7.66e+03    |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=1108.01 +/- 66.28
Episode length: 657.00 +/- 450.74
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 657          |
|    mean_reward          | 1.11e+03     |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0148947835 |
|    clip_fraction        | 0.175        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.00216      |
|    learning_rate        | 0.0003       |
|    loss                 | 5.88e+03     |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.0166      |
|    std                  | 0.882        |
|    value_loss           | 1.12e+04     |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.18e+03 |
|    ep_rew_mean     | 643      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 29535    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.15e+03    |
|    ep_rew_mean          | 666         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 29851       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.016247049 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.000547    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.99e+03    |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.878       |
|    value_loss           | 1.85e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.09e+03   |
|    ep_rew_mean          | 700        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 51         |
|    time_elapsed         | 30191      |
|    total_timesteps      | 104448     |
| train/                  |            |
|    approx_kl            | 0.02159525 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.000872   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.15e+03   |
|    n_updates            | 500        |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.879      |
|    value_loss           | 1.47e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.06e+03    |
|    ep_rew_mean          | 717         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 30519       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.014083533 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00178     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+04    |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.875       |
|    value_loss           | 2.48e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.03e+03    |
|    ep_rew_mean          | 749         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 30854       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.019785943 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00162     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15e+03    |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.873       |
|    value_loss           | 1.41e+04    |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=1027.73 +/- 16.48
Episode length: 92.80 +/- 53.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 92.8        |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.016652992 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00469    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.873       |
|    value_loss           | 7.49e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 999      |
|    ep_rew_mean     | 799      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 31235    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 948         |
|    ep_rew_mean          | 843         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31552       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.015534245 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -5.48e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.11e+03    |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.87        |
|    value_loss           | 1.07e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 916        |
|    ep_rew_mean          | 888        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 56         |
|    time_elapsed         | 31887      |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.01615332 |
|    clip_fraction        | 0.166      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.0038    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.73e+04   |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.865      |
|    value_loss           | 1.08e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 834         |
|    ep_rew_mean          | 958         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 32217       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.016848609 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000876   |
|    learning_rate        | 0.0003      |
|    loss                 | 74.2        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.862       |
|    value_loss           | 1.05e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 761         |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 32549       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.017205652 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00479     |
|    learning_rate        | 0.0003      |
|    loss                 | 992         |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.86        |
|    value_loss           | 2.05e+04    |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=1037.83 +/- 32.81
Episode length: 129.40 +/- 102.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 129         |
|    mean_reward          | 1.04e+03    |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.024895044 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.00405     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.97e+03    |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.86        |
|    value_loss           | 1.7e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 730      |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 32935    |
|    total_timesteps | 120832   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 672        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 60         |
|    time_elapsed         | 33280      |
|    total_timesteps      | 122880     |
| train/                  |            |
|    approx_kl            | 0.02322748 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.000204   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.26e+03   |
|    n_updates            | 590        |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.86       |
|    value_loss           | 7.01e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 646         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 33599       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.016632471 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.000197   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+04    |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.858       |
|    value_loss           | 2.38e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 603        |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 62         |
|    time_elapsed         | 33956      |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.01977522 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.00167   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.71e+03   |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.854      |
|    value_loss           | 1.01e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 524         |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34297       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.018459529 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0164     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.38e+03    |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.848       |
|    value_loss           | 1.65e+04    |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=1014.48 +/- 5.11
Episode length: 43.20 +/- 17.84
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 43.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.018443596 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.00523     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+04    |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.843       |
|    value_loss           | 3.3e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 494      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 34656    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 458         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 34974       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.021804798 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.00297     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+04    |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0224     |
|    std                  | 0.839       |
|    value_loss           | 2.91e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 444         |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 35299       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.029786276 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | -0.000931   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.3e+03     |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.836       |
|    value_loss           | 1.3e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 450         |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 35629       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.016410407 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.0409     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.17e+03    |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.833       |
|    value_loss           | 9.64e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 438         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 35942       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.013213436 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.00652     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26e+03    |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.834       |
|    value_loss           | 1.59e+04    |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=1020.74 +/- 7.10
Episode length: 55.20 +/- 18.99
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 55.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.01437149 |
|    clip_fraction        | 0.151      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.89      |
|    explained_variance   | 0.00605    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+04   |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.832      |
|    value_loss           | 1.92e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 418      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 36343    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 413         |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 36663       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.016737046 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.00491     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.92e+03    |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.829       |
|    value_loss           | 2.21e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 412         |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 37009       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.017979879 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | 0.00484     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03e+04    |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.824       |
|    value_loss           | 1.87e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 361        |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 72         |
|    time_elapsed         | 37366      |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.02243321 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | -0.00272   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.35e+04   |
|    n_updates            | 710        |
|    policy_gradient_loss | -0.00386   |
|    std                  | 0.823      |
|    value_loss           | 2.11e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 343         |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 37700       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.018955788 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 0.00305     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67e+04    |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.823       |
|    value_loss           | 3.01e+04    |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=1011.85 +/- 1.77
Episode length: 35.80 +/- 10.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.023678724 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | 0.000501    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.43e+03    |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0227     |
|    std                  | 0.821       |
|    value_loss           | 1.77e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 319      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 38068    |
|    total_timesteps | 151552   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 303        |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 75         |
|    time_elapsed         | 38409      |
|    total_timesteps      | 153600     |
| train/                  |            |
|    approx_kl            | 0.01762801 |
|    clip_fraction        | 0.145      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.74      |
|    explained_variance   | 0.00887    |
|    learning_rate        | 0.0003     |
|    loss                 | 1e+04      |
|    n_updates            | 740        |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.815      |
|    value_loss           | 3.63e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 278         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 76          |
|    time_elapsed         | 38768       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.030954033 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.00526     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.69e+04    |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.813       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 280        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 77         |
|    time_elapsed         | 39100      |
|    total_timesteps      | 157696     |
| train/                  |            |
|    approx_kl            | 0.01710679 |
|    clip_fraction        | 0.173      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.67      |
|    explained_variance   | 0.0105     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.12e+04   |
|    n_updates            | 760        |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.808      |
|    value_loss           | 3.41e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 285         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 78          |
|    time_elapsed         | 39434       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.018965643 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | 0.0018      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.81e+03    |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.804       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=804.96 +/- 441.15
Episode length: 769.20 +/- 1417.03
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 769         |
|    mean_reward          | 805         |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.015165285 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | 0.000854    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.19e+03    |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.801       |
|    value_loss           | 2.53e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 241      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 4        |
|    iterations      | 79       |
|    time_elapsed    | 40169    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 227         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 80          |
|    time_elapsed         | 40529       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.011898529 |
|    clip_fraction        | 0.102       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.0118      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+04    |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.799       |
|    value_loss           | 3.27e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 216        |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 81         |
|    time_elapsed         | 40871      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.01990134 |
|    clip_fraction        | 0.222      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.53      |
|    explained_variance   | 7.37e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.794      |
|    value_loss           | 3.01e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 214         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 82          |
|    time_elapsed         | 41193       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.028459474 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | 0.00253     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.76e+03    |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.788       |
|    value_loss           | 2.14e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 199         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 83          |
|    time_elapsed         | 41530       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.018048756 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | 0.00161     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+04    |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.785       |
|    value_loss           | 2.4e+04     |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=1013.46 +/- 4.17
Episode length: 35.00 +/- 8.37
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.018830152 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | 0.00288     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.64e+04    |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.781       |
|    value_loss           | 3.61e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 190      |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 84       |
|    time_elapsed    | 41903    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 189         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 85          |
|    time_elapsed         | 42243       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.019089576 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.35       |
|    explained_variance   | 0.00975     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.87e+04    |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.777       |
|    value_loss           | 4.11e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 189        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 86         |
|    time_elapsed         | 42595      |
|    total_timesteps      | 176128     |
| train/                  |            |
|    approx_kl            | 0.03063919 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.00546    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.86e+04   |
|    n_updates            | 850        |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.773      |
|    value_loss           | 2.8e+04    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 87          |
|    time_elapsed         | 42938       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.020014226 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | 0.00732     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.26e+03    |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.0234     |
|    std                  | 0.768       |
|    value_loss           | 2.05e+04    |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=1029.34 +/- 11.47
Episode length: 260.20 +/- 256.95
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 260         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.024160001 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.0114      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.63e+04    |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.765       |
|    value_loss           | 3.09e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 4        |
|    iterations      | 88       |
|    time_elapsed    | 43409    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 171         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 89          |
|    time_elapsed         | 43737       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.019553216 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.00226     |
|    learning_rate        | 0.0003      |
|    loss                 | 9.7e+03     |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.763       |
|    value_loss           | 2.73e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 170         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 90          |
|    time_elapsed         | 44058       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.020407148 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.00724     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.36e+04    |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.757       |
|    value_loss           | 3.65e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 172        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 91         |
|    time_elapsed         | 44396      |
|    total_timesteps      | 186368     |
| train/                  |            |
|    approx_kl            | 0.02749694 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.00548    |
|    learning_rate        | 0.0003     |
|    loss                 | 6.81e+03   |
|    n_updates            | 900        |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.754      |
|    value_loss           | 1.91e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 171         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 92          |
|    time_elapsed         | 44735       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.015037464 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.00988     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.13e+03    |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.751       |
|    value_loss           | 2.2e+04     |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=1043.42 +/- 14.65
Episode length: 113.40 +/- 42.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 113        |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.01728398 |
|    clip_fraction        | 0.164      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.05      |
|    explained_variance   | -0.00597   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.56e+04   |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.75       |
|    value_loss           | 3.5e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 180      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 4        |
|    iterations      | 93       |
|    time_elapsed    | 45132    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 179        |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 94         |
|    time_elapsed         | 45462      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.06060213 |
|    clip_fraction        | 0.509      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.03      |
|    explained_variance   | -0.00109   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.38e+03   |
|    n_updates            | 930        |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.749      |
|    value_loss           | 2.36e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 183         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 95          |
|    time_elapsed         | 45797       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.019590508 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.00139     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.1e+03     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.745       |
|    value_loss           | 1.87e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 182         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 96          |
|    time_elapsed         | 46146       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.016620142 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | 0.00459     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.29e+04    |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.743       |
|    value_loss           | 2.76e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 175         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 97          |
|    time_elapsed         | 46500       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.020886814 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | 0.00113     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+04    |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.74        |
|    value_loss           | 2.54e+04    |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=1012.63 +/- 4.33
Episode length: 36.80 +/- 11.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 36.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.014344607 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.00786     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.68e+04    |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.739       |
|    value_loss           | 3.14e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 183      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 98       |
|    time_elapsed    | 46856    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 178         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 99          |
|    time_elapsed         | 47186       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.018550336 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.00608     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.39e+03    |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.0202     |
|    std                  | 0.738       |
|    value_loss           | 2.28e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 172         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 100         |
|    time_elapsed         | 47514       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.016589947 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | 0.00247     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.37e+03    |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.736       |
|    value_loss           | 2.84e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 184        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 101        |
|    time_elapsed         | 47855      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.05004842 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | -0.000647  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.77e+03   |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.732      |
|    value_loss           | 1.99e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 184         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 102         |
|    time_elapsed         | 48201       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.014338918 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.0158      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.73        |
|    value_loss           | 2.6e+04     |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=1019.67 +/- 5.48
Episode length: 43.60 +/- 12.78
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 43.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.019654347 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.00144     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+04    |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.731       |
|    value_loss           | 1.78e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 181      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 103      |
|    time_elapsed    | 48552    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 173         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 104         |
|    time_elapsed         | 48894       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.020368494 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.81       |
|    explained_variance   | 0.00886     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+04    |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.727       |
|    value_loss           | 2.75e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 167         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 105         |
|    time_elapsed         | 49229       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.016288038 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | -0.0233     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+04    |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.723       |
|    value_loss           | 3.17e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 167         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 106         |
|    time_elapsed         | 49582       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.022990074 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.74       |
|    explained_variance   | -0.00134    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.73e+03    |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.0202     |
|    std                  | 0.721       |
|    value_loss           | 3.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 154         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 107         |
|    time_elapsed         | 49927       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.024278678 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.00407     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79e+04    |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.717       |
|    value_loss           | 2.9e+04     |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=1015.43 +/- 5.90
Episode length: 58.80 +/- 20.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 58.8        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.025265057 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.00707     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+04    |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.715       |
|    value_loss           | 3.02e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 161      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 4        |
|    iterations      | 108      |
|    time_elapsed    | 50289    |
|    total_timesteps | 221184   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 159        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 109        |
|    time_elapsed         | 50633      |
|    total_timesteps      | 223232     |
| train/                  |            |
|    approx_kl            | 0.02822867 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | 0.00349    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.46e+03   |
|    n_updates            | 1080       |
|    policy_gradient_loss | 0.000612   |
|    std                  | 0.716      |
|    value_loss           | 1.68e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 154         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 110         |
|    time_elapsed         | 50965       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.022174736 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.0118      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42e+04    |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.717       |
|    value_loss           | 2.58e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 141         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 111         |
|    time_elapsed         | 51311       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.026971497 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.0203      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.63e+03    |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.715       |
|    value_loss           | 2.36e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 142         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 112         |
|    time_elapsed         | 51657       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.009569071 |
|    clip_fraction        | 0.09        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | 0.0162      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.21e+04    |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.715       |
|    value_loss           | 4.36e+04    |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=1021.18 +/- 8.54
Episode length: 46.80 +/- 12.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 46.8       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.02159169 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.00871    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.95e+03   |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.711      |
|    value_loss           | 2.69e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 137      |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 113      |
|    time_elapsed    | 52025    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 119         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 114         |
|    time_elapsed         | 52388       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.010466805 |
|    clip_fraction        | 0.0886      |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.0072      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.92e+04    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.711       |
|    value_loss           | 3.91e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 111         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 115         |
|    time_elapsed         | 52732       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.027977517 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | 0.0108      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+04    |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.708       |
|    value_loss           | 3.17e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 111         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 116         |
|    time_elapsed         | 53067       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.020271594 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.0171      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+04    |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.707       |
|    value_loss           | 3.11e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 113         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 117         |
|    time_elapsed         | 53416       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.017741395 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | 0.0126      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+04    |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0202     |
|    std                  | 0.704       |
|    value_loss           | 3.89e+04    |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=1014.56 +/- 4.43
Episode length: 66.20 +/- 71.03
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 66.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.026899084 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.00652     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84e+04    |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00603    |
|    std                  | 0.704       |
|    value_loss           | 2.72e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 115      |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 118      |
|    time_elapsed    | 53794    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 119         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 119         |
|    time_elapsed         | 54139       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.024808172 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.00807     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+04    |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.704       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 120         |
|    time_elapsed         | 54474       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.016182337 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | 0.0201      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42e+04    |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.705       |
|    value_loss           | 3.34e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 117         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 121         |
|    time_elapsed         | 54810       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.022862438 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | 0.0154      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.81e+04    |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.704       |
|    value_loss           | 3.09e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 121         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 122         |
|    time_elapsed         | 55166       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.026737474 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.0146      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+04    |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.703       |
|    value_loss           | 2.83e+04    |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=1014.41 +/- 3.25
Episode length: 36.80 +/- 4.12
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 36.8      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 250000    |
| train/                  |           |
|    approx_kl            | 0.0210065 |
|    clip_fraction        | 0.19      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.51     |
|    explained_variance   | 0.02      |
|    learning_rate        | 0.0003    |
|    loss                 | 2.04e+04  |
|    n_updates            | 1220      |
|    policy_gradient_loss | -0.0229   |
|    std                  | 0.701     |
|    value_loss           | 3.07e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 114      |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 123      |
|    time_elapsed    | 55534    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 112         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 124         |
|    time_elapsed         | 55881       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.023966193 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | 0.0149      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.1e+04     |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.698       |
|    value_loss           | 3.15e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 115         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 125         |
|    time_elapsed         | 56235       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.019836225 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.44       |
|    explained_variance   | 0.00617     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.27e+04    |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 0.694       |
|    value_loss           | 3.07e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 122         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 126         |
|    time_elapsed         | 56537       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.024237849 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.0114      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.68e+04    |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.692       |
|    value_loss           | 2.48e+04    |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=1023.62 +/- 16.26
Episode length: 60.00 +/- 35.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 60         |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.02423026 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.00749    |
|    learning_rate        | 0.0003     |
|    loss                 | 7.54e+03   |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.689      |
|    value_loss           | 1.98e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 113      |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 127      |
|    time_elapsed    | 56891    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 116         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 128         |
|    time_elapsed         | 57218       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.017629443 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.35       |
|    explained_variance   | 0.027       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.72e+04    |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.687       |
|    value_loss           | 3.97e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 113         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 129         |
|    time_elapsed         | 57549       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.030947693 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.00106     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88e+04    |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.00587    |
|    std                  | 0.683       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 102         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 130         |
|    time_elapsed         | 57898       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.015484361 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | 0.00685     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76e+04    |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.682       |
|    value_loss           | 3.33e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 94.7        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 131         |
|    time_elapsed         | 58247       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.023571482 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.0261      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.71e+03    |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.68        |
|    value_loss           | 3.55e+04    |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=1015.90 +/- 3.23
Episode length: 41.00 +/- 10.04
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41          |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.014022486 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.0256      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.31e+04    |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.678       |
|    value_loss           | 3.38e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 95.7     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 132      |
|    time_elapsed    | 58592    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 92.1        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 133         |
|    time_elapsed         | 58919       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.021655016 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | 0.0172      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.03e+04    |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.674       |
|    value_loss           | 2.94e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.9        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 134         |
|    time_elapsed         | 59262       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.015655346 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.0132      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.675       |
|    value_loss           | 3.46e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 92.9        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 135         |
|    time_elapsed         | 59604       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.028210267 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.0305      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+04    |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.673       |
|    value_loss           | 3.56e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 85.6        |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 136         |
|    time_elapsed         | 59970       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.022513377 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | 0.0176      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+04    |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.67        |
|    value_loss           | 2.56e+04    |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=1016.89 +/- 7.40
Episode length: 41.60 +/- 20.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.017825896 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.00831     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.63e+04    |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.668       |
|    value_loss           | 3.55e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 82.8     |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 137      |
|    time_elapsed    | 60348    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.8        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 138         |
|    time_elapsed         | 60688       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.019709092 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.09       |
|    explained_variance   | 0.0236      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.664       |
|    value_loss           | 3.49e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 75.7        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 139         |
|    time_elapsed         | 61058       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.016254736 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | 0.0325      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.06e+04    |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.662       |
|    value_loss           | 4.02e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 73.8        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 140         |
|    time_elapsed         | 61418       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.024929482 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.03       |
|    explained_variance   | 0.0121      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.69e+03    |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.661       |
|    value_loss           | 3.18e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 71.9       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 141        |
|    time_elapsed         | 61760      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.01610836 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.01      |
|    explained_variance   | 0.0778     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+04   |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.659      |
|    value_loss           | 3.69e+04   |
----------------------------------------
Eval num_timesteps=290000, episode_reward=1011.58 +/- 1.35
Episode length: 31.00 +/- 6.93
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.028630346 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8          |
|    explained_variance   | 0.0417      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+04    |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.658       |
|    value_loss           | 3.62e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 71.8     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 142      |
|    time_elapsed    | 62116    |
|    total_timesteps | 290816   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 66.4       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 143        |
|    time_elapsed         | 62475      |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.04315525 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.0129     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.63e+04   |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.657      |
|    value_loss           | 3.75e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 64.7        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 144         |
|    time_elapsed         | 62852       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.027578073 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.98       |
|    explained_variance   | 0.0222      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.47e+04    |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.656       |
|    value_loss           | 3.77e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 61.1       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 145        |
|    time_elapsed         | 63199      |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.03960731 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.019      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.59e+04   |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.653      |
|    value_loss           | 3.92e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 66.4       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 146        |
|    time_elapsed         | 63532      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.01937132 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.0107     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.45e+04   |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.652      |
|    value_loss           | 3.85e+04   |
----------------------------------------
Eval num_timesteps=300000, episode_reward=1020.73 +/- 5.66
Episode length: 41.00 +/- 10.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41          |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.034840707 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.91       |
|    explained_variance   | 0.01        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+04    |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.65        |
|    value_loss           | 2.88e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 67.7     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 147      |
|    time_elapsed    | 63905    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 69.5        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 148         |
|    time_elapsed         | 64249       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.025460225 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.0355      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.43e+04    |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.646       |
|    value_loss           | 3.54e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 68.6       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 149        |
|    time_elapsed         | 64600      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.02386268 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.0362     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53e+04   |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.644      |
|    value_loss           | 3.32e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 70.4       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 150        |
|    time_elapsed         | 64950      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.03120699 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.81      |
|    explained_variance   | 0.037      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.06e+04   |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.642      |
|    value_loss           | 2.97e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 65.6       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 151        |
|    time_elapsed         | 65316      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.04322075 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.79      |
|    explained_variance   | 0.0206     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.52e+04   |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.641      |
|    value_loss           | 3.24e+04   |
----------------------------------------
Eval num_timesteps=310000, episode_reward=1011.52 +/- 1.67
Episode length: 27.00 +/- 6.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.019028341 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | 0.0243      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.15e+04    |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.0221     |
|    std                  | 0.638       |
|    value_loss           | 3.77e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 62.1     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 152      |
|    time_elapsed    | 65672    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.1        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 153         |
|    time_elapsed         | 66029       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.018248934 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.73       |
|    explained_variance   | 0.0256      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+04    |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.637       |
|    value_loss           | 3.41e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 61.2        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 154         |
|    time_elapsed         | 66387       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.021129437 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | 0.0182      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+04    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.635       |
|    value_loss           | 3.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59.7        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 155         |
|    time_elapsed         | 66755       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.020747969 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.7        |
|    explained_variance   | 0.0264      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.73e+04    |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.635       |
|    value_loss           | 3.46e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59.4        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 156         |
|    time_elapsed         | 67099       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.029369056 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.69       |
|    explained_variance   | 0.0231      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.633       |
|    value_loss           | 3.31e+04    |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=1013.46 +/- 4.15
Episode length: 27.60 +/- 6.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.02081933 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.0404     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.81e+04   |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.632      |
|    value_loss           | 3.17e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 56.8     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 157      |
|    time_elapsed    | 67472    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 158         |
|    time_elapsed         | 67839       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.054441452 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.0347      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.92e+04    |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.63        |
|    value_loss           | 3.73e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 54.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 159         |
|    time_elapsed         | 68200       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.029225742 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.62       |
|    explained_variance   | 0.0132      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+04     |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.627       |
|    value_loss           | 3.16e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 55.8       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 160        |
|    time_elapsed         | 68554      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.03857277 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.0517     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.36e+04   |
|    n_updates            | 1590       |
|    policy_gradient_loss | -0.00948   |
|    std                  | 0.627      |
|    value_loss           | 3.71e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.3        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 161         |
|    time_elapsed         | 68905       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.045674212 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.58       |
|    explained_variance   | 0.0229      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28e+04    |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.625       |
|    value_loss           | 2.83e+04    |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=1012.37 +/- 3.48
Episode length: 31.80 +/- 7.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.023637518 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | 0.0396      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.13e+04    |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.622       |
|    value_loss           | 3.03e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.8     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 162      |
|    time_elapsed    | 69282    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 58          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 163         |
|    time_elapsed         | 69629       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.030575281 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.53       |
|    explained_variance   | 0.0463      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.45e+04    |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.62        |
|    value_loss           | 3e+04       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 56.8        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 164         |
|    time_elapsed         | 69980       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.022841893 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.0529      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76e+04    |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.618       |
|    value_loss           | 3.11e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 59.5       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 165        |
|    time_elapsed         | 70342      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.02726618 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.48      |
|    explained_variance   | 0.0346     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.48e+04   |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.617      |
|    value_loss           | 2.88e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 57.4        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 166         |
|    time_elapsed         | 70690       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.017907048 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.46       |
|    explained_variance   | 0.0482      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+04    |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.616       |
|    value_loss           | 2.67e+04    |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=1014.20 +/- 4.71
Episode length: 30.60 +/- 9.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.023638705 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.088       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.82e+04    |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.613       |
|    value_loss           | 3.3e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 52       |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 167      |
|    time_elapsed    | 71068    |
|    total_timesteps | 342016   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 51.8      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 168       |
|    time_elapsed         | 71433     |
|    total_timesteps      | 344064    |
| train/                  |           |
|    approx_kl            | 0.0250091 |
|    clip_fraction        | 0.18      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.42     |
|    explained_variance   | 0.0486    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.47e+04  |
|    n_updates            | 1670      |
|    policy_gradient_loss | -0.0232   |
|    std                  | 0.611     |
|    value_loss           | 3.09e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 169         |
|    time_elapsed         | 71784       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.022341888 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.4        |
|    explained_variance   | 0.0318      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.66e+04    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.611       |
|    value_loss           | 2.95e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52         |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 170        |
|    time_elapsed         | 72139      |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.03360922 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.41      |
|    explained_variance   | 0.0249     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.8e+03    |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.612      |
|    value_loss           | 2.86e+04   |
----------------------------------------
Eval num_timesteps=350000, episode_reward=1015.84 +/- 8.42
Episode length: 36.40 +/- 18.99
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 36.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.016298123 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.39       |
|    explained_variance   | 0.0453      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+04    |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.609       |
|    value_loss           | 2.99e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 171      |
|    time_elapsed    | 72510    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 172         |
|    time_elapsed         | 72848       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.030023314 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | 0.0355      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54e+04    |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.608       |
|    value_loss           | 3.03e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 173         |
|    time_elapsed         | 73199       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.041209187 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.34       |
|    explained_variance   | 0.0142      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+04    |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.605       |
|    value_loss           | 2.71e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 174        |
|    time_elapsed         | 73555      |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.05403294 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.3       |
|    explained_variance   | 0.023      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53e+04   |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0277    |
|    std                  | 0.602      |
|    value_loss           | 2.68e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 49.2        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 175         |
|    time_elapsed         | 73901       |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.039417222 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.27       |
|    explained_variance   | 0.0622      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55e+04    |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.6         |
|    value_loss           | 2.9e+04     |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=1012.83 +/- 4.00
Episode length: 29.20 +/- 6.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.026432633 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.0243      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.43e+04    |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.599       |
|    value_loss           | 2.6e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 48.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 176      |
|    time_elapsed    | 74295    |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 47.9       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 177        |
|    time_elapsed         | 74653      |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.01992263 |
|    clip_fraction        | 0.14       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | 0.0388     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.48e+04   |
|    n_updates            | 1760       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.598      |
|    value_loss           | 2.77e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 178         |
|    time_elapsed         | 75025       |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.020901278 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.0263      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.69e+03    |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0238     |
|    std                  | 0.597       |
|    value_loss           | 2.67e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 179        |
|    time_elapsed         | 75399      |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.05519275 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.0311     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.55e+04   |
|    n_updates            | 1780       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.594      |
|    value_loss           | 2.93e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48         |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 180        |
|    time_elapsed         | 75756      |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.02900181 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.0136     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.99e+03   |
|    n_updates            | 1790       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.593      |
|    value_loss           | 2.47e+04   |
----------------------------------------
Eval num_timesteps=370000, episode_reward=1014.79 +/- 5.97
Episode length: 29.80 +/- 10.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.021787982 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.15       |
|    explained_variance   | 0.0297      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+04    |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.592       |
|    value_loss           | 2.48e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 48.8     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 181      |
|    time_elapsed    | 76124    |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 182        |
|    time_elapsed         | 76490      |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.03428632 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.0325     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.55e+04   |
|    n_updates            | 1810       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.591      |
|    value_loss           | 2.45e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 183         |
|    time_elapsed         | 76881       |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.020800235 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | 0.0307      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24e+04    |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.589       |
|    value_loss           | 2.13e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.6        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 184         |
|    time_elapsed         | 77235       |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.021637082 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.11       |
|    explained_variance   | 0.0483      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.92e+04    |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.589       |
|    value_loss           | 2.52e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 185        |
|    time_elapsed         | 77568      |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.02488821 |
|    clip_fraction        | 0.17       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | 0.0344     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25e+04   |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.588      |
|    value_loss           | 2.34e+04   |
----------------------------------------
Eval num_timesteps=380000, episode_reward=1014.29 +/- 6.76
Episode length: 34.40 +/- 9.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 34.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.037738867 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | 0.0534      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+04    |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.589       |
|    value_loss           | 2.35e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.6     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 186      |
|    time_elapsed    | 77948    |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 187         |
|    time_elapsed         | 78320       |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.033181623 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.08       |
|    explained_variance   | 0.0549      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.85e+03    |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.586       |
|    value_loss           | 2.4e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.9        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 188         |
|    time_elapsed         | 78703       |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.026052698 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.05       |
|    explained_variance   | 0.0579      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.4e+04     |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.583       |
|    value_loss           | 2.37e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 46.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 189         |
|    time_elapsed         | 79066       |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.022033323 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.02       |
|    explained_variance   | 0.04        |
|    learning_rate        | 0.0003      |
|    loss                 | 8.03e+03    |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.582       |
|    value_loss           | 2e+04       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 47.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 190        |
|    time_elapsed         | 79426      |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.02068659 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7         |
|    explained_variance   | 0.0559     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.92e+03   |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.581      |
|    value_loss           | 2.15e+04   |
----------------------------------------
Eval num_timesteps=390000, episode_reward=1016.36 +/- 4.43
Episode length: 32.40 +/- 10.89
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 32.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.021919146 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.0352      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+04    |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.578       |
|    value_loss           | 1.96e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 191      |
|    time_elapsed    | 79781    |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 192         |
|    time_elapsed         | 80130       |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.028181821 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.95       |
|    explained_variance   | 0.127       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+04    |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.577       |
|    value_loss           | 2.15e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 43.5      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 193       |
|    time_elapsed         | 80466     |
|    total_timesteps      | 395264    |
| train/                  |           |
|    approx_kl            | 0.0346082 |
|    clip_fraction        | 0.167     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.94     |
|    explained_variance   | 0.0665    |
|    learning_rate        | 0.0003    |
|    loss                 | 8.18e+03  |
|    n_updates            | 1920      |
|    policy_gradient_loss | -0.0173   |
|    std                  | 0.576     |
|    value_loss           | 1.96e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 41.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 194         |
|    time_elapsed         | 80831       |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.026862107 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 0.0825      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+04     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.576       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 195         |
|    time_elapsed         | 81181       |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.022072777 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.92       |
|    explained_variance   | 0.0503      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.9e+03     |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.575       |
|    value_loss           | 2.07e+04    |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=1023.61 +/- 13.86
Episode length: 46.60 +/- 26.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 46.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.029235411 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.91       |
|    explained_variance   | 0.0498      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.14e+03    |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0224     |
|    std                  | 0.574       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 42.8     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 196      |
|    time_elapsed    | 81531    |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.9       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 197        |
|    time_elapsed         | 81914      |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.03864252 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | 0.0474     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.77e+03   |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.571      |
|    value_loss           | 1.77e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 198         |
|    time_elapsed         | 82257       |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.020858748 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | 0.0412      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03e+04    |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.57        |
|    value_loss           | 1.86e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 199         |
|    time_elapsed         | 82605       |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.029333126 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.84       |
|    explained_variance   | 0.0775      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.31e+03    |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.569       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 41          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 200         |
|    time_elapsed         | 82957       |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.018290346 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.82       |
|    explained_variance   | 0.0373      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+04    |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.567       |
|    value_loss           | 1.7e+04     |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=1011.24 +/- 1.18
Episode length: 30.20 +/- 7.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.023991056 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.8        |
|    explained_variance   | 0.0694      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.08e+03    |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.566       |
|    value_loss           | 1.83e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 201      |
|    time_elapsed    | 83328    |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 202        |
|    time_elapsed         | 83673      |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.03624873 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.0535     |
|    learning_rate        | 0.0003     |
|    loss                 | 8.43e+03   |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.564      |
|    value_loss           | 1.64e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 203         |
|    time_elapsed         | 83999       |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.028803768 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.75       |
|    explained_variance   | 0.0877      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.17e+03    |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.563       |
|    value_loss           | 1.74e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 204         |
|    time_elapsed         | 84356       |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.023346502 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.74       |
|    explained_variance   | 0.0738      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.47e+03    |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.562       |
|    value_loss           | 1.58e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 205         |
|    time_elapsed         | 84703       |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.041055802 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.73       |
|    explained_variance   | 0.0855      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.62e+03    |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.561       |
|    value_loss           | 1.54e+04    |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=1014.06 +/- 7.10
Episode length: 28.20 +/- 10.57
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.029673362 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.72       |
|    explained_variance   | 0.1         |
|    learning_rate        | 0.0003      |
|    loss                 | 6.19e+03    |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.561       |
|    value_loss           | 1.66e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 206      |
|    time_elapsed    | 85079    |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 207        |
|    time_elapsed         | 85410      |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.03062418 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.72      |
|    explained_variance   | 0.104      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.4e+03    |
|    n_updates            | 2060       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.562      |
|    value_loss           | 1.51e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 208        |
|    time_elapsed         | 85754      |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.04480438 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.73      |
|    explained_variance   | 0.0962     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.87e+03   |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.562      |
|    value_loss           | 1.53e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 209         |
|    time_elapsed         | 86099       |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.017034918 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.72       |
|    explained_variance   | 0.0596      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.4e+03     |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 0.561       |
|    value_loss           | 1.44e+04    |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=1016.89 +/- 8.44
Episode length: 35.60 +/- 17.50
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.037535742 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.0993      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.59e+03    |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.561       |
|    value_loss           | 1.41e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 38       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 210      |
|    time_elapsed    | 86455    |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 211         |
|    time_elapsed         | 86802       |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.037947938 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.68       |
|    explained_variance   | 0.0575      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.53e+03    |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.557       |
|    value_loss           | 1.36e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 212         |
|    time_elapsed         | 87174       |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.037198212 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.65       |
|    explained_variance   | 0.0888      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.8e+03     |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.555       |
|    value_loss           | 1.34e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 213        |
|    time_elapsed         | 87528      |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.04728292 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.62      |
|    explained_variance   | 0.159      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.38e+03   |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.553      |
|    value_loss           | 1.37e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 214         |
|    time_elapsed         | 87883       |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.038811374 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.6        |
|    explained_variance   | 0.078       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.79e+03    |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.553       |
|    value_loss           | 1.29e+04    |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=1012.73 +/- 2.60
Episode length: 26.80 +/- 3.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.051459633 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.59       |
|    explained_variance   | 0.09        |
|    learning_rate        | 0.0003      |
|    loss                 | 6.45e+03    |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.551       |
|    value_loss           | 1.14e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 215      |
|    time_elapsed    | 88272    |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 216         |
|    time_elapsed         | 88630       |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.065405935 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.59       |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.91e+03    |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.552       |
|    value_loss           | 1.26e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 217         |
|    time_elapsed         | 88999       |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.034603275 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.59       |
|    explained_variance   | 0.106       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.04e+03    |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0189     |
|    std                  | 0.552       |
|    value_loss           | 1.07e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 218         |
|    time_elapsed         | 89346       |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.024059366 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.58       |
|    explained_variance   | 0.0871      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.01e+03    |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.551       |
|    value_loss           | 1.12e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 219         |
|    time_elapsed         | 89674       |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.027443048 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | 0.12        |
|    learning_rate        | 0.0003      |
|    loss                 | 5.71e+03    |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.548       |
|    value_loss           | 1.09e+04    |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=1014.02 +/- 4.57
Episode length: 30.00 +/- 12.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.04617094 |
|    clip_fraction        | 0.197      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.52      |
|    explained_variance   | 0.12       |
|    learning_rate        | 0.0003     |
|    loss                 | 4.31e+03   |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.547      |
|    value_loss           | 1e+04      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 220      |
|    time_elapsed    | 90019    |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 221         |
|    time_elapsed         | 90365       |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.023415634 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.5        |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.33e+03    |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.545       |
|    value_loss           | 1.06e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 222         |
|    time_elapsed         | 90723       |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.047788415 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.47       |
|    explained_variance   | 0.118       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.63e+03    |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.543       |
|    value_loss           | 1.03e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 223         |
|    time_elapsed         | 91081       |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.033965245 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.43       |
|    explained_variance   | 0.089       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.35e+03    |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.54        |
|    value_loss           | 1.06e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 224        |
|    time_elapsed         | 91438      |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.03415492 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.107      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.19e+03   |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.538      |
|    value_loss           | 9.69e+03   |
----------------------------------------
Eval num_timesteps=460000, episode_reward=1010.40 +/- 0.46
Episode length: 22.60 +/- 2.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.03864578 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.0778     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.41e+03   |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.0206    |
|    std                  | 0.537      |
|    value_loss           | 9.53e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 225      |
|    time_elapsed    | 91806    |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 226        |
|    time_elapsed         | 92164      |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.04026139 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.097      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.92e+03   |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.0216    |
|    std                  | 0.536      |
|    value_loss           | 9.4e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 227         |
|    time_elapsed         | 92501       |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.046611153 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.106       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.07e+03    |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.535       |
|    value_loss           | 8.9e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 228         |
|    time_elapsed         | 92835       |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.027567547 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.33       |
|    explained_variance   | 0.154       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.48e+03    |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0241     |
|    std                  | 0.535       |
|    value_loss           | 8.21e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 229        |
|    time_elapsed         | 93204      |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.06936098 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.31      |
|    explained_variance   | 0.219      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.49e+03   |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.533      |
|    value_loss           | 7.91e+03   |
----------------------------------------
Eval num_timesteps=470000, episode_reward=1010.43 +/- 0.76
Episode length: 20.40 +/- 2.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.02430056 |
|    clip_fraction        | 0.207      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.29      |
|    explained_variance   | 0.138      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.53e+03   |
|    n_updates            | 2290       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.532      |
|    value_loss           | 7.77e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 230      |
|    time_elapsed    | 93566    |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 231         |
|    time_elapsed         | 93896       |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.035605624 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.212       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.73e+03    |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.531       |
|    value_loss           | 7.28e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 232        |
|    time_elapsed         | 94262      |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.02501572 |
|    clip_fraction        | 0.167      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.18       |
|    learning_rate        | 0.0003     |
|    loss                 | 3.83e+03   |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.531      |
|    value_loss           | 7.13e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 233         |
|    time_elapsed         | 94613       |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.040078893 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | 0.183       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.22e+03    |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.53        |
|    value_loss           | 7e+03       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 234         |
|    time_elapsed         | 94976       |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.036045454 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.24       |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.27e+03    |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.528       |
|    value_loss           | 6.61e+03    |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=1011.65 +/- 2.61
Episode length: 21.80 +/- 5.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.052083258 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.22       |
|    explained_variance   | 0.218       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.96e+03    |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.527       |
|    value_loss           | 6.68e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 235      |
|    time_elapsed    | 95319    |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 236         |
|    time_elapsed         | 95668       |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.040509555 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.21       |
|    explained_variance   | 0.15        |
|    learning_rate        | 0.0003      |
|    loss                 | 2.98e+03    |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.527       |
|    value_loss           | 6.43e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 33        |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 237       |
|    time_elapsed         | 96012     |
|    total_timesteps      | 485376    |
| train/                  |           |
|    approx_kl            | 0.0354636 |
|    clip_fraction        | 0.19      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.21     |
|    explained_variance   | 0.199     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.49e+03  |
|    n_updates            | 2360      |
|    policy_gradient_loss | -0.018    |
|    std                  | 0.527     |
|    value_loss           | 6.05e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 33.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 238         |
|    time_elapsed         | 96362       |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.019333985 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.2        |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.93e+03    |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.526       |
|    value_loss           | 6.01e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 239        |
|    time_elapsed         | 96702      |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.02832778 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | 0.221      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.22e+03   |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.523      |
|    value_loss           | 5.8e+03    |
----------------------------------------
Eval num_timesteps=490000, episode_reward=1012.20 +/- 3.84
Episode length: 30.00 +/- 16.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.033163738 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.15       |
|    explained_variance   | 0.225       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.02e+03    |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.523       |
|    value_loss           | 5.59e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 30.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 240      |
|    time_elapsed    | 97070    |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 241        |
|    time_elapsed         | 97402      |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.04272583 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.14      |
|    explained_variance   | 0.273      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.34e+03   |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.522      |
|    value_loss           | 5.44e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 242         |
|    time_elapsed         | 97742       |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.039199863 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.13       |
|    explained_variance   | 0.179       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.86e+03    |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 0.521       |
|    value_loss           | 5.82e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 29.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 243         |
|    time_elapsed         | 98090       |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.045762487 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.11       |
|    explained_variance   | 0.287       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.36e+03    |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.52        |
|    value_loss           | 4.97e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 244        |
|    time_elapsed         | 98450      |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.03939224 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.09      |
|    explained_variance   | 0.283      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.32e+03   |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.518      |
|    value_loss           | 4.85e+03   |
----------------------------------------
Eval num_timesteps=500000, episode_reward=1011.59 +/- 1.09
Episode length: 23.60 +/- 4.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.024799854 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.07       |
|    explained_variance   | 0.224       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.65e+03    |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.517       |
|    value_loss           | 5.04e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 245      |
|    time_elapsed    | 98812    |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 246         |
|    time_elapsed         | 99153       |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.041115373 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.06       |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.45e+03    |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.516       |
|    value_loss           | 5.12e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 247        |
|    time_elapsed         | 99500      |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.04853238 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.201      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.32e+03   |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0208    |
|    std                  | 0.514      |
|    value_loss           | 5.24e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 248         |
|    time_elapsed         | 99848       |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.022277124 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.99       |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.64e+03    |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.512       |
|    value_loss           | 4.8e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 249         |
|    time_elapsed         | 100196      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.041128095 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.97       |
|    explained_variance   | 0.353       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.28e+03    |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.511       |
|    value_loss           | 3.95e+03    |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=1010.64 +/- 0.48
Episode length: 21.80 +/- 3.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.03132362 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.218      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.1e+03    |
|    n_updates            | 2490       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.511      |
|    value_loss           | 4.66e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 250      |
|    time_elapsed    | 100562   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 251        |
|    time_elapsed         | 100907     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.03338924 |
|    clip_fraction        | 0.201      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.96      |
|    explained_variance   | 0.236      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.47e+03   |
|    n_updates            | 2500       |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.51       |
|    value_loss           | 5.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 252         |
|    time_elapsed         | 101267      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.027910154 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.94       |
|    explained_variance   | 0.272       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.23e+03    |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.509       |
|    value_loss           | 4.52e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 253         |
|    time_elapsed         | 101631      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.041179303 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.92       |
|    explained_variance   | 0.304       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6e+03     |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.508       |
|    value_loss           | 4.02e+03    |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=1014.42 +/- 6.59
Episode length: 30.00 +/- 9.84
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.035645194 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.92       |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.2e+03     |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.508       |
|    value_loss           | 4.09e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 254      |
|    time_elapsed    | 101998   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 255         |
|    time_elapsed         | 102373      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.034343693 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.89       |
|    explained_variance   | 0.302       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.82e+03    |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.505       |
|    value_loss           | 3.79e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 256         |
|    time_elapsed         | 102731      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.031626664 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.86       |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.98e+03    |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.504       |
|    value_loss           | 3.88e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 257         |
|    time_elapsed         | 103072      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.036625348 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.83       |
|    explained_variance   | 0.369       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.85e+03    |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.502       |
|    value_loss           | 3.36e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 258         |
|    time_elapsed         | 103439      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.033816397 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.8        |
|    explained_variance   | 0.364       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76e+03    |
|    n_updates            | 2570        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.501       |
|    value_loss           | 3.2e+03     |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=1012.37 +/- 2.59
Episode length: 24.40 +/- 5.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.047421336 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.78       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95e+03    |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.499       |
|    value_loss           | 3.37e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 259      |
|    time_elapsed    | 103811   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 260         |
|    time_elapsed         | 104181      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.039989766 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.75       |
|    explained_variance   | 0.228       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.16e+03    |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.496       |
|    value_loss           | 4.17e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 261         |
|    time_elapsed         | 104516      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.056823872 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.71       |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+03    |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.495       |
|    value_loss           | 3.64e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 262         |
|    time_elapsed         | 104866      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.039631754 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.71       |
|    explained_variance   | 0.364       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+03    |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.495       |
|    value_loss           | 2.98e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 263         |
|    time_elapsed         | 105231      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.036122087 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.7        |
|    explained_variance   | 0.363       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78e+03    |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.494       |
|    value_loss           | 2.92e+03    |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=1011.95 +/- 2.44
Episode length: 24.20 +/- 3.87
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.039694466 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.68       |
|    explained_variance   | 0.303       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.7e+03     |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.493       |
|    value_loss           | 3.38e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 264      |
|    time_elapsed    | 105619   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 265        |
|    time_elapsed         | 105959     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.03689765 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.66      |
|    explained_variance   | 0.337      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.22e+03   |
|    n_updates            | 2640       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.492      |
|    value_loss           | 3.24e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 266         |
|    time_elapsed         | 106317      |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.022370184 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.65       |
|    explained_variance   | 0.342       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.49e+03    |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.491       |
|    value_loss           | 3.13e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 267        |
|    time_elapsed         | 106669     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.03101535 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.63      |
|    explained_variance   | 0.366      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.44e+03   |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.49       |
|    value_loss           | 2.88e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.3        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 268         |
|    time_elapsed         | 107025      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.028879957 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.61       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.81e+03    |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.489       |
|    value_loss           | 3.78e+03    |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=1010.82 +/- 0.72
Episode length: 21.20 +/- 2.86
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.10588224 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.59      |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.87e+03   |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.487      |
|    value_loss           | 3.3e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 269      |
|    time_elapsed    | 107380   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 270        |
|    time_elapsed         | 107738     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.02537998 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.57      |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36e+03   |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 0.487      |
|    value_loss           | 3.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 271         |
|    time_elapsed         | 108076      |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.044451393 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.56       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.87e+03    |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.486       |
|    value_loss           | 2.74e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 272         |
|    time_elapsed         | 108431      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.029561302 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.56       |
|    explained_variance   | 0.353       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.27e+03    |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.486       |
|    value_loss           | 2.7e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 273         |
|    time_elapsed         | 108800      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.027868547 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.54       |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1e+03     |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.484       |
|    value_loss           | 2.71e+03    |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=1010.45 +/- 0.45
Episode length: 20.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.04245308 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.5       |
|    explained_variance   | 0.438      |
|    learning_rate        | 0.0003     |
|    loss                 | 868        |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.482      |
|    value_loss           | 2.38e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26       |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 274      |
|    time_elapsed    | 109164   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 275         |
|    time_elapsed         | 109514      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.035479598 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.48       |
|    explained_variance   | 0.35        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.8e+03     |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.481       |
|    value_loss           | 2.84e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 276         |
|    time_elapsed         | 109878      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.031174522 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.45       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41e+03    |
|    n_updates            | 2750        |
|    policy_gradient_loss | -0.0253     |
|    std                  | 0.478       |
|    value_loss           | 2.59e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 277        |
|    time_elapsed         | 110235     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.06169855 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.42      |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.29e+03   |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.477      |
|    value_loss           | 2.35e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 278         |
|    time_elapsed         | 110580      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.034516886 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.41       |
|    explained_variance   | 0.39        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0208     |
|    std                  | 0.477       |
|    value_loss           | 2.6e+03     |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=1012.58 +/- 2.06
Episode length: 23.60 +/- 4.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 23.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.036416903 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.4        |
|    explained_variance   | 0.341       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+03    |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 0.476       |
|    value_loss           | 2.94e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 279      |
|    time_elapsed    | 110923   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 280         |
|    time_elapsed         | 111282      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.041180715 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.38       |
|    explained_variance   | 0.456       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.36e+03    |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.475       |
|    value_loss           | 2.47e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 281         |
|    time_elapsed         | 111646      |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.042563546 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.37       |
|    explained_variance   | 0.424       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 2800        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.474       |
|    value_loss           | 2.24e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 282        |
|    time_elapsed         | 112007     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.04863015 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.426      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+03   |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.473      |
|    value_loss           | 2.22e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 283        |
|    time_elapsed         | 112340     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.02901398 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.35      |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.03e+03   |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.473      |
|    value_loss           | 2.38e+03   |
----------------------------------------
Eval num_timesteps=580000, episode_reward=1010.65 +/- 0.75
Episode length: 21.00 +/- 1.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.045361057 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.34       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14e+03    |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.472       |
|    value_loss           | 2.53e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 284      |
|    time_elapsed    | 112709   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 285        |
|    time_elapsed         | 113055     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.03239087 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.32      |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.37e+03   |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.472      |
|    value_loss           | 3.07e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 23.2      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 286       |
|    time_elapsed         | 113399    |
|    total_timesteps      | 585728    |
| train/                  |           |
|    approx_kl            | 0.0882671 |
|    clip_fraction        | 0.29      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.32     |
|    explained_variance   | 0.308     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.05e+03  |
|    n_updates            | 2850      |
|    policy_gradient_loss | -0.0112   |
|    std                  | 0.472     |
|    value_loss           | 2.88e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 287         |
|    time_elapsed         | 113754      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.093977205 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.29       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04e+03    |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.469       |
|    value_loss           | 1.96e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 288         |
|    time_elapsed         | 114085      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.043318562 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.26       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 2870        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.467       |
|    value_loss           | 2.34e+03    |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=1013.70 +/- 5.91
Episode length: 27.40 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.068593174 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.24       |
|    explained_variance   | 0.448       |
|    learning_rate        | 0.0003      |
|    loss                 | 963         |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.00425    |
|    std                  | 0.466       |
|    value_loss           | 2.16e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 289      |
|    time_elapsed    | 114447   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 290        |
|    time_elapsed         | 114812     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.04358965 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.24      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.42e+03   |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.467      |
|    value_loss           | 2.51e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 291        |
|    time_elapsed         | 115172     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.02789408 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.24      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17e+03   |
|    n_updates            | 2900       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.467      |
|    value_loss           | 2.98e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 292         |
|    time_elapsed         | 115522      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.036730684 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.22       |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+03    |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.465       |
|    value_loss           | 2.37e+03    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=1011.24 +/- 0.42
Episode length: 21.20 +/- 1.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.03529346 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.21      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 938        |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.0214    |
|    std                  | 0.465      |
|    value_loss           | 1.92e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 293      |
|    time_elapsed    | 115855   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 294         |
|    time_elapsed         | 116204      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.028362682 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.2        |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.0003      |
|    loss                 | 981         |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.464       |
|    value_loss           | 2.25e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 295         |
|    time_elapsed         | 116559      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.053920433 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.19       |
|    explained_variance   | 0.493       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26e+03    |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.00957    |
|    std                  | 0.463       |
|    value_loss           | 1.91e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 296         |
|    time_elapsed         | 116889      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.044044454 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.19       |
|    explained_variance   | 0.45        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.465       |
|    value_loss           | 2.08e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 297         |
|    time_elapsed         | 117231      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.060206763 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.19       |
|    explained_variance   | 0.447       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+03    |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.464       |
|    value_loss           | 2.19e+03    |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=1013.29 +/- 2.73
Episode length: 27.60 +/- 3.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.04760237 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.18      |
|    explained_variance   | 0.41       |
|    learning_rate        | 0.0003     |
|    loss                 | 895        |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.463      |
|    value_loss           | 2.47e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 298      |
|    time_elapsed    | 117604   |
|    total_timesteps | 610304   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 24.8     |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 5        |
|    iterations           | 299      |
|    time_elapsed         | 117959   |
|    total_timesteps      | 612352   |
| train/                  |          |
|    approx_kl            | 0.037399 |
|    clip_fraction        | 0.255    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.17    |
|    explained_variance   | 0.458    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.14e+03 |
|    n_updates            | 2980     |
|    policy_gradient_loss | -0.0184  |
|    std                  | 0.463    |
|    value_loss           | 2.27e+03 |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 300         |
|    time_elapsed         | 118326      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.038188856 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.16       |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55e+03    |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.462       |
|    value_loss           | 2.4e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 301         |
|    time_elapsed         | 118686      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.048710324 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.14       |
|    explained_variance   | 0.461       |
|    learning_rate        | 0.0003      |
|    loss                 | 982         |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.46        |
|    value_loss           | 2.01e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 302         |
|    time_elapsed         | 119049      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.030434057 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.12       |
|    explained_variance   | 0.375       |
|    learning_rate        | 0.0003      |
|    loss                 | 907         |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.46        |
|    value_loss           | 2.55e+03    |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=1011.91 +/- 2.39
Episode length: 27.00 +/- 8.27
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.035599608 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.13       |
|    explained_variance   | 0.382       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24e+03    |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.461       |
|    value_loss           | 2.45e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 303      |
|    time_elapsed    | 119434   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 304        |
|    time_elapsed         | 119765     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.15165888 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.14      |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.0003     |
|    loss                 | 972        |
|    n_updates            | 3030       |
|    policy_gradient_loss | 0.00198    |
|    std                  | 0.461      |
|    value_loss           | 2.01e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 305         |
|    time_elapsed         | 120103      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.050434057 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.13       |
|    explained_variance   | 0.416       |
|    learning_rate        | 0.0003      |
|    loss                 | 906         |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.46        |
|    value_loss           | 2.25e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 306         |
|    time_elapsed         | 120455      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.030700568 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.11       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25e+03    |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.459       |
|    value_loss           | 2.57e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 307         |
|    time_elapsed         | 120796      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.055232525 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.09       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+03    |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.458       |
|    value_loss           | 2.37e+03    |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=1011.37 +/- 1.89
Episode length: 24.60 +/- 4.32
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.030875305 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.08       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0003      |
|    loss                 | 485         |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.457       |
|    value_loss           | 1.87e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 308      |
|    time_elapsed    | 121166   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 309         |
|    time_elapsed         | 121506      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.052530732 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.07       |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+03    |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.457       |
|    value_loss           | 2.26e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 310        |
|    time_elapsed         | 121876     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.07495856 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.05      |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | 947        |
|    n_updates            | 3090       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.456      |
|    value_loss           | 1.81e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 311         |
|    time_elapsed         | 122225      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.046089794 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.03       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23e+03    |
|    n_updates            | 3100        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.454       |
|    value_loss           | 2.34e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 312        |
|    time_elapsed         | 122596     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.04931379 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.01      |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.0003     |
|    loss                 | 900        |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.453      |
|    value_loss           | 1.64e+03   |
----------------------------------------
Eval num_timesteps=640000, episode_reward=1010.67 +/- 0.48
Episode length: 20.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.03180324 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5         |
|    explained_variance   | 0.486      |
|    learning_rate        | 0.0003     |
|    loss                 | 740        |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.0228    |
|    std                  | 0.453      |
|    value_loss           | 1.75e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 313      |
|    time_elapsed    | 122957   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 314        |
|    time_elapsed         | 123324     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.05844466 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.99      |
|    explained_variance   | 0.509      |
|    learning_rate        | 0.0003     |
|    loss                 | 736        |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.452      |
|    value_loss           | 1.6e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 315         |
|    time_elapsed         | 123675      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.049604867 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.97       |
|    explained_variance   | 0.416       |
|    learning_rate        | 0.0003      |
|    loss                 | 933         |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.451       |
|    value_loss           | 2.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 316         |
|    time_elapsed         | 124033      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.047855563 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.95       |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.45        |
|    value_loss           | 1.97e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 317         |
|    time_elapsed         | 124369      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.035044383 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.93       |
|    explained_variance   | 0.334       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+03    |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.448       |
|    value_loss           | 2.66e+03    |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=1011.62 +/- 2.59
Episode length: 22.80 +/- 5.67
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.08516763 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.9       |
|    explained_variance   | 0.434      |
|    learning_rate        | 0.0003     |
|    loss                 | 887        |
|    n_updates            | 3170       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.447      |
|    value_loss           | 2.1e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 318      |
|    time_elapsed    | 124747   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 319        |
|    time_elapsed         | 125101     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.08978502 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.88      |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.0003     |
|    loss                 | 926        |
|    n_updates            | 3180       |
|    policy_gradient_loss | -0.009     |
|    std                  | 0.446      |
|    value_loss           | 1.96e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 320        |
|    time_elapsed         | 125461     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.03505629 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.87      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | 735        |
|    n_updates            | 3190       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.445      |
|    value_loss           | 1.65e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 321        |
|    time_elapsed         | 125824     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.05412688 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.84      |
|    explained_variance   | 0.492      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.3e+03    |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.444      |
|    value_loss           | 1.85e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 322         |
|    time_elapsed         | 126178      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.040077962 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.82       |
|    explained_variance   | 0.502       |
|    learning_rate        | 0.0003      |
|    loss                 | 604         |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.443       |
|    value_loss           | 1.72e+03    |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=1011.64 +/- 1.14
Episode length: 21.20 +/- 2.23
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.04169285 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.82      |
|    explained_variance   | 0.489      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.1e+03    |
|    n_updates            | 3220       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.444      |
|    value_loss           | 1.71e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 323      |
|    time_elapsed    | 126553   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 324        |
|    time_elapsed         | 126902     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.04089833 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.83      |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | 738        |
|    n_updates            | 3230       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.443      |
|    value_loss           | 1.6e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 325        |
|    time_elapsed         | 127254     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.07367228 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.81      |
|    explained_variance   | 0.489      |
|    learning_rate        | 0.0003     |
|    loss                 | 718        |
|    n_updates            | 3240       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.442      |
|    value_loss           | 1.67e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 326         |
|    time_elapsed         | 127609      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.043559127 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.78       |
|    explained_variance   | 0.368       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+03    |
|    n_updates            | 3250        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.44        |
|    value_loss           | 2.28e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 327        |
|    time_elapsed         | 127984     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.05674777 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.76      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | 694        |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.44       |
|    value_loss           | 1.68e+03   |
----------------------------------------
Eval num_timesteps=670000, episode_reward=1010.49 +/- 0.51
Episode length: 19.60 +/- 2.42
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 19.6      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 670000    |
| train/                  |           |
|    approx_kl            | 0.0642555 |
|    clip_fraction        | 0.28      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.75     |
|    explained_variance   | 0.354     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.1e+03   |
|    n_updates            | 3270      |
|    policy_gradient_loss | -0.0137   |
|    std                  | 0.439     |
|    value_loss           | 2.34e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 328      |
|    time_elapsed    | 128360   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 329         |
|    time_elapsed         | 128711      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.062336266 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.74       |
|    explained_variance   | 0.53        |
|    learning_rate        | 0.0003      |
|    loss                 | 625         |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.439       |
|    value_loss           | 1.56e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 330         |
|    time_elapsed         | 129067      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.037473634 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.75       |
|    explained_variance   | 0.461       |
|    learning_rate        | 0.0003      |
|    loss                 | 846         |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.44        |
|    value_loss           | 1.84e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 24.4        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 331         |
|    time_elapsed         | 129444      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.041556213 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.75       |
|    explained_variance   | 0.421       |
|    learning_rate        | 0.0003      |
|    loss                 | 746         |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.0235     |
|    std                  | 0.439       |
|    value_loss           | 2.1e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 332         |
|    time_elapsed         | 129797      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.041161314 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.74       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 934         |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.439       |
|    value_loss           | 1.99e+03    |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=1013.95 +/- 2.88
Episode length: 25.40 +/- 4.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.05491793 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.74      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.0003     |
|    loss                 | 903        |
|    n_updates            | 3320       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.439      |
|    value_loss           | 1.86e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 23.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 333      |
|    time_elapsed    | 130169   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 23.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 334         |
|    time_elapsed         | 130510      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.053929083 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.73       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.38e+03    |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.438       |
|    value_loss           | 1.93e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 335        |
|    time_elapsed         | 130845     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.06849241 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.72      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 888        |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.438      |
|    value_loss           | 2.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 336         |
|    time_elapsed         | 131200      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.043964203 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.7        |
|    explained_variance   | 0.519       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06e+03    |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.436       |
|    value_loss           | 1.59e+03    |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=1010.49 +/- 0.49
Episode length: 20.20 +/- 1.94
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.066540524 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.69       |
|    explained_variance   | 0.53        |
|    learning_rate        | 0.0003      |
|    loss                 | 679         |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.00426     |
|    std                  | 0.436       |
|    value_loss           | 1.55e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 337      |
|    time_elapsed    | 131561   |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 338        |
|    time_elapsed         | 131910     |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.04043803 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.68      |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | 754        |
|    n_updates            | 3370       |
|    policy_gradient_loss | -0.0209    |
|    std                  | 0.435      |
|    value_loss           | 1.28e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 339         |
|    time_elapsed         | 132250      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.029904418 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.67       |
|    explained_variance   | 0.519       |
|    learning_rate        | 0.0003      |
|    loss                 | 527         |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.435       |
|    value_loss           | 1.52e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 340        |
|    time_elapsed         | 132623     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.06899597 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.66      |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 668        |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.434      |
|    value_loss           | 1.24e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 341         |
|    time_elapsed         | 132999      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.040624447 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.65       |
|    explained_variance   | 0.503       |
|    learning_rate        | 0.0003      |
|    loss                 | 642         |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.434       |
|    value_loss           | 1.58e+03    |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=1014.13 +/- 6.27
Episode length: 24.20 +/- 7.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 24.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.040578242 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.66       |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.0003      |
|    loss                 | 427         |
|    n_updates            | 3410        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.435       |
|    value_loss           | 1.21e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 342      |
|    time_elapsed    | 133382   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 343         |
|    time_elapsed         | 133732      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.056349363 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.65       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.0003      |
|    loss                 | 840         |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.433       |
|    value_loss           | 1.32e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 344        |
|    time_elapsed         | 134091     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.06016303 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.63      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 605        |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.433      |
|    value_loss           | 1.17e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 345         |
|    time_elapsed         | 134456      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.074271694 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.63       |
|    explained_variance   | 0.511       |
|    learning_rate        | 0.0003      |
|    loss                 | 827         |
|    n_updates            | 3440        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.432       |
|    value_loss           | 1.48e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 346         |
|    time_elapsed         | 134801      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.057675295 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.61       |
|    explained_variance   | 0.57        |
|    learning_rate        | 0.0003      |
|    loss                 | 742         |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.431       |
|    value_loss           | 1.18e+03    |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=1010.67 +/- 0.45
Episode length: 20.60 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.054927297 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.59       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.0003      |
|    loss                 | 424         |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.43        |
|    value_loss           | 1.11e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 347      |
|    time_elapsed    | 135174   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 348        |
|    time_elapsed         | 135520     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.06390451 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.56      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 435        |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.428      |
|    value_loss           | 1.02e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 349        |
|    time_elapsed         | 135870     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.05703125 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.55      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | 727        |
|    n_updates            | 3480       |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.428      |
|    value_loss           | 1.37e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 350         |
|    time_elapsed         | 136217      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.033992104 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.53       |
|    explained_variance   | 0.566       |
|    learning_rate        | 0.0003      |
|    loss                 | 504         |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.427       |
|    value_loss           | 1.25e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 351         |
|    time_elapsed         | 136561      |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.052958213 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.52       |
|    explained_variance   | 0.547       |
|    learning_rate        | 0.0003      |
|    loss                 | 704         |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.427       |
|    value_loss           | 1.36e+03    |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=1010.46 +/- 0.50
Episode length: 20.00 +/- 1.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.08338034 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.51      |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | 677        |
|    n_updates            | 3510       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.426      |
|    value_loss           | 1.56e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 352      |
|    time_elapsed    | 136935   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 22          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 353         |
|    time_elapsed         | 137286      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.038683787 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.48       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0003      |
|    loss                 | 786         |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.424       |
|    value_loss           | 1.76e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 354        |
|    time_elapsed         | 137645     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.07301341 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.46      |
|    explained_variance   | 0.538      |
|    learning_rate        | 0.0003     |
|    loss                 | 615        |
|    n_updates            | 3530       |
|    policy_gradient_loss | -0.00763   |
|    std                  | 0.423      |
|    value_loss           | 1.45e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 355         |
|    time_elapsed         | 137988      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.058417153 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.43       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.0003      |
|    loss                 | 878         |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.422       |
|    value_loss           | 1.26e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.8      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 356       |
|    time_elapsed         | 138353    |
|    total_timesteps      | 729088    |
| train/                  |           |
|    approx_kl            | 0.0507358 |
|    clip_fraction        | 0.316     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.4      |
|    explained_variance   | 0.557     |
|    learning_rate        | 0.0003    |
|    loss                 | 446       |
|    n_updates            | 3550      |
|    policy_gradient_loss | -0.0223   |
|    std                  | 0.42      |
|    value_loss           | 1.36e+03  |
---------------------------------------
Eval num_timesteps=730000, episode_reward=1010.46 +/- 0.48
Episode length: 19.80 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 19.8      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 730000    |
| train/                  |           |
|    approx_kl            | 0.1032002 |
|    clip_fraction        | 0.315     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.37     |
|    explained_variance   | 0.577     |
|    learning_rate        | 0.0003    |
|    loss                 | 550       |
|    n_updates            | 3560      |
|    policy_gradient_loss | -0.0136   |
|    std                  | 0.418     |
|    value_loss           | 1.23e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 357      |
|    time_elapsed    | 138700   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 358        |
|    time_elapsed         | 139052     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.05196219 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.34      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | 646        |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.417      |
|    value_loss           | 1.37e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 359        |
|    time_elapsed         | 139399     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.22186673 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.33      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | 454        |
|    n_updates            | 3580       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.417      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 360         |
|    time_elapsed         | 139760      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.054957945 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.31       |
|    explained_variance   | 0.539       |
|    learning_rate        | 0.0003      |
|    loss                 | 862         |
|    n_updates            | 3590        |
|    policy_gradient_loss | -0.00876    |
|    std                  | 0.415       |
|    value_loss           | 1.37e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 361         |
|    time_elapsed         | 140097      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.041042704 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.29       |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0003      |
|    loss                 | 585         |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.415       |
|    value_loss           | 1.48e+03    |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=1012.63 +/- 4.08
Episode length: 22.60 +/- 5.43
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 22.6      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 740000    |
| train/                  |           |
|    approx_kl            | 0.0478658 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.28     |
|    explained_variance   | 0.625     |
|    learning_rate        | 0.0003    |
|    loss                 | 439       |
|    n_updates            | 3610      |
|    policy_gradient_loss | -0.0164   |
|    std                  | 0.414     |
|    value_loss           | 1.09e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 362      |
|    time_elapsed    | 140456   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 363         |
|    time_elapsed         | 140805      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.069116816 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.26       |
|    explained_variance   | 0.6         |
|    learning_rate        | 0.0003      |
|    loss                 | 397         |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.412       |
|    value_loss           | 1.13e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 364        |
|    time_elapsed         | 141150     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.06500675 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.22      |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.0003     |
|    loss                 | 461        |
|    n_updates            | 3630       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.41       |
|    value_loss           | 1.22e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 365        |
|    time_elapsed         | 141497     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.07244291 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.0003     |
|    loss                 | 670        |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.00613   |
|    std                  | 0.409      |
|    value_loss           | 1.41e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 366        |
|    time_elapsed         | 141845     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.07358624 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.17      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 495        |
|    n_updates            | 3650       |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.409      |
|    value_loss           | 1.11e+03   |
----------------------------------------
Eval num_timesteps=750000, episode_reward=1010.65 +/- 0.48
Episode length: 20.80 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.046808325 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.17       |
|    explained_variance   | 0.534       |
|    learning_rate        | 0.0003      |
|    loss                 | 811         |
|    n_updates            | 3660        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.409       |
|    value_loss           | 1.43e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 367      |
|    time_elapsed    | 142195   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 368         |
|    time_elapsed         | 142561      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.089803286 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.18       |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0003      |
|    loss                 | 678         |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.409       |
|    value_loss           | 1.27e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 369        |
|    time_elapsed         | 142918     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.07287507 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | 492        |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.00575   |
|    std                  | 0.41       |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 370        |
|    time_elapsed         | 143258     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.10025515 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.17      |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.0003     |
|    loss                 | 712        |
|    n_updates            | 3690       |
|    policy_gradient_loss | -0.00989   |
|    std                  | 0.408      |
|    value_loss           | 1.19e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 22.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 371        |
|    time_elapsed         | 143602     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.07789093 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.14      |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.0003     |
|    loss                 | 520        |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.00999   |
|    std                  | 0.407      |
|    value_loss           | 765        |
----------------------------------------
Eval num_timesteps=760000, episode_reward=1012.79 +/- 4.43
Episode length: 22.60 +/- 6.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 22.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.050854154 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.12       |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.0003      |
|    loss                 | 499         |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.406       |
|    value_loss           | 1.15e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 372      |
|    time_elapsed    | 143984   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 373        |
|    time_elapsed         | 144337     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.07329635 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.1       |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.0003     |
|    loss                 | 401        |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.405      |
|    value_loss           | 1.16e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 374        |
|    time_elapsed         | 144679     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.06861681 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.07      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.0003     |
|    loss                 | 490        |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.404      |
|    value_loss           | 838        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 375        |
|    time_elapsed         | 145025     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.07887131 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.06      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | 538        |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.00478   |
|    std                  | 0.403      |
|    value_loss           | 1.03e+03   |
----------------------------------------
Eval num_timesteps=770000, episode_reward=1010.89 +/- 0.38
Episode length: 19.40 +/- 1.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.073101744 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.05       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 716         |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.403       |
|    value_loss           | 1.19e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 22.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 376      |
|    time_elapsed    | 145385   |
|    total_timesteps | 770048   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 377        |
|    time_elapsed         | 145737     |
|    total_timesteps      | 772096     |
| train/                  |            |
|    approx_kl            | 0.05803909 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.03      |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 924        |
|    n_updates            | 3760       |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.401      |
|    value_loss           | 1.42e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 378        |
|    time_elapsed         | 146109     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.06441632 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.99      |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.0003     |
|    loss                 | 625        |
|    n_updates            | 3770       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.399      |
|    value_loss           | 1.19e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 379        |
|    time_elapsed         | 146470     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.18671672 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.98      |
|    explained_variance   | 0.523      |
|    learning_rate        | 0.0003     |
|    loss                 | 693        |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.399      |
|    value_loss           | 1.42e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 380        |
|    time_elapsed         | 146794     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.04850921 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.97      |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.0003     |
|    loss                 | 588        |
|    n_updates            | 3790       |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.399      |
|    value_loss           | 1.18e+03   |
----------------------------------------
Eval num_timesteps=780000, episode_reward=1010.50 +/- 0.48
Episode length: 18.80 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 18.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.066345416 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.96       |
|    explained_variance   | 0.596       |
|    learning_rate        | 0.0003      |
|    loss                 | 423         |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.398       |
|    value_loss           | 1.11e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 381      |
|    time_elapsed    | 147157   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 382         |
|    time_elapsed         | 147505      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.097730376 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.94       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | 845         |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.397       |
|    value_loss           | 1.34e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 383         |
|    time_elapsed         | 147859      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.061732866 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.92       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | 418         |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.396       |
|    value_loss           | 1.1e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 384        |
|    time_elapsed         | 148211     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.12392541 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.9       |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.0003     |
|    loss                 | 413        |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.00463   |
|    std                  | 0.395      |
|    value_loss           | 1.12e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 385         |
|    time_elapsed         | 148563      |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.078617565 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.88       |
|    explained_variance   | 0.546       |
|    learning_rate        | 0.0003      |
|    loss                 | 888         |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.0205     |
|    std                  | 0.394       |
|    value_loss           | 1.3e+03     |
-----------------------------------------
Eval num_timesteps=790000, episode_reward=1010.59 +/- 0.43
Episode length: 22.00 +/- 3.52
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 22         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.06612873 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.88      |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.0003     |
|    loss                 | 358        |
|    n_updates            | 3850       |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.395      |
|    value_loss           | 1.1e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 386      |
|    time_elapsed    | 148936   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 387         |
|    time_elapsed         | 149269      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.063410915 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.89       |
|    explained_variance   | 0.544       |
|    learning_rate        | 0.0003      |
|    loss                 | 532         |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.395       |
|    value_loss           | 1.25e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 388        |
|    time_elapsed         | 149616     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.11239074 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.89      |
|    explained_variance   | 0.604      |
|    learning_rate        | 0.0003     |
|    loss                 | 469        |
|    n_updates            | 3870       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.395      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 389         |
|    time_elapsed         | 149946      |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.079435736 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.88       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 499         |
|    n_updates            | 3880        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.394       |
|    value_loss           | 1.25e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 390        |
|    time_elapsed         | 150293     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.06963245 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.87      |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0003     |
|    loss                 | 423        |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.00921   |
|    std                  | 0.394      |
|    value_loss           | 1.05e+03   |
----------------------------------------
Eval num_timesteps=800000, episode_reward=1010.46 +/- 0.48
Episode length: 20.20 +/- 1.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.10989712 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.85      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 708        |
|    n_updates            | 3900       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.392      |
|    value_loss           | 1.1e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 21       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 391      |
|    time_elapsed    | 150656   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 392        |
|    time_elapsed         | 150999     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.05419617 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.83      |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.0003     |
|    loss                 | 539        |
|    n_updates            | 3910       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.391      |
|    value_loss           | 1.29e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 393        |
|    time_elapsed         | 151338     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.11272044 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.81      |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.0003     |
|    loss                 | 720        |
|    n_updates            | 3920       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.391      |
|    value_loss           | 1.18e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 394        |
|    time_elapsed         | 151701     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.43301812 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.8       |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | 762        |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.00813    |
|    std                  | 0.391      |
|    value_loss           | 1.19e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 395        |
|    time_elapsed         | 152055     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.10043718 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.8       |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.0003     |
|    loss                 | 477        |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.0027    |
|    std                  | 0.391      |
|    value_loss           | 1.1e+03    |
----------------------------------------
Eval num_timesteps=810000, episode_reward=1010.62 +/- 0.73
Episode length: 21.80 +/- 4.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.06544511 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.8       |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.0003     |
|    loss                 | 338        |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.391      |
|    value_loss           | 943        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 396      |
|    time_elapsed    | 152416   |
|    total_timesteps | 811008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20        |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 397       |
|    time_elapsed         | 152774    |
|    total_timesteps      | 813056    |
| train/                  |           |
|    approx_kl            | 0.0666613 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.78     |
|    explained_variance   | 0.639     |
|    learning_rate        | 0.0003    |
|    loss                 | 271       |
|    n_updates            | 3960      |
|    policy_gradient_loss | -0.0159   |
|    std                  | 0.389     |
|    value_loss           | 939       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 398        |
|    time_elapsed         | 153184     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.09662587 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.77      |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0003     |
|    loss                 | 442        |
|    n_updates            | 3970       |
|    policy_gradient_loss | -0.00369   |
|    std                  | 0.39       |
|    value_loss           | 933        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 21.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 399         |
|    time_elapsed         | 153524      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.052751392 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.76       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.0003      |
|    loss                 | 474         |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.388       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 400        |
|    time_elapsed         | 153856     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.07694295 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.74      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 511        |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.388      |
|    value_loss           | 1e+03      |
----------------------------------------
Eval num_timesteps=820000, episode_reward=1011.77 +/- 1.85
Episode length: 23.40 +/- 3.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.16494882 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.73      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.0003     |
|    loss                 | 354        |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.00605   |
|    std                  | 0.387      |
|    value_loss           | 733        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 401      |
|    time_elapsed    | 154218   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 402        |
|    time_elapsed         | 154570     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.07233722 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.7       |
|    explained_variance   | 0.641      |
|    learning_rate        | 0.0003     |
|    loss                 | 505        |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.385      |
|    value_loss           | 956        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 403        |
|    time_elapsed         | 154935     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.07454145 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.68      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 275        |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.385      |
|    value_loss           | 935        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 404         |
|    time_elapsed         | 155309      |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.077979244 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.67       |
|    explained_variance   | 0.622       |
|    learning_rate        | 0.0003      |
|    loss                 | 477         |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.385       |
|    value_loss           | 995         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 405        |
|    time_elapsed         | 155668     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.11506568 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.65      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 431        |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.383      |
|    value_loss           | 915        |
----------------------------------------
Eval num_timesteps=830000, episode_reward=1011.08 +/- 0.62
Episode length: 20.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 20.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.122854084 |
|    clip_fraction        | 0.478       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.64       |
|    explained_variance   | 0.746       |
|    learning_rate        | 0.0003      |
|    loss                 | 250         |
|    n_updates            | 4050        |
|    policy_gradient_loss | 0.00989     |
|    std                  | 0.384       |
|    value_loss           | 644         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 406      |
|    time_elapsed    | 156017   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 407         |
|    time_elapsed         | 156380      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.071871355 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.65       |
|    explained_variance   | 0.666       |
|    learning_rate        | 0.0003      |
|    loss                 | 510         |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.384       |
|    value_loss           | 839         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 408         |
|    time_elapsed         | 156738      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.050741017 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.65       |
|    explained_variance   | 0.697       |
|    learning_rate        | 0.0003      |
|    loss                 | 341         |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.0094     |
|    std                  | 0.384       |
|    value_loss           | 756         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 409       |
|    time_elapsed         | 157082    |
|    total_timesteps      | 837632    |
| train/                  |           |
|    approx_kl            | 0.2571419 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.63     |
|    explained_variance   | 0.547     |
|    learning_rate        | 0.0003    |
|    loss                 | 576       |
|    n_updates            | 4080      |
|    policy_gradient_loss | 0.0123    |
|    std                  | 0.383     |
|    value_loss           | 1.19e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 410        |
|    time_elapsed         | 157446     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.05404691 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.62      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 329        |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.382      |
|    value_loss           | 943        |
----------------------------------------
Eval num_timesteps=840000, episode_reward=1011.64 +/- 1.64
Episode length: 21.40 +/- 3.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.10064591 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.6       |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.0003     |
|    loss                 | 361        |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.381      |
|    value_loss           | 896        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 411      |
|    time_elapsed    | 157832   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 412        |
|    time_elapsed         | 158182     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.21989189 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.59      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 310        |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.00948   |
|    std                  | 0.381      |
|    value_loss           | 759        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 413        |
|    time_elapsed         | 158538     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.09653328 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.56      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 465        |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0058    |
|    std                  | 0.379      |
|    value_loss           | 886        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 414        |
|    time_elapsed         | 158884     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.11261085 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.54      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 407        |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.378      |
|    value_loss           | 771        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 415        |
|    time_elapsed         | 159230     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.13630661 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.0003     |
|    loss                 | 295        |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.00537    |
|    std                  | 0.378      |
|    value_loss           | 721        |
----------------------------------------
Eval num_timesteps=850000, episode_reward=1010.66 +/- 0.48
Episode length: 21.20 +/- 2.48
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 21.2      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 850000    |
| train/                  |           |
|    approx_kl            | 0.2540971 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.53     |
|    explained_variance   | 0.67      |
|    learning_rate        | 0.0003    |
|    loss                 | 314       |
|    n_updates            | 4150      |
|    policy_gradient_loss | -0.00211  |
|    std                  | 0.378     |
|    value_loss           | 822       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 416      |
|    time_elapsed    | 159575   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 417        |
|    time_elapsed         | 159907     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.18849286 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.54      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.0003     |
|    loss                 | 766        |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.00545    |
|    std                  | 0.379      |
|    value_loss           | 826        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 418        |
|    time_elapsed         | 160266     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.13965249 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.0003     |
|    loss                 | 373        |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.00274   |
|    std                  | 0.378      |
|    value_loss           | 717        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 419        |
|    time_elapsed         | 160608     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.08758636 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.51      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 457        |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.377      |
|    value_loss           | 887        |
----------------------------------------
Eval num_timesteps=860000, episode_reward=1010.66 +/- 0.46
Episode length: 21.20 +/- 2.93
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.14505206 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.49      |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.0003     |
|    loss                 | 330        |
|    n_updates            | 4190       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.376      |
|    value_loss           | 883        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 420      |
|    time_elapsed    | 160991   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 421        |
|    time_elapsed         | 161352     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.11937503 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.49      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | 565        |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.00941    |
|    std                  | 0.376      |
|    value_loss           | 1.15e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 422         |
|    time_elapsed         | 161716      |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.092296824 |
|    clip_fraction        | 0.422       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.46       |
|    explained_variance   | 0.683       |
|    learning_rate        | 0.0003      |
|    loss                 | 470         |
|    n_updates            | 4210        |
|    policy_gradient_loss | -0.00882    |
|    std                  | 0.375       |
|    value_loss           | 869         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 423        |
|    time_elapsed         | 162052     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.09459568 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.45      |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.0003     |
|    loss                 | 352        |
|    n_updates            | 4220       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.374      |
|    value_loss           | 877        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 21.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 424        |
|    time_elapsed         | 162405     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.09032346 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.43      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 661        |
|    n_updates            | 4230       |
|    policy_gradient_loss | -0.00834   |
|    std                  | 0.373      |
|    value_loss           | 943        |
----------------------------------------
Eval num_timesteps=870000, episode_reward=1011.37 +/- 0.75
Episode length: 23.20 +/- 1.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.09314719 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.4       |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0003     |
|    loss                 | 536        |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.371      |
|    value_loss           | 1.02e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 425      |
|    time_elapsed    | 162766   |
|    total_timesteps | 870400   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 20.2      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 426       |
|    time_elapsed         | 163117    |
|    total_timesteps      | 872448    |
| train/                  |           |
|    approx_kl            | 0.1434161 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.39     |
|    explained_variance   | 0.655     |
|    learning_rate        | 0.0003    |
|    loss                 | 315       |
|    n_updates            | 4250      |
|    policy_gradient_loss | 0.00262   |
|    std                  | 0.372     |
|    value_loss           | 914       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 427        |
|    time_elapsed         | 163478     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.11390915 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.41      |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0003     |
|    loss                 | 514        |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.00658   |
|    std                  | 0.373      |
|    value_loss           | 956        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 428        |
|    time_elapsed         | 163831     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.14318542 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.42      |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.0003     |
|    loss                 | 469        |
|    n_updates            | 4270       |
|    policy_gradient_loss | -0.000129  |
|    std                  | 0.373      |
|    value_loss           | 888        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 429         |
|    time_elapsed         | 164188      |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.094709344 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.41       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 575         |
|    n_updates            | 4280        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.372       |
|    value_loss           | 893         |
-----------------------------------------
Eval num_timesteps=880000, episode_reward=1011.05 +/- 0.59
Episode length: 21.20 +/- 2.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 21.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.09658837 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.41      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 319        |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.00705   |
|    std                  | 0.373      |
|    value_loss           | 870        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 430      |
|    time_elapsed    | 164521   |
|    total_timesteps | 880640   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 431       |
|    time_elapsed         | 164871    |
|    total_timesteps      | 882688    |
| train/                  |           |
|    approx_kl            | 0.0877711 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.41     |
|    explained_variance   | 0.721     |
|    learning_rate        | 0.0003    |
|    loss                 | 373       |
|    n_updates            | 4300      |
|    policy_gradient_loss | -0.0108   |
|    std                  | 0.372     |
|    value_loss           | 710       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 432        |
|    time_elapsed         | 165224     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.21400182 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.39      |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0003     |
|    loss                 | 288        |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.00118   |
|    std                  | 0.371      |
|    value_loss           | 605        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 433        |
|    time_elapsed         | 165573     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.10413505 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.36      |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | 364        |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.37       |
|    value_loss           | 848        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 434        |
|    time_elapsed         | 165913     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.06429994 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.36      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | 388        |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.371      |
|    value_loss           | 980        |
----------------------------------------
Eval num_timesteps=890000, episode_reward=1010.64 +/- 0.53
Episode length: 21.20 +/- 3.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.084796764 |
|    clip_fraction        | 0.442       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.35       |
|    explained_variance   | 0.673       |
|    learning_rate        | 0.0003      |
|    loss                 | 486         |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.0098      |
|    std                  | 0.369       |
|    value_loss           | 805         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 435      |
|    time_elapsed    | 166298   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 436        |
|    time_elapsed         | 166652     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.12085609 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.33      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.0003     |
|    loss                 | 463        |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.369      |
|    value_loss           | 792        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 437        |
|    time_elapsed         | 167011     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.14959905 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.32      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 345        |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.00135    |
|    std                  | 0.368      |
|    value_loss           | 655        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 438        |
|    time_elapsed         | 167393     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.19179417 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.28      |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 231        |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.00445   |
|    std                  | 0.367      |
|    value_loss           | 707        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 439         |
|    time_elapsed         | 167736      |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.122649275 |
|    clip_fraction        | 0.451       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.28       |
|    explained_variance   | 0.732       |
|    learning_rate        | 0.0003      |
|    loss                 | 220         |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.00671    |
|    std                  | 0.367       |
|    value_loss           | 633         |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=1010.77 +/- 0.37
Episode length: 23.20 +/- 4.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.06538987 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.27      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | 350        |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.366      |
|    value_loss           | 880        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 440      |
|    time_elapsed    | 168098   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 441        |
|    time_elapsed         | 168452     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.22440422 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.26      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.0003     |
|    loss                 | 230        |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.00151   |
|    std                  | 0.366      |
|    value_loss           | 717        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 442        |
|    time_elapsed         | 168803     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.17019796 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.25      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.0003     |
|    loss                 | 237        |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.00823   |
|    std                  | 0.365      |
|    value_loss           | 603        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 443         |
|    time_elapsed         | 169181      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.093848854 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.24       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.0003      |
|    loss                 | 286         |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.365       |
|    value_loss           | 682         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 444        |
|    time_elapsed         | 169558     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.19542055 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.24      |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.0003     |
|    loss                 | 612        |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.00329   |
|    std                  | 0.365      |
|    value_loss           | 771        |
----------------------------------------
Eval num_timesteps=910000, episode_reward=1013.18 +/- 4.76
Episode length: 23.40 +/- 6.83
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 23.4     |
|    mean_reward          | 1.01e+03 |
| time/                   |          |
|    total_timesteps      | 910000   |
| train/                  |          |
|    approx_kl            | 0.088598 |
|    clip_fraction        | 0.453    |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.23    |
|    explained_variance   | 0.741    |
|    learning_rate        | 0.0003   |
|    loss                 | 317      |
|    n_updates            | 4440     |
|    policy_gradient_loss | -0.0118  |
|    std                  | 0.364    |
|    value_loss           | 566      |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 445      |
|    time_elapsed    | 169918   |
|    total_timesteps | 911360   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 446       |
|    time_elapsed         | 170255    |
|    total_timesteps      | 913408    |
| train/                  |           |
|    approx_kl            | 0.1624817 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.22     |
|    explained_variance   | 0.69      |
|    learning_rate        | 0.0003    |
|    loss                 | 351       |
|    n_updates            | 4450      |
|    policy_gradient_loss | 0.00258   |
|    std                  | 0.365     |
|    value_loss           | 727       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 447        |
|    time_elapsed         | 170624     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.11951996 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.23      |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.0003     |
|    loss                 | 280        |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.00657   |
|    std                  | 0.365      |
|    value_loss           | 661        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 20          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 448         |
|    time_elapsed         | 170983      |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.109972924 |
|    clip_fraction        | 0.453       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.24       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.0003      |
|    loss                 | 232         |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.00235    |
|    std                  | 0.366       |
|    value_loss           | 628         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 449         |
|    time_elapsed         | 171326      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.060701538 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.24       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.0003      |
|    loss                 | 262         |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.365       |
|    value_loss           | 746         |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=1011.07 +/- 1.01
Episode length: 20.60 +/- 3.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.12807283 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.25      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0003     |
|    loss                 | 217        |
|    n_updates            | 4490       |
|    policy_gradient_loss | -0.00937   |
|    std                  | 0.366      |
|    value_loss           | 588        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 450      |
|    time_elapsed    | 171704   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 451        |
|    time_elapsed         | 172058     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.09056261 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.25      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 270        |
|    n_updates            | 4500       |
|    policy_gradient_loss | -0.0123    |
|    std                  | 0.365      |
|    value_loss           | 808        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 452       |
|    time_elapsed         | 172437    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 0.1513969 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.24     |
|    explained_variance   | 0.654     |
|    learning_rate        | 0.0003    |
|    loss                 | 373       |
|    n_updates            | 4510      |
|    policy_gradient_loss | -0.00287  |
|    std                  | 0.365     |
|    value_loss           | 775       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 453        |
|    time_elapsed         | 172807     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.08694146 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.24      |
|    explained_variance   | 0.559      |
|    learning_rate        | 0.0003     |
|    loss                 | 405        |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.365      |
|    value_loss           | 984        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 454        |
|    time_elapsed         | 173152     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.14712285 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.22      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | 400        |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.00811   |
|    std                  | 0.364      |
|    value_loss           | 801        |
----------------------------------------
Eval num_timesteps=930000, episode_reward=1010.67 +/- 0.46
Episode length: 20.00 +/- 1.90
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.09819021 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.21      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.0003     |
|    loss                 | 417        |
|    n_updates            | 4540       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.364      |
|    value_loss           | 761        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 455      |
|    time_elapsed    | 173523   |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 456        |
|    time_elapsed         | 173869     |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.06723288 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.21      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | 424        |
|    n_updates            | 4550       |
|    policy_gradient_loss | -0.00485   |
|    std                  | 0.364      |
|    value_loss           | 1.09e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 457        |
|    time_elapsed         | 174241     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.09418529 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.18      |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.0003     |
|    loss                 | 287        |
|    n_updates            | 4560       |
|    policy_gradient_loss | -0.00383   |
|    std                  | 0.362      |
|    value_loss           | 744        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 458        |
|    time_elapsed         | 174572     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.13852838 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.16      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.0003     |
|    loss                 | 320        |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.00899   |
|    std                  | 0.361      |
|    value_loss           | 633        |
----------------------------------------
Eval num_timesteps=940000, episode_reward=1011.46 +/- 1.82
Episode length: 21.40 +/- 3.01
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 21.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.066272385 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.14       |
|    explained_variance   | 0.668       |
|    learning_rate        | 0.0003      |
|    loss                 | 391         |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.0074     |
|    std                  | 0.361       |
|    value_loss           | 774         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 459      |
|    time_elapsed    | 174953   |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 460         |
|    time_elapsed         | 175311      |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.073915266 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.13       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.0003      |
|    loss                 | 619         |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.36        |
|    value_loss           | 975         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 461        |
|    time_elapsed         | 175681     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.10101721 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.13      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 452        |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.00702   |
|    std                  | 0.361      |
|    value_loss           | 736        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.5      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 462       |
|    time_elapsed         | 176015    |
|    total_timesteps      | 946176    |
| train/                  |           |
|    approx_kl            | 0.0720235 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.14     |
|    explained_variance   | 0.651     |
|    learning_rate        | 0.0003    |
|    loss                 | 317       |
|    n_updates            | 4610      |
|    policy_gradient_loss | -0.00423  |
|    std                  | 0.361     |
|    value_loss           | 780       |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 19.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 463       |
|    time_elapsed         | 176372    |
|    total_timesteps      | 948224    |
| train/                  |           |
|    approx_kl            | 0.1962081 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.11     |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.0003    |
|    loss                 | 376       |
|    n_updates            | 4620      |
|    policy_gradient_loss | 0.000399  |
|    std                  | 0.359     |
|    value_loss           | 623       |
---------------------------------------
Eval num_timesteps=950000, episode_reward=1010.89 +/- 0.73
Episode length: 19.80 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 19.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.088868365 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.1        |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 502         |
|    n_updates            | 4630        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.359       |
|    value_loss           | 847         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 464      |
|    time_elapsed    | 176765   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 20.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 465        |
|    time_elapsed         | 177119     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.07163378 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.1       |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | 561        |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.359      |
|    value_loss           | 925        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 466         |
|    time_elapsed         | 177469      |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.065385535 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.1        |
|    explained_variance   | 0.616       |
|    learning_rate        | 0.0003      |
|    loss                 | 483         |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.359       |
|    value_loss           | 993         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 467         |
|    time_elapsed         | 177834      |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.110370755 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.08       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.0003      |
|    loss                 | 369         |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.00889    |
|    std                  | 0.358       |
|    value_loss           | 852         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 18.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 468         |
|    time_elapsed         | 178195      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.114745535 |
|    clip_fraction        | 0.449       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.05       |
|    explained_variance   | 0.68        |
|    learning_rate        | 0.0003      |
|    loss                 | 352         |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.357       |
|    value_loss           | 749         |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=1010.52 +/- 0.46
Episode length: 19.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.13242573 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.04      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 350        |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.00715   |
|    std                  | 0.357      |
|    value_loss           | 652        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 469      |
|    time_elapsed    | 178583   |
|    total_timesteps | 960512   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 18.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 5         |
|    iterations           | 470       |
|    time_elapsed         | 178976    |
|    total_timesteps      | 962560    |
| train/                  |           |
|    approx_kl            | 0.1539233 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.04     |
|    explained_variance   | 0.768     |
|    learning_rate        | 0.0003    |
|    loss                 | 269       |
|    n_updates            | 4690      |
|    policy_gradient_loss | 0.0178    |
|    std                  | 0.357     |
|    value_loss           | 481       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 471         |
|    time_elapsed         | 179330      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.058047667 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.04       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.0003      |
|    loss                 | 416         |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.357       |
|    value_loss           | 796         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 472        |
|    time_elapsed         | 179708     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.23404257 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.03      |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.0003     |
|    loss                 | 387        |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.00312    |
|    std                  | 0.356      |
|    value_loss           | 737        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 473        |
|    time_elapsed         | 180082     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.24461511 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.0003     |
|    loss                 | 327        |
|    n_updates            | 4720       |
|    policy_gradient_loss | -0.00314   |
|    std                  | 0.355      |
|    value_loss           | 605        |
----------------------------------------
Eval num_timesteps=970000, episode_reward=1010.85 +/- 0.38
Episode length: 20.00 +/- 1.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 20         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.11311962 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.0003     |
|    loss                 | 302        |
|    n_updates            | 4730       |
|    policy_gradient_loss | -0.00713   |
|    std                  | 0.356      |
|    value_loss           | 687        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 474      |
|    time_elapsed    | 180454   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 475        |
|    time_elapsed         | 180810     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.08288417 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 505        |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.0124    |
|    std                  | 0.355      |
|    value_loss           | 797        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 476         |
|    time_elapsed         | 181167      |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.088333525 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3          |
|    explained_variance   | 0.65        |
|    learning_rate        | 0.0003      |
|    loss                 | 361         |
|    n_updates            | 4750        |
|    policy_gradient_loss | -0.0232     |
|    std                  | 0.354       |
|    value_loss           | 855         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 477        |
|    time_elapsed         | 181537     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.14330748 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.98      |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.0003     |
|    loss                 | 310        |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.00107   |
|    std                  | 0.354      |
|    value_loss           | 682        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 478        |
|    time_elapsed         | 181903     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.16041909 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.98      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 379        |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.00444   |
|    std                  | 0.354      |
|    value_loss           | 843        |
----------------------------------------
Eval num_timesteps=980000, episode_reward=1010.90 +/- 0.38
Episode length: 19.40 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.10299398 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.0003     |
|    loss                 | 413        |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.0013    |
|    std                  | 0.355      |
|    value_loss           | 677        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 479      |
|    time_elapsed    | 182280   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 480        |
|    time_elapsed         | 182620     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.31807253 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.0003     |
|    loss                 | 404        |
|    n_updates            | 4790       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.355      |
|    value_loss           | 796        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 481        |
|    time_elapsed         | 182970     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.21140724 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.02      |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | 402        |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.356      |
|    value_loss           | 781        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 482        |
|    time_elapsed         | 183322     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.08388343 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.02      |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.0003     |
|    loss                 | 351        |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.356      |
|    value_loss           | 715        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 18.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 483        |
|    time_elapsed         | 183657     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.09482821 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.03      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.0003     |
|    loss                 | 352        |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.356      |
|    value_loss           | 610        |
----------------------------------------
Eval num_timesteps=990000, episode_reward=1010.48 +/- 0.50
Episode length: 19.20 +/- 1.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.21320944 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.02      |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.0003     |
|    loss                 | 161        |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.00562    |
|    std                  | 0.355      |
|    value_loss           | 583        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 19.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 484      |
|    time_elapsed    | 184018   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 485        |
|    time_elapsed         | 184389     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.09110838 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.0003     |
|    loss                 | 239        |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.355      |
|    value_loss           | 820        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 19.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 486         |
|    time_elapsed         | 184757      |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.102334365 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.01       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.0003      |
|    loss                 | 646         |
|    n_updates            | 4850        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.355       |
|    value_loss           | 859         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 487        |
|    time_elapsed         | 185115     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.07637088 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0003     |
|    loss                 | 540        |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.354      |
|    value_loss           | 856        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 19.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 488        |
|    time_elapsed         | 185484     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.08793226 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 320        |
|    n_updates            | 4870       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.355      |
|    value_loss           | 672        |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=1011.04 +/- 0.57
Episode length: 19.80 +/- 2.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 19.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.12482824 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.0003     |
|    loss                 | 350        |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.00198   |
|    std                  | 0.355      |
|    value_loss           | 737        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 18.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 5        |
|    iterations      | 489      |
|    time_elapsed    | 185871   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-24_14-26-37_llm_triton_qwen_14b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 2 days, 3:33:13 < 0:00:00 , 6 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.532066  -99.574016  -99.358371  -99.559816  -99.045331]
 [ -99.377228  -99.393478  -99.324141  -99.288276  -99.241401]
 [ -99.146857  -99.056684  -98.766963  -98.895124  -99.297445]
 [ -94.4115    -94.429979  -97.522644  -95.368177  -96.845719]
 [ -11.063266  -22.104793  -31.22969   -22.006072  -21.221906]
 [ 344.766901  197.250653  174.316746  250.118439  276.822531]
 [1067.046902 1197.65312   207.434182  231.894951  222.23965 ]
 [1333.963854 1138.424006 1102.487191 1173.538797 1023.540459]
 [1073.211448 1073.304943 1064.789659 1152.308898 1085.942191]
 [1014.799458 1092.879291 1221.838087 1099.179555 1111.334405]
 [1030.768874 1019.803973 1058.511967 1013.655772 1015.907573]
 [1016.754413 1022.453875 1102.081181 1033.565835 1014.275563]
 [1022.838796 1018.054892 1010.902206 1010.730828 1009.868393]
 [1014.368041 1030.547507 1024.099902 1010.973603 1023.692202]
 [1012.21723  1014.589266 1012.608127 1009.842321 1010.007302]
 [1009.939949 1010.943543 1011.025617 1069.059615  -76.173275]
 [1021.42069  1010.639801 1010.020039 1011.514412 1013.687082]
 [1034.008942 1022.036894 1036.039942 1011.030041 1043.588904]
 [1016.49529  1053.691814 1054.404109 1038.981866 1053.508618]
 [1010.013396 1010.383756 1010.917757 1010.555804 1021.256812]
 [1018.53757  1021.518072 1019.569991 1027.881342 1010.839493]
 [1026.658149 1013.563858 1011.565611 1009.998535 1015.369557]
 [1031.989017 1021.438996 1009.846093 1013.596078 1029.030968]
 [1011.772727 1015.599891 1011.757722 1022.785834 1010.880899]
 [1011.685238 1016.642905 1010.587597 1019.43055  1013.702842]
 [1009.864721 1014.682683 1025.533947 1054.418891 1013.593218]
 [1011.887206 1021.186567 1016.479069 1013.24721  1016.677884]
 [1016.761083 1009.951359 1030.667553 1010.923306 1016.125266]
 [1013.665338 1012.573013 1009.882055 1010.983512 1010.816818]
 [1031.098427 1015.801854 1022.400164 1016.752524 1017.612935]
 [1014.618348 1010.020906 1011.78848  1011.017064 1010.17242 ]
 [1020.584303 1009.977856 1010.912053 1010.064423 1015.756271]
 [1013.808809 1018.595294 1009.981557 1009.856953 1009.610583]
 [1011.023207 1009.984718 1022.394592 1011.030479 1016.574777]
 [1012.855983 1010.037262 1011.853986 1011.875019 1032.583665]
 [1012.697624 1011.031684 1009.90532  1009.938707 1020.572936]
 [1014.7453   1010.943863 1011.834852 1026.311165 1010.101123]
 [1027.328519 1009.636971 1014.50236  1010.013957 1009.988295]
 [1011.005118 1015.784301 1024.284312 1013.918353 1016.79612 ]
 [1048.221708 1019.737621 1010.125135 1011.89433  1028.079368]
 [1013.450875 1011.019377 1010.860266 1010.951877 1009.904659]
 [1010.941512 1028.236804 1011.092342 1009.918873 1010.100153]
 [1022.463808 1010.158252 1010.047212 1010.874588 1030.902833]
 [1011.80285  1011.946079 1017.863002 1011.028811 1011.007797]
 [1011.007672 1022.159227 1015.9453   1009.898651 1011.084422]
 [1010.035438 1009.982304 1011.010839 1010.907475 1010.045511]
 [1010.155802 1009.991678 1009.992329 1010.062177 1011.933439]
 [1010.14726  1016.828105 1011.033172 1010.10075  1010.153372]
 [1010.076161 1010.02922  1010.054039 1019.840466 1011.017077]
 [1012.921283 1012.799672 1011.061348 1010.149595 1011.030442]
 [1010.182289 1011.054002 1010.938896 1009.945572 1011.078998]
 [1027.423556 1010.003949 1011.708523 1012.875719 1010.068576]
 [1010.0805   1013.86288  1016.750661 1010.023274 1011.148986]
 [1011.029439 1011.051076 1016.75791  1009.979088 1010.908809]
 [1011.895578 1009.986485 1010.058514 1011.094784 1011.055487]
 [1010.112304 1010.958322 1010.004598 1010.129679 1011.029155]
 [1010.169837 1011.056967 1013.798165 1015.92444  1011.932963]
 [1011.066101 1010.029603 1010.166849 1011.944549 1010.044236]
 [1011.013803 1010.002709 1011.097186 1010.91374  1025.491511]
 [1010.999137 1012.068083 1010.982207 1011.048559 1011.080554]
 [1010.936427 1012.008304 1018.61708  1012.848567 1012.049501]
 [1016.531238 1010.103051 1011.021646 1011.782744 1010.117609]
 [1011.932032 1010.037091 1009.844169 1014.847126 1010.185968]
 [1011.016834 1010.083348 1010.079709 1011.084086 1011.09032 ]
 [1010.070982 1010.108353 1011.021942 1016.741694 1010.1349  ]
 [1011.05391  1011.064093 1013.920021 1011.1326   1011.052982]
 [1010.126065 1011.098058 1009.993063 1010.116662 1011.132135]
 [1010.082562 1014.888781 1012.90439  1013.032183 1018.823939]
 [1010.14606  1009.983551 1011.098252 1011.056628 1010.141639]
 [1011.013105 1010.092662 1026.609866 1011.909742 1010.999995]
 [1011.006857 1011.046428 1011.052716 1010.156514 1010.094066]
 [1010.053907 1011.049128 1011.081307 1010.087399 1010.010354]
 [1010.060178 1010.989418 1010.079436 1011.105672 1010.068351]
 [1011.109735 1020.741935 1009.998542 1010.163892 1011.13148 ]
 [1011.027854 1010.991554 1010.025334 1010.112699 1011.108783]
 [1011.093548 1010.11165  1021.60474  1010.056835 1011.098338]
 [1011.067873 1010.124677 1011.080694 1011.082468 1011.080378]
 [1011.045065 1010.136385 1010.09193  1010.100092 1011.124296]
 [1010.907032 1010.064814 1010.851359 1011.053909 1010.077717]
 [1011.04801  1011.061724 1010.122087 1010.049177 1010.043742]
 [1011.079241 1010.104477 1010.005714 1010.083674 1011.850705]
 [1014.805684 1012.966664 1010.097637 1010.960101 1010.019292]
 [1011.107016 1012.00054  1011.146395 1010.051312 1011.085698]
 [1014.834653 1011.094584 1010.167583 1011.155488 1010.952372]
 [1010.043162 1010.997518 1011.061564 1011.107723 1010.106695]
 [1011.01689  1010.110338 1011.108527 1010.087196 1010.972685]
 [1010.996802 1011.078134 1010.951923 1012.868709 1010.957495]
 [1011.984137 1010.955498 1011.128328 1010.139933 1011.03667 ]
 [1011.025971 1011.127974 1009.892366 1010.106267 1011.035469]
 [1010.075131 1011.010704 1010.994514 1010.732712 1011.045359]
 [1010.866947 1022.680632 1011.071711 1011.14625  1010.126401]
 [1012.908248 1010.083474 1011.10225  1010.186867 1011.060241]
 [1011.028404 1011.062136 1010.05926  1010.167592 1011.044689]
 [1015.001635 1011.006404 1011.066729 1010.123588 1010.084648]
 [1011.129251 1011.137483 1011.990679 1010.074053 1010.094521]
 [1010.110567 1010.155116 1011.093241 1011.06304  1010.170416]
 [1011.017328 1010.089426 1011.049377 1011.061751 1011.055708]
 [1011.090226 1011.050462 1011.144829 1011.044884 1010.14845 ]
 [1011.136351 1010.006428 1010.10138  1010.12628  1011.051244]
 [1011.941713 1011.061604 1011.021852 1010.148307 1011.012543]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3598 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [ 721 3236 3601 3601 3601]
 [2776 1288  933 1431  119]
 [ 591  669  297 1411  675]
 [  30  517 1432  618  688]
 [ 105   65  191   35   68]
 [  72   80  330  117   48]
 [  70   59   26   32   29]
 [  44   77   58   25   72]
 [  53   38   36   30   22]
 [  25   25   24  171 3601]
 [  45   34   21   42   33]
 [ 678   62   96   23  442]
 [  40  152  157  101  117]
 [  20   46   26   42   50]
 [  42   42   39   67   28]
 [  75   36   35   62   86]
 [  61   44   27   41   61]
 [  28   38   32  208   25]
 [  34   36   38   44   32]
 [  30   35   77  122   36]
 [  27   54   44   48   32]
 [  32   22   75   23   56]
 [  37   41   25   23   29]
 [  59   29   44   35   38]
 [  37   22   32   25   19]
 [  39   23   25   21   30]
 [  32   41   21   26   39]
 [  23   25   45   21   39]
 [  30   22   28   28   74]
 [  35   22   25   26   38]
 [  31   23   26   49   20]
 [  46   38   41   25   22]
 [  20   32   52   25   33]
 [  94   33   21   28   57]
 [  45   24   29   26   27]
 [  26   49   21   24   21]
 [  44   18   24   26   66]
 [  31   27   30   22   24]
 [  24   53   27   28   18]
 [  21   25   20   27   20]
 [  17   22   20   20   23]
 [  18   32   22   18   19]
 [  21   20   23   62   24]
 [  29   29   21   18   21]
 [  17   22   25   25   20]
 [  46   21   35   29   19]
 [  23   30   32   19   18]
 [  21   21   31   22   26]
 [  26   23   19   19   19]
 [  20   24   23   16   20]
 [  18   19   27   27   27]
 [  21   20   19   23   22]
 [  24   22   19   28   44]
 [  24   20   23   19   20]
 [  26   25   34   30   23]
 [  41   21   21   32   20]
 [  27   21   29   28   18]
 [  21   19   18   20   22]
 [  19   21   21   34   19]
 [  21   21   25   21   18]
 [  18   19   24   17   20]
 [  19   28   25   24   31]
 [  19   24   20   19   19]
 [  19   19   39   24   20]
 [  23   23   20   19   18]
 [  20   18   21   21   20]
 [  19   23   19   19   19]
 [  21   33   21   17   21]
 [  20   24   20   20   20]
 [  20   18   36   19   20]
 [  21   19   19   20   18]
 [  19   18   18   18   21]
 [  24   20   28   19   19]
 [  21   20   18   19   23]
 [  18   21   20   19   31]
 [  29   26   18   23   21]
 [  20   21   19   22   19]
 [  28   20   18   19   22]
 [  20   26   20   19   21]
 [  23   18   19   20   26]
 [  22   22   25   25   22]
 [  23   24   19   19   21]
 [  20   19   28   19   20]
 [  20   24   22   31   19]
 [  29   34   18   17   19]
 [  27   19   20   19   18]
 [  23   20   20   17   20]
 [  26   20   23   21   17]
 [  19   20   21   21   18]
 [  20   19   19   21   19]
 [  22   18   20   19   21]
 [  20   19   19   20   19]
 [  20   22   18   17   19]
 [  22   18   20   17   22]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-24_14-26-37_llm_triton_qwen_14b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-24_14-26-37_llm_triton_qwen_14b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/model
