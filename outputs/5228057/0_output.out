####################
/var/spool/slurmd/job5293448/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_14B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-23_21-46-11_llm_triton_qwen_14b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and +9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 5    |
|    iterations      | 1    |
|    time_elapsed    | 348  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.15e+03    |
|    ep_rew_mean          | -942        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 2           |
|    time_elapsed         | 689         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.010656441 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.425      |
|    learning_rate        | 0.0003      |
|    loss                 | 25.2        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.997       |
|    value_loss           | 52.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.16e+03    |
|    ep_rew_mean          | -913        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 3           |
|    time_elapsed         | 1030        |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.011038141 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.348       |
|    learning_rate        | 0.0003      |
|    loss                 | 14.1        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.996       |
|    value_loss           | 40.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.16e+03   |
|    ep_rew_mean          | -900       |
| time/                   |            |
|    fps                  | 5          |
|    iterations           | 4          |
|    time_elapsed         | 1368       |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.00892627 |
|    clip_fraction        | 0.109      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | 8.68       |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.999      |
|    value_loss           | 27.7       |
----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.98 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.008517109 |
|    clip_fraction        | 0.0793      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.87        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.999       |
|    value_loss           | 20.7        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -874     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 5        |
|    time_elapsed    | 3504     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | -847        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 6           |
|    time_elapsed         | 3843        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.002233456 |
|    clip_fraction        | 0.00591     |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.00168    |
|    learning_rate        | 0.0003      |
|    loss                 | 919         |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00356    |
|    std                  | 0.999       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | -847        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 7           |
|    time_elapsed         | 4179        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008392493 |
|    clip_fraction        | 0.0681      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.45        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0135     |
|    std                  | 1           |
|    value_loss           | 10.9        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.05e+03     |
|    ep_rew_mean          | -826         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 8            |
|    time_elapsed         | 4510         |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0077166837 |
|    clip_fraction        | 0.0611       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.377        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.4          |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0119      |
|    std                  | 0.999        |
|    value_loss           | 8.47         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.08e+03    |
|    ep_rew_mean          | -819        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 9           |
|    time_elapsed         | 4838        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.010066874 |
|    clip_fraction        | 0.082       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.996       |
|    value_loss           | 7.07        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.010734472 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.997       |
|    value_loss           | 4.95        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -808     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 10       |
|    time_elapsed    | 6967     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.02e+03     |
|    ep_rew_mean          | -789         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 7291         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0048587695 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00293     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.16e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00353     |
|    std                  | 0.997        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -777        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 12          |
|    time_elapsed         | 7616        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.012159681 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.605       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.995       |
|    value_loss           | 3.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -777        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 7944        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.011560854 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.598       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.997       |
|    value_loss           | 2.97        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.06e+03    |
|    ep_rew_mean          | -766        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 8268        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.013604704 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.42        |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.996       |
|    value_loss           | 2.77        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.87 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.011672216 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.521       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.969       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.999       |
|    value_loss           | 2.23        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -753     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 15       |
|    time_elapsed    | 10394    |
|    total_timesteps | 30720    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.02e+03 |
|    ep_rew_mean          | -741     |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 16       |
|    time_elapsed         | 10719    |
|    total_timesteps      | 32768    |
| train/                  |          |
|    approx_kl            | 0.012356 |
|    clip_fraction        | 0.128    |
|    clip_range           | 0.2      |
|    entropy_loss         | -11.3    |
|    explained_variance   | 0.000328 |
|    learning_rate        | 0.0003   |
|    loss                 | 37.3     |
|    n_updates            | 150      |
|    policy_gradient_loss | -0.0107  |
|    std                  | 0.997    |
|    value_loss           | 1.04e+03 |
--------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.03e+03     |
|    ep_rew_mean          | -728         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 17           |
|    time_elapsed         | 11044        |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0155541925 |
|    clip_fraction        | 0.224        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.135       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.629        |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.0114      |
|    std                  | 0.991        |
|    value_loss           | 1.59         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -717        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 11369       |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.021776501 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.424       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.901       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.992       |
|    value_loss           | 1.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -717        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 11694       |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.013800304 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.41        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.721       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.995       |
|    value_loss           | 1.76        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.89 +/- 0.02
Episode length: 3601.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.9        |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0143551305 |
|    clip_fraction        | 0.166        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.519        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.477        |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.0175      |
|    std                  | 0.994        |
|    value_loss           | 1.33         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -707     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 20       |
|    time_elapsed    | 13818    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -695         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 14141        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0077561717 |
|    clip_fraction        | 0.0827       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.00312      |
|    learning_rate        | 0.0003       |
|    loss                 | 1.51e+03     |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00354     |
|    std                  | 0.993        |
|    value_loss           | 1.05e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.03e+03   |
|    ep_rew_mean          | -689       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 22         |
|    time_elapsed         | 14465      |
|    total_timesteps      | 45056      |
| train/                  |            |
|    approx_kl            | 0.00884816 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.328      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.895      |
|    n_updates            | 210        |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.993      |
|    value_loss           | 2.7        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -680        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 14787       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.016460104 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.331       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.985       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.997       |
|    value_loss           | 1.48        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.05e+03    |
|    ep_rew_mean          | -671        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 24          |
|    time_elapsed         | 15111       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.016693048 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.444       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00031    |
|    std                  | 0.991       |
|    value_loss           | 1.63        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.95 +/- 0.12
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.029560853 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.486       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.482       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00513    |
|    std                  | 0.988       |
|    value_loss           | 1.27        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -670     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 25       |
|    time_elapsed    | 17233    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -661        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 17555       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.011651063 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.002      |
|    learning_rate        | 0.0003      |
|    loss                 | 359         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00273    |
|    std                  | 0.988       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -654        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 17878       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.030017847 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.53       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.709       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00706    |
|    std                  | 0.986       |
|    value_loss           | 1.58        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | -650        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 18204       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.018227894 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.419       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.586       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00443    |
|    std                  | 0.978       |
|    value_loss           | 1.29        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.04e+03     |
|    ep_rew_mean          | -643         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 29           |
|    time_elapsed         | 18529        |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0061005508 |
|    clip_fraction        | 0.0813       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.527        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.52         |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00713     |
|    std                  | 0.976        |
|    value_loss           | 5.09         |
------------------------------------------
Eval num_timesteps=60000, episode_reward=-99.92 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.026187044 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.398       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.565       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00434    |
|    std                  | 0.971       |
|    value_loss           | 1.36        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -644     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 30       |
|    time_elapsed    | 20653    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -637        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 20975       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.021739572 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.00454     |
|    learning_rate        | 0.0003      |
|    loss                 | 244         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.973       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.02e+03     |
|    ep_rew_mean          | -637         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 32           |
|    time_elapsed         | 21297        |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0076133814 |
|    clip_fraction        | 0.0527       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.901        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.66         |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00624     |
|    std                  | 0.974        |
|    value_loss           | 5.87         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | -636        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 21621       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.013053092 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.108       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.68        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.973       |
|    value_loss           | 3.86        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.03e+03   |
|    ep_rew_mean          | -631       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 34         |
|    time_elapsed         | 21943      |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.02577444 |
|    clip_fraction        | 0.193      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.942      |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.0099    |
|    std                  | 0.971      |
|    value_loss           | 2.09       |
----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.81 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.019262286 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.77        |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00871    |
|    std                  | 0.968       |
|    value_loss           | 1.68        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -633     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 35       |
|    time_elapsed    | 24067    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -628        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 24389       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.007583122 |
|    clip_fraction        | 0.0581      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.0847     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00684    |
|    std                  | 0.968       |
|    value_loss           | 996         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -623        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 24713       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.034674436 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.27        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 360         |
|    policy_gradient_loss | 0.00981     |
|    std                  | 0.964       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -623        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 25036       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.011136672 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.965       |
|    value_loss           | 3.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.03e+03    |
|    ep_rew_mean          | -621        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 25358       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.009834867 |
|    clip_fraction        | 0.0714      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.57        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.962       |
|    value_loss           | 4.35        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.85 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.019757165 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.321       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.695       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.965       |
|    value_loss           | 1.34        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -621     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 40       |
|    time_elapsed    | 27483    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -622        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 27805       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.006988881 |
|    clip_fraction        | 0.0628      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.104       |
|    learning_rate        | 0.0003      |
|    loss                 | 412         |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00195    |
|    std                  | 0.965       |
|    value_loss           | 1e+03       |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -617         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 42           |
|    time_elapsed         | 28126        |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0069004647 |
|    clip_fraction        | 0.0393       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.864        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.78         |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.00864     |
|    std                  | 0.966        |
|    value_loss           | 2.52         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -613        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 28446       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.006310364 |
|    clip_fraction        | 0.0443      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.329       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.961       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.965       |
|    value_loss           | 2.19        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.78 +/- 0.02
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.004112782 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.315       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.917       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.00434    |
|    std                  | 0.965       |
|    value_loss           | 2.21        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -610     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 44       |
|    time_elapsed    | 30570    |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -610         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 45           |
|    time_elapsed         | 30892        |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0030524598 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -0.037       |
|    learning_rate        | 0.0003       |
|    loss                 | 2.02e+03     |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00413     |
|    std                  | 0.965        |
|    value_loss           | 1.01e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -611        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 31213       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.010116067 |
|    clip_fraction        | 0.092       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.964      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.681       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.966       |
|    value_loss           | 2.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -607        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 31535       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.012715824 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.504       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.966       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -602        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 31855       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.027790062 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.474       |
|    n_updates            | 470         |
|    policy_gradient_loss | 0.00207     |
|    std                  | 0.969       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.80 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.030598124 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.752       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00803    |
|    std                  | 0.966       |
|    value_loss           | 1.43        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -598     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 49       |
|    time_elapsed    | 33975    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -594        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 50          |
|    time_elapsed         | 34295       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.005671926 |
|    clip_fraction        | 0.0689      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0233      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.27e+03    |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00298    |
|    std                  | 0.966       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -594        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 34613       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.007737863 |
|    clip_fraction        | 0.0555      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.382       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.927       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.966       |
|    value_loss           | 2.49        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -589        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 34935       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.023408495 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.347       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.587       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00425    |
|    std                  | 0.958       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -589        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 35257       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.023765992 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.7         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.528       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.956       |
|    value_loss           | 1.57        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.86 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.014616409 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.8         |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00929    |
|    std                  | 0.952       |
|    value_loss           | 1.66        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -587     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 54       |
|    time_elapsed    | 37376    |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -586         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 55           |
|    time_elapsed         | 37696        |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0078114714 |
|    clip_fraction        | 0.0489       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | 0.0108       |
|    learning_rate        | 0.0003       |
|    loss                 | 1.16e+03     |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00731     |
|    std                  | 0.951        |
|    value_loss           | 1.03e+03     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -586         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 56           |
|    time_elapsed         | 38016        |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0075005456 |
|    clip_fraction        | 0.0579       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | -0.203       |
|    learning_rate        | 0.0003       |
|    loss                 | 2.02         |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00714     |
|    std                  | 0.95         |
|    value_loss           | 2.92         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -586        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 38335       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.006404411 |
|    clip_fraction        | 0.0333      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0947      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00866    |
|    std                  | 0.95        |
|    value_loss           | 2.02        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -582        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 38656       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.010798123 |
|    clip_fraction        | 0.0881      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -1.25       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.656       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.949       |
|    value_loss           | 1.52        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.85 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.014975237 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.35        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.663       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00622    |
|    std                  | 0.949       |
|    value_loss           | 1.47        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -583     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 59       |
|    time_elapsed    | 40777    |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -582         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 60           |
|    time_elapsed         | 41101        |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0065452717 |
|    clip_fraction        | 0.0407       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | -0.000735    |
|    learning_rate        | 0.0003       |
|    loss                 | 270          |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00442     |
|    std                  | 0.949        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -581        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 41421       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.016207358 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.443      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.913       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00961    |
|    std                  | 0.948       |
|    value_loss           | 1.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -578        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 41742       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.029837951 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.559       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.946       |
|    value_loss           | 1.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -578        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 42064       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.020450301 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.711       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.797       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.946       |
|    value_loss           | 1.28        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.82 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.018721335 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.316       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.693       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00457    |
|    std                  | 0.942       |
|    value_loss           | 1.31        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -578     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 64       |
|    time_elapsed    | 44184    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -575         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 65           |
|    time_elapsed         | 44506        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0064814226 |
|    clip_fraction        | 0.0735       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | -0.00311     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.25e+03     |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00633     |
|    std                  | 0.942        |
|    value_loss           | 1.05e+03     |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.01e+03  |
|    ep_rew_mean          | -572      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 66        |
|    time_elapsed         | 44827     |
|    total_timesteps      | 135168    |
| train/                  |           |
|    approx_kl            | 0.0358012 |
|    clip_fraction        | 0.242     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.9     |
|    explained_variance   | 0.0611    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.446     |
|    n_updates            | 650       |
|    policy_gradient_loss | -0.00817  |
|    std                  | 0.941     |
|    value_loss           | 1.15      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -568       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 67         |
|    time_elapsed         | 45148      |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.02991885 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.549      |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.0058    |
|    std                  | 0.939      |
|    value_loss           | 1.1        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -565        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 45469       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.032866433 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.494       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.465       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.000246   |
|    std                  | 0.937       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 140000    |
| train/                  |           |
|    approx_kl            | 0.0296547 |
|    clip_fraction        | 0.27      |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.8     |
|    explained_variance   | 0.605     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.785     |
|    n_updates            | 680       |
|    policy_gradient_loss | -0.0109   |
|    std                  | 0.937     |
|    value_loss           | 1.49      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -567     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 69       |
|    time_elapsed    | 47590    |
|    total_timesteps | 141312   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -564         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 70           |
|    time_elapsed         | 47911        |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0040601008 |
|    clip_fraction        | 0.0285       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.0315       |
|    learning_rate        | 0.0003       |
|    loss                 | 196          |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.00423     |
|    std                  | 0.937        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -564        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 48233       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.026949123 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.96        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.639       |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00364    |
|    std                  | 0.932       |
|    value_loss           | 1.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -560        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 48552       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.018138688 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.973       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00648    |
|    std                  | 0.933       |
|    value_loss           | 0.99        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -556        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 48870       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.068036154 |
|    clip_fraction        | 0.447       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.498       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.495       |
|    n_updates            | 720         |
|    policy_gradient_loss | 0.0175      |
|    std                  | 0.935       |
|    value_loss           | 1.25        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.03741913 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.336      |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00273   |
|    std                  | 0.934      |
|    value_loss           | 0.837      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -556     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 74       |
|    time_elapsed    | 50988    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -555        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 75          |
|    time_elapsed         | 51308       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.008081573 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.000584    |
|    learning_rate        | 0.0003      |
|    loss                 | 13.6        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00475    |
|    std                  | 0.934       |
|    value_loss           | 1e+03       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -551        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 51626       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.010838841 |
|    clip_fraction        | 0.058       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.908      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.685       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00527    |
|    std                  | 0.934       |
|    value_loss           | 2.28        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -547         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 77           |
|    time_elapsed         | 51947        |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0093330685 |
|    clip_fraction        | 0.093        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.509        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.803        |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.0133      |
|    std                  | 0.933        |
|    value_loss           | 1.24         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -547        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 52269       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.016397897 |
|    clip_fraction        | 0.0805      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.693       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.933       |
|    value_loss           | 1.41        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.85 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.011588378 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.64        |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.933       |
|    value_loss           | 1.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -549     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 79       |
|    time_elapsed    | 54392    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -546        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 80          |
|    time_elapsed         | 54710       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.004770373 |
|    clip_fraction        | 0.0381      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0209      |
|    learning_rate        | 0.0003      |
|    loss                 | 46.6        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00427    |
|    std                  | 0.932       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -543        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 55032       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.020975461 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.933       |
|    value_loss           | 1.66        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -542        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 55353       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.024570178 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.579       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00734    |
|    std                  | 0.932       |
|    value_loss           | 1.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -538        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 55673       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.040723417 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.312       |
|    n_updates            | 820         |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.938       |
|    value_loss           | 0.973       |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.86 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.022161081 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.697       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00625    |
|    std                  | 0.946       |
|    value_loss           | 1.51        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -540     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 84       |
|    time_elapsed    | 57792    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -538        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 85          |
|    time_elapsed         | 58110       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.010558946 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00184    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.17        |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00537    |
|    std                  | 0.945       |
|    value_loss           | 916         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -535        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 58426       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.028665856 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.587       |
|    n_updates            | 850         |
|    policy_gradient_loss | 0.000975    |
|    std                  | 0.935       |
|    value_loss           | 1.02        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -531        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 58743       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.040759705 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.584       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.461       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.934       |
|    value_loss           | 0.846       |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.80 +/- 0.06
Episode length: 3599.80 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.02537961 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.00817   |
|    std                  | 0.927      |
|    value_loss           | 0.909      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -528     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 88       |
|    time_elapsed    | 60861    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -528        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 89          |
|    time_elapsed         | 61183       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.013365664 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.000245   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.92        |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00694    |
|    std                  | 0.926       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -528        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 90          |
|    time_elapsed         | 61505       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.012473299 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.944       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.925       |
|    value_loss           | 1.61        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.01e+03  |
|    ep_rew_mean          | -528      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 91        |
|    time_elapsed         | 61827     |
|    total_timesteps      | 186368    |
| train/                  |           |
|    approx_kl            | 0.0163936 |
|    clip_fraction        | 0.192     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.7     |
|    explained_variance   | 0.342     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.741     |
|    n_updates            | 900       |
|    policy_gradient_loss | -0.0162   |
|    std                  | 0.923     |
|    value_loss           | 1.61      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -527        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 62150       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.018207574 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.399       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.248       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.921       |
|    value_loss           | 1.15        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.79 +/- 0.05
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.02221825 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.684      |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.919      |
|    value_loss           | 1.57       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -529     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 93       |
|    time_elapsed    | 64273    |
|    total_timesteps | 190464   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -529         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 94           |
|    time_elapsed         | 64594        |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0125878975 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.7        |
|    explained_variance   | 0.00276      |
|    learning_rate        | 0.0003       |
|    loss                 | 420          |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.00656     |
|    std                  | 0.919        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -529        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 95          |
|    time_elapsed         | 64910       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.024723677 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.724       |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.922       |
|    value_loss           | 1.41        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -526       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 96         |
|    time_elapsed         | 65228      |
|    total_timesteps      | 196608     |
| train/                  |            |
|    approx_kl            | 0.03979625 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.302      |
|    n_updates            | 950        |
|    policy_gradient_loss | 0.00545    |
|    std                  | 0.92       |
|    value_loss           | 0.67       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -523       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 65545      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.04286721 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.00918   |
|    std                  | 0.912      |
|    value_loss           | 0.829      |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.83 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.023634665 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.462       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00877    |
|    std                  | 0.91        |
|    value_loss           | 0.923       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -521     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 98       |
|    time_elapsed    | 67664    |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -514       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 99         |
|    time_elapsed         | 67983      |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.01423412 |
|    clip_fraction        | 0.139      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.108      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+03   |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.00639   |
|    std                  | 0.91       |
|    value_loss           | 1.02e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -508        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 100         |
|    time_elapsed         | 68303       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.023771662 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.463       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.905       |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -508        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 68621       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.029572887 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.946       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.471       |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.899       |
|    value_loss           | 2.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -501        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 68938       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.027155166 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.315       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00177    |
|    std                  | 0.895       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.78 +/- 0.03
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.028259564 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.408       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00972    |
|    std                  | 0.891       |
|    value_loss           | 0.849       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -492     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 103      |
|    time_elapsed    | 71059    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -490        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 104         |
|    time_elapsed         | 71380       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.014485622 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00722     |
|    learning_rate        | 0.0003      |
|    loss                 | 618         |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00671    |
|    std                  | 0.892       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -484        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 105         |
|    time_elapsed         | 71698       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.020722779 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.959       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.48        |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.891       |
|    value_loss           | 1.3         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -481       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 72018      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.02519657 |
|    clip_fraction        | 0.225      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.383      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.00993   |
|    std                  | 0.885      |
|    value_loss           | 1.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -481       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 72339      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.01964787 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.927      |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.882      |
|    value_loss           | 2.01       |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.84 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 220000    |
| train/                  |           |
|    approx_kl            | 0.0221388 |
|    clip_fraction        | 0.232     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.3     |
|    explained_variance   | 0.266     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.485     |
|    n_updates            | 1070      |
|    policy_gradient_loss | -0.0107   |
|    std                  | 0.881     |
|    value_loss           | 1.24      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -477     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 108      |
|    time_elapsed    | 74455    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -472        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 109         |
|    time_elapsed         | 74775       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.018265408 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00346     |
|    learning_rate        | 0.0003      |
|    loss                 | 901         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00414    |
|    std                  | 0.88        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -468        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 75091       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.044995695 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.573       |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0026     |
|    std                  | 0.877       |
|    value_loss           | 1.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -467        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 75409       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.028696183 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.506       |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00838    |
|    std                  | 0.871       |
|    value_loss           | 1.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -463        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 75724       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.017789379 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.495       |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.873       |
|    value_loss           | 1.31        |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.87 +/- 0.07
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.034842417 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.484       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00504     |
|    std                  | 0.876       |
|    value_loss           | 1.19        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -461     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 113      |
|    time_elapsed    | 77840    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -457        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 114         |
|    time_elapsed         | 78157       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.017376501 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0905      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8         |
|    n_updates            | 1130        |
|    policy_gradient_loss | 0.00198     |
|    std                  | 0.875       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -456        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 78473       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.015244357 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.985       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.876       |
|    value_loss           | 1.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -454        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 78791       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.024408208 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.969       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.89        |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.876       |
|    value_loss           | 1.85        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -451        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 79106       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.028539076 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.873       |
|    value_loss           | 2.06        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0458982 |
|    clip_fraction        | 0.342     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | 0.897     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.06      |
|    n_updates            | 1170      |
|    policy_gradient_loss | -0.00497  |
|    std                  | 0.864     |
|    value_loss           | 1.82      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -450     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 118      |
|    time_elapsed    | 81222    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -447        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 119         |
|    time_elapsed         | 81536       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.016331008 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00345     |
|    learning_rate        | 0.0003      |
|    loss                 | 373         |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0036     |
|    std                  | 0.863       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -442       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 120        |
|    time_elapsed         | 81848      |
|    total_timesteps      | 245760     |
| train/                  |            |
|    approx_kl            | 0.04253919 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | -0.0825    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.376      |
|    n_updates            | 1190       |
|    policy_gradient_loss | 0.00393    |
|    std                  | 0.86       |
|    value_loss           | 1.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -438       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 121        |
|    time_elapsed         | 82163      |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.04801634 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.529      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 1200       |
|    policy_gradient_loss | 0.00502    |
|    std                  | 0.858      |
|    value_loss           | 0.827      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -435        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 82477       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.037216768 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.484       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00272    |
|    std                  | 0.857       |
|    value_loss           | 0.834       |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.00 +/- 1.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.040720932 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.551       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00456    |
|    std                  | 0.85        |
|    value_loss           | 0.887       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -434     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 123      |
|    time_elapsed    | 84592    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -430        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 124         |
|    time_elapsed         | 84908       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.014399407 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.00146    |
|    learning_rate        | 0.0003      |
|    loss                 | 86.2        |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00461    |
|    std                  | 0.85        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -427       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 125        |
|    time_elapsed         | 85222      |
|    total_timesteps      | 256000     |
| train/                  |            |
|    approx_kl            | 0.03065494 |
|    clip_fraction        | 0.166      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.0273    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.43       |
|    n_updates            | 1240       |
|    policy_gradient_loss | -0.00642   |
|    std                  | 0.846      |
|    value_loss           | 1.17       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -422        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 85536       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.046785966 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.531       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00245    |
|    std                  | 0.846       |
|    value_loss           | 0.95        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.75 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.036061257 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.365       |
|    n_updates            | 1260        |
|    policy_gradient_loss | 0.00398     |
|    std                  | 0.844       |
|    value_loss           | 0.791       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -418     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 127      |
|    time_elapsed    | 87652    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -418        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 128         |
|    time_elapsed         | 87973       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.022569347 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.0909      |
|    learning_rate        | 0.0003      |
|    loss                 | 16.1        |
|    n_updates            | 1270        |
|    policy_gradient_loss | 0.00522     |
|    std                  | 0.844       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -418        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 129         |
|    time_elapsed         | 88294       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.022541583 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.135      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.386       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.844       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -417        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 88611       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.015461273 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.694       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.844       |
|    value_loss           | 1.31        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -412       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 131        |
|    time_elapsed         | 88930      |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.02360123 |
|    clip_fraction        | 0.209      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.00724   |
|    std                  | 0.843      |
|    value_loss           | 1.08       |
----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.038932234 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.988       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.526       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00892    |
|    std                  | 0.843       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -410     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 132      |
|    time_elapsed    | 91049    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -407        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 133         |
|    time_elapsed         | 91364       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.008508368 |
|    clip_fraction        | 0.0638      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | 16.1        |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00046    |
|    std                  | 0.843       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -407       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 134        |
|    time_elapsed         | 91680      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.04260766 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.467      |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.00986    |
|    std                  | 0.84       |
|    value_loss           | 0.717      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -403       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 91992      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.07190128 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.93      |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.423      |
|    n_updates            | 1340       |
|    policy_gradient_loss | 0.00866    |
|    std                  | 0.842      |
|    value_loss           | 0.953      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -397        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 92309       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.053375185 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.608       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.292       |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.00802     |
|    std                  | 0.842       |
|    value_loss           | 0.763       |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.84 +/- 0.06
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 280000   |
| train/                  |          |
|    approx_kl            | 0.043128 |
|    clip_fraction        | 0.32     |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.93    |
|    explained_variance   | 0.974    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.39     |
|    n_updates            | 1360     |
|    policy_gradient_loss | -0.00397 |
|    std                  | 0.838    |
|    value_loss           | 2.43     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -393     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 137      |
|    time_elapsed    | 94423    |
|    total_timesteps | 280576   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -387      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 138       |
|    time_elapsed         | 94739     |
|    total_timesteps      | 282624    |
| train/                  |           |
|    approx_kl            | 0.0221836 |
|    clip_fraction        | 0.21      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.91     |
|    explained_variance   | 0.00979   |
|    learning_rate        | 0.0003    |
|    loss                 | 4.04      |
|    n_updates            | 1370      |
|    policy_gradient_loss | -0.00865  |
|    std                  | 0.838     |
|    value_loss           | 1.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -387       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 139        |
|    time_elapsed         | 95054      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.18784094 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.9       |
|    explained_variance   | -0.175     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.271      |
|    n_updates            | 1380       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.836      |
|    value_loss           | 1.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -384       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 140        |
|    time_elapsed         | 95368      |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.07565917 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.545      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.308      |
|    n_updates            | 1390       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.831      |
|    value_loss           | 0.919      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -381       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 95683      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.03884913 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.85      |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36       |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.00349   |
|    std                  | 0.83       |
|    value_loss           | 1.6        |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.78 +/- 0.06
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.04208893 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 1410       |
|    policy_gradient_loss | 0.00602    |
|    std                  | 0.827      |
|    value_loss           | 0.733      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -377     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 142      |
|    time_elapsed    | 97800    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -371        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 143         |
|    time_elapsed         | 98117       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.014947572 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+03    |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00463    |
|    std                  | 0.828       |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -368        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 144         |
|    time_elapsed         | 98431       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.036850296 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.413       |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.829       |
|    value_loss           | 2.41        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -368        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 98745       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.040939838 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | 0.635       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.305       |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.00475     |
|    std                  | 0.832       |
|    value_loss           | 0.655       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -364       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 99058      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.03472118 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.8       |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.429      |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.00526   |
|    std                  | 0.824      |
|    value_loss           | 0.811      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.77 +/- 0.05
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.026194222 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | 0.559       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.299       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00113    |
|    std                  | 0.818       |
|    value_loss           | 0.791       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -360     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 147      |
|    time_elapsed    | 101172   |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -356        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 148         |
|    time_elapsed         | 101485      |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.016780352 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.00222     |
|    learning_rate        | 0.0003      |
|    loss                 | 394         |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00353    |
|    std                  | 0.819       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -354        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 149         |
|    time_elapsed         | 101798      |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.031318236 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.843       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.323       |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.000729   |
|    std                  | 0.818       |
|    value_loss           | 1.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -349        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 102112      |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.054284543 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.444       |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.809       |
|    value_loss           | 1.78        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -349        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 102424      |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.044606276 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.805       |
|    value_loss           | 1.36        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.78 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.047776066 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.363       |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.000923    |
|    std                  | 0.802       |
|    value_loss           | 0.65        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -344     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 152      |
|    time_elapsed    | 104539   |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -339        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 153         |
|    time_elapsed         | 104852      |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.033673435 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | 0.00883     |
|    learning_rate        | 0.0003      |
|    loss                 | 917         |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00668    |
|    std                  | 0.801       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -333       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 154        |
|    time_elapsed         | 105164     |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.06718576 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | 0.222      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.388      |
|    n_updates            | 1530       |
|    policy_gradient_loss | 0.00357    |
|    std                  | 0.795      |
|    value_loss           | 0.749      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -330        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 105477      |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.036045343 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.346       |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.000762   |
|    std                  | 0.799       |
|    value_loss           | 0.805       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -324        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 105790      |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.028296992 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.51       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.349       |
|    n_updates            | 1550        |
|    policy_gradient_loss | 0.000891    |
|    std                  | 0.799       |
|    value_loss           | 0.691       |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.77 +/- 0.05
Episode length: 3598.80 +/- 4.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.04428813 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.32       |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.00396   |
|    std                  | 0.796      |
|    value_loss           | 0.768      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -322     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 157      |
|    time_elapsed    | 107902   |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -317        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 158         |
|    time_elapsed         | 108217      |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.020855106 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.00244     |
|    learning_rate        | 0.0003      |
|    loss                 | 389         |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00465    |
|    std                  | 0.796       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -313        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 108530      |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.042551666 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00227    |
|    std                  | 0.792       |
|    value_loss           | 1           |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -309        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 108843      |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.064279646 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.247       |
|    n_updates            | 1590        |
|    policy_gradient_loss | 0.00928     |
|    std                  | 0.79        |
|    value_loss           | 0.652       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -303        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 109156      |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.042875588 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | 0.629       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.339       |
|    n_updates            | 1600        |
|    policy_gradient_loss | 0.00126     |
|    std                  | 0.789       |
|    value_loss           | 0.661       |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.78 +/- 0.05
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.04302183 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.44      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.354      |
|    n_updates            | 1610       |
|    policy_gradient_loss | 0.000725   |
|    std                  | 0.793      |
|    value_loss           | 0.582      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -301     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 162      |
|    time_elapsed    | 111271   |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -298        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 163         |
|    time_elapsed         | 111583      |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.021338575 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.000569    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.41        |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00647    |
|    std                  | 0.793       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -294        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 111894      |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.047770627 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.45       |
|    explained_variance   | 0.882       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.821       |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.00412    |
|    std                  | 0.791       |
|    value_loss           | 1.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -291        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 112207      |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.047376327 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.426       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.0142      |
|    std                  | 0.787       |
|    value_loss           | 0.831       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -287       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 112519     |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.05461336 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.37      |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.366      |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.00101   |
|    std                  | 0.783      |
|    value_loss           | 0.579      |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.84 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.034728948 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.35       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.363       |
|    n_updates            | 1660        |
|    policy_gradient_loss | 0.00725     |
|    std                  | 0.782       |
|    value_loss           | 0.708       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -285     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 167      |
|    time_elapsed    | 114631   |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -281        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 168         |
|    time_elapsed         | 114944      |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.028586946 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | 0.00301     |
|    learning_rate        | 0.0003      |
|    loss                 | 825         |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00527    |
|    std                  | 0.781       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -277        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 115255      |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.073265605 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13        |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0014     |
|    std                  | 0.782       |
|    value_loss           | 1.54        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -274        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 115566      |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.047946412 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.514       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.371       |
|    n_updates            | 1690        |
|    policy_gradient_loss | 0.00203     |
|    std                  | 0.776       |
|    value_loss           | 0.783       |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.80 +/- 0.04
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.05072509 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 1700       |
|    policy_gradient_loss | 0.00436    |
|    std                  | 0.775      |
|    value_loss           | 0.777      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -270     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 171      |
|    time_elapsed    | 117679   |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -270        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 172         |
|    time_elapsed         | 117990      |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.045910828 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.00109     |
|    learning_rate        | 0.0003      |
|    loss                 | 716         |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.000713   |
|    std                  | 0.776       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -265      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 173       |
|    time_elapsed         | 118303    |
|    total_timesteps      | 354304    |
| train/                  |           |
|    approx_kl            | 0.0894714 |
|    clip_fraction        | 0.347     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.27     |
|    explained_variance   | 0.0862    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.407     |
|    n_updates            | 1720      |
|    policy_gradient_loss | 0.0117    |
|    std                  | 0.774     |
|    value_loss           | 0.901     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -263       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 118616     |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.06844221 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.26      |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.773      |
|    value_loss           | 1.15       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -260        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 118928      |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.055074096 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.277       |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.00779     |
|    std                  | 0.771       |
|    value_loss           | 0.621       |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.82 +/- 0.02
Episode length: 3598.40 +/- 4.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.07032825 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.23      |
|    explained_variance   | 0.663      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.4        |
|    n_updates            | 1750       |
|    policy_gradient_loss | 0.00253    |
|    std                  | 0.77       |
|    value_loss           | 0.571      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -253     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 176      |
|    time_elapsed    | 121043   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -250        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 177         |
|    time_elapsed         | 121354      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.026377903 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.0115      |
|    learning_rate        | 0.0003      |
|    loss                 | 818         |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.0057     |
|    std                  | 0.77        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -250       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 178        |
|    time_elapsed         | 121664     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.08667827 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.363      |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.00965    |
|    std                  | 0.772      |
|    value_loss           | 0.79       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 121974      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.058856692 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.686       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.158       |
|    n_updates            | 1780        |
|    policy_gradient_loss | 0.0145      |
|    std                  | 0.768       |
|    value_loss           | 0.474       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -242        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 122285      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.053083222 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.283       |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.00789     |
|    std                  | 0.763       |
|    value_loss           | 0.559       |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.045939572 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.752       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 8.39e-05    |
|    std                  | 0.758       |
|    value_loss           | 1.27        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -237     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 181      |
|    time_elapsed    | 124399   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -232        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 182         |
|    time_elapsed         | 124708      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.027519204 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -0.00198    |
|    learning_rate        | 0.0003      |
|    loss                 | 444         |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00535    |
|    std                  | 0.758       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -229       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 183        |
|    time_elapsed         | 125018     |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.19761397 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.09      |
|    explained_variance   | 0.0251     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.758      |
|    value_loss           | 0.698      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -229       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 125330     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.05104572 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.4        |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.76       |
|    value_loss           | 0.769      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -227        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 125642      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.043463107 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.296       |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.757       |
|    value_loss           | 0.578       |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.81 +/- 0.03
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.057302687 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.622       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.754       |
|    value_loss           | 1.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -224     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 186      |
|    time_elapsed    | 127755   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -217        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 187         |
|    time_elapsed         | 128065      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.040499844 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.00296     |
|    learning_rate        | 0.0003      |
|    loss                 | 10.3        |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00159    |
|    std                  | 0.755       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -211       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 188        |
|    time_elapsed         | 128377     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.08246449 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.171      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.289      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.751      |
|    value_loss           | 0.945      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -211        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 128686      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.071551174 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.62        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.327       |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.754       |
|    value_loss           | 0.715       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -206        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 190         |
|    time_elapsed         | 128995      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.058305733 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.37        |
|    n_updates            | 1890        |
|    policy_gradient_loss | 0.00872     |
|    std                  | 0.752       |
|    value_loss           | 0.721       |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.84 +/- 0.03
Episode length: 3598.00 +/- 4.10
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.051165007 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.573       |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00508    |
|    std                  | 0.753       |
|    value_loss           | 0.958       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -199     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 191      |
|    time_elapsed    | 131107   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -193        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 192         |
|    time_elapsed         | 131419      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.031230541 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.0154      |
|    learning_rate        | 0.0003      |
|    loss                 | 71.6        |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00297    |
|    std                  | 0.753       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -190       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 193        |
|    time_elapsed         | 131729     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.20061824 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | 0.289      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.454      |
|    n_updates            | 1920       |
|    policy_gradient_loss | 0.0379     |
|    std                  | 0.75       |
|    value_loss           | 1.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -188       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 194        |
|    time_elapsed         | 132039     |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.08319108 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68       |
|    n_updates            | 1930       |
|    policy_gradient_loss | -0.00224   |
|    std                  | 0.742      |
|    value_loss           | 1.52       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -188       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 195        |
|    time_elapsed         | 132349     |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.06282381 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.466      |
|    n_updates            | 1940       |
|    policy_gradient_loss | 0.00903    |
|    std                  | 0.742      |
|    value_loss           | 0.839      |
----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.83 +/- 0.02
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.04398135 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.233      |
|    n_updates            | 1950       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.738      |
|    value_loss           | 0.669      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -183     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 196      |
|    time_elapsed    | 134460   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -180        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 197         |
|    time_elapsed         | 134768      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.045414284 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.00326     |
|    learning_rate        | 0.0003      |
|    loss                 | 43.7        |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.00196    |
|    std                  | 0.739       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -176       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 198        |
|    time_elapsed         | 135077     |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.27664346 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.86      |
|    explained_variance   | 0.364      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.255      |
|    n_updates            | 1970       |
|    policy_gradient_loss | 0.00482    |
|    std                  | 0.736      |
|    value_loss           | 0.797      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -174       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 135387     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07355479 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.83      |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.342      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.00784    |
|    std                  | 0.733      |
|    value_loss           | 0.562      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -171      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 200       |
|    time_elapsed         | 135697    |
|    total_timesteps      | 409600    |
| train/                  |           |
|    approx_kl            | 0.1615155 |
|    clip_fraction        | 0.36      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.8      |
|    explained_variance   | 0.743     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.355     |
|    n_updates            | 1990      |
|    policy_gradient_loss | 0.00785   |
|    std                  | 0.729     |
|    value_loss           | 0.695     |
---------------------------------------
Eval num_timesteps=410000, episode_reward=-99.81 +/- 0.03
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.089636505 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.0183      |
|    std                  | 0.727       |
|    value_loss           | 0.554       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -170     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 201      |
|    time_elapsed    | 137806   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -164        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 202         |
|    time_elapsed         | 138116      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.038177386 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.00238     |
|    learning_rate        | 0.0003      |
|    loss                 | 161         |
|    n_updates            | 2010        |
|    policy_gradient_loss | 0.00567     |
|    std                  | 0.727       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -162       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 138425     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.12456041 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.73      |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.347      |
|    n_updates            | 2020       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.723      |
|    value_loss           | 0.682      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -157       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 138735     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.09132385 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.264      |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.722      |
|    value_loss           | 0.598      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -151       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 139046     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.05471719 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.336      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.722      |
|    value_loss           | 0.539      |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.77 +/- 0.06
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.07286326 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.68      |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.151      |
|    n_updates            | 2050       |
|    policy_gradient_loss | 0.00171    |
|    std                  | 0.722      |
|    value_loss           | 0.546      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -150     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 206      |
|    time_elapsed    | 141156   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -148        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 207         |
|    time_elapsed         | 141464      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.040908687 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | -0.00166    |
|    learning_rate        | 0.0003      |
|    loss                 | 120         |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.722       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -145      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 208       |
|    time_elapsed         | 141776    |
|    total_timesteps      | 425984    |
| train/                  |           |
|    approx_kl            | 0.9763334 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.7      |
|    explained_variance   | -0.0379   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.307     |
|    n_updates            | 2070      |
|    policy_gradient_loss | 0.042     |
|    std                  | 0.721     |
|    value_loss           | 0.83      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -140       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 142089     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.45297095 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | 0.55       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.316      |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0363     |
|    std                  | 0.722      |
|    value_loss           | 0.973      |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.83 +/- 0.02
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.062825605 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.455       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.0047      |
|    std                  | 0.72        |
|    value_loss           | 0.965       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -137     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 210      |
|    time_elapsed    | 144201   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -137        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 211         |
|    time_elapsed         | 144512      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.044626385 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.00376     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.73        |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00493    |
|    std                  | 0.72        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -136       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 212        |
|    time_elapsed         | 144826     |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.10399909 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.415      |
|    n_updates            | 2110       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.717      |
|    value_loss           | 1          |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -132       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 213        |
|    time_elapsed         | 145139     |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.08566591 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.396      |
|    n_updates            | 2120       |
|    policy_gradient_loss | 0.00559    |
|    std                  | 0.713      |
|    value_loss           | 0.794      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -128       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 145449     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.07828854 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.579      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.715      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.80 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.07829198 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.61      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 2140       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.715      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -124     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 215      |
|    time_elapsed    | 147560   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -122        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 216         |
|    time_elapsed         | 147875      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.046513885 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.000444    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.38e+03    |
|    n_updates            | 2150        |
|    policy_gradient_loss | 1.82e-05    |
|    std                  | 0.715       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -122       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 217        |
|    time_elapsed         | 148187     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.10546526 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.27       |
|    n_updates            | 2160       |
|    policy_gradient_loss | 0.00597    |
|    std                  | 0.718      |
|    value_loss           | 0.739      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -120       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 148498     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.06396742 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.567      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.55       |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.714      |
|    value_loss           | 0.922      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -119        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 148808      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.073748015 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.66        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.287       |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.0178      |
|    std                  | 0.712       |
|    value_loss           | 0.668       |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.79 +/- 0.04
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.06116157 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.409      |
|    n_updates            | 2190       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.711      |
|    value_loss           | 0.761      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -117     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 220      |
|    time_elapsed    | 150922   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -115        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 221         |
|    time_elapsed         | 151234      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.030411284 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.00164     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56e+03    |
|    n_updates            | 2200        |
|    policy_gradient_loss | 0.000287    |
|    std                  | 0.712       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -115       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 151546     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.47696513 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.307      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.518      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.713      |
|    value_loss           | 1.21       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -114       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 151858     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.13920367 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 2220       |
|    policy_gradient_loss | 0.0369     |
|    std                  | 0.713      |
|    value_loss           | 0.789      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -114       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 224        |
|    time_elapsed         | 152169     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.17145877 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.438      |
|    n_updates            | 2230       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.713      |
|    value_loss           | 0.846      |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.78 +/- 0.06
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.07528174 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.61      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.294      |
|    n_updates            | 2240       |
|    policy_gradient_loss | 0.00664    |
|    std                  | 0.715      |
|    value_loss           | 0.651      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -112     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 225      |
|    time_elapsed    | 154281   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -107        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 226         |
|    time_elapsed         | 154593      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.037335783 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.00104     |
|    learning_rate        | 0.0003      |
|    loss                 | 240         |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.716       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -102      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 227       |
|    time_elapsed         | 154904    |
|    total_timesteps      | 464896    |
| train/                  |           |
|    approx_kl            | 1.2009051 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.64     |
|    explained_variance   | 0.329     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.47      |
|    n_updates            | 2260      |
|    policy_gradient_loss | 0.0278    |
|    std                  | 0.717     |
|    value_loss           | 0.82      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -102      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 228       |
|    time_elapsed         | 155215    |
|    total_timesteps      | 466944    |
| train/                  |           |
|    approx_kl            | 1.1168333 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.64     |
|    explained_variance   | 0.671     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.416     |
|    n_updates            | 2270      |
|    policy_gradient_loss | 0.0209    |
|    std                  | 0.717     |
|    value_loss           | 0.609     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -99.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 155527     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.22411023 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.61      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.458      |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.714      |
|    value_loss           | 0.781      |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.81 +/- 0.03
Episode length: 3598.60 +/- 4.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.05613291 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.536      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.435      |
|    n_updates            | 2290       |
|    policy_gradient_loss | 0.00114    |
|    std                  | 0.713      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -94.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 230      |
|    time_elapsed    | 157640   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -93.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 231         |
|    time_elapsed         | 157952      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.094609134 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | -0.00372    |
|    learning_rate        | 0.0003      |
|    loss                 | 842         |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.0027     |
|    std                  | 0.714       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -91.9     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 232       |
|    time_elapsed         | 158263    |
|    total_timesteps      | 475136    |
| train/                  |           |
|    approx_kl            | 0.9510344 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.6      |
|    explained_variance   | 0.309     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.309     |
|    n_updates            | 2310      |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.713     |
|    value_loss           | 1.16      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -90.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 158573     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.06603311 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.57      |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.433      |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.71       |
|    value_loss           | 0.942      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -90.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 158884     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.07429138 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.508      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.0053     |
|    std                  | 0.706      |
|    value_loss           | 0.789      |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.80 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.052726686 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.323       |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.00139     |
|    std                  | 0.701       |
|    value_loss           | 0.724       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -86      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 235      |
|    time_elapsed    | 160998   |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -84.6      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 236        |
|    time_elapsed         | 161309     |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.06575321 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.000775   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.15e+03   |
|    n_updates            | 2350       |
|    policy_gradient_loss | -0.00022   |
|    std                  | 0.703      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -82.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 161618     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.59085196 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.284      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.422      |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.006      |
|    std                  | 0.7        |
|    value_loss           | 0.905      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -80.4     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 238       |
|    time_elapsed         | 161929    |
|    total_timesteps      | 487424    |
| train/                  |           |
|    approx_kl            | 0.5558031 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.44     |
|    explained_variance   | 0.635     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.599     |
|    n_updates            | 2370      |
|    policy_gradient_loss | 0.117     |
|    std                  | 0.702     |
|    value_loss           | 0.667     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -80.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 162238     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.12944566 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.46      |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.25       |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.00937    |
|    std                  | 0.703      |
|    value_loss           | 0.573      |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.74 +/- 0.06
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.18561755 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.278      |
|    n_updates            | 2390       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.701      |
|    value_loss           | 0.712      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -77.3    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 240      |
|    time_elapsed    | 164348   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -75.1       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 241         |
|    time_elapsed         | 164660      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.061547823 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.44       |
|    explained_variance   | 0.00465     |
|    learning_rate        | 0.0003      |
|    loss                 | 32.6        |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.00496    |
|    std                  | 0.7         |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -73.1     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 242       |
|    time_elapsed         | 164968    |
|    total_timesteps      | 495616    |
| train/                  |           |
|    approx_kl            | 0.6827044 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.45     |
|    explained_variance   | 0.226     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.291     |
|    n_updates            | 2410      |
|    policy_gradient_loss | 0.0171    |
|    std                  | 0.702     |
|    value_loss           | 0.715     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -71.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 165277     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.24643141 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.516      |
|    n_updates            | 2420       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.702      |
|    value_loss           | 0.763      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -70.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 165585     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.08095156 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.44      |
|    explained_variance   | 0.538      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.277      |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.7        |
|    value_loss           | 0.668      |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.76 +/- 0.05
Episode length: 3598.00 +/- 3.58
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 500000   |
| train/                  |          |
|    approx_kl            | 0.10658  |
|    clip_fraction        | 0.408    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.42    |
|    explained_variance   | 0.855    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.531    |
|    n_updates            | 2440     |
|    policy_gradient_loss | 0.0198   |
|    std                  | 0.698    |
|    value_loss           | 0.641    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -70.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 245      |
|    time_elapsed    | 167695   |
|    total_timesteps | 501760   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -68.9      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 246        |
|    time_elapsed         | 168002     |
|    total_timesteps      | 503808     |
| train/                  |            |
|    approx_kl            | 0.06401038 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.00247    |
|    learning_rate        | 0.0003     |
|    loss                 | 925        |
|    n_updates            | 2450       |
|    policy_gradient_loss | -0.00296   |
|    std                  | 0.7        |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -67.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 247       |
|    time_elapsed         | 168312    |
|    total_timesteps      | 505856    |
| train/                  |           |
|    approx_kl            | 0.3301134 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.43     |
|    explained_variance   | 0.38      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.304     |
|    n_updates            | 2460      |
|    policy_gradient_loss | 0.0228    |
|    std                  | 0.701     |
|    value_loss           | 0.877     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -65.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 248        |
|    time_elapsed         | 168620     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.14343244 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.356      |
|    n_updates            | 2470       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.698      |
|    value_loss           | 0.713      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -63.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 249        |
|    time_elapsed         | 168927     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.59840655 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.39      |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.302      |
|    n_updates            | 2480       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.694      |
|    value_loss           | 0.779      |
----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.75 +/- 0.06
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.09213268 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.398      |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.00939    |
|    std                  | 0.697      |
|    value_loss           | 0.703      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -63.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 250      |
|    time_elapsed    | 171037   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -61.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 171346      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.054206103 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.00137     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+03    |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.697       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -60.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 171655     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.25576627 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | 0.37       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 2510       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.693      |
|    value_loss           | 0.747      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -59.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 171966     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.16635102 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.35      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.335      |
|    n_updates            | 2520       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.693      |
|    value_loss           | 0.608      |
----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.73 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 520000     |
| train/                  |            |
|    approx_kl            | 0.10984568 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.37      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.42       |
|    n_updates            | 2530       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.697      |
|    value_loss           | 0.609      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -58.3    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 254      |
|    time_elapsed    | 174076   |
|    total_timesteps | 520192   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -58.3      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 255        |
|    time_elapsed         | 174386     |
|    total_timesteps      | 522240     |
| train/                  |            |
|    approx_kl            | 0.04621833 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.39      |
|    explained_variance   | 0.00397    |
|    learning_rate        | 0.0003     |
|    loss                 | 23.4       |
|    n_updates            | 2540       |
|    policy_gradient_loss | 0.00304    |
|    std                  | 0.697      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -57.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 256       |
|    time_elapsed         | 174695    |
|    total_timesteps      | 524288    |
| train/                  |           |
|    approx_kl            | 1.4960012 |
|    clip_fraction        | 0.462     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.4      |
|    explained_variance   | 0.253     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.43      |
|    n_updates            | 2550      |
|    policy_gradient_loss | 0.0229    |
|    std                  | 0.697     |
|    value_loss           | 0.577     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -55.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 175006     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.34384602 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.254      |
|    n_updates            | 2560       |
|    policy_gradient_loss | 0.0201     |
|    std                  | 0.701      |
|    value_loss           | 0.579      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -55.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 175317     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.10726039 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.43      |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.205      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.699      |
|    value_loss           | 0.541      |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.79 +/- 0.03
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.16886953 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.383      |
|    n_updates            | 2580       |
|    policy_gradient_loss | 0.00691    |
|    std                  | 0.698      |
|    value_loss           | 0.673      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -54.3    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 259      |
|    time_elapsed    | 177429   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -53.1      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 260        |
|    time_elapsed         | 177739     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.07472976 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | -0.000113  |
|    learning_rate        | 0.0003     |
|    loss                 | 6.72       |
|    n_updates            | 2590       |
|    policy_gradient_loss | -0.000423  |
|    std                  | 0.699      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -53.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 178051     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.51627994 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.43      |
|    explained_variance   | 0.295      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.378      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.0585     |
|    std                  | 0.7        |
|    value_loss           | 0.814      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -52.6    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 262      |
|    time_elapsed         | 178362   |
|    total_timesteps      | 536576   |
| train/                  |          |
|    approx_kl            | 0.207392 |
|    clip_fraction        | 0.384    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.43    |
|    explained_variance   | 0.539    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.317    |
|    n_updates            | 2610     |
|    policy_gradient_loss | 0.0203   |
|    std                  | 0.7      |
|    value_loss           | 0.727    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -52        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 263        |
|    time_elapsed         | 178673     |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.08032054 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.344      |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.698      |
|    value_loss           | 0.761      |
----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.80 +/- 0.03
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.052834496 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | 0.594       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.697       |
|    value_loss           | 0.698       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -51.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 264      |
|    time_elapsed    | 180785   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -50.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 265         |
|    time_elapsed         | 181096      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.052017555 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | 0.000294    |
|    learning_rate        | 0.0003      |
|    loss                 | 11.9        |
|    n_updates            | 2640        |
|    policy_gradient_loss | 0.0026      |
|    std                  | 0.698       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -48.6     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 266       |
|    time_elapsed         | 181404    |
|    total_timesteps      | 544768    |
| train/                  |           |
|    approx_kl            | 0.3758056 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.37     |
|    explained_variance   | 0.526     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.322     |
|    n_updates            | 2650      |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.694     |
|    value_loss           | 0.755     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -48.6     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 267       |
|    time_elapsed         | 181712    |
|    total_timesteps      | 546816    |
| train/                  |           |
|    approx_kl            | 0.8854569 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.34     |
|    explained_variance   | 0.56      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.372     |
|    n_updates            | 2660      |
|    policy_gradient_loss | 0.0382    |
|    std                  | 0.693     |
|    value_loss           | 0.637     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -47.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 182024      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.043844238 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | 0.682       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.342       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.69        |
|    value_loss           | 0.509       |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.74 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.06804892 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.29      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.343      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.00877    |
|    std                  | 0.689      |
|    value_loss           | 0.671      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -47.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 269      |
|    time_elapsed    | 184135   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -46.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 270         |
|    time_elapsed         | 184444      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.035925366 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | 7.69e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 450         |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00481    |
|    std                  | 0.688       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -45.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 184755     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.19527154 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.25      |
|    explained_variance   | 0.283      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.299      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.684      |
|    value_loss           | 0.705      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -45.3     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 272       |
|    time_elapsed         | 185063    |
|    total_timesteps      | 557056    |
| train/                  |           |
|    approx_kl            | 0.2922397 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.24     |
|    explained_variance   | 0.586     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.591     |
|    n_updates            | 2710      |
|    policy_gradient_loss | 0.0333    |
|    std                  | 0.687     |
|    value_loss           | 0.653     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -44.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 273         |
|    time_elapsed         | 185371      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.096179605 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.361       |
|    n_updates            | 2720        |
|    policy_gradient_loss | 0.0468      |
|    std                  | 0.689       |
|    value_loss           | 0.685       |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.77 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.08958644 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.29      |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.0362     |
|    std                  | 0.69       |
|    value_loss           | 0.581      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -43.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 274      |
|    time_elapsed    | 187482   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -41.9      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 275        |
|    time_elapsed         | 187791     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.12529725 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.3       |
|    explained_variance   | 0.0024     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.12       |
|    n_updates            | 2740       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.691      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -40.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 188101     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.59690857 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.27      |
|    explained_variance   | 0.0281     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.472      |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.687      |
|    value_loss           | 1.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -40.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 188409     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.17834441 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.23      |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.283      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.683      |
|    value_loss           | 0.63       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -40.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 188718     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.05712293 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.00867    |
|    std                  | 0.679      |
|    value_loss           | 0.686      |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.76 +/- 0.08
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.055636235 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.696       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.301       |
|    n_updates            | 2780        |
|    policy_gradient_loss | 0.0224      |
|    std                  | 0.677       |
|    value_loss           | 0.478       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -39.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 279      |
|    time_elapsed    | 190828   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -38.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 191136      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.048670806 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.13       |
|    explained_variance   | -0.000506   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.59e+03    |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.00323    |
|    std                  | 0.675       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -38.7     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 281       |
|    time_elapsed         | 191448    |
|    total_timesteps      | 575488    |
| train/                  |           |
|    approx_kl            | 1.6348155 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.13     |
|    explained_variance   | 0.291     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.227     |
|    n_updates            | 2800      |
|    policy_gradient_loss | 0.0259    |
|    std                  | 0.677     |
|    value_loss           | 0.828     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 191759     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.09052828 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.13      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.175      |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.000733   |
|    std                  | 0.678      |
|    value_loss           | 0.716      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 192069     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.07293022 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.14      |
|    explained_variance   | 0.637      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.376      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.678      |
|    value_loss           | 0.712      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.78 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.060570568 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | 0.66        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.232       |
|    n_updates            | 2830        |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.679       |
|    value_loss           | 0.563       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -38.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 284      |
|    time_elapsed    | 194180   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -37.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 194491      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.061377544 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.17       |
|    explained_variance   | 0.0038      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.97        |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.0021     |
|    std                  | 0.68        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -37.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 194802     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.36517447 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.18      |
|    explained_variance   | 0.393      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.366      |
|    n_updates            | 2850       |
|    policy_gradient_loss | 0.0276     |
|    std                  | 0.681      |
|    value_loss           | 0.66       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -38       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 287       |
|    time_elapsed         | 195113    |
|    total_timesteps      | 587776    |
| train/                  |           |
|    approx_kl            | 0.2141208 |
|    clip_fraction        | 0.388     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.15     |
|    explained_variance   | 0.641     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.367     |
|    n_updates            | 2860      |
|    policy_gradient_loss | 0.00952   |
|    std                  | 0.676     |
|    value_loss           | 0.656     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -37.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 288         |
|    time_elapsed         | 195424      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.056583628 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | 0.648       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.322       |
|    n_updates            | 2870        |
|    policy_gradient_loss | 0.00576     |
|    std                  | 0.676       |
|    value_loss           | 0.635       |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.84 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.056168698 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.13       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.367       |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.678       |
|    value_loss           | 0.693       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -36.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 289      |
|    time_elapsed    | 197535   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -36.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 197846     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.06996773 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.14      |
|    explained_variance   | 0.000402   |
|    learning_rate        | 0.0003     |
|    loss                 | 356        |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.000993  |
|    std                  | 0.679      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -36.8     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 291       |
|    time_elapsed         | 198159    |
|    total_timesteps      | 595968    |
| train/                  |           |
|    approx_kl            | 1.3239269 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.14     |
|    explained_variance   | 0.404     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.26      |
|    n_updates            | 2900      |
|    policy_gradient_loss | 0.0013    |
|    std                  | 0.677     |
|    value_loss           | 0.646     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -36.9     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 292       |
|    time_elapsed         | 198471    |
|    total_timesteps      | 598016    |
| train/                  |           |
|    approx_kl            | 0.1480734 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.1      |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.269     |
|    n_updates            | 2910      |
|    policy_gradient_loss | 0.0238    |
|    std                  | 0.674     |
|    value_loss           | 0.637     |
---------------------------------------
Eval num_timesteps=600000, episode_reward=-99.79 +/- 0.04
Episode length: 3598.20 +/- 4.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.17356813 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.46       |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.674      |
|    value_loss           | 0.708      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -37.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 293      |
|    time_elapsed    | 200583   |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -37.5      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 294        |
|    time_elapsed         | 200894     |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.06807932 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.00136    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.37e+03   |
|    n_updates            | 2930       |
|    policy_gradient_loss | 0.00471    |
|    std                  | 0.674      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 201205     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.29254365 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.0673     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.49       |
|    n_updates            | 2940       |
|    policy_gradient_loss | 0.0288     |
|    std                  | 0.67       |
|    value_loss           | 0.857      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 201516     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.21008855 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.4        |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.668      |
|    value_loss           | 0.811      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 201827     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.06639169 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.445      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.664      |
|    value_loss           | 0.636      |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.82 +/- 0.04
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.07321407 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.00897    |
|    std                  | 0.663      |
|    value_loss           | 0.737      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -38.7    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 298      |
|    time_elapsed    | 203938   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38.7      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 299        |
|    time_elapsed         | 204247     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.05381996 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.0032     |
|    learning_rate        | 0.0003     |
|    loss                 | 26.5       |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.00318   |
|    std                  | 0.663      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -38.7     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 300       |
|    time_elapsed         | 204555    |
|    total_timesteps      | 614400    |
| train/                  |           |
|    approx_kl            | 1.2523441 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.92     |
|    explained_variance   | 0.189     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.14      |
|    n_updates            | 2990      |
|    policy_gradient_loss | 0.00787   |
|    std                  | 0.66      |
|    value_loss           | 0.683     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -38.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 204866     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.15744814 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.311      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.0323     |
|    std                  | 0.66       |
|    value_loss           | 0.767      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -37.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 205175     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.62687427 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.257      |
|    n_updates            | 3010       |
|    policy_gradient_loss | 0.0267     |
|    std                  | 0.66       |
|    value_loss           | 0.648      |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.82 +/- 0.03
Episode length: 3598.20 +/- 5.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.08110598 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.259      |
|    n_updates            | 3020       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.659      |
|    value_loss           | 0.578      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -37.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 303      |
|    time_elapsed    | 207284   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -36.7       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 304         |
|    time_elapsed         | 207593      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.060181364 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.87       |
|    explained_variance   | 0.00123     |
|    learning_rate        | 0.0003      |
|    loss                 | 69.6        |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.66        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -36.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 305        |
|    time_elapsed         | 207902     |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.56740665 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.339      |
|    n_updates            | 3040       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.658      |
|    value_loss           | 0.923      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -36.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 208211     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.06832447 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.404      |
|    n_updates            | 3050       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.659      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -35.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 208521     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.13610007 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.604      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.252      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.0332     |
|    std                  | 0.66       |
|    value_loss           | 0.693      |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.78 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.084199496 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.349       |
|    n_updates            | 3070        |
|    policy_gradient_loss | 0.0069      |
|    std                  | 0.659       |
|    value_loss           | 0.803       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -34      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 308      |
|    time_elapsed    | 210632   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -32.9       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 210940      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.035570845 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | 0.00625     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+03    |
|    n_updates            | 3080        |
|    policy_gradient_loss | 0.00117     |
|    std                  | 0.659       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -31.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 211249     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.30262595 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 3090       |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.657      |
|    value_loss           | 0.861      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -31.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 311        |
|    time_elapsed         | 211559     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.12305968 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.85      |
|    explained_variance   | 0.663      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.363      |
|    n_updates            | 3100       |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.656      |
|    value_loss           | 0.532      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -30.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 312       |
|    time_elapsed         | 211869    |
|    total_timesteps      | 638976    |
| train/                  |           |
|    approx_kl            | 0.0547269 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.87     |
|    explained_variance   | 0.65      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.28      |
|    n_updates            | 3110      |
|    policy_gradient_loss | 0.0256    |
|    std                  | 0.66      |
|    value_loss           | 0.561     |
---------------------------------------
Eval num_timesteps=640000, episode_reward=-99.83 +/- 0.05
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.05183468 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.414      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.659      |
|    value_loss           | 0.957      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -30.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 313      |
|    time_elapsed    | 213978   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -29.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 214286      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.037434317 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.88       |
|    explained_variance   | 0.000876    |
|    learning_rate        | 0.0003      |
|    loss                 | 103         |
|    n_updates            | 3130        |
|    policy_gradient_loss | 0.0074      |
|    std                  | 0.659       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -28.9    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 315      |
|    time_elapsed         | 214594   |
|    total_timesteps      | 645120   |
| train/                  |          |
|    approx_kl            | 0.381881 |
|    clip_fraction        | 0.445    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.88    |
|    explained_variance   | 0.353    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.23     |
|    n_updates            | 3140     |
|    policy_gradient_loss | 0.0157   |
|    std                  | 0.658    |
|    value_loss           | 0.567    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -28.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 214902     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.24199513 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.86      |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.275      |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.659      |
|    value_loss           | 0.656      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -27.8    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 317      |
|    time_elapsed         | 215209   |
|    total_timesteps      | 649216   |
| train/                  |          |
|    approx_kl            | 0.275974 |
|    clip_fraction        | 0.396    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.86    |
|    explained_variance   | 0.623    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.365    |
|    n_updates            | 3160     |
|    policy_gradient_loss | 0.00939  |
|    std                  | 0.657    |
|    value_loss           | 0.587    |
--------------------------------------
Eval num_timesteps=650000, episode_reward=-99.76 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 650000    |
| train/                  |           |
|    approx_kl            | 0.1251294 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.85     |
|    explained_variance   | 0.821     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.48      |
|    n_updates            | 3170      |
|    policy_gradient_loss | 0.0302    |
|    std                  | 0.658     |
|    value_loss           | 0.953     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -27.3    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 318      |
|    time_elapsed    | 217319   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -26.9       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 217628      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.042149432 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.85       |
|    explained_variance   | 0.00338     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.36e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.00136     |
|    std                  | 0.658       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -25.4     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 320       |
|    time_elapsed         | 217939    |
|    total_timesteps      | 655360    |
| train/                  |           |
|    approx_kl            | 4.4356427 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.82     |
|    explained_variance   | 0.2       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.313     |
|    n_updates            | 3190      |
|    policy_gradient_loss | 0.0204    |
|    std                  | 0.652     |
|    value_loss           | 0.784     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -24.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 218250     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.27935842 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.78      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.234      |
|    n_updates            | 3200       |
|    policy_gradient_loss | 0.0577     |
|    std                  | 0.651      |
|    value_loss           | 0.566      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -24.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 218559     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.12022922 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.78      |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.292      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.652      |
|    value_loss           | 0.922      |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.74 +/- 0.06
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.082423545 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | 0.637       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.242       |
|    n_updates            | 3220        |
|    policy_gradient_loss | 0.0201      |
|    std                  | 0.648       |
|    value_loss           | 0.519       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -23.6    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 323      |
|    time_elapsed    | 220669   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -22.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 220980     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.10316505 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.74      |
|    explained_variance   | 0.000579   |
|    learning_rate        | 0.0003     |
|    loss                 | 390        |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.00564    |
|    std                  | 0.649      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -22.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 221290     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.45878038 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.227      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.00568    |
|    std                  | 0.651      |
|    value_loss           | 1.08       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -22.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 221598     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.60773236 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.22       |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.0346     |
|    std                  | 0.648      |
|    value_loss           | 0.519      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -21.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 221906     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.16933689 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.74      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.206      |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.649      |
|    value_loss           | 0.538      |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.78 +/- 0.03
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 670000    |
| train/                  |           |
|    approx_kl            | 0.2170939 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.74     |
|    explained_variance   | 0.598     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.481     |
|    n_updates            | 3270      |
|    policy_gradient_loss | 0.0342    |
|    std                  | 0.648     |
|    value_loss           | 0.61      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -21.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 328      |
|    time_elapsed    | 224017   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 224327     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.03438046 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.00609    |
|    learning_rate        | 0.0003     |
|    loss                 | 817        |
|    n_updates            | 3280       |
|    policy_gradient_loss | -3.28e-05  |
|    std                  | 0.649      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -19.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 330         |
|    time_elapsed         | 224635      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.118538424 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.72       |
|    explained_variance   | 0.318       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.27        |
|    n_updates            | 3290        |
|    policy_gradient_loss | 0.0289      |
|    std                  | 0.646       |
|    value_loss           | 0.616       |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -19.4     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 331       |
|    time_elapsed         | 224943    |
|    total_timesteps      | 677888    |
| train/                  |           |
|    approx_kl            | 0.5963493 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.69     |
|    explained_variance   | 0.675     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.245     |
|    n_updates            | 3300      |
|    policy_gradient_loss | 0.0285    |
|    std                  | 0.644     |
|    value_loss           | 0.611     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -18.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 225252     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.17282952 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.33       |
|    n_updates            | 3310       |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.645      |
|    value_loss           | 0.507      |
----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.77 +/- 0.04
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.12910843 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.401      |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.643      |
|    value_loss           | 0.676      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -19      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 333      |
|    time_elapsed    | 227362   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -18.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 334         |
|    time_elapsed         | 227671      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.051359385 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.67       |
|    explained_variance   | 0.00636     |
|    learning_rate        | 0.0003      |
|    loss                 | 20.3        |
|    n_updates            | 3330        |
|    policy_gradient_loss | 0.00292     |
|    std                  | 0.645       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -18.6     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 335       |
|    time_elapsed         | 227983    |
|    total_timesteps      | 686080    |
| train/                  |           |
|    approx_kl            | 1.0808649 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.68     |
|    explained_variance   | 0.691     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.201     |
|    n_updates            | 3340      |
|    policy_gradient_loss | 0.0211    |
|    std                  | 0.643     |
|    value_loss           | 0.626     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -19.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 228292     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.11680996 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.261      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.00254    |
|    std                  | 0.641      |
|    value_loss           | 1.51       |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.80 +/- 0.05
Episode length: 3600.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.63530207 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.359      |
|    n_updates            | 3360       |
|    policy_gradient_loss | 0.0455     |
|    std                  | 0.642      |
|    value_loss           | 0.618      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -19.5    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 337      |
|    time_elapsed    | 230404   |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -19.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 338        |
|    time_elapsed         | 230715     |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.06729942 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | -0.000379  |
|    learning_rate        | 0.0003     |
|    loss                 | 651        |
|    n_updates            | 3370       |
|    policy_gradient_loss | 0.00195    |
|    std                  | 0.644      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -20.1     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 339       |
|    time_elapsed         | 231024    |
|    total_timesteps      | 694272    |
| train/                  |           |
|    approx_kl            | 3.0935287 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.7      |
|    explained_variance   | -0.207    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.126     |
|    n_updates            | 3380      |
|    policy_gradient_loss | 0.0521    |
|    std                  | 0.647     |
|    value_loss           | 0.588     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 231336     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.36351585 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.391      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0269     |
|    std                  | 0.646      |
|    value_loss           | 0.66       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 231646     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.17665029 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.68      |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.418      |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.0369     |
|    std                  | 0.644      |
|    value_loss           | 1.04       |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.81 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 700000    |
| train/                  |           |
|    approx_kl            | 0.1845443 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.66     |
|    explained_variance   | 0.621     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.513     |
|    n_updates            | 3410      |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.643     |
|    value_loss           | 0.659     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -20.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 342      |
|    time_elapsed    | 233758   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 234068     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.04381194 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | 0.00116    |
|    learning_rate        | 0.0003     |
|    loss                 | 14         |
|    n_updates            | 3420       |
|    policy_gradient_loss | 0.00444    |
|    std                  | 0.643      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 234377     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.09480121 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.0293     |
|    std                  | 0.643      |
|    value_loss           | 0.728      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -19.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 345         |
|    time_elapsed         | 234686      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.120386764 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 3440        |
|    policy_gradient_loss | 0.0226      |
|    std                  | 0.642       |
|    value_loss           | 0.821       |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -19.5    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 346      |
|    time_elapsed         | 234996   |
|    total_timesteps      | 708608   |
| train/                  |          |
|    approx_kl            | 0.103224 |
|    clip_fraction        | 0.358    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.66    |
|    explained_variance   | 0.64     |
|    learning_rate        | 0.0003   |
|    loss                 | 0.286    |
|    n_updates            | 3450     |
|    policy_gradient_loss | 0.0149   |
|    std                  | 0.643    |
|    value_loss           | 0.641    |
--------------------------------------
Eval num_timesteps=710000, episode_reward=-99.84 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.20678328 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.68      |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.484      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.645      |
|    value_loss           | 0.804      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -19.4    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 347      |
|    time_elapsed    | 237106   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -19.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 237417     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.24509442 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.00266    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.54e+03   |
|    n_updates            | 3470       |
|    policy_gradient_loss | 0.0029     |
|    std                  | 0.646      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -19.2     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 349       |
|    time_elapsed         | 237724    |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 1.5264819 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.68     |
|    explained_variance   | 0.147     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.432     |
|    n_updates            | 3480      |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.644     |
|    value_loss           | 0.851     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -18.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 238031     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.23616308 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.65      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.301      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.029      |
|    std                  | 0.643      |
|    value_loss           | 0.58       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -17.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 351         |
|    time_elapsed         | 238337      |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.116590425 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.63       |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.237       |
|    n_updates            | 3500        |
|    policy_gradient_loss | 0.0131      |
|    std                  | 0.64        |
|    value_loss           | 0.72        |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.77 +/- 0.04
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 720000    |
| train/                  |           |
|    approx_kl            | 0.1570554 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.6      |
|    explained_variance   | 0.653     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.338     |
|    n_updates            | 3510      |
|    policy_gradient_loss | 0.0283    |
|    std                  | 0.637     |
|    value_loss           | 0.645     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -16.6    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 352      |
|    time_elapsed    | 240444   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -15.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 240751      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.109081134 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | 0.0019      |
|    learning_rate        | 0.0003      |
|    loss                 | 41.1        |
|    n_updates            | 3520        |
|    policy_gradient_loss | -6.34e-05   |
|    std                  | 0.636       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -14.9     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 241058    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.8053098 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.56     |
|    explained_variance   | -0.197    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.184     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.634     |
|    value_loss           | 0.672     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -14.9     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 355       |
|    time_elapsed         | 241364    |
|    total_timesteps      | 727040    |
| train/                  |           |
|    approx_kl            | 0.1261408 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.51     |
|    explained_variance   | 0.549     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.392     |
|    n_updates            | 3540      |
|    policy_gradient_loss | 0.0309    |
|    std                  | 0.629     |
|    value_loss           | 0.81      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -13.8     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 356       |
|    time_elapsed         | 241671    |
|    total_timesteps      | 729088    |
| train/                  |           |
|    approx_kl            | 0.2966842 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.47     |
|    explained_variance   | 0.647     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.414     |
|    n_updates            | 3550      |
|    policy_gradient_loss | 0.0335    |
|    std                  | 0.627     |
|    value_loss           | 0.667     |
---------------------------------------
Eval num_timesteps=730000, episode_reward=-99.80 +/- 0.06
Episode length: 3598.40 +/- 3.77
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.65505934 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.497      |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.0396     |
|    std                  | 0.625      |
|    value_loss           | 0.948      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 357      |
|    time_elapsed    | 243780   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -12.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 244088      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.062096138 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.43       |
|    explained_variance   | -0.00103    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.67        |
|    n_updates            | 3570        |
|    policy_gradient_loss | 0.00302     |
|    std                  | 0.625       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -12.1    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 359      |
|    time_elapsed         | 244397   |
|    total_timesteps      | 735232   |
| train/                  |          |
|    approx_kl            | 1.435671 |
|    clip_fraction        | 0.433    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.43    |
|    explained_variance   | 0.0137   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.359    |
|    n_updates            | 3580     |
|    policy_gradient_loss | 0.00105  |
|    std                  | 0.624    |
|    value_loss           | 0.849    |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -12.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 244706      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.061405715 |
|    clip_fraction        | 0.413       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.43       |
|    explained_variance   | 0.554       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.624       |
|    value_loss           | 0.846       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -12.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 245014     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.09109588 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.42      |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.551      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.623      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.82 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.09220308 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.4       |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.445      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.622      |
|    value_loss           | 0.915      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 247124   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -12.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 363        |
|    time_elapsed         | 247435     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.08002166 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.38      |
|    explained_variance   | -0.000185  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 3620       |
|    policy_gradient_loss | 2.3e-05    |
|    std                  | 0.621      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -13.9     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 364       |
|    time_elapsed         | 247750    |
|    total_timesteps      | 745472    |
| train/                  |           |
|    approx_kl            | 1.2490952 |
|    clip_fraction        | 0.54      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.37     |
|    explained_variance   | 0.148     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.346     |
|    n_updates            | 3630      |
|    policy_gradient_loss | 0.0517    |
|    std                  | 0.621     |
|    value_loss           | 0.815     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -15.6     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 365       |
|    time_elapsed         | 248063    |
|    total_timesteps      | 747520    |
| train/                  |           |
|    approx_kl            | 0.1324713 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.36     |
|    explained_variance   | 0.604     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.401     |
|    n_updates            | 3640      |
|    policy_gradient_loss | 0.0193    |
|    std                  | 0.619     |
|    value_loss           | 0.988     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -16.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 248375     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.29433215 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.58       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.481      |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.622      |
|    value_loss           | 0.903      |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.85 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.07195522 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.559      |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.622      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -17      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 250489   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -18.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 250802     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.05813783 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.00159    |
|    learning_rate        | 0.0003     |
|    loss                 | 648        |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.00428   |
|    std                  | 0.623      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -19.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 251115     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.07706982 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.36      |
|    explained_variance   | 0.108      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.453      |
|    n_updates            | 3680       |
|    policy_gradient_loss | 0.0238     |
|    std                  | 0.619      |
|    value_loss           | 1.08       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 251429     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.06504433 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.618      |
|    value_loss           | 0.821      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -21.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 371       |
|    time_elapsed         | 251741    |
|    total_timesteps      | 759808    |
| train/                  |           |
|    approx_kl            | 1.0162379 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.29     |
|    explained_variance   | 0.607     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.44      |
|    n_updates            | 3700      |
|    policy_gradient_loss | 0.0326    |
|    std                  | 0.614     |
|    value_loss           | 0.795     |
---------------------------------------
Eval num_timesteps=760000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.18676423 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 3710       |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.61       |
|    value_loss           | 0.701      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -21.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 253854   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -22.7      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 373        |
|    time_elapsed         | 254168     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.14478838 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.000795   |
|    learning_rate        | 0.0003     |
|    loss                 | 215        |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.000769  |
|    std                  | 0.609      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -23.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 254479     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.29054523 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | -0.104     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.508      |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.607      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -24.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 254790     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.19408903 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.341      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0318     |
|    std                  | 0.609      |
|    value_loss           | 0.737      |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.82 +/- 0.03
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.56249315 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.361      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.608      |
|    value_loss           | 0.903      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -26.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 376      |
|    time_elapsed    | 256904   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -26.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 257217      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.061502464 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.17       |
|    explained_variance   | -0.00089    |
|    learning_rate        | 0.0003      |
|    loss                 | 84.6        |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.000155    |
|    std                  | 0.609       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -27        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 257529     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.13305627 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.377      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.637      |
|    n_updates            | 3770       |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.608      |
|    value_loss           | 1.08       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -27.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 257841     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.40750673 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.0499     |
|    std                  | 0.606      |
|    value_loss           | 0.917      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -27.2     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 380       |
|    time_elapsed         | 258153    |
|    total_timesteps      | 778240    |
| train/                  |           |
|    approx_kl            | 0.0759977 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.14     |
|    explained_variance   | 0.603     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.344     |
|    n_updates            | 3790      |
|    policy_gradient_loss | 0.0281    |
|    std                  | 0.606     |
|    value_loss           | 0.812     |
---------------------------------------
Eval num_timesteps=780000, episode_reward=-99.80 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 780000     |
| train/                  |            |
|    approx_kl            | 0.07606266 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 0.567      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.551      |
|    n_updates            | 3800       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.604      |
|    value_loss           | 0.924      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -27.4    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 381      |
|    time_elapsed    | 260266   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -27.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 260576      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.039415844 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.11       |
|    explained_variance   | 0.003       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.08        |
|    n_updates            | 3810        |
|    policy_gradient_loss | 0.000134    |
|    std                  | 0.604       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -27.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 383       |
|    time_elapsed         | 260886    |
|    total_timesteps      | 784384    |
| train/                  |           |
|    approx_kl            | 0.2927866 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.12     |
|    explained_variance   | 0.4       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.401     |
|    n_updates            | 3820      |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.605     |
|    value_loss           | 0.942     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -27.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 261195     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.41648522 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.481      |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.0251     |
|    std                  | 0.607      |
|    value_loss           | 0.814      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -26.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 385         |
|    time_elapsed         | 261508      |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.061412375 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.323       |
|    n_updates            | 3840        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.606       |
|    value_loss           | 0.895       |
-----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.60 +/- 0.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.12443973 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.337      |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.608      |
|    value_loss           | 0.792      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -26      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 386      |
|    time_elapsed    | 263622   |
|    total_timesteps | 790528   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -26       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 387       |
|    time_elapsed         | 263933    |
|    total_timesteps      | 792576    |
| train/                  |           |
|    approx_kl            | 0.0701513 |
|    clip_fraction        | 0.344     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.17     |
|    explained_variance   | -0.00218  |
|    learning_rate        | 0.0003    |
|    loss                 | 839       |
|    n_updates            | 3860      |
|    policy_gradient_loss | 0.00538   |
|    std                  | 0.607     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -26       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 388       |
|    time_elapsed         | 264243    |
|    total_timesteps      | 794624    |
| train/                  |           |
|    approx_kl            | 0.9488054 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.17     |
|    explained_variance   | -0.183    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.337     |
|    n_updates            | 3870      |
|    policy_gradient_loss | 0.0511    |
|    std                  | 0.607     |
|    value_loss           | 0.817     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -25.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 264552     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.06473723 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | 0.509      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.343      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.6        |
|    value_loss           | 0.734      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -24.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 264863     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.08527528 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.328      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.6        |
|    value_loss           | 0.887      |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.80 +/- 0.03
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.071772605 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | 0.534       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.612       |
|    n_updates            | 3900        |
|    policy_gradient_loss | 0.0142      |
|    std                  | 0.6         |
|    value_loss           | 0.949       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -23.4    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 391      |
|    time_elapsed    | 266972   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -22.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 267282      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.052997164 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.06       |
|    explained_variance   | 0.003       |
|    learning_rate        | 0.0003      |
|    loss                 | 110         |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.000213   |
|    std                  | 0.601       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -21.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 267593     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.22761638 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.322      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.36       |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.598      |
|    value_loss           | 1.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -21.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 267905     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.14701736 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.01      |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.704      |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.0324     |
|    std                  | 0.595      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -21.5     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 395       |
|    time_elapsed         | 268215    |
|    total_timesteps      | 808960    |
| train/                  |           |
|    approx_kl            | 0.3012135 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.01     |
|    explained_variance   | 0.406     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.844     |
|    n_updates            | 3940      |
|    policy_gradient_loss | 0.0318    |
|    std                  | 0.596     |
|    value_loss           | 1.19      |
---------------------------------------
Eval num_timesteps=810000, episode_reward=-99.82 +/- 0.05
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.17833734 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.02      |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.876      |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.596      |
|    value_loss           | 1.44       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -20.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 270327   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -19.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 270635     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.05919089 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.02      |
|    explained_variance   | 0.00222    |
|    learning_rate        | 0.0003     |
|    loss                 | 6.4        |
|    n_updates            | 3960       |
|    policy_gradient_loss | 0.00569    |
|    std                  | 0.596      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -19.2     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 398       |
|    time_elapsed         | 270944    |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 0.4503733 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7        |
|    explained_variance   | 0.272     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.409     |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.594     |
|    value_loss           | 1.01      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -19.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 271253     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.26021498 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.281      |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.0414     |
|    std                  | 0.591      |
|    value_loss           | 0.878      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -18.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 271562     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.15818322 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.94      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.588      |
|    value_loss           | 0.774      |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.84 +/- 0.05
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.11798996 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.387      |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.588      |
|    value_loss           | 0.772      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -17.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 273671   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -17.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 273977      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.052525893 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.92       |
|    explained_variance   | 0.0009      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.99e+03    |
|    n_updates            | 4010        |
|    policy_gradient_loss | 0.00314     |
|    std                  | 0.588       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -16.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 274287     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.51302385 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.359      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.789      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0378     |
|    std                  | 0.589      |
|    value_loss           | 0.768      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -16.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 274596     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.15240738 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.37       |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0242     |
|    std                  | 0.587      |
|    value_loss           | 0.759      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -16.3      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 274905     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.12452944 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.588      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.81 +/- 0.03
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.15865055 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.549      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.587      |
|    value_loss           | 0.77       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -15.6    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 277016   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -15.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 277326     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.08465504 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | -0.000532  |
|    learning_rate        | 0.0003     |
|    loss                 | 4.75       |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.00376    |
|    std                  | 0.587      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -15.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 277638     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.26143697 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.349      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.352      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.0359     |
|    std                  | 0.588      |
|    value_loss           | 0.802      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -15.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 277947     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.34886497 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.516      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0395     |
|    std                  | 0.586      |
|    value_loss           | 0.985      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -14.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 278256     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.09221074 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.332      |
|    n_updates            | 4090       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.586      |
|    value_loss           | 0.768      |
----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.85 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.41564715 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.579      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.583      |
|    value_loss           | 0.944      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -14.1    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 280363   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -13.4      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 280674     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.11017344 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | -0.000399  |
|    learning_rate        | 0.0003     |
|    loss                 | 6.57       |
|    n_updates            | 4110       |
|    policy_gradient_loss | 0.00555    |
|    std                  | 0.582      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -12.9      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 280981     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.08683011 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.28       |
|    n_updates            | 4120       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.583      |
|    value_loss           | 0.743      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -12.3    |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 414      |
|    time_elapsed         | 281289   |
|    total_timesteps      | 847872   |
| train/                  |          |
|    approx_kl            | 0.124329 |
|    clip_fraction        | 0.411    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.87    |
|    explained_variance   | 0.647    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.381    |
|    n_updates            | 4130     |
|    policy_gradient_loss | 0.0334   |
|    std                  | 0.586    |
|    value_loss           | 0.672    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -11.2      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 281596     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.29456997 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.87      |
|    explained_variance   | 0.663      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.245      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.583      |
|    value_loss           | 0.688      |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.82 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.15772758 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.215      |
|    n_updates            | 4150       |
|    policy_gradient_loss | 0.0578     |
|    std                  | 0.583      |
|    value_loss           | 0.539      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 283704   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -9.87      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 284012     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.11409694 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | -0.00122   |
|    learning_rate        | 0.0003     |
|    loss                 | 3.99       |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.000584   |
|    std                  | 0.582      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -9.15      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 418        |
|    time_elapsed         | 284319     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.13130964 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.36       |
|    n_updates            | 4170       |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.581      |
|    value_loss           | 0.883      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -7.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 284628     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.05824585 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.318      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.579      |
|    value_loss           | 0.882      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.83 +/- 0.02
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.095646486 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.524       |
|    n_updates            | 4190        |
|    policy_gradient_loss | 0.0169      |
|    std                  | 0.577       |
|    value_loss           | 0.84        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -6.47    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 420      |
|    time_elapsed    | 286737   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -6.47      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 287045     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.03610076 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.77      |
|    explained_variance   | 0.00112    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.38       |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.00174    |
|    std                  | 0.576      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -5.79      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 287352     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.15276793 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.461      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.0321     |
|    std                  | 0.575      |
|    value_loss           | 0.748      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -3.65     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 423       |
|    time_elapsed         | 287659    |
|    total_timesteps      | 866304    |
| train/                  |           |
|    approx_kl            | 0.1485019 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.75     |
|    explained_variance   | 0.595     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.508     |
|    n_updates            | 4220      |
|    policy_gradient_loss | 0.0311    |
|    std                  | 0.576     |
|    value_loss           | 0.833     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -2.76      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 287965     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.10125144 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.161      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0277     |
|    std                  | 0.57       |
|    value_loss           | 0.627      |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.84 +/- 0.04
Episode length: 3597.80 +/- 4.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.09116134 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.64      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.274      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.0306     |
|    std                  | 0.566      |
|    value_loss           | 0.599      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -1.51    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 290073   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -0.307     |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 290378     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.06873283 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.62      |
|    explained_variance   | 0.00282    |
|    learning_rate        | 0.0003     |
|    loss                 | 34.7       |
|    n_updates            | 4250       |
|    policy_gradient_loss | 0.00605    |
|    std                  | 0.566      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -0.307     |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 290685     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.15997516 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.62      |
|    explained_variance   | 0.264      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.321      |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.0356     |
|    std                  | 0.566      |
|    value_loss           | 0.7        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 0.799      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 290990     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.16937909 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.63      |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.291      |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.567      |
|    value_loss           | 0.578      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 1.99       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 291297     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.34645593 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.63      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.341      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0309     |
|    std                  | 0.565      |
|    value_loss           | 0.601      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.81 +/- 0.03
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 880000    |
| train/                  |           |
|    approx_kl            | 0.2940927 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.61     |
|    explained_variance   | 0.677     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.321     |
|    n_updates            | 4290      |
|    policy_gradient_loss | 0.007     |
|    std                  | 0.565     |
|    value_loss           | 0.964     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 3.12     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 293404   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 4.88       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 293711     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.11451185 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.00427    |
|    learning_rate        | 0.0003     |
|    loss                 | 832        |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.00538    |
|    std                  | 0.564      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 4.88      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 294018    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 0.2384483 |
|    clip_fraction        | 0.505     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.58     |
|    explained_variance   | 0.514     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.358     |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.037     |
|    std                  | 0.561     |
|    value_loss           | 0.728     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 6.26        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 294324      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.079373345 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.55       |
|    explained_variance   | 0.704       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.301       |
|    n_updates            | 4320        |
|    policy_gradient_loss | 0.028       |
|    std                  | 0.559       |
|    value_loss           | 0.639       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 8.58       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 294629     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.07581569 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.562      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.372      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.558      |
|    value_loss           | 0.992      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.82 +/- 0.04
Episode length: 3598.40 +/- 4.72
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 890000    |
| train/                  |           |
|    approx_kl            | 0.1622381 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.53     |
|    explained_variance   | 0.714     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.175     |
|    n_updates            | 4340      |
|    policy_gradient_loss | 0.011     |
|    std                  | 0.559     |
|    value_loss           | 0.565     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 296739   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 12.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 297046     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.06730372 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.0018     |
|    learning_rate        | 0.0003     |
|    loss                 | 113        |
|    n_updates            | 4350       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.558      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 14.4      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 437       |
|    time_elapsed         | 297352    |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 1.9975088 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.53     |
|    explained_variance   | -0.149    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.292     |
|    n_updates            | 4360      |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.559     |
|    value_loss           | 1.13      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 14.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 297657     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.42317498 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.51      |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.352      |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.0401     |
|    std                  | 0.555      |
|    value_loss           | 0.861      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 16.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 297963     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.34444174 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.47      |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.3        |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.045      |
|    std                  | 0.554      |
|    value_loss           | 0.624      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.81 +/- 0.06
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 900000    |
| train/                  |           |
|    approx_kl            | 0.7690011 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.43     |
|    explained_variance   | 0.6       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.507     |
|    n_updates            | 4390      |
|    policy_gradient_loss | 0.0562    |
|    std                  | 0.551     |
|    value_loss           | 1.05      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 18.9     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 300069   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 21         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 300372     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.08612008 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.00423    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.22e+03   |
|    n_updates            | 4400       |
|    policy_gradient_loss | 0.00554    |
|    std                  | 0.551      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 22.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 300677     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.63413316 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.41      |
|    explained_variance   | 0.198      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.322      |
|    n_updates            | 4410       |
|    policy_gradient_loss | 0.00679    |
|    std                  | 0.549      |
|    value_loss           | 0.772      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 22.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 300979     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.32500768 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.424      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0287     |
|    std                  | 0.549      |
|    value_loss           | 0.82       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 24.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 301284     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.10113415 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.265      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.548      |
|    value_loss           | 0.749      |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.85 +/- 0.04
Episode length: 3597.60 +/- 4.08
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.39105403 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0276     |
|    std                  | 0.549      |
|    value_loss           | 0.854      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 26.2     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 303389   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 28.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 303692     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.07790902 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.00316    |
|    learning_rate        | 0.0003     |
|    loss                 | 607        |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.551      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 29.6      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 447       |
|    time_elapsed         | 303998    |
|    total_timesteps      | 915456    |
| train/                  |           |
|    approx_kl            | 1.6667191 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.41     |
|    explained_variance   | 0.154     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.331     |
|    n_updates            | 4460      |
|    policy_gradient_loss | 0.0155    |
|    std                  | 0.55      |
|    value_loss           | 1.03      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 31         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 448        |
|    time_elapsed         | 304302     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.09801901 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.278      |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.549      |
|    value_loss           | 0.757      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 31         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 304606     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.14881836 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.38      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.262      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0271     |
|    std                  | 0.548      |
|    value_loss           | 0.897      |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.77 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.68155587 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.37      |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.414      |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.0342     |
|    std                  | 0.548      |
|    value_loss           | 0.68       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 32       |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 306713   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 33.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 307018      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.067967676 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.37       |
|    explained_variance   | 0.00414     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72e+03    |
|    n_updates            | 4500        |
|    policy_gradient_loss | 0.000261    |
|    std                  | 0.548       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 35        |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 452       |
|    time_elapsed         | 307324    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 1.0671701 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.36     |
|    explained_variance   | 0.33      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.227     |
|    n_updates            | 4510      |
|    policy_gradient_loss | 0.0141    |
|    std                  | 0.547     |
|    value_loss           | 0.777     |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | 35.9     |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 453      |
|    time_elapsed         | 307628   |
|    total_timesteps      | 927744   |
| train/                  |          |
|    approx_kl            | 0.59454  |
|    clip_fraction        | 0.459    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.33    |
|    explained_variance   | 0.56     |
|    learning_rate        | 0.0003   |
|    loss                 | 0.385    |
|    n_updates            | 4520     |
|    policy_gradient_loss | 0.0242   |
|    std                  | 0.544    |
|    value_loss           | 1        |
--------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | 36.5     |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 454      |
|    time_elapsed         | 307933   |
|    total_timesteps      | 929792   |
| train/                  |          |
|    approx_kl            | 1.019712 |
|    clip_fraction        | 0.461    |
|    clip_range           | 0.2      |
|    entropy_loss         | -6.31    |
|    explained_variance   | 0.747    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.315    |
|    n_updates            | 4530     |
|    policy_gradient_loss | 0.0261   |
|    std                  | 0.542    |
|    value_loss           | 0.646    |
--------------------------------------
Eval num_timesteps=930000, episode_reward=-99.84 +/- 0.03
Episode length: 3598.80 +/- 4.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 930000    |
| train/                  |           |
|    approx_kl            | 0.5916902 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.29     |
|    explained_variance   | 0.656     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.04      |
|    n_updates            | 4540      |
|    policy_gradient_loss | 0.0356    |
|    std                  | 0.541     |
|    value_loss           | 0.686     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 36.7     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 310039   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 38.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 310344      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.105717584 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.00156     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.72e+03    |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.000404   |
|    std                  | 0.541       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 40.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 310647     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.37833297 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.227      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.381      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.0536     |
|    std                  | 0.54       |
|    value_loss           | 0.982      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 42.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 310952     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.46242887 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.24      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.346      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.0623     |
|    std                  | 0.538      |
|    value_loss           | 0.799      |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.09410189 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.22      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.355      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.537      |
|    value_loss           | 0.872      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 45.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 313056   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 45.8       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 313360     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.10952422 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.21      |
|    explained_variance   | 7.21e-06   |
|    learning_rate        | 0.0003     |
|    loss                 | 11         |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.00561    |
|    std                  | 0.537      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 48.6      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 461       |
|    time_elapsed         | 313667    |
|    total_timesteps      | 944128    |
| train/                  |           |
|    approx_kl            | 1.0348942 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.21     |
|    explained_variance   | 0.182     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.185     |
|    n_updates            | 4600      |
|    policy_gradient_loss | 0.0259    |
|    std                  | 0.537     |
|    value_loss           | 0.797     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 51.8       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 313974     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.17581002 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.2       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.366      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0335     |
|    std                  | 0.537      |
|    value_loss           | 0.745      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 55         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 314282     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.08013284 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.18      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.31       |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.534      |
|    value_loss           | 0.687      |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.79 +/- 0.04
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 950000    |
| train/                  |           |
|    approx_kl            | 0.0933879 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.15     |
|    explained_variance   | 0.54      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.455     |
|    n_updates            | 4630      |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.532     |
|    value_loss           | 0.892     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 59.2     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 316388   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 59.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 316693      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.071227625 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.13       |
|    explained_variance   | -0.00722    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.35        |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.00413    |
|    std                  | 0.532       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 62.8      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 466       |
|    time_elapsed         | 316998    |
|    total_timesteps      | 954368    |
| train/                  |           |
|    approx_kl            | 2.2715936 |
|    clip_fraction        | 0.542     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.13     |
|    explained_variance   | -0.502    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.252     |
|    n_updates            | 4650      |
|    policy_gradient_loss | 0.0268    |
|    std                  | 0.53      |
|    value_loss           | 0.804     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 66.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 317303     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.64359367 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.3        |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.525      |
|    value_loss           | 0.794      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 69.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 468        |
|    time_elapsed         | 317607     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.14707945 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.394      |
|    n_updates            | 4670       |
|    policy_gradient_loss | 0.00775    |
|    std                  | 0.523      |
|    value_loss           | 0.561      |
----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.79 +/- 0.05
Episode length: 3598.20 +/- 5.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.16622224 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.203      |
|    n_updates            | 4680       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.524      |
|    value_loss           | 0.604      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 73.7     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 319712   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 77.2       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 320016     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.32325953 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.00679    |
|    learning_rate        | 0.0003     |
|    loss                 | 41.1       |
|    n_updates            | 4690       |
|    policy_gradient_loss | 0.00132    |
|    std                  | 0.525      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 77.2      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 471       |
|    time_elapsed         | 320320    |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 3.8581104 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.03     |
|    explained_variance   | 0.523     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.43      |
|    n_updates            | 4700      |
|    policy_gradient_loss | 0.0374    |
|    std                  | 0.524     |
|    value_loss           | 1.04      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 80.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 320624     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.11444775 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.34       |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.0377     |
|    std                  | 0.523      |
|    value_loss           | 0.704      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 82.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 320929     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.38272834 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.812      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.881      |
|    std                  | 0.52       |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 970000    |
| train/                  |           |
|    approx_kl            | 0.5606843 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.95     |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.349     |
|    n_updates            | 4730      |
|    policy_gradient_loss | 0.0424    |
|    std                  | 0.52      |
|    value_loss           | 0.676     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 85.9     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 323036   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 88.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 323340     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.09307261 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.94      |
|    explained_variance   | -0.00418   |
|    learning_rate        | 0.0003     |
|    loss                 | 567        |
|    n_updates            | 4740       |
|    policy_gradient_loss | 0.00556    |
|    std                  | 0.519      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 91.7      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 323646    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 0.5001089 |
|    clip_fraction        | 0.539     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.9      |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.34      |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0569    |
|    std                  | 0.516     |
|    value_loss           | 0.667     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 91.7      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 477       |
|    time_elapsed         | 323955    |
|    total_timesteps      | 976896    |
| train/                  |           |
|    approx_kl            | 0.1003315 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.87     |
|    explained_variance   | 0.779     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.308     |
|    n_updates            | 4760      |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.514     |
|    value_loss           | 0.553     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 94.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 324260     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.19496979 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.251      |
|    n_updates            | 4770       |
|    policy_gradient_loss | 0.026      |
|    std                  | 0.513      |
|    value_loss           | 0.552      |
----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.80 +/- 0.03
Episode length: 3596.80 +/- 7.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.19718833 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.464      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.259      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.511      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 97.6     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 326368   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 100        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 326676     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.11351457 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.8       |
|    explained_variance   | -0.000439  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72e+03   |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.0011    |
|    std                  | 0.511      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 103       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 481       |
|    time_elapsed         | 326984    |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 0.8265003 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.79     |
|    explained_variance   | 0.407     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.187     |
|    n_updates            | 4800      |
|    policy_gradient_loss | 0.0265    |
|    std                  | 0.51      |
|    value_loss           | 0.674     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 103        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 327292     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.14717393 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.76      |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.327      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.0332     |
|    std                  | 0.507      |
|    value_loss           | 0.594      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 105        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 327599     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.12226652 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.74      |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.203      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.507      |
|    value_loss           | 0.431      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.80 +/- 0.04
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.77357507 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.76      |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.357      |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0517     |
|    std                  | 0.509      |
|    value_loss           | 0.592      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 108      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 329707   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 111        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 330012     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.09830807 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.77      |
|    explained_variance   | 0.000558   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.14e+03   |
|    n_updates            | 4840       |
|    policy_gradient_loss | 0.00393    |
|    std                  | 0.509      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 112       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 486       |
|    time_elapsed         | 330320    |
|    total_timesteps      | 995328    |
| train/                  |           |
|    approx_kl            | 1.9752132 |
|    clip_fraction        | 0.557     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.78     |
|    explained_variance   | 0.337     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.296     |
|    n_updates            | 4850      |
|    policy_gradient_loss | 0.0381    |
|    std                  | 0.509     |
|    value_loss           | 0.631     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 114        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 330626     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.15136614 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.78      |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.78       |
|    n_updates            | 4860       |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.508      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 114       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 488       |
|    time_elapsed         | 330932    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.3849415 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.76     |
|    explained_variance   | 0.5       |
|    learning_rate        | 0.0003    |
|    loss                 | 0.601     |
|    n_updates            | 4870      |
|    policy_gradient_loss | 0.0376    |
|    std                  | 0.509     |
|    value_loss           | 0.914     |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.83 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.07706985 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.75      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.398      |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.507      |
|    value_loss           | 0.867      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 117      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 333042   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-23_21-46-11_llm_triton_qwen_14b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 20:26:53 < 0:00:00 , 7 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.965854 -100.03337   -99.987643  -99.914864 -100.017279]
 [ -99.89002   -99.863165  -99.96472   -99.963576  -99.842415]
 [ -99.813391  -99.931577  -99.7999    -99.876767  -99.928562]
 [ -99.859875  -99.90769   -99.876834  -99.89995   -99.923453]
 [ -99.996394  -99.849368 -100.062671 -100.079531  -99.765024]
 [ -99.853062  -99.987767  -99.891083  -99.946971  -99.921763]
 [ -99.78443   -99.844402  -99.757857  -99.843109  -99.803681]
 [ -99.89412   -99.855693  -99.896927  -99.836911  -99.768064]
 [ -99.790473  -99.757162  -99.757303  -99.805992  -99.804367]
 [ -99.844291  -99.874608  -99.742585  -99.755688  -99.765926]
 [ -99.929306  -99.844054  -99.91789   -99.785196  -99.839837]
 [ -99.755276  -99.832095  -99.867002  -99.897751  -99.918854]
 [ -99.757509  -99.903013  -99.84985   -99.759425  -99.850281]
 [ -99.79864   -99.77768   -99.7278    -99.895067  -99.856472]
 [ -99.865735  -99.791329  -99.782916  -99.72188   -99.875717]
 [ -99.878122  -99.769111  -99.862874  -99.793378  -99.945297]
 [ -99.850345  -99.889698  -99.859864  -99.873339  -99.840878]
 [ -99.706285  -99.867891  -99.845804  -99.737757  -99.819159]
 [ -99.746359  -99.803259  -99.773915  -99.880262  -99.752187]
 [ -99.858883  -99.778864  -99.822842  -99.847156  -99.850909]
 [ -99.73403   -99.80668   -99.798156  -99.774842  -99.799434]
 [ -99.792818  -99.837741  -99.853206  -99.77735   -99.921542]
 [ -99.762068  -99.893907  -99.829342  -99.911715  -99.946183]
 [ -99.773402  -99.893575  -99.823932  -99.822009  -99.853139]
 [ -99.848148  -99.780093  -99.86793   -99.83207   -99.824272]
 [ -99.809226  -99.77166   -99.714842  -99.713712  -99.75613 ]
 [ -99.732492  -99.794611  -99.879097  -99.876688  -99.771003]
 [ -99.86959   -99.734974  -99.868814  -99.844542  -99.892707]
 [ -99.829597  -99.817595  -99.804631  -99.800264  -99.65814 ]
 [ -99.681986  -99.761645  -99.831856  -99.766961  -99.795943]
 [ -99.785887  -99.734539  -99.830114  -99.824361  -99.745286]
 [ -99.719166  -99.807088  -99.846228  -99.754099  -99.740758]
 [ -99.733964  -99.786589  -99.724959  -99.864083  -99.767506]
 [ -99.842829  -99.79921   -99.810543  -99.876752  -99.871196]
 [ -99.79274   -99.886883  -99.772221  -99.768207  -99.791711]
 [ -99.79908   -99.838256  -99.823281  -99.805566  -99.856841]
 [ -99.76235   -99.827168  -99.875867  -99.847368  -99.847068]
 [ -99.782285  -99.820191  -99.782558  -99.851152  -99.806844]
 [ -99.851474  -99.867625  -99.811368  -99.800385  -99.880997]
 [ -99.853202  -99.820421  -99.825062  -99.85148   -99.806713]
 [ -99.762282  -99.854996  -99.796258  -99.839237  -99.79047 ]
 [ -99.662622  -99.82239   -99.786164  -99.842906  -99.74354 ]
 [ -99.784004  -99.829518  -99.82757   -99.840083  -99.857866]
 [ -99.777436  -99.801474  -99.808838  -99.765714  -99.837442]
 [ -99.765489  -99.840883  -99.788659  -99.829395  -99.719569]
 [ -99.803057  -99.727475  -99.720119  -99.780235  -99.873499]
 [ -99.829801  -99.762817  -99.785462  -99.827599  -99.851795]
 [ -99.790242  -99.840736  -99.767277  -99.741469  -99.853774]
 [ -99.696132  -99.741191  -99.647373  -99.801225  -99.812304]
 [ -99.690431  -99.766165  -99.804407  -99.805085  -99.720117]
 [ -99.704227  -99.704995  -99.709459  -99.847788  -99.783306]
 [ -99.680709  -99.732975  -99.747167  -99.775281  -99.70998 ]
 [ -99.74833   -99.843702  -99.801905  -99.796523  -99.755613]
 [ -99.825254  -99.746667  -99.790779  -99.834022  -99.799068]
 [ -99.720451  -99.751455  -99.717815  -99.754486  -99.772666]
 [ -99.746677  -99.839243  -99.734979  -99.733843  -99.810416]
 [ -99.599149  -99.810296  -99.821836  -99.764721  -99.77964 ]
 [ -99.770604  -99.761886  -99.735578  -99.781078  -99.85903 ]
 [ -99.899183  -99.800256  -99.922738  -99.776284  -99.810269]
 [ -99.827582  -99.784964  -99.751368  -99.752055  -99.832747]
 [ -99.798841  -99.856785  -99.819719  -99.755619  -99.848612]
 [ -99.797318  -99.802856  -99.779483  -99.824922  -99.878825]
 [ -99.74535   -99.803218  -99.750063  -99.838882  -99.759026]
 [ -99.895739  -99.801102  -99.865166  -99.82826   -99.765232]
 [ -99.775991  -99.846687  -99.740253  -99.71647   -99.736655]
 [ -99.636198  -99.752678  -99.732265  -99.727385  -99.831403]
 [ -99.734144  -99.805324  -99.770585  -99.813739  -99.784077]
 [ -99.828745  -99.763253  -99.753871  -99.721741  -99.789844]
 [ -99.884262  -99.749862  -99.849832  -99.788995  -99.746944]
 [ -99.869491  -99.753669  -99.766647  -99.878614  -99.789378]
 [ -99.860769  -99.814806  -99.861328  -99.86634   -99.811548]
 [ -99.828968  -99.722028  -99.711271  -99.7841    -99.788322]
 [ -99.78224   -99.869673  -99.855245  -99.75967   -99.723311]
 [ -99.784631  -99.86087   -99.863441  -99.809187  -99.758398]
 [ -99.865079  -99.834912  -99.862591  -99.800522  -99.888627]
 [ -99.767615  -99.885034  -99.802     -99.765495  -99.88349 ]
 [ -99.782826  -99.803113  -99.825319  -99.865007  -99.843205]
 [ -99.834335  -99.7549    -99.840209  -99.780287  -99.782715]
 [ -99.835583  -99.80653   -99.86895   -99.833884  -99.786618]
 [ -99.808577  -99.857214  -99.797432  -99.765008  -99.769816]
 [ -99.837769  -99.865414  -99.780364  -99.740493  -99.852192]
 [ -99.78043   -99.885741  -99.769168  -99.865061  -99.89919 ]
 [ -99.777871  -99.87442   -99.798607  -99.79058   -99.832476]
 [ -99.815955  -99.902424  -99.815629  -99.839295  -99.89238 ]
 [ -99.814879  -99.895077  -99.766899  -99.766803  -99.838728]
 [ -99.812209  -99.820415  -99.814222  -99.84851   -99.877138]
 [ -99.891923  -99.807496  -99.7992    -99.811531  -99.898754]
 [ -99.755403  -99.845276  -99.838832  -99.815503  -99.812134]
 [ -99.772715  -99.814034  -99.774558  -99.884268  -99.860626]
 [ -99.874166  -99.758168  -99.764765  -99.888145  -99.772729]
 [ -99.797538  -99.817223  -99.87642   -99.869394  -99.89071 ]
 [ -99.720329  -99.811408  -99.810688  -99.789774  -99.742189]
 [ -99.857889  -99.871274  -99.857193  -99.846556  -99.782505]
 [ -99.810583  -99.745166  -99.844916  -99.898636  -99.752311]
 [ -99.765734  -99.840081  -99.752703  -99.762948  -99.849575]
 [ -99.797243  -99.871239  -99.775213  -99.783923  -99.727242]
 [ -99.715962  -99.850773  -99.889111  -99.824389  -99.780585]
 [ -99.759983  -99.833197  -99.771852  -99.807266  -99.815792]
 [ -99.767379  -99.875635  -99.780316  -99.80664   -99.762004]
 [ -99.778489  -99.864045  -99.829896  -99.827368  -99.837998]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3587 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3595 3601 3601 3601 3601]
 [3601 3587 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3601 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3599 3601 3601 3598]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3600 3600 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3590 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3589 3600 3601 3601]
 [3601 3600 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3599 3599 3601 3590]
 [3601 3600 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3599 3601 3601 3601]
 [3589 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3588]
 [3599 3591 3600 3599 3601]
 [3601 3601 3601 3600 3599]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3601 3599 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3590 3601 3598]
 [3601 3596 3601 3601 3601]
 [3601 3588 3601 3601 3600]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3591 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3599 3601 3601 3600]
 [3600 3599 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3591 3601 3600 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3600 3601 3601 3601]
 [3601 3586 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3600 3600 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3601 3601 3601 3601 3587]
 [3601 3601 3601 3601 3600]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3600]
 [3590 3601 3601 3601 3596]
 [3601 3599 3601 3601 3601]
 [3601 3601 3589 3601 3600]
 [3601 3597 3601 3601 3601]
 [3599 3590 3597 3601 3601]
 [3601 3601 3601 3601 3601]
 [3590 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3587 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3583 3598 3601]
 [3601 3598 3601 3601 3601]
 [3601 3601 3599 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-23_21-46-11_llm_triton_qwen_14b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-23_21-46-11_llm_triton_qwen_14b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/model
