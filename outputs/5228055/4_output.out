####################
/var/spool/slurmd/job5244192/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_3B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-21_05-48-34_llm_triton_qwen_3b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the movement of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0. You have to output the following calculations:
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 Response: 1
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 212  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.58e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 419         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012570732 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0362      |
|    learning_rate        | 0.0003      |
|    loss                 | 19          |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.999       |
|    value_loss           | 37.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.58e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 624         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.010028975 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0627      |
|    learning_rate        | 0.0003      |
|    loss                 | 14.8        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.997       |
|    value_loss           | 37.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.58e+03    |
|    ep_rew_mean          | 1.46e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 830         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.009384969 |
|    clip_fraction        | 0.0949      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.809      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.72        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0197     |
|    std                  | 0.994       |
|    value_loss           | 32.9        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.91 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009964211 |
|    clip_fraction        | 0.091       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.287      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.63        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.021      |
|    std                  | 0.991       |
|    value_loss           | 27          |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2836     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3041        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.008082684 |
|    clip_fraction        | 0.0581      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.00206    |
|    learning_rate        | 0.0003      |
|    loss                 | 19.5        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00984    |
|    std                  | 0.99        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.33e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3247        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008442976 |
|    clip_fraction        | 0.0825      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.476      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.96        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.987       |
|    value_loss           | 20.5        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.4e+03      |
|    ep_rew_mean          | 1.33e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 8            |
|    time_elapsed         | 3453         |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0074424706 |
|    clip_fraction        | 0.0549       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.453        |
|    learning_rate        | 0.0003       |
|    loss                 | 8.72         |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.012       |
|    std                  | 0.986        |
|    value_loss           | 26.9         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.43e+03    |
|    ep_rew_mean          | 1.4e+03     |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3658        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.008277409 |
|    clip_fraction        | 0.0671      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | 5.81        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.986       |
|    value_loss           | 24.3        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-100.00 +/- 0.03
Episode length: 3594.80 +/- 12.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.59e+03     |
|    mean_reward          | -100         |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0140633825 |
|    clip_fraction        | 0.159        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | -0.256       |
|    learning_rate        | 0.0003       |
|    loss                 | 1.5          |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.015       |
|    std                  | 0.983        |
|    value_loss           | 8.03         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5670     |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 5876        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.009400185 |
|    clip_fraction        | 0.0857      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0109     |
|    learning_rate        | 0.0003      |
|    loss                 | 15.2        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00548    |
|    std                  | 0.984       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6081        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.017342854 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.178      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.00979    |
|    std                  | 0.969       |
|    value_loss           | 3.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6287        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.015200546 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0717     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.959       |
|    value_loss           | 2.76        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.42e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6492        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014371118 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -1.03       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.96        |
|    value_loss           | 4.4         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.86 +/- 0.05
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.017225549 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0545     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.941       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.959       |
|    value_loss           | 2.49        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8499     |
|    total_timesteps | 30720    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 16         |
|    time_elapsed         | 8704       |
|    total_timesteps      | 32768      |
| train/                  |            |
|    approx_kl            | 0.00665079 |
|    clip_fraction        | 0.116      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.0255    |
|    learning_rate        | 0.0003     |
|    loss                 | 20.4       |
|    n_updates            | 150        |
|    policy_gradient_loss | 0.00173    |
|    std                  | 0.958      |
|    value_loss           | 1.07e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 1.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 17         |
|    time_elapsed         | 8910       |
|    total_timesteps      | 34816      |
| train/                  |            |
|    approx_kl            | 0.01344957 |
|    clip_fraction        | 0.165      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.132     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05       |
|    n_updates            | 160        |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.96       |
|    value_loss           | 2.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.41e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9115        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.003609302 |
|    clip_fraction        | 0.0159      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0992     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.34        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00406    |
|    std                  | 0.96        |
|    value_loss           | 21.2        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.38e+03     |
|    ep_rew_mean          | 1.46e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 19           |
|    time_elapsed         | 9321         |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0009928339 |
|    clip_fraction        | 0.000635     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.0146       |
|    learning_rate        | 0.0003       |
|    loss                 | 11.1         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00287     |
|    std                  | 0.96         |
|    value_loss           | 26.6         |
------------------------------------------
Eval num_timesteps=40000, episode_reward=-99.88 +/- 0.04
Episode length: 3600.80 +/- 0.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.9        |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0024348365 |
|    clip_fraction        | 0.00234      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.499        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.65         |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.0049      |
|    std                  | 0.96         |
|    value_loss           | 8.84         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11330    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.41e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 11537        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0007033887 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | -0.00473     |
|    learning_rate        | 0.0003       |
|    loss                 | 727          |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00163     |
|    std                  | 0.96         |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11744       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.020147493 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.245      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.958       |
|    value_loss           | 2.56        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 23         |
|    time_elapsed         | 11950      |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.01299254 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.493     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.99       |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.951      |
|    value_loss           | 3.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.48e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12155       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.020351369 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0731     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.757       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.948       |
|    value_loss           | 2.25        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.85 +/- 0.04
Episode length: 3601.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.8        |
| time/                   |              |
|    total_timesteps      | 50000        |
| train/                  |              |
|    approx_kl            | 0.0048711374 |
|    clip_fraction        | 0.0783       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | 0.11         |
|    learning_rate        | 0.0003       |
|    loss                 | 4.21         |
|    n_updates            | 240          |
|    policy_gradient_loss | 0.000355     |
|    std                  | 0.948        |
|    value_loss           | 18.3         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14162    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.45e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 14368        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0002776807 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | -0.00245     |
|    learning_rate        | 0.0003       |
|    loss                 | 22.1         |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00101     |
|    std                  | 0.948        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14573       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.015246814 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.207      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.963       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00867    |
|    std                  | 0.941       |
|    value_loss           | 2.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14779       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.016786952 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.238      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.817       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.94        |
|    value_loss           | 2.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14984       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.017777415 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -1.25       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00688    |
|    std                  | 0.94        |
|    value_loss           | 3.61        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.84 +/- 0.05
Episode length: 3596.40 +/- 6.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.004951187 |
|    clip_fraction        | 0.0241      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.5         |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00863    |
|    std                  | 0.94        |
|    value_loss           | 6.96        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.48e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16996    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17203       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.008873115 |
|    clip_fraction        | 0.0393      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000166   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+03    |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00411    |
|    std                  | 0.939       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.51e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 32         |
|    time_elapsed         | 17408      |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.02196132 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.248     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.946      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.934      |
|    value_loss           | 1.62       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 1.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 33         |
|    time_elapsed         | 17614      |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.01511709 |
|    clip_fraction        | 0.165      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.54       |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.931      |
|    value_loss           | 3.06       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17819       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.020522086 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0342      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.889       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00942    |
|    std                  | 0.93        |
|    value_loss           | 1.75        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.84 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.016110614 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0224      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.588       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00718    |
|    std                  | 0.933       |
|    value_loss           | 1.66        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.51e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19827    |
|    total_timesteps | 71680    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.54e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 36         |
|    time_elapsed         | 20032      |
|    total_timesteps      | 73728      |
| train/                  |            |
|    approx_kl            | 0.00869292 |
|    clip_fraction        | 0.124      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.0343    |
|    learning_rate        | 0.0003     |
|    loss                 | 20.6       |
|    n_updates            | 350        |
|    policy_gradient_loss | 0.00156    |
|    std                  | 0.932      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20238       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.009611029 |
|    clip_fraction        | 0.088       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.336       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.933       |
|    value_loss           | 6.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20443       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.010019266 |
|    clip_fraction        | 0.0978      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.932       |
|    value_loss           | 3.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20649       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.023559982 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0972     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00926    |
|    std                  | 0.927       |
|    value_loss           | 2.08        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.83 +/- 0.08
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.01900366 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.0956    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.776      |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.929      |
|    value_loss           | 1.33       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.54e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22659    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22866       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.011115247 |
|    clip_fraction        | 0.0993      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0222     |
|    learning_rate        | 0.0003      |
|    loss                 | 76.4        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00375    |
|    std                  | 0.929       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.56e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 42           |
|    time_elapsed         | 23072        |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0061007673 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.493        |
|    learning_rate        | 0.0003       |
|    loss                 | 36.4         |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.00935     |
|    std                  | 0.929        |
|    value_loss           | 30           |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 1.58e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 43           |
|    time_elapsed         | 23278        |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0045892764 |
|    clip_fraction        | 0.0112       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 0.389        |
|    learning_rate        | 0.0003       |
|    loss                 | 11.6         |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.005       |
|    std                  | 0.929        |
|    value_loss           | 28.6         |
------------------------------------------
Eval num_timesteps=90000, episode_reward=-99.78 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.01966871 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.581     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.15       |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.931      |
|    value_loss           | 2.84       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25286    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25492       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.006967957 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.000234   |
|    learning_rate        | 0.0003      |
|    loss                 | 793         |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00369    |
|    std                  | 0.93        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25697       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.007634449 |
|    clip_fraction        | 0.0312      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.35        |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00781    |
|    std                  | 0.93        |
|    value_loss           | 25.4        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 47         |
|    time_elapsed         | 25903      |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.02470051 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | -0.0152    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.553      |
|    n_updates            | 460        |
|    policy_gradient_loss | -0.000394  |
|    std                  | 0.925      |
|    value_loss           | 1.3        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26109       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.017775033 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.87        |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00771    |
|    std                  | 0.925       |
|    value_loss           | 16          |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.83 +/- 0.06
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.022870578 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.681      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.949       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.918       |
|    value_loss           | 2.03        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28116    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 28322       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.019337393 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00123    |
|    learning_rate        | 0.0003      |
|    loss                 | 173         |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.0079     |
|    std                  | 0.916       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28527       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.021861741 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.39        |
|    learning_rate        | 0.0003      |
|    loss                 | 3.7         |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.001      |
|    std                  | 0.916       |
|    value_loss           | 23.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28733       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.026659332 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.176      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.579       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00461    |
|    std                  | 0.908       |
|    value_loss           | 1.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28938       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.022466712 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00408     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.751       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00723    |
|    std                  | 0.908       |
|    value_loss           | 1.73        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.83 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.009418895 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.8        |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.908       |
|    value_loss           | 30.8        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30945    |
|    total_timesteps | 110592   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.6e+03      |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 55           |
|    time_elapsed         | 31150        |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0050616553 |
|    clip_fraction        | 0.0275       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.6        |
|    explained_variance   | 0.000241     |
|    learning_rate        | 0.0003       |
|    loss                 | 10.9         |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00405     |
|    std                  | 0.908        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31357       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.020816969 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.213      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.678       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00319    |
|    std                  | 0.91        |
|    value_loss           | 1.59        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31563       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.011335971 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.75        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0016     |
|    std                  | 0.91        |
|    value_loss           | 33.8        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 1.62e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 58           |
|    time_elapsed         | 31768        |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0084241405 |
|    clip_fraction        | 0.0864       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.6        |
|    explained_variance   | 0.924        |
|    learning_rate        | 0.0003       |
|    loss                 | 1.74         |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.0102      |
|    std                  | 0.91         |
|    value_loss           | 23.1         |
------------------------------------------
Eval num_timesteps=120000, episode_reward=-99.89 +/- 0.03
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.021649294 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00167    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.589       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.903       |
|    value_loss           | 1.8         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33778    |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.61e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 60           |
|    time_elapsed         | 33986        |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0066392305 |
|    clip_fraction        | 0.0534       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.5        |
|    explained_variance   | 0.36         |
|    learning_rate        | 0.0003       |
|    loss                 | 114          |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.903        |
|    value_loss           | 1.07e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34191       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.010595979 |
|    clip_fraction        | 0.0701      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.12        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.904       |
|    value_loss           | 12.3        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34397       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.011219961 |
|    clip_fraction        | 0.0908      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.0003      |
|    loss                 | 9.56        |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.905       |
|    value_loss           | 18.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34602       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.028473675 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0209     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00852    |
|    std                  | 0.896       |
|    value_loss           | 2.1         |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.86 +/- 0.02
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.020289611 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0744      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.991       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.893       |
|    value_loss           | 3.86        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36609    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.61e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 65           |
|    time_elapsed         | 36815        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0023320634 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.0551       |
|    learning_rate        | 0.0003       |
|    loss                 | 346          |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00179     |
|    std                  | 0.893        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 37020       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.024408387 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.584      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.576       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.89        |
|    value_loss           | 1.48        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37226       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.025047597 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.0003      |
|    loss                 | 9.36        |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00721    |
|    std                  | 0.892       |
|    value_loss           | 11          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 68         |
|    time_elapsed         | 37431      |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.02765252 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47       |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.00446   |
|    std                  | 0.891      |
|    value_loss           | 4.09       |
----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.78 +/- 0.06
Episode length: 3596.40 +/- 6.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.02267193 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.81       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17       |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.889      |
|    value_loss           | 4.61       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39439    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39645       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.011179563 |
|    clip_fraction        | 0.101       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0025     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.53        |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.89        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39851       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.021476474 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0385     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.818       |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00483    |
|    std                  | 0.891       |
|    value_loss           | 1.78        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40056       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.026072752 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0286     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.679       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.894       |
|    value_loss           | 1.6         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40262       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.022083873 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0722     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.915       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00812    |
|    std                  | 0.895       |
|    value_loss           | 1.86        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.76 +/- 0.07
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.014494946 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.542       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.82        |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.895       |
|    value_loss           | 7.56        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42268    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42473       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.010006791 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00319    |
|    learning_rate        | 0.0003      |
|    loss                 | 6.49        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0062     |
|    std                  | 0.895       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42679       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.023130111 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.132      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.983       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00329    |
|    std                  | 0.896       |
|    value_loss           | 1.84        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.66e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 77        |
|    time_elapsed         | 42885     |
|    total_timesteps      | 157696    |
| train/                  |           |
|    approx_kl            | 0.0230528 |
|    clip_fraction        | 0.248     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.4     |
|    explained_variance   | -0.268    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.06      |
|    n_updates            | 760       |
|    policy_gradient_loss | -0.0146   |
|    std                  | 0.89      |
|    value_loss           | 2.44      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43091       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.023039278 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.143      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.702       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.889       |
|    value_loss           | 1.91        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.76 +/- 0.05
Episode length: 3596.60 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.021457154 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.0135      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.848       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.894       |
|    value_loss           | 1.36        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45101    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45308       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.014419889 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -4.17e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.61        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00631    |
|    std                  | 0.894       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.67e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 81           |
|    time_elapsed         | 45514        |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0065511586 |
|    clip_fraction        | 0.0516       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | 0.754        |
|    learning_rate        | 0.0003       |
|    loss                 | 3.4          |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00159     |
|    std                  | 0.894        |
|    value_loss           | 22.6         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45719       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.008778598 |
|    clip_fraction        | 0.0232      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.98        |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00581    |
|    std                  | 0.894       |
|    value_loss           | 21.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45925       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.024935633 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.692       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5         |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00924    |
|    std                  | 0.892       |
|    value_loss           | 5.31        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.82 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.025543142 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0193     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.712       |
|    n_updates            | 830         |
|    policy_gradient_loss | 0.00169     |
|    std                  | 0.893       |
|    value_loss           | 1.62        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47931    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48137       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.014513617 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00116     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.91        |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00865    |
|    std                  | 0.891       |
|    value_loss           | 931         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48342       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.030536797 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0279     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00379    |
|    std                  | 0.884       |
|    value_loss           | 1.89        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48548       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.023651894 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.432       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.962       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00953    |
|    std                  | 0.883       |
|    value_loss           | 4.17        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.78 +/- 0.02
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.024004348 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0173     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.556       |
|    n_updates            | 870         |
|    policy_gradient_loss | 0.000167    |
|    std                  | 0.881       |
|    value_loss           | 1.43        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50556    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50764       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.021761749 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00289    |
|    learning_rate        | 0.0003      |
|    loss                 | 30.9        |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.00166     |
|    std                  | 0.878       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 50970       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.030469544 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0203     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.802       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.876       |
|    value_loss           | 1.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51175       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.016373008 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0911      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.09        |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.874       |
|    value_loss           | 3.83        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51381       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.022244267 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0154      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.773       |
|    n_updates            | 910         |
|    policy_gradient_loss | 0.0016      |
|    std                  | 0.875       |
|    value_loss           | 1.5         |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.77 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.025356924 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.26       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.468       |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00968    |
|    std                  | 0.872       |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53387    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53593       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.023581386 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000769   |
|    learning_rate        | 0.0003      |
|    loss                 | 73.3        |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00457    |
|    std                  | 0.873       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.7e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 95        |
|    time_elapsed         | 53798     |
|    total_timesteps      | 194560    |
| train/                  |           |
|    approx_kl            | 0.0337616 |
|    clip_fraction        | 0.177     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | -0.0342   |
|    learning_rate        | 0.0003    |
|    loss                 | 3.19      |
|    n_updates            | 940       |
|    policy_gradient_loss | -0.0089   |
|    std                  | 0.872     |
|    value_loss           | 10.2      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 54004       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.034497492 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.311      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19        |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00316    |
|    std                  | 0.869       |
|    value_loss           | 1.83        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 54209      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.02763642 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.0154    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.756      |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.00323   |
|    std                  | 0.866      |
|    value_loss           | 1.74       |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.79 +/- 0.03
Episode length: 3596.20 +/- 9.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.016104877 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.0003      |
|    loss                 | 2           |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.866       |
|    value_loss           | 4.76        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.71e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56218    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56424       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.020837689 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00112    |
|    learning_rate        | 0.0003      |
|    loss                 | 815         |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00332    |
|    std                  | 0.867       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56630       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.032953065 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0138     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.839       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.000937   |
|    std                  | 0.858       |
|    value_loss           | 1.53        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56835       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.021848585 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0999      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.29        |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.00827    |
|    std                  | 0.851       |
|    value_loss           | 2.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57041       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.024955291 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.0195      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.977       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.848       |
|    value_loss           | 2.1         |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.74 +/- 0.08
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.023378627 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.0104      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.714       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00195    |
|    std                  | 0.842       |
|    value_loss           | 1.68        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.72e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59048    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59254       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.022442307 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.00547    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.17e+03    |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00498    |
|    std                  | 0.843       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 59459      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.02577224 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | -0.138     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.703      |
|    n_updates            | 1040       |
|    policy_gradient_loss | 0.00284    |
|    std                  | 0.842      |
|    value_loss           | 1.58       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.73e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 59665      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.03068874 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | -4.48      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.727      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.00504   |
|    std                  | 0.842      |
|    value_loss           | 2.41       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 59870       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.022516143 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -0.108      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.686       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00493    |
|    std                  | 0.839       |
|    value_loss           | 2.15        |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.55 +/- 0.04
Episode length: 3597.00 +/- 8.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.025619425 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.743      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.003      |
|    std                  | 0.837       |
|    value_loss           | 1.95        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.73e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61881    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62087       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.021975584 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | -0.000324   |
|    learning_rate        | 0.0003      |
|    loss                 | 313         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00471    |
|    std                  | 0.838       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 62293       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.029904952 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | -0.0578     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.803       |
|    n_updates            | 1090        |
|    policy_gradient_loss | 2.62e-05    |
|    std                  | 0.836       |
|    value_loss           | 1.68        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62499       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.035877287 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.803      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00211    |
|    std                  | 0.833       |
|    value_loss           | 4.48        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.75e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 62704      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.02025185 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.86      |
|    explained_variance   | -2.5       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.931      |
|    n_updates            | 1110       |
|    policy_gradient_loss | -0.00465   |
|    std                  | 0.831      |
|    value_loss           | 2.33       |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.61 +/- 0.08
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.02274652 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.86      |
|    explained_variance   | 0.0122     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.824      |
|    n_updates            | 1120       |
|    policy_gradient_loss | 0.00087    |
|    std                  | 0.833      |
|    value_loss           | 1.61       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64711    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64917       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.018689916 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.000975    |
|    learning_rate        | 0.0003      |
|    loss                 | 25.7        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00859    |
|    std                  | 0.832       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65123       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.028763436 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | -0.068      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.892       |
|    n_updates            | 1140        |
|    policy_gradient_loss | 0.000563    |
|    std                  | 0.831       |
|    value_loss           | 1.69        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65328       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.023686158 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.0327      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.661       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0027     |
|    std                  | 0.831       |
|    value_loss           | 1.91        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65534       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.024602676 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.0269      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.897       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00298    |
|    std                  | 0.833       |
|    value_loss           | 1.85        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.59 +/- 0.05
Episode length: 3596.20 +/- 7.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.029574968 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.0356      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.00466     |
|    std                  | 0.833       |
|    value_loss           | 2.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67542    |
|    total_timesteps | 241664   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 119        |
|    time_elapsed         | 67748      |
|    total_timesteps      | 243712     |
| train/                  |            |
|    approx_kl            | 0.02404105 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 9.69e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 700        |
|    n_updates            | 1180       |
|    policy_gradient_loss | -0.00052   |
|    std                  | 0.833      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67954       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.028019596 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | -4.02       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.737       |
|    n_updates            | 1190        |
|    policy_gradient_loss | 0.000619    |
|    std                  | 0.832       |
|    value_loss           | 2.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68159       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.026765492 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.00423     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 1200        |
|    policy_gradient_loss | 0.00297     |
|    std                  | 0.833       |
|    value_loss           | 1.88        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68365       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.034279566 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -9.89e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.877       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00557    |
|    std                  | 0.829       |
|    value_loss           | 2.02        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.57 +/- 0.05
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.024659324 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | 0.0679      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.886       |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00179    |
|    std                  | 0.823       |
|    value_loss           | 1.87        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.77e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70373    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70578       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.038234897 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.000978   |
|    learning_rate        | 0.0003      |
|    loss                 | 568         |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00175    |
|    std                  | 0.824       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70784       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.027844436 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -2.64       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.692       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.000271   |
|    std                  | 0.826       |
|    value_loss           | 1.74        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70990       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.033054672 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.00389     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.737       |
|    n_updates            | 1250        |
|    policy_gradient_loss | 0.00224     |
|    std                  | 0.823       |
|    value_loss           | 1.57        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.54 +/- 0.04
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.037900504 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.016      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.906       |
|    n_updates            | 1260        |
|    policy_gradient_loss | 0.0011      |
|    std                  | 0.825       |
|    value_loss           | 1.93        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72998    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73204       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.028808638 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -0.0155     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.07e+03    |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00323    |
|    std                  | 0.827       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 73410       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.061305344 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -0.0406     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.69        |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.00308     |
|    std                  | 0.824       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73616       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.030615594 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.0833     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.855       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00408    |
|    std                  | 0.823       |
|    value_loss           | 2.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 73821       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.028658684 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | 0.0141      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.613       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00322    |
|    std                  | 0.822       |
|    value_loss           | 1.49        |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.62 +/- 0.04
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.048810445 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | -0.841      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.1         |
|    n_updates            | 1310        |
|    policy_gradient_loss | 0.00271     |
|    std                  | 0.824       |
|    value_loss           | 15.1        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75828    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 76033       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.028997153 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | -0.00665    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 1320        |
|    policy_gradient_loss | 0.00106     |
|    std                  | 0.822       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76239      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.03178698 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.76      |
|    explained_variance   | -0.0112    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.66       |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.000299  |
|    std                  | 0.823      |
|    value_loss           | 1.51       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76444       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.028206136 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.76       |
|    explained_variance   | 0.367       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.862       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.000292   |
|    std                  | 0.822       |
|    value_loss           | 2.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 76650       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.024976283 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | 0.0106      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.547       |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00186    |
|    std                  | 0.814       |
|    value_loss           | 1.24        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.52 +/- 0.06
Episode length: 3597.80 +/- 3.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.031886213 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | 0.0321      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.00171     |
|    std                  | 0.815       |
|    value_loss           | 1.91        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78662    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78869       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.026494423 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | -0.000983   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.27e+03    |
|    n_updates            | 1370        |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.814       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 79075       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.033198547 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.134       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24        |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00248    |
|    std                  | 0.81        |
|    value_loss           | 2.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79280       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.033074424 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | 0.2         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.964       |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00812    |
|    std                  | 0.807       |
|    value_loss           | 2.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 141         |
|    time_elapsed         | 79486       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.028005918 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.0492      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.00473    |
|    std                  | 0.807       |
|    value_loss           | 1.39        |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.56 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.031051101 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.822       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00747    |
|    std                  | 0.804       |
|    value_loss           | 1.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81492    |
|    total_timesteps | 290816   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 143        |
|    time_elapsed         | 81697      |
|    total_timesteps      | 292864     |
| train/                  |            |
|    approx_kl            | 0.03035312 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | 6.28e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 12.9       |
|    n_updates            | 1420       |
|    policy_gradient_loss | -0.00078   |
|    std                  | 0.805      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 81903       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.034727294 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -0.0814     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.00417     |
|    std                  | 0.802       |
|    value_loss           | 1.97        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 145        |
|    time_elapsed         | 82110      |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.02585898 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.53      |
|    explained_variance   | 0.0187     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.72       |
|    n_updates            | 1440       |
|    policy_gradient_loss | 0.00155    |
|    std                  | 0.797      |
|    value_loss           | 1.68       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82316       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.032816656 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.0273      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.696       |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.00195    |
|    std                  | 0.799       |
|    value_loss           | 1.39        |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.57 +/- 0.03
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.029283749 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.912       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00257    |
|    std                  | 0.794       |
|    value_loss           | 1.54        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84326    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 84533       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.047215775 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.000614    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17e+03    |
|    n_updates            | 1470        |
|    policy_gradient_loss | 0.0037      |
|    std                  | 0.795       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84738       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.036719736 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | -0.00365    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.00186    |
|    std                  | 0.79        |
|    value_loss           | 2.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 84944       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.029202921 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -0.168      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.14        |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.789       |
|    value_loss           | 3.02        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85149      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.03506575 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | -4.83      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.859      |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.00144   |
|    std                  | 0.789      |
|    value_loss           | 2.06       |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.60 +/- 0.03
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.034299448 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.0364      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.856       |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.00327    |
|    std                  | 0.785       |
|    value_loss           | 1.84        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87156    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87362       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.028837403 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | -8.34e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 148         |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.000678    |
|    std                  | 0.784       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 87567       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.028500509 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -0.0113     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.734       |
|    n_updates            | 1530        |
|    policy_gradient_loss | 8.53e-05    |
|    std                  | 0.781       |
|    value_loss           | 1.61        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 155        |
|    time_elapsed         | 87773      |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.03254048 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | 0.0349     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.735      |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.00494   |
|    std                  | 0.78       |
|    value_loss           | 2.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 87978       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.039275818 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.153       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.1         |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.000115   |
|    std                  | 0.777       |
|    value_loss           | 1.53        |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.64 +/- 0.03
Episode length: 3596.40 +/- 8.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.025441848 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | 0.0191      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.463       |
|    n_updates            | 1560        |
|    policy_gradient_loss | 0.00427     |
|    std                  | 0.776       |
|    value_loss           | 1.42        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89988    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90194       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.029112922 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | 0.000224    |
|    learning_rate        | 0.0003      |
|    loss                 | 24.3        |
|    n_updates            | 1570        |
|    policy_gradient_loss | 0.0053      |
|    std                  | 0.775       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90399       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.029177304 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | -0.0078     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.937       |
|    n_updates            | 1580        |
|    policy_gradient_loss | 0.00313     |
|    std                  | 0.777       |
|    value_loss           | 1.84        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 90605       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.026526678 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.0416      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14        |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.00377    |
|    std                  | 0.773       |
|    value_loss           | 1.62        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 90810       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.028895024 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | -0.00866    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19        |
|    n_updates            | 1600        |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.778       |
|    value_loss           | 1.96        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.61 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.033508126 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | 0.0335      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.646       |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.000282   |
|    std                  | 0.775       |
|    value_loss           | 1.5         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92817    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 163         |
|    time_elapsed         | 93022       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.034056645 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 2.58e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 13.8        |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00311    |
|    std                  | 0.775       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93228       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.027214227 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.26       |
|    explained_variance   | -0.119      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 1630        |
|    policy_gradient_loss | 0.00233     |
|    std                  | 0.773       |
|    value_loss           | 1.71        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93433       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.035595167 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.22       |
|    explained_variance   | 0.0121      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.871       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.00337     |
|    std                  | 0.768       |
|    value_loss           | 1.58        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 93639      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.03692884 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.21      |
|    explained_variance   | -0.444     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.963      |
|    n_updates            | 1650       |
|    policy_gradient_loss | 6.52e-05   |
|    std                  | 0.77       |
|    value_loss           | 1.68       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.58 +/- 0.05
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.034217473 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | -0.0358     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.718       |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.00214    |
|    std                  | 0.773       |
|    value_loss           | 2.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95650    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 95857       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.019934695 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | -0.00061    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00159    |
|    std                  | 0.775       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 96063       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.019040814 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | 0.00497     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.667       |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.00239     |
|    std                  | 0.773       |
|    value_loss           | 2.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 96268       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.040732637 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.0116      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07        |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.00242    |
|    std                  | 0.766       |
|    value_loss           | 1.78        |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.62 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.026632687 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.0282      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.723       |
|    n_updates            | 1700        |
|    policy_gradient_loss | 0.00934     |
|    std                  | 0.766       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98276    |
|    total_timesteps | 350208   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.88e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 172       |
|    time_elapsed         | 98481     |
|    total_timesteps      | 352256    |
| train/                  |           |
|    approx_kl            | 0.0527653 |
|    clip_fraction        | 0.276     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.16     |
|    explained_variance   | -0.0041   |
|    learning_rate        | 0.0003    |
|    loss                 | 6         |
|    n_updates            | 1710      |
|    policy_gradient_loss | -0.00315  |
|    std                  | 0.766     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 173        |
|    time_elapsed         | 98687      |
|    total_timesteps      | 354304     |
| train/                  |            |
|    approx_kl            | 0.02775002 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.14      |
|    explained_variance   | 0.0388     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06       |
|    n_updates            | 1720       |
|    policy_gradient_loss | 0.00209    |
|    std                  | 0.763      |
|    value_loss           | 2.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 98892      |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.03510193 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.13      |
|    explained_variance   | 0.0476     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.834      |
|    n_updates            | 1730       |
|    policy_gradient_loss | 0.00885    |
|    std                  | 0.762      |
|    value_loss           | 2.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 99098       |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.035564166 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.065       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.0034      |
|    std                  | 0.757       |
|    value_loss           | 1.44        |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.54 +/- 0.04
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.033348616 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | -0.033      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.632       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.00297     |
|    std                  | 0.758       |
|    value_loss           | 1.42        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101108   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101315      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.028996935 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | 5.84e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32e+03    |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00254    |
|    std                  | 0.757       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 101521      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.030356215 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.078       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 1770        |
|    policy_gradient_loss | 0.00335     |
|    std                  | 0.756       |
|    value_loss           | 1.92        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 101728     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.03016068 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.0379     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.898      |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.753      |
|    value_loss           | 1.63       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 101934      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.027056258 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.22        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.651       |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00421    |
|    std                  | 0.752       |
|    value_loss           | 2.04        |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.67 +/- 0.15
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.030299237 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.01       |
|    explained_variance   | -4.22       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.759       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.000351    |
|    std                  | 0.752       |
|    value_loss           | 1.73        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103940   |
|    total_timesteps | 370688   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.92e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 182        |
|    time_elapsed         | 104145     |
|    total_timesteps      | 372736     |
| train/                  |            |
|    approx_kl            | 0.03744567 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | -4.23e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 28.6       |
|    n_updates            | 1810       |
|    policy_gradient_loss | 0.00219    |
|    std                  | 0.751      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.94e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 183       |
|    time_elapsed         | 104351    |
|    total_timesteps      | 374784    |
| train/                  |           |
|    approx_kl            | 0.0591231 |
|    clip_fraction        | 0.341     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.98     |
|    explained_variance   | -0.0437   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.827     |
|    n_updates            | 1820      |
|    policy_gradient_loss | 0.00558   |
|    std                  | 0.748     |
|    value_loss           | 1.8       |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.94e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 104556      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.033085924 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.96       |
|    explained_variance   | 0.0134      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.73        |
|    n_updates            | 1830        |
|    policy_gradient_loss | 0.00869     |
|    std                  | 0.747       |
|    value_loss           | 1.5         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.95e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 104762     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.03256975 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.95      |
|    explained_variance   | 0.0441     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02       |
|    n_updates            | 1840       |
|    policy_gradient_loss | 0.00202    |
|    std                  | 0.746      |
|    value_loss           | 1.57       |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.53 +/- 0.03
Episode length: 3597.60 +/- 4.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.028752275 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | -0.0122     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.767       |
|    n_updates            | 1850        |
|    policy_gradient_loss | 0.00439     |
|    std                  | 0.745       |
|    value_loss           | 1.5         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.94e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106772   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.94e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 106978      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.023007337 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | -0.00041    |
|    learning_rate        | 0.0003      |
|    loss                 | 732         |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.00218     |
|    std                  | 0.746       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 188         |
|    time_elapsed         | 107184      |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.041831076 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | -0.0114     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.771       |
|    n_updates            | 1870        |
|    policy_gradient_loss | 0.00617     |
|    std                  | 0.74        |
|    value_loss           | 1.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107389      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.027323216 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | -0.00387    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.00519     |
|    std                  | 0.745       |
|    value_loss           | 1.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 190         |
|    time_elapsed         | 107595      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.028141849 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.0134      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.64        |
|    n_updates            | 1890        |
|    policy_gradient_loss | 0.00698     |
|    std                  | 0.744       |
|    value_loss           | 1.33        |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.54 +/- 0.04
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.050904855 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.00691     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.807       |
|    n_updates            | 1900        |
|    policy_gradient_loss | 0.00701     |
|    std                  | 0.74        |
|    value_loss           | 1.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.96e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109602   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.96e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 109808     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.01076648 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.88      |
|    explained_variance   | -0.0102    |
|    learning_rate        | 0.0003     |
|    loss                 | 5.75       |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.003     |
|    std                  | 0.741      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.97e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 110013      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.034375943 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.85       |
|    explained_variance   | -0.566      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.79        |
|    n_updates            | 1920        |
|    policy_gradient_loss | 0.00223     |
|    std                  | 0.735       |
|    value_loss           | 1.84        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110219      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.038316276 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | -0.00951    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.675       |
|    n_updates            | 1930        |
|    policy_gradient_loss | 0.00112     |
|    std                  | 0.729       |
|    value_loss           | 1.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110424      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.040383603 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.74       |
|    explained_variance   | 0.0271      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.00504     |
|    std                  | 0.726       |
|    value_loss           | 1.61        |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.57 +/- 0.02
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.046381786 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | -0.165      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.00287     |
|    std                  | 0.726       |
|    value_loss           | 1.82        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.98e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112435   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112642      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.027787728 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.72       |
|    explained_variance   | -0.000592   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.89        |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00121     |
|    std                  | 0.724       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.99e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 198        |
|    time_elapsed         | 112848     |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.04531238 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.7       |
|    explained_variance   | -0.0157    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.952      |
|    n_updates            | 1970       |
|    policy_gradient_loss | 0.00711    |
|    std                  | 0.725      |
|    value_loss           | 1.63       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 113053     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.07521148 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.71      |
|    explained_variance   | -0.972     |
|    learning_rate        | 0.0003     |
|    loss                 | 4.3        |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.00618    |
|    std                  | 0.726      |
|    value_loss           | 4.45       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2e+03       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 200         |
|    time_elapsed         | 113261      |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.037880905 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | -0.236      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.782       |
|    n_updates            | 1990        |
|    policy_gradient_loss | 0.00567     |
|    std                  | 0.725       |
|    value_loss           | 1.64        |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.52 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.038111895 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.029       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.639       |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.72        |
|    value_loss           | 1.8         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.99e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115267   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 115473      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.031621724 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | -0.000772   |
|    learning_rate        | 0.0003      |
|    loss                 | 198         |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00245    |
|    std                  | 0.721       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 115679     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.03311059 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | -0.0383    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.505      |
|    n_updates            | 2020       |
|    policy_gradient_loss | 0.00333    |
|    std                  | 0.719      |
|    value_loss           | 1.41       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 115884      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.079522245 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | -0.44       |
|    learning_rate        | 0.0003      |
|    loss                 | 15.4        |
|    n_updates            | 2030        |
|    policy_gradient_loss | -2.34e-05   |
|    std                  | 0.72        |
|    value_loss           | 8.27        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 116090     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.04092538 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.032      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02       |
|    n_updates            | 2040       |
|    policy_gradient_loss | -0.000701  |
|    std                  | 0.717      |
|    value_loss           | 1.52       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.47 +/- 0.06
Episode length: 3596.20 +/- 6.68
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.04276175 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.00694    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05       |
|    n_updates            | 2050       |
|    policy_gradient_loss | 0.00769    |
|    std                  | 0.716      |
|    value_loss           | 1.74       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118100   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118306      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.034476355 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | -0.00633    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2e+03     |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00151    |
|    std                  | 0.717       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 208         |
|    time_elapsed         | 118512      |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.047002196 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | -0.117      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.539       |
|    n_updates            | 2070        |
|    policy_gradient_loss | 0.00378     |
|    std                  | 0.714       |
|    value_loss           | 1.6         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 118717      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.038402967 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.799       |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.00824     |
|    std                  | 0.712       |
|    value_loss           | 1.61        |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.51 +/- 0.05
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.040176753 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | -0.0188     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.561       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.00576     |
|    std                  | 0.709       |
|    value_loss           | 1.51        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120724   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 120929      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.031176686 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.000526    |
|    learning_rate        | 0.0003      |
|    loss                 | 125         |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.707       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121136      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.037813142 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | -0.00197    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.628       |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.0152      |
|    std                  | 0.706       |
|    value_loss           | 1.25        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 213        |
|    time_elapsed         | 121342     |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.04117503 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | -2.72      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.542      |
|    n_updates            | 2120       |
|    policy_gradient_loss | 0.00646    |
|    std                  | 0.708      |
|    value_loss           | 3.72       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 121547     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.03437241 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | 0.00367    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.961      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.707      |
|    value_loss           | 1.67       |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.56 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.051311955 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.49       |
|    explained_variance   | -1.27       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.985       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.009       |
|    std                  | 0.703       |
|    value_loss           | 2.6         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123558   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123764      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.038150467 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | -0.00534    |
|    learning_rate        | 0.0003      |
|    loss                 | 5.53        |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.000385   |
|    std                  | 0.702       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.06e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 217       |
|    time_elapsed         | 123970    |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 0.0423292 |
|    clip_fraction        | 0.366     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.44     |
|    explained_variance   | 0.0121    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.844     |
|    n_updates            | 2160      |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.7       |
|    value_loss           | 1.41      |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.06e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 218      |
|    time_elapsed         | 124176   |
|    total_timesteps      | 446464   |
| train/                  |          |
|    approx_kl            | 0.04562  |
|    clip_fraction        | 0.356    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.42    |
|    explained_variance   | 0.0082   |
|    learning_rate        | 0.0003   |
|    loss                 | 0.785    |
|    n_updates            | 2170     |
|    policy_gradient_loss | 0.00614  |
|    std                  | 0.699    |
|    value_loss           | 1.52     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 219        |
|    time_elapsed         | 124381     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.06280197 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.4       |
|    explained_variance   | 0.0189     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.993      |
|    n_updates            | 2180       |
|    policy_gradient_loss | 0.01       |
|    std                  | 0.697      |
|    value_loss           | 1.42       |
----------------------------------------
Eval num_timesteps=450000, episode_reward=-98.67 +/- 0.89
Episode length: 3599.40 +/- 2.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.7       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.033282936 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.0899      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.811       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.00276     |
|    std                  | 0.696       |
|    value_loss           | 1.8         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126389   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 126595      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.041755214 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | -0.000311   |
|    learning_rate        | 0.0003      |
|    loss                 | 765         |
|    n_updates            | 2200        |
|    policy_gradient_loss | 0.00704     |
|    std                  | 0.697       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 126801     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.04795593 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.0247     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.812      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.695      |
|    value_loss           | 1.41       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 127006      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.061038338 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.36       |
|    explained_variance   | -0.0226     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.687       |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.00433     |
|    std                  | 0.694       |
|    value_loss           | 1.56        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 224        |
|    time_elapsed         | 127212     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.03190154 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.35      |
|    explained_variance   | 0.00988    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.66       |
|    n_updates            | 2230       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.694      |
|    value_loss           | 1.56       |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.42 +/- 0.37
Episode length: 3596.00 +/- 6.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.041842584 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.34       |
|    explained_variance   | 0.0285      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.617       |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.692       |
|    value_loss           | 1.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129223   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 129430      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.036347754 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.33       |
|    explained_variance   | 0.000264    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.12        |
|    n_updates            | 2250        |
|    policy_gradient_loss | 0.00303     |
|    std                  | 0.691       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 129635      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.034975417 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | -0.00263    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.25        |
|    n_updates            | 2260        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.688       |
|    value_loss           | 1.85        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 129841      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.052232876 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.0267      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.85        |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.685       |
|    value_loss           | 1.68        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 130046      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.032001328 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.129       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28        |
|    n_updates            | 2280        |
|    policy_gradient_loss | 0.00353     |
|    std                  | 0.685       |
|    value_loss           | 1.85        |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.59 +/- 0.04
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.034716103 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.23       |
|    explained_variance   | 0.0414      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.544       |
|    n_updates            | 2290        |
|    policy_gradient_loss | 0.00791     |
|    std                  | 0.684       |
|    value_loss           | 1.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 132053   |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 231        |
|    time_elapsed         | 132258     |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.03767614 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.23      |
|    explained_variance   | -0.0072    |
|    learning_rate        | 0.0003     |
|    loss                 | 91.3       |
|    n_updates            | 2300       |
|    policy_gradient_loss | 0.00256    |
|    std                  | 0.685      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 132464     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.04318363 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.24      |
|    explained_variance   | -0.00724   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09       |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.685      |
|    value_loss           | 1.58       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 132670      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.044077754 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.0111      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.87        |
|    n_updates            | 2320        |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.687       |
|    value_loss           | 1.58        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 234         |
|    time_elapsed         | 132877      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.047933564 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.0446      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.877       |
|    n_updates            | 2330        |
|    policy_gradient_loss | 0.00849     |
|    std                  | 0.683       |
|    value_loss           | 1.75        |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.54 +/- 0.03
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.045086205 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.00752     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.808       |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.00418     |
|    std                  | 0.681       |
|    value_loss           | 1.43        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134887   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 135094      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.044221886 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | -0.0267     |
|    learning_rate        | 0.0003      |
|    loss                 | 21.2        |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00181    |
|    std                  | 0.681       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 237        |
|    time_elapsed         | 135300     |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.05582515 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.17      |
|    explained_variance   | 0.0176     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.76       |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.68       |
|    value_loss           | 1.46       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 135505      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.038661808 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.13       |
|    explained_variance   | 0.0235      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.609       |
|    n_updates            | 2370        |
|    policy_gradient_loss | 0.0146      |
|    std                  | 0.674       |
|    value_loss           | 1.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 239         |
|    time_elapsed         | 135711      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.069741845 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.0327      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.674       |
|    n_updates            | 2380        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.674       |
|    value_loss           | 1.57        |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.56 +/- 0.04
Episode length: 3598.40 +/- 3.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.03535582 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.0306     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.817      |
|    n_updates            | 2390       |
|    policy_gradient_loss | 0.00879    |
|    std                  | 0.671      |
|    value_loss           | 1.46       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137717   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 137923     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.06678317 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | -0.000631  |
|    learning_rate        | 0.0003     |
|    loss                 | 131        |
|    n_updates            | 2400       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.671      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 242         |
|    time_elapsed         | 138129      |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.042952966 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | -0.00208    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.736       |
|    n_updates            | 2410        |
|    policy_gradient_loss | 0.0148      |
|    std                  | 0.668       |
|    value_loss           | 1.58        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 243       |
|    time_elapsed         | 138334    |
|    total_timesteps      | 497664    |
| train/                  |           |
|    approx_kl            | 0.0329989 |
|    clip_fraction        | 0.333     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.01     |
|    explained_variance   | 0.0565    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.543     |
|    n_updates            | 2420      |
|    policy_gradient_loss | 0.00529   |
|    std                  | 0.666     |
|    value_loss           | 1.48      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138540     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.03788869 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.02      |
|    explained_variance   | -4.46      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.711      |
|    n_updates            | 2430       |
|    policy_gradient_loss | 0.00632    |
|    std                  | 0.669      |
|    value_loss           | 2.44       |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.54 +/- 0.05
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.03928805 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.01      |
|    explained_variance   | -0.0196    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.948      |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.00384    |
|    std                  | 0.666      |
|    value_loss           | 1.67       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140547   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 140754      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.048785087 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.99       |
|    explained_variance   | -0.0185     |
|    learning_rate        | 0.0003      |
|    loss                 | 274         |
|    n_updates            | 2450        |
|    policy_gradient_loss | 0.00252     |
|    std                  | 0.666       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 140959     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.05021873 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.163      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04       |
|    n_updates            | 2460       |
|    policy_gradient_loss | 0.00745    |
|    std                  | 0.666      |
|    value_loss           | 2.2        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 141165      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.055917367 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.97       |
|    explained_variance   | 0.0473      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.91        |
|    n_updates            | 2470        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.661       |
|    value_loss           | 1.45        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 249        |
|    time_elapsed         | 141371     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.04905979 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.23       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.73       |
|    n_updates            | 2480       |
|    policy_gradient_loss | 0.00699    |
|    std                  | 0.663      |
|    value_loss           | 1.43       |
----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.59 +/- 0.01
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.04564328 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.94      |
|    explained_variance   | 0.0526     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.00606    |
|    std                  | 0.66       |
|    value_loss           | 1.33       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143377   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 143582      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.038912274 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | -0.000337   |
|    learning_rate        | 0.0003      |
|    loss                 | 64          |
|    n_updates            | 2500        |
|    policy_gradient_loss | 0.000801    |
|    std                  | 0.661       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 143788      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.036733795 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | 0.00725     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.801       |
|    n_updates            | 2510        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.66        |
|    value_loss           | 1.64        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 143994      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.039750393 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | 0.000868    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09        |
|    n_updates            | 2520        |
|    policy_gradient_loss | 0.00998     |
|    std                  | 0.661       |
|    value_loss           | 1.64        |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.63 +/- 0.13
Episode length: 3595.20 +/- 11.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.043959115 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | -4.43       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.822       |
|    n_updates            | 2530        |
|    policy_gradient_loss | 0.00771     |
|    std                  | 0.659       |
|    value_loss           | 3.68        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 146003   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146208      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.044261675 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.92       |
|    explained_variance   | -0.00104    |
|    learning_rate        | 0.0003      |
|    loss                 | 15.9        |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00489    |
|    std                  | 0.659       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 146414     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.03909712 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | -0.0178    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.569      |
|    n_updates            | 2550       |
|    policy_gradient_loss | 0.00522    |
|    std                  | 0.653      |
|    value_loss           | 1.4        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 146619      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.041205235 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | 0.0668      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.878       |
|    n_updates            | 2560        |
|    policy_gradient_loss | 0.00808     |
|    std                  | 0.65        |
|    value_loss           | 1.83        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 146825      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.052160554 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.78       |
|    explained_variance   | 0.0282      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17        |
|    n_updates            | 2570        |
|    policy_gradient_loss | 0.00843     |
|    std                  | 0.646       |
|    value_loss           | 1.72        |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.61 +/- 0.19
Episode length: 3599.20 +/- 2.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.047558423 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | -0.032      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.621       |
|    n_updates            | 2580        |
|    policy_gradient_loss | 0.00949     |
|    std                  | 0.646       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148832   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 149038     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.04564156 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | -0.00133   |
|    learning_rate        | 0.0003     |
|    loss                 | 53.6       |
|    n_updates            | 2590       |
|    policy_gradient_loss | 0.0084     |
|    std                  | 0.647      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 149243      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.037731353 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.79       |
|    explained_variance   | 0.000258    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.757       |
|    n_updates            | 2600        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.65        |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 149449      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.048339404 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | -3.79       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.745       |
|    n_updates            | 2610        |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.644       |
|    value_loss           | 1.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 149654      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.040364053 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.72       |
|    explained_variance   | 0.0208      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.635       |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.643       |
|    value_loss           | 1.53        |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.55 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.049141303 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.72       |
|    explained_variance   | 0.0479      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.639       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.0161      |
|    std                  | 0.642       |
|    value_loss           | 1.25        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151664   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 151870      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.044369787 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | -0.00484    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.97e+03    |
|    n_updates            | 2640        |
|    policy_gradient_loss | 0.00186     |
|    std                  | 0.642       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 266       |
|    time_elapsed         | 152075    |
|    total_timesteps      | 544768    |
| train/                  |           |
|    approx_kl            | 0.0362276 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.71     |
|    explained_variance   | -0.00651  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.684     |
|    n_updates            | 2650      |
|    policy_gradient_loss | 0.00952   |
|    std                  | 0.642     |
|    value_loss           | 1.38      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.21e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 267       |
|    time_elapsed         | 152281    |
|    total_timesteps      | 546816    |
| train/                  |           |
|    approx_kl            | 0.0614094 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.68     |
|    explained_variance   | 0.0227    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.696     |
|    n_updates            | 2660      |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.638     |
|    value_loss           | 1.44      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 152487     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.05977826 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.65      |
|    explained_variance   | -0.0731    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.692      |
|    n_updates            | 2670       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.636      |
|    value_loss           | 1.1        |
----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.71 +/- 0.18
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.037765093 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.62       |
|    explained_variance   | 0.00439     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.562       |
|    n_updates            | 2680        |
|    policy_gradient_loss | 0.00532     |
|    std                  | 0.634       |
|    value_loss           | 1.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154494   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 154699      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.033020593 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.00146     |
|    learning_rate        | 0.0003      |
|    loss                 | 11          |
|    n_updates            | 2690        |
|    policy_gradient_loss | 0.00236     |
|    std                  | 0.634       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 271         |
|    time_elapsed         | 154905      |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.031066693 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | -0.187      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.827       |
|    n_updates            | 2700        |
|    policy_gradient_loss | 0.0184      |
|    std                  | 0.634       |
|    value_loss           | 1.45        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 155110      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.046151996 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.59       |
|    explained_variance   | 0.0109      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.841       |
|    n_updates            | 2710        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.632       |
|    value_loss           | 1.44        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.22e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 273       |
|    time_elapsed         | 155316    |
|    total_timesteps      | 559104    |
| train/                  |           |
|    approx_kl            | 0.0530565 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.6      |
|    explained_variance   | 0.0254    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.994     |
|    n_updates            | 2720      |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.634     |
|    value_loss           | 1.5       |
---------------------------------------
Eval num_timesteps=560000, episode_reward=-99.54 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.049394883 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | 0.0249      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.69        |
|    n_updates            | 2730        |
|    policy_gradient_loss | 0.0118      |
|    std                  | 0.633       |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157324   |
|    total_timesteps | 561152   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.33e+03 |
|    ep_rew_mean          | 2.22e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 275      |
|    time_elapsed         | 157530   |
|    total_timesteps      | 563200   |
| train/                  |          |
|    approx_kl            | 0.051262 |
|    clip_fraction        | 0.463    |
|    clip_range           | 0.2      |
|    entropy_loss         | -7.61    |
|    explained_variance   | -0.0129  |
|    learning_rate        | 0.0003   |
|    loss                 | 2.16e+03 |
|    n_updates            | 2740     |
|    policy_gradient_loss | 0.00731  |
|    std                  | 0.635    |
|    value_loss           | 1.05e+03 |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 276         |
|    time_elapsed         | 157735      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.044212196 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.0108      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.7         |
|    n_updates            | 2750        |
|    policy_gradient_loss | 0.00706     |
|    std                  | 0.633       |
|    value_loss           | 1.58        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 157941      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.049269736 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.57       |
|    explained_variance   | 0.116       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.702       |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.00745     |
|    std                  | 0.629       |
|    value_loss           | 1.46        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 158146     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.04986553 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.52      |
|    explained_variance   | 0.0953     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.703      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.625      |
|    value_loss           | 1.44       |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.55 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.06658825 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | 0.0398     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.564      |
|    n_updates            | 2780       |
|    policy_gradient_loss | 0.00933    |
|    std                  | 0.626      |
|    value_loss           | 1.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160155   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160360      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.059257533 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.48       |
|    explained_variance   | -7.01e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 73.4        |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.00178     |
|    std                  | 0.624       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 160566     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.07472614 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.00107    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 2800       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.622      |
|    value_loss           | 1.22       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 160772      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.040168554 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.0684      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 2810        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.621       |
|    value_loss           | 1.5         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 283         |
|    time_elapsed         | 160977      |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.040793747 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | -1.54       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 2820        |
|    policy_gradient_loss | 0.0197      |
|    std                  | 0.623       |
|    value_loss           | 1.55        |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.57 +/- 0.05
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.07688016 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.0139     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.536      |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.622      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162985   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 285        |
|    time_elapsed         | 163191     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.06267362 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | -0.0252    |
|    learning_rate        | 0.0003     |
|    loss                 | 15.3       |
|    n_updates            | 2840       |
|    policy_gradient_loss | 0.00401    |
|    std                  | 0.623      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 286         |
|    time_elapsed         | 163397      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.070985004 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | -2.75       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.509       |
|    n_updates            | 2850        |
|    policy_gradient_loss | 0.017       |
|    std                  | 0.621       |
|    value_loss           | 2.59        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163603     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.06311107 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.43      |
|    explained_variance   | 0.00113    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.611      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.621      |
|    value_loss           | 1.17       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 163808     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.12721291 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.43      |
|    explained_variance   | 0.00111    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.568      |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.621      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.69 +/- 0.19
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.041266017 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.42       |
|    explained_variance   | 0.0103      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.506       |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.619       |
|    value_loss           | 1.23        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.25e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165816   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 166022      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.074603274 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.4        |
|    explained_variance   | 0.0013      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.71e+03    |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.00787     |
|    std                  | 0.62        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166227     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.10516579 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.0129     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13       |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.617      |
|    value_loss           | 1.64       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.27e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 292       |
|    time_elapsed         | 166433    |
|    total_timesteps      | 598016    |
| train/                  |           |
|    approx_kl            | 0.0576302 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.36     |
|    explained_variance   | 0.0293    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.531     |
|    n_updates            | 2910      |
|    policy_gradient_loss | 0.0185    |
|    std                  | 0.615     |
|    value_loss           | 1.42      |
---------------------------------------
Eval num_timesteps=600000, episode_reward=-99.33 +/- 0.38
Episode length: 3595.20 +/- 7.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.07922991 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.803      |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.00683    |
|    std                  | 0.616      |
|    value_loss           | 1.51       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.26e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168445   |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 294        |
|    time_elapsed         | 168652     |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.06473991 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | -0.00312   |
|    learning_rate        | 0.0003     |
|    loss                 | 41.1       |
|    n_updates            | 2930       |
|    policy_gradient_loss | 0.00379    |
|    std                  | 0.617      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 295         |
|    time_elapsed         | 168857      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.049849764 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.36       |
|    explained_variance   | -0.131      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.689       |
|    n_updates            | 2940        |
|    policy_gradient_loss | 0.0252      |
|    std                  | 0.615       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 296         |
|    time_elapsed         | 169063      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.051995456 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.0544      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.603       |
|    n_updates            | 2950        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.61        |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 297         |
|    time_elapsed         | 169268      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.054731898 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.038       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 2960        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.61        |
|    value_loss           | 1.36        |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.16 +/- 0.73
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.2      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.04029099 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.28      |
|    explained_variance   | -1.94      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.799      |
|    n_updates            | 2970       |
|    policy_gradient_loss | 0.00864    |
|    std                  | 0.609      |
|    value_loss           | 1.73       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171275   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 171481      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.058741033 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | -0.0011     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 2980        |
|    policy_gradient_loss | 0.00159     |
|    std                  | 0.611       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171686     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.06227284 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.31      |
|    explained_variance   | -0.0294    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.58       |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.612      |
|    value_loss           | 1.38       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 171894     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.05014729 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | 0.0784     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.613      |
|    value_loss           | 1.53       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 172099     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.07441015 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | 0.434      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5        |
|    n_updates            | 3010       |
|    policy_gradient_loss | -0.000408  |
|    std                  | 0.615      |
|    value_loss           | 2.67       |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.51 +/- 0.04
Episode length: 3598.60 +/- 4.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.045198143 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.924       |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.0025     |
|    std                  | 0.612       |
|    value_loss           | 2.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 174109   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 174315      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.035206098 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | -0.000412   |
|    learning_rate        | 0.0003      |
|    loss                 | 568         |
|    n_updates            | 3030        |
|    policy_gradient_loss | 0.00304     |
|    std                  | 0.612       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 305         |
|    time_elapsed         | 174521      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.053060345 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.3        |
|    explained_variance   | 0.278       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09        |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.0073     |
|    std                  | 0.612       |
|    value_loss           | 2.44        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 174726     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.06565842 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.26      |
|    explained_variance   | 0.158      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.598      |
|    n_updates            | 3050       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.607      |
|    value_loss           | 1.57       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 307         |
|    time_elapsed         | 174932      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.055463567 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.331       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.93        |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0044     |
|    std                  | 0.605       |
|    value_loss           | 2.27        |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.52 +/- 0.05
Episode length: 3600.00 +/- 2.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.06497747 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.0944     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.735      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.00767    |
|    std                  | 0.6        |
|    value_loss           | 1.53       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176940   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 177146     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.05541106 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.15      |
|    explained_variance   | -0.00165   |
|    learning_rate        | 0.0003     |
|    loss                 | 640        |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00799    |
|    std                  | 0.6        |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 177351     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.07301565 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | -0.255     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.585      |
|    n_updates            | 3090       |
|    policy_gradient_loss | 0.0062     |
|    std                  | 0.599      |
|    value_loss           | 1.25       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.31e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 311         |
|    time_elapsed         | 177557      |
|    total_timesteps      | 636928      |
| train/                  |             |
|    approx_kl            | 0.055453844 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.13       |
|    explained_variance   | 0.0402      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.585       |
|    n_updates            | 3100        |
|    policy_gradient_loss | 0.00692     |
|    std                  | 0.599       |
|    value_loss           | 1.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.31e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 177762      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.050965555 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | 0.0227      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.843       |
|    n_updates            | 3110        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.599       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.58 +/- 0.01
Episode length: 3595.60 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.052074723 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | 0.0266      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 3120        |
|    policy_gradient_loss | 0.0157      |
|    std                  | 0.601       |
|    value_loss           | 1.74        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179773   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 179980     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.07203238 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | -0.00407   |
|    learning_rate        | 0.0003     |
|    loss                 | 746        |
|    n_updates            | 3130       |
|    policy_gradient_loss | 0.00939    |
|    std                  | 0.601      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 315         |
|    time_elapsed         | 180185      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.050695285 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | -0.00115    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.691       |
|    n_updates            | 3140        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.601       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 180391      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.053730104 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | 0.221       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 3150        |
|    policy_gradient_loss | 0.00994     |
|    std                  | 0.602       |
|    value_loss           | 4.32        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 317         |
|    time_elapsed         | 180596      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.059473805 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | -0.00532    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.592       |
|    n_updates            | 3160        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.603       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.51 +/- 0.02
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.069208406 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | 0.0255      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.897       |
|    n_updates            | 3170        |
|    policy_gradient_loss | 0.0207      |
|    std                  | 0.601       |
|    value_loss           | 1.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182603   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 319        |
|    time_elapsed         | 182809     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.05963067 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | -0.00585   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08e+03   |
|    n_updates            | 3180       |
|    policy_gradient_loss | 0.00697    |
|    std                  | 0.602      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 320        |
|    time_elapsed         | 183015     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.05824292 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | -0.00189   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.686      |
|    n_updates            | 3190       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.603      |
|    value_loss           | 1.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 183220      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.058724813 |
|    clip_fraction        | 0.437       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 0.0137      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.741       |
|    n_updates            | 3200        |
|    policy_gradient_loss | 0.0183      |
|    std                  | 0.605       |
|    value_loss           | 1.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 322         |
|    time_elapsed         | 183426      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.044330545 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | -0.0061     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.655       |
|    n_updates            | 3210        |
|    policy_gradient_loss | 0.0251      |
|    std                  | 0.603       |
|    value_loss           | 1.26        |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.14 +/- 0.77
Episode length: 3595.80 +/- 10.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.04154458 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | 0.0386     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.508      |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.604      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185437   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 185645      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.029579176 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | -0.00131    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95e+03    |
|    n_updates            | 3230        |
|    policy_gradient_loss | 0.00784     |
|    std                  | 0.605       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 185850     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.07263395 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | -0.00503   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.946      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.603      |
|    value_loss           | 1.73       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 326         |
|    time_elapsed         | 186056      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.077778056 |
|    clip_fraction        | 0.48        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | -0.128      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 3250        |
|    policy_gradient_loss | 0.0202      |
|    std                  | 0.602       |
|    value_loss           | 3.61        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 186261     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.07756618 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | -0.0144    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.775      |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.0089     |
|    std                  | 0.601      |
|    value_loss           | 1.38       |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.60 +/- 0.06
Episode length: 3599.20 +/- 2.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.06787819 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | 0.011      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.726      |
|    n_updates            | 3270       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.602      |
|    value_loss           | 1.45       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188269   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 188475      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.066565536 |
|    clip_fraction        | 0.469       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.17       |
|    explained_variance   | -0.00408    |
|    learning_rate        | 0.0003      |
|    loss                 | 870         |
|    n_updates            | 3280        |
|    policy_gradient_loss | 0.00763     |
|    std                  | 0.603       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 330         |
|    time_elapsed         | 188681      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.072033145 |
|    clip_fraction        | 0.466       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | -8.91       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.803       |
|    n_updates            | 3290        |
|    policy_gradient_loss | 0.0195      |
|    std                  | 0.606       |
|    value_loss           | 2.58        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 331         |
|    time_elapsed         | 188887      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.047562756 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.19       |
|    explained_variance   | -0.00241    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.633       |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.601       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 332         |
|    time_elapsed         | 189092      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.046404917 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.17       |
|    explained_variance   | -0.00383    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.533       |
|    n_updates            | 3310        |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.601       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.53 +/- 0.06
Episode length: 3597.40 +/- 7.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 680000    |
| train/                  |           |
|    approx_kl            | 0.0814561 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.18     |
|    explained_variance   | 0.00172   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.483     |
|    n_updates            | 3320      |
|    policy_gradient_loss | 0.016     |
|    std                  | 0.603     |
|    value_loss           | 1.07      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 191102   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 191309     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.03894539 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -0.000188  |
|    learning_rate        | 0.0003     |
|    loss                 | 390        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.00664    |
|    std                  | 0.604      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 191516     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.09269291 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -7.54      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.712      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.603      |
|    value_loss           | 1.8        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 191722     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.04995408 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | 0.0145     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.668      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.6        |
|    value_loss           | 1.19       |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.55 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.06885874 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.833      |
|    n_updates            | 3360       |
|    policy_gradient_loss | 0.00606    |
|    std                  | 0.605      |
|    value_loss           | 1.89       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193729   |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 338        |
|    time_elapsed         | 193935     |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.05148891 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | -0.000326  |
|    learning_rate        | 0.0003     |
|    loss                 | 9.49       |
|    n_updates            | 3370       |
|    policy_gradient_loss | 0.00263    |
|    std                  | 0.607      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 194140     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.03236748 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | -0.0564    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.822      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.608      |
|    value_loss           | 1.42       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 194346     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.07604748 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | -0.0579    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.608      |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.607      |
|    value_loss           | 1.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 194551      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.040699136 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | 0.0259      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.547       |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.605       |
|    value_loss           | 1.32        |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.55 +/- 0.05
Episode length: 3595.20 +/- 7.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.08039421 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.0341     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.561      |
|    n_updates            | 3410       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.604      |
|    value_loss           | 1.43       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196562   |
|    total_timesteps | 700416   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 343        |
|    time_elapsed         | 196768     |
|    total_timesteps      | 702464     |
| train/                  |            |
|    approx_kl            | 0.06101436 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -0.0147    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.28e+03   |
|    n_updates            | 3420       |
|    policy_gradient_loss | 0.00177    |
|    std                  | 0.604      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 196974     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.06833347 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.22      |
|    explained_variance   | 0.00234    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15       |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.608      |
|    value_loss           | 1.7        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 345         |
|    time_elapsed         | 197179      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.049175356 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.0162      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.785       |
|    n_updates            | 3440        |
|    policy_gradient_loss | 0.0054      |
|    std                  | 0.61        |
|    value_loss           | 1.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 197385      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.062912986 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.24       |
|    explained_variance   | 0.0671      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.694       |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.0079      |
|    std                  | 0.607       |
|    value_loss           | 1.38        |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.64 +/- 0.10
Episode length: 3599.20 +/- 2.23
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.07032706 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | -0.275     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.00627    |
|    std                  | 0.604      |
|    value_loss           | 1.89       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199393   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 199599     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.05415239 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | -0.00181   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+03   |
|    n_updates            | 3470       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.607      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 349        |
|    time_elapsed         | 199804     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.07441681 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | -0.000314  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.646      |
|    n_updates            | 3480       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.606      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 350         |
|    time_elapsed         | 200010      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.049731076 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 0.759       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.763       |
|    n_updates            | 3490        |
|    policy_gradient_loss | 0.0189      |
|    std                  | 0.604       |
|    value_loss           | 1.5         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 351         |
|    time_elapsed         | 200216      |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.053295385 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | -0.0253     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.583       |
|    n_updates            | 3500        |
|    policy_gradient_loss | 0.00979     |
|    std                  | 0.606       |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.59 +/- 0.14
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.05310796 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.0186     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.667      |
|    n_updates            | 3510       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.605      |
|    value_loss           | 1.22       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202224   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 202430     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.05134832 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -0.000541  |
|    learning_rate        | 0.0003     |
|    loss                 | 5          |
|    n_updates            | 3520       |
|    policy_gradient_loss | 0.00584    |
|    std                  | 0.603      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 202635     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.08716233 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | -0.00526   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.532      |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.601      |
|    value_loss           | 1.21       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 355         |
|    time_elapsed         | 202841      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.066463366 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | -0.00961    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 3540        |
|    policy_gradient_loss | 0.00901     |
|    std                  | 0.597       |
|    value_loss           | 1.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 356         |
|    time_elapsed         | 203046      |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.046842225 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | 0.0164      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 3550        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.597       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.55 +/- 0.08
Episode length: 3595.00 +/- 12.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.07759474 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.08      |
|    explained_variance   | -0.00703   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.699      |
|    n_updates            | 3560       |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.594      |
|    value_loss           | 1.35       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 205057   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205264      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.057312146 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | -0.000842   |
|    learning_rate        | 0.0003      |
|    loss                 | 7.33        |
|    n_updates            | 3570        |
|    policy_gradient_loss | 0.01        |
|    std                  | 0.595       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.39e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 359        |
|    time_elapsed         | 205472     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.06190122 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | -0.229     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 3580       |
|    policy_gradient_loss | 0.0311     |
|    std                  | 0.593      |
|    value_loss           | 1.19       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 205677      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.062014055 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.03       |
|    explained_variance   | -0.0239     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.625       |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.589       |
|    value_loss           | 1.24        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 205883     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.06356896 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.99      |
|    explained_variance   | -1.07      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.598      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.586      |
|    value_loss           | 1.93       |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.66 +/- 0.10
Episode length: 3596.40 +/- 9.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.03859654 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.0273     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.697      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.584      |
|    value_loss           | 1.44       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207892   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 208100      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.057308547 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.94       |
|    explained_variance   | -0.000756   |
|    learning_rate        | 0.0003      |
|    loss                 | 61.3        |
|    n_updates            | 3620        |
|    policy_gradient_loss | 0.00568     |
|    std                  | 0.585       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 364         |
|    time_elapsed         | 208305      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.062401287 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | -0.0547     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.679       |
|    n_updates            | 3630        |
|    policy_gradient_loss | 0.0111      |
|    std                  | 0.581       |
|    value_loss           | 1.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 208511     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.06808707 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.9       |
|    explained_variance   | -5.25      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.767      |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.579      |
|    value_loss           | 3.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 208716      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.095475554 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.86       |
|    explained_variance   | -0.0329     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.825       |
|    n_updates            | 3650        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.577       |
|    value_loss           | 1.46        |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.50 +/- 0.01
Episode length: 3599.20 +/- 2.23
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.035235375 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.84       |
|    explained_variance   | 0.00545     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.483       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.0213      |
|    std                  | 0.576       |
|    value_loss           | 1.24        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210726   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 210932     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.08460556 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | -0.00112   |
|    learning_rate        | 0.0003     |
|    loss                 | 132        |
|    n_updates            | 3670       |
|    policy_gradient_loss | 0.000391   |
|    std                  | 0.576      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 369         |
|    time_elapsed         | 211140      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.049220584 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.82       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 3680        |
|    policy_gradient_loss | 0.00349     |
|    std                  | 0.574       |
|    value_loss           | 1.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 211347      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.050210755 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.0237      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 3690        |
|    policy_gradient_loss | 0.016       |
|    std                  | 0.576       |
|    value_loss           | 1.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 371         |
|    time_elapsed         | 211553      |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.072077416 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.0136      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.691       |
|    n_updates            | 3700        |
|    policy_gradient_loss | 0.0141      |
|    std                  | 0.576       |
|    value_loss           | 1.53        |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.53 +/- 0.04
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.051340416 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | 0.0149      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.72        |
|    n_updates            | 3710        |
|    policy_gradient_loss | 0.0185      |
|    std                  | 0.576       |
|    value_loss           | 1.64        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213560   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 213766      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.052683517 |
|    clip_fraction        | 0.47        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | -0.000733   |
|    learning_rate        | 0.0003      |
|    loss                 | 720         |
|    n_updates            | 3720        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.579       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 374         |
|    time_elapsed         | 213972      |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.082618125 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | -0.13       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 3730        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.578       |
|    value_loss           | 1.45        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 214177     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.05797585 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | -0.00225   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.679      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.578      |
|    value_loss           | 1.53       |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.33 +/- 0.29
Episode length: 3599.00 +/- 2.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.04316984 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | 0.0399     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.564      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.00978    |
|    std                  | 0.576      |
|    value_loss           | 1.28       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 216186   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216392      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.076187104 |
|    clip_fraction        | 0.462       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | -0.000226   |
|    learning_rate        | 0.0003      |
|    loss                 | 10.9        |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00157     |
|    std                  | 0.578       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 216597     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.06814921 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | 0.000843   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.715      |
|    n_updates            | 3770       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.578      |
|    value_loss           | 1.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 216804     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.09643227 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.0016     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.935      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.575      |
|    value_loss           | 1.82       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 217010     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.11706496 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.8       |
|    explained_variance   | 0.0088     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02       |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.576      |
|    value_loss           | 1.41       |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.51 +/- 0.03
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.057853512 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.8        |
|    explained_variance   | -0.496      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.429       |
|    n_updates            | 3800        |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.576       |
|    value_loss           | 1.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 219020   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 219227      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.033270016 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.8        |
|    explained_variance   | -0.000292   |
|    learning_rate        | 0.0003      |
|    loss                 | 374         |
|    n_updates            | 3810        |
|    policy_gradient_loss | 0.00239     |
|    std                  | 0.577       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 383         |
|    time_elapsed         | 219432      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.052054927 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.82       |
|    explained_variance   | 0.00703     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.543       |
|    n_updates            | 3820        |
|    policy_gradient_loss | 0.0221      |
|    std                  | 0.578       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 219638      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.059853204 |
|    clip_fraction        | 0.422       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | -1.37       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.791       |
|    n_updates            | 3830        |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.579       |
|    value_loss           | 1.81        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 219843     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.09666344 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.00516    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.744      |
|    n_updates            | 3840       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.578      |
|    value_loss           | 1.38       |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.55 +/- 0.03
Episode length: 3599.80 +/- 1.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.08537225 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.111      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.593      |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.575      |
|    value_loss           | 1.28       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221851   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 222057      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.062432766 |
|    clip_fraction        | 0.474       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | -1.22e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 56.1        |
|    n_updates            | 3860        |
|    policy_gradient_loss | 0.0082      |
|    std                  | 0.577       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 388         |
|    time_elapsed         | 222264      |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.098526806 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | -0.0243     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.797       |
|    n_updates            | 3870        |
|    policy_gradient_loss | 0.0279      |
|    std                  | 0.58        |
|    value_loss           | 1.12        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 222470     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.06751853 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | 0.0106     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.562      |
|    n_updates            | 3880       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.583      |
|    value_loss           | 1.44       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 222676     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.11493796 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | 0.0221     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.623      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.582      |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.55 +/- 0.04
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 800000     |
| train/                  |            |
|    approx_kl            | 0.07028742 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.85      |
|    explained_variance   | -0.0545    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.447      |
|    n_updates            | 3900       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.582      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224684   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.41e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 224892     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.09488857 |
|    clip_fraction        | 0.515      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.84      |
|    explained_variance   | -0.000543  |
|    learning_rate        | 0.0003     |
|    loss                 | 929        |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.581      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 393         |
|    time_elapsed         | 225098      |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.048642464 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | -0.0068     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.696       |
|    n_updates            | 3920        |
|    policy_gradient_loss | 0.0284      |
|    std                  | 0.579       |
|    value_loss           | 1.29        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.42e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 394       |
|    time_elapsed         | 225304    |
|    total_timesteps      | 806912    |
| train/                  |           |
|    approx_kl            | 0.0551636 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.78     |
|    explained_variance   | -0.391    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.597     |
|    n_updates            | 3930      |
|    policy_gradient_loss | 0.0276    |
|    std                  | 0.577     |
|    value_loss           | 1.41      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 395         |
|    time_elapsed         | 225509      |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.047573272 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.76       |
|    explained_variance   | 0.00926     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.524       |
|    n_updates            | 3940        |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.574       |
|    value_loss           | 1.32        |
-----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.76 +/- 0.19
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.06984678 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.75      |
|    explained_variance   | 0.00828    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.542      |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.576      |
|    value_loss           | 1.25       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227519   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 397         |
|    time_elapsed         | 227726      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.044316206 |
|    clip_fraction        | 0.443       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.79       |
|    explained_variance   | -6.94e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 968         |
|    n_updates            | 3960        |
|    policy_gradient_loss | 0.0057      |
|    std                  | 0.579       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 227932     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.04949694 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.000961   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.608      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.578      |
|    value_loss           | 1.31       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 399         |
|    time_elapsed         | 228137      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.047069233 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.8        |
|    explained_variance   | -1.59       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42        |
|    n_updates            | 3980        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.576       |
|    value_loss           | 2.13        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 400       |
|    time_elapsed         | 228343    |
|    total_timesteps      | 819200    |
| train/                  |           |
|    approx_kl            | 0.0536825 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.79     |
|    explained_variance   | -0.00696  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.66      |
|    n_updates            | 3990      |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.577     |
|    value_loss           | 1.25      |
---------------------------------------
Eval num_timesteps=820000, episode_reward=-98.88 +/- 1.56
Episode length: 3599.40 +/- 1.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.9      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.06464529 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.8       |
|    explained_variance   | 0.0101     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.678      |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.0182     |
|    std                  | 0.577      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230351   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 230557     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.11944607 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | -0.00902   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.84e+03   |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.00657    |
|    std                  | 0.575      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 230763     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.12775102 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.74      |
|    explained_variance   | -0.0103    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.769      |
|    n_updates            | 4020       |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.572      |
|    value_loss           | 1.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 404         |
|    time_elapsed         | 230968      |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.043430682 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.72       |
|    explained_variance   | 0.00765     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.54        |
|    n_updates            | 4030        |
|    policy_gradient_loss | 0.0166      |
|    std                  | 0.572       |
|    value_loss           | 1.24        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 231174     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.06342803 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | -0.296     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.935      |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.00918    |
|    std                  | 0.572      |
|    value_loss           | 1.9        |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.76 +/- 0.17
Episode length: 3596.00 +/- 7.13
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.04880491 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.00588    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.729      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.57       |
|    value_loss           | 1.46       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 233183   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.42e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233390     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.06977906 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | -0.000911  |
|    learning_rate        | 0.0003     |
|    loss                 | 99.5       |
|    n_updates            | 4060       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.572      |
|    value_loss           | 1.06e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 408       |
|    time_elapsed         | 233595    |
|    total_timesteps      | 835584    |
| train/                  |           |
|    approx_kl            | 0.0704045 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.73     |
|    explained_variance   | 0.00329   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.736     |
|    n_updates            | 4070      |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.573     |
|    value_loss           | 1.32      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 233801     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.07919151 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.73      |
|    explained_variance   | -0.032     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.712      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0456     |
|    std                  | 0.573      |
|    value_loss           | 1.55       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 234006     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.04823231 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.72      |
|    explained_variance   | -5.8       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.556      |
|    n_updates            | 4090       |
|    policy_gradient_loss | 0.00719    |
|    std                  | 0.572      |
|    value_loss           | 2.36       |
----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.54 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.07958711 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.69      |
|    explained_variance   | 0.000545   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.779      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.57       |
|    value_loss           | 1.54       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 236015   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 236222      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.045941778 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.67       |
|    explained_variance   | -9.51e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 34.2        |
|    n_updates            | 4110        |
|    policy_gradient_loss | 0.00102     |
|    std                  | 0.57        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.43e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 413       |
|    time_elapsed         | 236427    |
|    total_timesteps      | 845824    |
| train/                  |           |
|    approx_kl            | 0.0523936 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.67     |
|    explained_variance   | -0.0118   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.363     |
|    n_updates            | 4120      |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.571     |
|    value_loss           | 1.13      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 414        |
|    time_elapsed         | 236633     |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.05864588 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.65      |
|    explained_variance   | 0.00522    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.643      |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.566      |
|    value_loss           | 1.32       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 236839     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.05132453 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.62      |
|    explained_variance   | -0.114     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.412      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.565      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.64 +/- 0.18
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.053463727 |
|    clip_fraction        | 0.44        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.61       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.77        |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.026       |
|    std                  | 0.564       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238847   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 239054      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.051042747 |
|    clip_fraction        | 0.467       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.61       |
|    explained_variance   | -0.000827   |
|    learning_rate        | 0.0003      |
|    loss                 | 212         |
|    n_updates            | 4160        |
|    policy_gradient_loss | 0.00892     |
|    std                  | 0.567       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.44e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 239260    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 0.0578511 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.59     |
|    explained_variance   | 0.00178   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.682     |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.0258    |
|    std                  | 0.563     |
|    value_loss           | 1.22      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 239466     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.06503358 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | -0.000727  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.423      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.562      |
|    value_loss           | 0.975      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.64 +/- 0.16
Episode length: 3599.00 +/- 1.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.08071281 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | -0.585     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.552      |
|    n_updates            | 4190       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.564      |
|    value_loss           | 1.97       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241474   |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 421         |
|    time_elapsed         | 241680      |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.105230846 |
|    clip_fraction        | 0.452       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | 0.000119    |
|    learning_rate        | 0.0003      |
|    loss                 | 58.5        |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.000453   |
|    std                  | 0.563       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 241886     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.07798958 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.54      |
|    explained_variance   | -0.00534   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.619      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.0296     |
|    std                  | 0.561      |
|    value_loss           | 1.21       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 242091     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.08595963 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.49      |
|    explained_variance   | -0.481     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.929      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.558      |
|    value_loss           | 1.76       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 242297     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.08506926 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.48      |
|    explained_variance   | 0.0329     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.591      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.558      |
|    value_loss           | 1.39       |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.52 +/- 0.03
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.05005942 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.45      |
|    explained_variance   | 0.03       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.654      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.557      |
|    value_loss           | 1.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244304   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244510     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.06274498 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.44      |
|    explained_variance   | -0.00121   |
|    learning_rate        | 0.0003     |
|    loss                 | 20         |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.00257   |
|    std                  | 0.556      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 427         |
|    time_elapsed         | 244716      |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.062427714 |
|    clip_fraction        | 0.448       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.42       |
|    explained_variance   | -0.0451     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.635       |
|    n_updates            | 4260        |
|    policy_gradient_loss | 0.0356      |
|    std                  | 0.553       |
|    value_loss           | 1.3         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 244922     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.06592925 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.39      |
|    explained_variance   | 0.0422     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.637      |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.551      |
|    value_loss           | 1.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 245128     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.08715343 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.4       |
|    explained_variance   | 0.0145     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.668      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.553      |
|    value_loss           | 1.33       |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.54 +/- 0.02
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.059352066 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.39       |
|    explained_variance   | 0.0623      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.532       |
|    n_updates            | 4290        |
|    policy_gradient_loss | 0.0159      |
|    std                  | 0.549       |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 247136   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.44e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 247342     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.05322128 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.37      |
|    explained_variance   | -0.000265  |
|    learning_rate        | 0.0003     |
|    loss                 | 398        |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.548      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 432        |
|    time_elapsed         | 247547     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.07550961 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.39      |
|    explained_variance   | 0.000815   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.516      |
|    n_updates            | 4310       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.551      |
|    value_loss           | 1.18       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 247753      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.048572786 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.39       |
|    explained_variance   | -0.00689    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.675       |
|    n_updates            | 4320        |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.548       |
|    value_loss           | 1.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 434         |
|    time_elapsed         | 247959      |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.050131507 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.36       |
|    explained_variance   | 0.0017      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.617       |
|    n_updates            | 4330        |
|    policy_gradient_loss | 0.0198      |
|    std                  | 0.547       |
|    value_loss           | 1.29        |
-----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.55 +/- 0.02
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.044361785 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.0968      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.427       |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.547       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249967   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 250173      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.064817876 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.34       |
|    explained_variance   | -4.46e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 639         |
|    n_updates            | 4350        |
|    policy_gradient_loss | 0.011       |
|    std                  | 0.546       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 250378     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.07272147 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.34      |
|    explained_variance   | -0.0527    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.508      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.547      |
|    value_loss           | 1.14       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 438         |
|    time_elapsed         | 250584      |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.053939562 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.36       |
|    explained_variance   | 0.041       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.797       |
|    n_updates            | 4370        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.548       |
|    value_loss           | 1.42        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 250789     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.07413926 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.0314     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.518      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.549      |
|    value_loss           | 1.3        |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.55 +/- 0.02
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.06591998 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.00145    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.941      |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.548      |
|    value_loss           | 1.72       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.45e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252799   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 253005      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.061256446 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.37       |
|    explained_variance   | -0.000544   |
|    learning_rate        | 0.0003      |
|    loss                 | 18.8        |
|    n_updates            | 4400        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.551       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 442         |
|    time_elapsed         | 253211      |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.070131615 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.38       |
|    explained_variance   | -0.046      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.697       |
|    n_updates            | 4410        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.55        |
|    value_loss           | 1.41        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 253416     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.08267635 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.37      |
|    explained_variance   | -1.27      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.551      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.46e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 444       |
|    time_elapsed         | 253622    |
|    total_timesteps      | 909312    |
| train/                  |           |
|    approx_kl            | 0.0717464 |
|    clip_fraction        | 0.354     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.33     |
|    explained_variance   | 0.271     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.867     |
|    n_updates            | 4430      |
|    policy_gradient_loss | -0.000589 |
|    std                  | 0.546     |
|    value_loss           | 2.05      |
---------------------------------------
Eval num_timesteps=910000, episode_reward=-99.75 +/- 0.17
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.06728119 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.29      |
|    explained_variance   | 0.0298     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.704      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.546      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.45e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255630   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 255838      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.035989456 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.00135     |
|    learning_rate        | 0.0003      |
|    loss                 | 282         |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.545       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 256043     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.04965345 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 0.0327     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.399      |
|    n_updates            | 4460       |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.544      |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.46e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 448       |
|    time_elapsed         | 256250    |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 0.0739408 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.27     |
|    explained_variance   | -0.222    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.616     |
|    n_updates            | 4470      |
|    policy_gradient_loss | 0.0204    |
|    std                  | 0.548     |
|    value_loss           | 1.15      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 449         |
|    time_elapsed         | 256455      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.032241248 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.29       |
|    explained_variance   | -0.494      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.77        |
|    n_updates            | 4480        |
|    policy_gradient_loss | 0.0139      |
|    std                  | 0.548       |
|    value_loss           | 1.31        |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.72 +/- 0.19
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.05063592 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.0396     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.547      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.45e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258464   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 258669      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.058512032 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | -0.00636    |
|    learning_rate        | 0.0003      |
|    loss                 | 112         |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.000195   |
|    std                  | 0.547       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 258875      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.072226316 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.922       |
|    n_updates            | 4510        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.545       |
|    value_loss           | 1.84        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 453        |
|    time_elapsed         | 259081     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.06023798 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | -0.0509    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.938      |
|    n_updates            | 4520       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.547      |
|    value_loss           | 1.52       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 454         |
|    time_elapsed         | 259286      |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.056194577 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | -0.391      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.716       |
|    n_updates            | 4530        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.546       |
|    value_loss           | 1.28        |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.57 +/- 0.04
Episode length: 3596.20 +/- 7.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.20349672 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.22      |
|    explained_variance   | 0.0104     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.736      |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.543      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261293   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261500      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.048609965 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.22       |
|    explained_variance   | -0.00566    |
|    learning_rate        | 0.0003      |
|    loss                 | 955         |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.000222    |
|    std                  | 0.544       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 261705     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.13008864 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.24      |
|    explained_variance   | -0.826     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.594      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.546      |
|    value_loss           | 1.25       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 261911     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.14143747 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.25      |
|    explained_variance   | 0.0373     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.767      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.546      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.82 +/- 0.19
Episode length: 3599.80 +/- 1.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.04806106 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 0.313      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.548      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263920   |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 460         |
|    time_elapsed         | 264127      |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.104082674 |
|    clip_fraction        | 0.463       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.26       |
|    explained_variance   | -0.000528   |
|    learning_rate        | 0.0003      |
|    loss                 | 27.6        |
|    n_updates            | 4590        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.547       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.47e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 461       |
|    time_elapsed         | 264332    |
|    total_timesteps      | 944128    |
| train/                  |           |
|    approx_kl            | 0.0736255 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.24     |
|    explained_variance   | -0.0165   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.838     |
|    n_updates            | 4600      |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.545     |
|    value_loss           | 1.36      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.47e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264538     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.09883342 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.25      |
|    explained_variance   | -0.00318   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.655      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.546      |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 264743      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.043809034 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | 0.00526     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 4620        |
|    policy_gradient_loss | 0.0126      |
|    std                  | 0.547       |
|    value_loss           | 1.45        |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.59 +/- 0.03
Episode length: 3597.00 +/- 8.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.07096042 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 0.0192     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.632      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.546      |
|    value_loss           | 1.35       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266752   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 266958      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.082443275 |
|    clip_fraction        | 0.392       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.27       |
|    explained_variance   | -0.00301    |
|    learning_rate        | 0.0003      |
|    loss                 | 301         |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.00124    |
|    std                  | 0.549       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 267164     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.07393684 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.28      |
|    explained_variance   | 0.0118     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.595      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.548      |
|    value_loss           | 1.19       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 267369     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.05772934 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.27      |
|    explained_variance   | 0.024      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.00958    |
|    std                  | 0.549      |
|    value_loss           | 1.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 267576      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.122460224 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.0171      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.49        |
|    n_updates            | 4670        |
|    policy_gradient_loss | 0.0158      |
|    std                  | 0.547       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.74 +/- 0.19
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.043401066 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.0485      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.528       |
|    n_updates            | 4680        |
|    policy_gradient_loss | 0.0135      |
|    std                  | 0.547       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269583   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 269789      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.054209188 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.25       |
|    explained_variance   | 0.000353    |
|    learning_rate        | 0.0003      |
|    loss                 | 70.1        |
|    n_updates            | 4690        |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.548       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 269994      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.061549343 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.23       |
|    explained_variance   | 0.0969      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.694       |
|    n_updates            | 4700        |
|    policy_gradient_loss | 0.00848     |
|    std                  | 0.546       |
|    value_loss           | 1.89        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.48e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 270200     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.06457672 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.2       |
|    explained_variance   | -0.059     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.55       |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.00605    |
|    std                  | 0.544      |
|    value_loss           | 1.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 473         |
|    time_elapsed         | 270406      |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.029052071 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.15       |
|    explained_variance   | 0.00229     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.632       |
|    n_updates            | 4720        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.539       |
|    value_loss           | 1.23        |
-----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.51 +/- 0.03
Episode length: 3597.40 +/- 5.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.12583275 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.12      |
|    explained_variance   | 0.0133     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.548      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.00982    |
|    std                  | 0.538      |
|    value_loss           | 1.08       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272415   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 272622      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.081640415 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.13       |
|    explained_variance   | -0.000512   |
|    learning_rate        | 0.0003      |
|    loss                 | 134         |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.000131   |
|    std                  | 0.539       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.49e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 476        |
|    time_elapsed         | 272827     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.18818083 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.12      |
|    explained_variance   | -0.00996   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 4750       |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.537      |
|    value_loss           | 0.999      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.49e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 273033     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.08926847 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.1       |
|    explained_variance   | -1.6       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.345      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.537      |
|    value_loss           | 1.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 478         |
|    time_elapsed         | 273238      |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.037143286 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.1        |
|    explained_variance   | 0.00622     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.682       |
|    n_updates            | 4770        |
|    policy_gradient_loss | 0.0103      |
|    std                  | 0.536       |
|    value_loss           | 1.17        |
-----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.70 +/- 0.17
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.05691102 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.11      |
|    explained_variance   | 0.02       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.509      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.537      |
|    value_loss           | 0.941      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.48e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 275247   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275453      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.051710837 |
|    clip_fraction        | 0.412       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.12       |
|    explained_variance   | -0.000971   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 4790        |
|    policy_gradient_loss | 0.00791     |
|    std                  | 0.54        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 481         |
|    time_elapsed         | 275659      |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.061654933 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.16       |
|    explained_variance   | -0.00364    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.633       |
|    n_updates            | 4800        |
|    policy_gradient_loss | 0.0237      |
|    std                  | 0.54        |
|    value_loss           | 0.985       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 482         |
|    time_elapsed         | 275865      |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.053912476 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.13       |
|    explained_variance   | 0.001       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.694       |
|    n_updates            | 4810        |
|    policy_gradient_loss | 0.0136      |
|    std                  | 0.537       |
|    value_loss           | 1.15        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.49e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 483       |
|    time_elapsed         | 276071    |
|    total_timesteps      | 989184    |
| train/                  |           |
|    approx_kl            | 0.0592391 |
|    clip_fraction        | 0.371     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.07     |
|    explained_variance   | 0.0263    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.868     |
|    n_updates            | 4820      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.533     |
|    value_loss           | 1.3       |
---------------------------------------
Eval num_timesteps=990000, episode_reward=-99.77 +/- 0.18
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.053646907 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.01       |
|    explained_variance   | 0.0509      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.547       |
|    n_updates            | 4830        |
|    policy_gradient_loss | 0.0164      |
|    std                  | 0.529       |
|    value_loss           | 0.991       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.48e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 278079   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.48e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 278286      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.057173144 |
|    clip_fraction        | 0.403       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.97       |
|    explained_variance   | -0.000641   |
|    learning_rate        | 0.0003      |
|    loss                 | 25.2        |
|    n_updates            | 4840        |
|    policy_gradient_loss | 0.0009      |
|    std                  | 0.529       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.49e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 486       |
|    time_elapsed         | 278491    |
|    total_timesteps      | 995328    |
| train/                  |           |
|    approx_kl            | 0.3349047 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.96     |
|    explained_variance   | 0.0162    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.54      |
|    n_updates            | 4850      |
|    policy_gradient_loss | 0.0296    |
|    std                  | 0.528     |
|    value_loss           | 0.985     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.49e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 278697     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.05845156 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6         |
|    explained_variance   | 0.29       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.496      |
|    n_updates            | 4860       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.532      |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.49e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 278903     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.21090664 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | 0.107      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.816      |
|    n_updates            | 4870       |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.53       |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.76 +/- 0.19
Episode length: 3598.60 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.06837952 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.97      |
|    explained_variance   | 0.0161     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.641      |
|    n_updates            | 4880       |
|    policy_gradient_loss | 0.0329     |
|    std                  | 0.527      |
|    value_loss           | 1.27       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280912   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-21_05-48-34_llm_triton_qwen_3b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 5:59:15 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.905348  -99.872219  -99.917646  -99.924517  -99.942668]
 [ -99.989249  -99.947043 -100.03522  -100.042184  -99.995448]
 [ -99.865448  -99.803659  -99.866915  -99.945984  -99.797699]
 [ -99.884067  -99.902496  -99.92521   -99.812718  -99.852251]
 [ -99.818178  -99.886054  -99.850544  -99.787333  -99.903797]
 [ -99.817448  -99.93888   -99.843028  -99.79416   -99.822352]
 [ -99.922531  -99.839225  -99.811588  -99.837547  -99.784688]
 [ -99.797895  -99.749593  -99.942486  -99.90612   -99.749947]
 [ -99.788148  -99.757255  -99.815696  -99.864208  -99.682536]
 [ -99.816516  -99.827914  -99.934286  -99.777195  -99.779275]
 [ -99.855534  -99.824832  -99.770327  -99.909264  -99.81403 ]
 [ -99.903248  -99.910708  -99.921773  -99.849606  -99.876843]
 [ -99.83148   -99.883759  -99.887009  -99.877348  -99.844464]
 [ -99.700519  -99.770799  -99.818097  -99.872426  -99.738653]
 [ -99.725793  -99.818843  -99.813457  -99.650189  -99.806075]
 [ -99.724678  -99.745983  -99.822117  -99.816886  -99.709997]
 [ -99.7823    -99.897194  -99.885981  -99.816279  -99.734758]
 [ -99.762956  -99.753847  -99.792884  -99.77681   -99.795597]
 [ -99.698844  -99.723424  -99.805609  -99.774565  -99.87007 ]
 [ -99.799862  -99.80773   -99.812351  -99.790561  -99.738596]
 [ -99.73494   -99.639345  -99.8756    -99.710086  -99.726842]
 [ -99.57517   -99.539986  -99.493112  -99.604316  -99.544762]
 [ -99.489233  -99.625838  -99.687533  -99.555367  -99.706294]
 [ -99.582676  -99.50067   -99.613543  -99.667714  -99.58847 ]
 [ -99.642697  -99.5427    -99.571083  -99.621184  -99.490172]
 [ -99.506256  -99.601285  -99.534203  -99.560125  -99.498857]
 [ -99.57095   -99.664631  -99.599672  -99.658528  -99.62257 ]
 [ -99.514554  -99.565538  -99.419177  -99.534971  -99.586178]
 [ -99.578193  -99.57267   -99.557859  -99.572384  -99.533562]
 [ -99.520176  -99.598681  -99.58138   -99.593815  -99.575282]
 [ -99.602272  -99.605126  -99.550101  -99.644333  -99.589088]
 [ -99.609302  -99.681714  -99.64124   -99.613846  -99.64764 ]
 [ -99.657443  -99.610612  -99.62364   -99.62933   -99.51601 ]
 [ -99.661873  -99.586562  -99.570968  -99.542007  -99.531501]
 [ -99.645582  -99.623567  -99.620255  -99.573781  -99.642221]
 [ -99.600611  -99.528636  -99.544834  -99.523045  -99.481834]
 [ -99.82118   -99.581946  -99.889859  -99.546501  -99.524822]
 [ -99.482984  -99.508975  -99.54452   -99.557752  -99.544243]
 [ -99.564634  -99.497365  -99.572994  -99.493466  -99.584978]
 [ -99.567883  -99.581473  -99.598508  -99.559447  -99.555638]
 [ -99.457675  -99.496854  -99.533694  -99.543601  -99.582538]
 [ -99.412124  -99.502289  -99.567194  -99.415438  -99.45626 ]
 [ -99.575062  -99.482061  -99.495618  -99.448222  -99.572055]
 [ -99.563716  -99.539896  -99.581188  -99.604682  -99.512418]
 [ -97.666701  -98.764159  -97.64656   -99.671083  -99.624564]
 [ -99.591008  -99.646667  -99.521708  -98.690885  -99.670898]
 [ -99.626723  -99.558767  -99.648653  -99.544244  -99.592113]
 [ -99.522011  -99.485038  -99.589303  -99.54051   -99.546267]
 [ -99.615951  -99.504173  -99.540788  -99.558866  -99.59767 ]
 [ -99.606302  -99.56358   -99.549674  -99.444483  -99.544832]
 [ -99.582863  -99.583676  -99.605381  -99.610087  -99.585341]
 [ -99.531135  -99.878029  -99.525613  -99.597698  -99.595321]
 [ -99.967748  -99.488988  -99.439332  -99.551808  -99.581381]
 [ -99.594496  -99.625336  -99.501283  -99.50227   -99.528597]
 [ -99.589968  -99.561505  -99.96778   -99.876988  -99.543145]
 [ -99.557264  -99.537466  -99.543521  -99.535718  -99.548212]
 [ -99.604474  -99.53629   -99.53115   -99.485562  -99.570291]
 [ -99.523454  -99.615212  -99.501533  -99.581279  -99.620048]
 [ -99.501764  -99.90981   -99.585942  -99.539972  -99.929503]
 [ -99.57163   -99.452213  -99.590094  -98.582206  -99.455034]
 [ -99.557538  -97.711463  -99.525542  -99.516604  -99.50037 ]
 [ -99.510911  -99.501554  -99.579333  -99.464858  -99.50181 ]
 [ -99.462599  -99.585683  -99.547611  -99.467608  -99.523574]
 [ -99.581859  -99.570745  -99.595667  -99.561049  -99.596698]
 [ -99.511506  -99.505074  -99.508183  -99.547929  -99.486392]
 [ -99.516963  -99.481111  -97.598112  -99.545373  -99.562297]
 [ -99.597414  -99.574158  -99.579391  -99.705763  -99.536091]
 [ -99.480374  -99.448366  -99.586606  -99.526414  -99.592929]
 [ -99.53689   -99.577098  -99.519342  -99.529023  -99.563188]
 [ -99.518445  -99.485696  -99.612816  -99.536982  -99.603061]
 [ -99.813775  -99.678668  -99.570658  -99.599915  -99.528022]
 [ -99.863347  -99.513206  -99.488576  -99.51925   -99.56212 ]
 [ -99.648028  -99.494413  -99.497769  -99.476102  -99.642681]
 [ -99.577199  -99.582251  -99.640156  -99.852471  -99.641215]
 [ -99.503091  -99.485474  -99.517601  -99.502714  -99.512678]
 [ -99.587009  -99.565149  -99.474218  -99.518584  -99.508493]
 [ -98.747969  -99.541659  -99.423444  -99.491908  -99.429659]
 [ -99.541939  -99.505097  -99.551101  -99.457796  -99.504917]
 [ -99.571133  -99.497156  -99.585863  -99.541355  -99.556324]
 [ -99.53244   -99.51412   -99.61887   -99.521325  -99.546999]
 [ -99.547328  -99.875195  -99.514242  -99.96675   -99.904868]
 [ -99.964594  -99.485597  -95.769236  -99.541374  -99.614388]
 [ -99.885436  -99.866466  -99.935509  -99.540725  -99.559493]
 [ -99.606744  -99.512075  -99.562788  -99.506245  -99.504244]
 [ -99.553771  -99.564248  -99.590658  -99.508723  -99.988944]
 [ -99.567453  -99.556442  -99.593416  -99.962667  -99.531843]
 [ -99.516986  -99.497043  -99.496366  -99.569777  -99.531532]
 [ -99.523957  -99.506554  -99.559486  -99.54599   -99.570086]
 [ -99.574745  -99.570778  -99.506155  -99.550265  -99.545648]
 [ -99.535354  -99.539666  -99.550822  -99.527493  -99.583128]
 [ -99.846726  -99.851828  -99.582862  -99.520211  -99.939029]
 [ -99.98022   -99.586502  -99.525791  -99.933189  -99.592104]
 [ -99.507731  -99.627988  -99.56589   -99.618518  -99.549006]
 [ -99.985004  -99.561069  -99.943053  -99.994197  -99.610042]
 [ -99.592261  -99.572922  -99.548135  -99.633024  -99.612415]
 [ -99.988068  -99.93909   -99.642897  -99.581125  -99.527111]
 [ -99.558529  -99.494947  -99.493204  -99.50939   -99.486109]
 [ -99.586263  -99.917697  -99.57831   -99.894102  -99.507998]
 [ -99.891092  -99.88368   -99.50734   -99.950183  -99.604489]
 [ -99.887386  -99.478197  -99.594525  -99.903959  -99.957507]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3570 3601 3601 3601 3601]
 [3601 3601 3601 3595 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3586 3593 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3595 3601 3601]
 [3598 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3596 3601 3601 3601]
 [3584 3601 3601 3601 3595]
 [3601 3601 3601 3601 3601]
 [3579 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3577 3601 3601 3601 3601]
 [3601 3601 3601 3596 3601]
 [3581 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3582 3601 3596 3601 3601]
 [3597 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3594 3601 3601 3601 3601]
 [3592 3601 3601 3594 3601]
 [3601 3601 3601 3601 3601]
 [3592 3601 3601 3601 3601]
 [3601 3594 3601 3601 3601]
 [3580 3601 3601 3601 3599]
 [3601 3601 3601 3601 3601]
 [3595 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3592 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3593 3592 3601 3601 3601]
 [3601 3601 3601 3601 3595]
 [3585 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3584 3601 3594 3601 3601]
 [3595 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3598 3596 3601 3601 3601]
 [3585 3601 3601 3601 3592]
 [3597 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3597 3601 3592 3601 3601]
 [3582 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3572 3601 3601 3601 3601]
 [3599 3601 3601 3594 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3583 3601 3601 3590 3601]
 [3597 3601 3601 3601 3601]
 [3589 3601 3601 3601 3601]
 [3601 3596 3601 3601 3601]
 [3583 3601 3601 3601 3592]
 [3598 3601 3601 3601 3601]
 [3575 3601 3601 3601 3601]
 [3598 3601 3601 3595 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3582 3591 3601 3601 3601]
 [3597 3601 3601 3601 3596]
 [3601 3601 3601 3601 3601]
 [3571 3601 3601 3601 3601]
 [3601 3601 3601 3578 3601]
 [3596 3601 3601 3601 3597]
 [3601 3601 3601 3595 3601]
 [3597 3595 3601 3601 3601]
 [3601 3601 3601 3601 3583]
 [3601 3598 3598 3601 3601]
 [3584 3601 3601 3601 3598]
 [3601 3601 3601 3586 3601]
 [3597 3597 3601 3601 3601]
 [3582 3601 3598 3601 3598]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3599 3597 3601 3601]
 [3584 3601 3601 3601 3598]
 [3596 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3601 3601 3601 3599]
 [3599 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3582 3601 3596 3601 3601]
 [3596 3601 3601 3600 3601]
 [3581 3601 3601 3601 3601]
 [3593 3601 3601 3601 3601]
 [3586 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3593 3597 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-21_05-48-34_llm_triton_qwen_3b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-21_05-48-34_llm_triton_qwen_3b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
