####################
/var/spool/slurmd/job5407174/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_32B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_1_example_explanation.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-31_11-20-05_llm_triton_qwen_32b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 1
 
 Explanation (Do not generate this in your output): The particle started at (17.25, -160.50) and ended at (16.50, -159.75), while the goal was at (5.75, -57.00). The distance to the goal at starting position was 104.13 while the distance at ending position was 103.31. Since, 103.31 < 104.13, the particle moved closer to the goal the score should be positive. But the magnitude of reduction in distance isn't very high so the magnitude should be low. Therfore, a score of 1 seems appropriate.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 6    |
|    iterations      | 1    |
|    time_elapsed    | 300  |
|    total_timesteps | 2048 |
-----------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.5e+03   |
|    ep_rew_mean          | -382      |
| time/                   |           |
|    fps                  | 6         |
|    iterations           | 2         |
|    time_elapsed         | 594       |
|    total_timesteps      | 4096      |
| train/                  |           |
|    approx_kl            | 0.0097834 |
|    clip_fraction        | 0.116     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.4     |
|    explained_variance   | -0.076    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.49      |
|    n_updates            | 10        |
|    policy_gradient_loss | -0.0167   |
|    std                  | 1         |
|    value_loss           | 6.43      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -394       |
| time/                   |            |
|    fps                  | 6          |
|    iterations           | 3          |
|    time_elapsed         | 890        |
|    total_timesteps      | 6144       |
| train/                  |            |
|    approx_kl            | 0.01155884 |
|    clip_fraction        | 0.132      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.4      |
|    explained_variance   | -0.287     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05       |
|    n_updates            | 20         |
|    policy_gradient_loss | -0.0181    |
|    std                  | 1          |
|    value_loss           | 4.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -386        |
| time/                   |             |
|    fps                  | 6           |
|    iterations           | 4           |
|    time_elapsed         | 1183        |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.012506187 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.172       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0204     |
|    std                  | 1           |
|    value_loss           | 3.61        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-96.17 +/- 4.40
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.2       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.013376974 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0425      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.857       |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.993       |
|    value_loss           | 2.24        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -496     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 3276     |
|    total_timesteps | 10240    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -496       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 6          |
|    time_elapsed         | 3569       |
|    total_timesteps      | 12288      |
| train/                  |            |
|    approx_kl            | 0.00574369 |
|    clip_fraction        | 0.0654     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.00725    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.56       |
|    n_updates            | 50         |
|    policy_gradient_loss | -0.00576   |
|    std                  | 0.993      |
|    value_loss           | 1.03e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -475        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 7           |
|    time_elapsed         | 3862        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.011614358 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.369      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.47        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.992       |
|    value_loss           | 3.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -456        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 8           |
|    time_elapsed         | 4151        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.012869161 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.144       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0211     |
|    std                  | 0.991       |
|    value_loss           | 2.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -431        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 9           |
|    time_elapsed         | 4439        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.011225251 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.766       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0238     |
|    std                  | 0.985       |
|    value_loss           | 1.57        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.57 +/- 0.08
Episode length: 3601.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.6        |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0135057205 |
|    clip_fraction        | 0.157        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.305        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.536        |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.0236      |
|    std                  | 0.981        |
|    value_loss           | 1.43         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -469     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 6528     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -469         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 6816         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0030337505 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.000994     |
|    learning_rate        | 0.0003       |
|    loss                 | 7.41         |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00781     |
|    std                  | 0.98         |
|    value_loss           | 1.01e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -448       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 12         |
|    time_elapsed         | 7109       |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.01183701 |
|    clip_fraction        | 0.127      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | -0.93      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06       |
|    n_updates            | 110        |
|    policy_gradient_loss | -0.0219    |
|    std                  | 0.978      |
|    value_loss           | 3.11       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -430        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 7399        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.016189247 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.485       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0202     |
|    std                  | 0.975       |
|    value_loss           | 1.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -414        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 7686        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.016824327 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.517       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.972       |
|    value_loss           | 1.03        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.38 +/- 0.28
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.4      |
| time/                   |            |
|    total_timesteps      | 30000      |
| train/                  |            |
|    approx_kl            | 0.01584524 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.35       |
|    n_updates            | 140        |
|    policy_gradient_loss | -0.0222    |
|    std                  | 0.968      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -438     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 9774     |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.51e+03     |
|    ep_rew_mean          | -418         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 10060        |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0052722474 |
|    clip_fraction        | 0.0276       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -0.00468     |
|    learning_rate        | 0.0003       |
|    loss                 | 347          |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00532     |
|    std                  | 0.967        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -418        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 10347       |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.018076459 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.862      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.35        |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0253     |
|    std                  | 0.966       |
|    value_loss           | 1.56        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -405       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 18         |
|    time_elapsed         | 10633      |
|    total_timesteps      | 36864      |
| train/                  |            |
|    approx_kl            | 0.02111457 |
|    clip_fraction        | 0.251      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.322      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.559      |
|    n_updates            | 170        |
|    policy_gradient_loss | -0.021     |
|    std                  | 0.964      |
|    value_loss           | 1.07       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -389        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 19          |
|    time_elapsed         | 10923       |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.020232975 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.385       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.674       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.964       |
|    value_loss           | 1.24        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-94.33 +/- 1.81
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -94.3       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.020755468 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.503       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.96        |
|    value_loss           | 1.21        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -406     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 13009    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.51e+03     |
|    ep_rew_mean          | -391         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 13293        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0056313574 |
|    clip_fraction        | 0.0496       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.00585      |
|    learning_rate        | 0.0003       |
|    loss                 | 6.14         |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00552     |
|    std                  | 0.959        |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -391        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 13578       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.023550812 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.772      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0217     |
|    std                  | 0.957       |
|    value_loss           | 2.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -379        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 13863       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.023709523 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.544       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.713       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.951       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.52e+03    |
|    ep_rew_mean          | -368        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 24          |
|    time_elapsed         | 14147       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.029607119 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.431       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.392       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.951       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-95.75 +/- 1.41
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -95.7       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.033034444 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.514       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.362       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.948       |
|    value_loss           | 0.871       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -379     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 16232    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -367        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 16514       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.007227641 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00188    |
|    learning_rate        | 0.0003      |
|    loss                 | 351         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.000217   |
|    std                  | 0.948       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -356        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 16797       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.024942018 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.622      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.948       |
|    value_loss           | 1.54        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -356        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 17081       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.031363443 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.36        |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0201     |
|    std                  | 0.944       |
|    value_loss           | 1.09        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -345       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 29         |
|    time_elapsed         | 17363      |
|    total_timesteps      | 59392      |
| train/                  |            |
|    approx_kl            | 0.03268005 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.509      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.519      |
|    n_updates            | 280        |
|    policy_gradient_loss | -0.0218    |
|    std                  | 0.943      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.18 +/- 0.58
Episode length: 3596.20 +/- 8.18
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.2       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.027025258 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.49        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0244     |
|    std                  | 0.938       |
|    value_loss           | 1.15        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -355     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 19448    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -345        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 19729       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.009646405 |
|    clip_fraction        | 0.0803      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.00359     |
|    learning_rate        | 0.0003      |
|    loss                 | 449         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00763    |
|    std                  | 0.937       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -334       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 32         |
|    time_elapsed         | 20010      |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.02964811 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.052     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.626      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.929      |
|    value_loss           | 1.45       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -334        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 20289       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.037566185 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.519       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0236     |
|    std                  | 0.921       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -321        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 20569       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.030816097 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.49        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.54        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.918       |
|    value_loss           | 1.14        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.48 +/- 0.13
Episode length: 3596.60 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.030574143 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.506       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.915       |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -327     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 22653    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -314        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 22935       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.019790519 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00022     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+03    |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00481    |
|    std                  | 0.915       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -304        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 23215       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.030722002 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00142    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.345       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.911       |
|    value_loss           | 0.884       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -304        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 23493       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.025720498 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.594       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.907       |
|    value_loss           | 0.922       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -294        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 23771       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.024555713 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.506       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.537       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.904       |
|    value_loss           | 1.41        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-98.44 +/- 1.53
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.4       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.026803166 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.897       |
|    value_loss           | 1.25        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -300     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 25850    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -289        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 26130       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.010359702 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0038      |
|    learning_rate        | 0.0003      |
|    loss                 | 641         |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00397    |
|    std                  | 0.897       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -279        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 26410       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.028384585 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.309      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.39        |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.891       |
|    value_loss           | 1.25        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -269       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 43         |
|    time_elapsed         | 26687      |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.02575237 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.627      |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.886      |
|    value_loss           | 1.1        |
----------------------------------------
Eval num_timesteps=90000, episode_reward=-95.47 +/- 2.79
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -95.5     |
| time/                   |           |
|    total_timesteps      | 90000     |
| train/                  |           |
|    approx_kl            | 0.0350995 |
|    clip_fraction        | 0.33      |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.3     |
|    explained_variance   | 0.546     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.582     |
|    n_updates            | 430       |
|    policy_gradient_loss | -0.0207   |
|    std                  | 0.879     |
|    value_loss           | 1.09      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -273     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 28765    |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.5e+03      |
|    ep_rew_mean          | -273         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 45           |
|    time_elapsed         | 29043        |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0124580115 |
|    clip_fraction        | 0.136        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.3        |
|    explained_variance   | 0.00111      |
|    learning_rate        | 0.0003       |
|    loss                 | 1.73e+03     |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00578     |
|    std                  | 0.881        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -264        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 29320       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.028093353 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0979      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.736       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.879       |
|    value_loss           | 1.53        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -253        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 29595       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.037307363 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.43        |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.878       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -243        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 29872       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.023278786 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.876       |
|    value_loss           | 1.43        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-96.59 +/- 1.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -96.6      |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.03266894 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.444      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.686      |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.874      |
|    value_loss           | 1.68       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -247     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 31953    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -247        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 32230       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.014106108 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00131     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.87        |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00773    |
|    std                  | 0.873       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -238        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 32506       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.029542627 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.557       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.871       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -229        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 32783       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.027657669 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.494       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.653       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.866       |
|    value_loss           | 1.57        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -221        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 33058       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.033759154 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.528       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.411       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.859       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-53.05 +/- 7.71
Episode length: 3600.00 +/- 1.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -53         |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.025091901 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.567       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.716       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0189     |
|    std                  | 0.861       |
|    value_loss           | 1.28        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -225     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 35135    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -225        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 35410       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.010427302 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.00186     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.11        |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00821    |
|    std                  | 0.861       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -215        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 35686       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.030641545 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0509      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.853       |
|    value_loss           | 1.63        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -207       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 57         |
|    time_elapsed         | 35962      |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.03831787 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.519      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.822      |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.849      |
|    value_loss           | 1.44       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.51e+03  |
|    ep_rew_mean          | -199      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 58        |
|    time_elapsed         | 36236     |
|    total_timesteps      | 118784    |
| train/                  |           |
|    approx_kl            | 0.0328025 |
|    clip_fraction        | 0.292     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10       |
|    explained_variance   | 0.524     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.761     |
|    n_updates            | 570       |
|    policy_gradient_loss | -0.0135   |
|    std                  | 0.847     |
|    value_loss           | 1.35      |
---------------------------------------
Eval num_timesteps=120000, episode_reward=-77.07 +/- 7.47
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -77.1       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.029472757 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.661       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.847       |
|    value_loss           | 1.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -201     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 38312    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -194        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 38587       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.019579183 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.00349     |
|    learning_rate        | 0.0003      |
|    loss                 | 158         |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00781    |
|    std                  | 0.846       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -194        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 38862       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.031593613 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.275       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.847       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -185        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 39137       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.028082572 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.509       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.841       |
|    value_loss           | 1.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -177        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 39412       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.028879885 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.553       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.625       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.84        |
|    value_loss           | 1.35        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-47.90 +/- 2.89
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -47.9       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.027566638 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.746       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.836       |
|    value_loss           | 1.3         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -181     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 41487    |
|    total_timesteps | 131072   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -174       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 65         |
|    time_elapsed         | 41763      |
|    total_timesteps      | 133120     |
| train/                  |            |
|    approx_kl            | 0.02090783 |
|    clip_fraction        | 0.176      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | 0.00355    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.98e+03   |
|    n_updates            | 640        |
|    policy_gradient_loss | -0.00501   |
|    std                  | 0.836      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -174        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 42040       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.032551784 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.128      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.559       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.832       |
|    value_loss           | 1.18        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -167       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 67         |
|    time_elapsed         | 42314      |
|    total_timesteps      | 137216     |
| train/                  |            |
|    approx_kl            | 0.03469138 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.858      |
|    n_updates            | 660        |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.828      |
|    value_loss           | 1.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -158       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 68         |
|    time_elapsed         | 42589      |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.03173509 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.662      |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.826      |
|    value_loss           | 1.37       |
----------------------------------------
Eval num_timesteps=140000, episode_reward=-38.12 +/- 7.43
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -38.1       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.031720374 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.624       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.439       |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0229     |
|    std                  | 0.823       |
|    value_loss           | 1.05        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -162     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 44664    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -154        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 44937       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.008648565 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | -0.00403    |
|    learning_rate        | 0.0003      |
|    loss                 | 219         |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00247    |
|    std                  | 0.823       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -147       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 71         |
|    time_elapsed         | 45211      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.03140202 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | 0.161      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.387      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.821      |
|    value_loss           | 1.23       |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2.51e+03 |
|    ep_rew_mean          | -147     |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 72       |
|    time_elapsed         | 45485    |
|    total_timesteps      | 147456   |
| train/                  |          |
|    approx_kl            | 0.024462 |
|    clip_fraction        | 0.274    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.75    |
|    explained_variance   | 0.572    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.598    |
|    n_updates            | 710      |
|    policy_gradient_loss | -0.017   |
|    std                  | 0.82     |
|    value_loss           | 1.28     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -140        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 45761       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.038073435 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.818       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-9.04 +/- 7.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -9.04       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.027409336 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.619       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.816       |
|    value_loss           | 1.35        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -143     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 47837    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -136        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 48110       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.020098522 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.000722   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.54        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00581    |
|    std                  | 0.817       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -129       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 76         |
|    time_elapsed         | 48383      |
|    total_timesteps      | 155648     |
| train/                  |            |
|    approx_kl            | 0.03383936 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.73      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 750        |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.818      |
|    value_loss           | 1.15       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -129        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 48656       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.032800227 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.645       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.809       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -122        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 48929       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.032947443 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.64       |
|    explained_variance   | 0.558       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.539       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.809       |
|    value_loss           | 1.33        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-29.70 +/- 4.64
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -29.7       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.031806435 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.548       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.612       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.804       |
|    value_loss           | 1.39        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -125     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 51002    |
|    total_timesteps | 161792   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -118       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 80         |
|    time_elapsed         | 51274      |
|    total_timesteps      | 163840     |
| train/                  |            |
|    approx_kl            | 0.01526381 |
|    clip_fraction        | 0.123      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | -0.00359   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.41       |
|    n_updates            | 790        |
|    policy_gradient_loss | -0.00184   |
|    std                  | 0.803      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2.51e+03  |
|    ep_rew_mean          | -112      |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 81        |
|    time_elapsed         | 51548     |
|    total_timesteps      | 165888    |
| train/                  |           |
|    approx_kl            | 0.0458173 |
|    clip_fraction        | 0.336     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.59     |
|    explained_variance   | -0.144    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.494     |
|    n_updates            | 800       |
|    policy_gradient_loss | -0.0211   |
|    std                  | 0.804     |
|    value_loss           | 1.39      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -112        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 51820       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.035543226 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.46        |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00867    |
|    std                  | 0.799       |
|    value_loss           | 1.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -105        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 52093       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.036443926 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06        |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.795       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-25.50 +/- 11.80
Episode length: 3595.60 +/- 10.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -25.5       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.036329746 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.49       |
|    explained_variance   | 0.606       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.495       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.794       |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -108     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 54170    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -101        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 54444       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.038497657 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | -0.00085    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.32        |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00193    |
|    std                  | 0.79        |
|    value_loss           | 931         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -94.6       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 54718       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.044260077 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -0.184      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.522       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.788       |
|    value_loss           | 1.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -89.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 54991       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.035147138 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.822       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.785       |
|    value_loss           | 1.56        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-22.76 +/- 6.49
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -22.8      |
| time/                   |            |
|    total_timesteps      | 180000     |
| train/                  |            |
|    approx_kl            | 0.04140221 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.35      |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.646      |
|    n_updates            | 870        |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.779      |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -91.3    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 57064    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -91.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 57336       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.022883054 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.00165     |
|    learning_rate        | 0.0003      |
|    loss                 | 766         |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.000938    |
|    std                  | 0.779       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -85.1      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 90         |
|    time_elapsed         | 57612      |
|    total_timesteps      | 184320     |
| train/                  |            |
|    approx_kl            | 0.04513999 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.32       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.654      |
|    n_updates            | 890        |
|    policy_gradient_loss | -0.0142    |
|    std                  | 0.774      |
|    value_loss           | 1.51       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -78.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 57884       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.035092644 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.615       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.775       |
|    value_loss           | 1.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -72.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 58155       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.040187243 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.405       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.776       |
|    value_loss           | 1.35        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-3.77 +/- 6.76
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -3.77      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.04876317 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.25      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.435      |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.77       |
|    value_loss           | 0.983      |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -75.1    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 60231    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -75.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 60503       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.023821827 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | -0.00123    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+03    |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00411    |
|    std                  | 0.77        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -69.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 95         |
|    time_elapsed         | 60775      |
|    total_timesteps      | 194560     |
| train/                  |            |
|    approx_kl            | 0.04559777 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.22      |
|    explained_variance   | 0.249      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.507      |
|    n_updates            | 940        |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.769      |
|    value_loss           | 1.42       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -63.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 61047       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.039104246 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.662       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.392       |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.771       |
|    value_loss           | 0.974       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -58.2       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 61322       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.036621653 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.493       |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.00996    |
|    std                  | 0.771       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=47.19 +/- 13.22
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 47.2        |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.040647324 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | 0.611       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.585       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.765       |
|    value_loss           | 1.13        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -60.4    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 63395    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -54.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 63666       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.022213634 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.00393     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95e+03    |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00959    |
|    std                  | 0.764       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -54.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 63938       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.043006744 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.36        |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.762       |
|    value_loss           | 1.48        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -49.6      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 101        |
|    time_elapsed         | 64211      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.04234113 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.13      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.419      |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.761      |
|    value_loss           | 1.22       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -44.1       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 64483       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.044879925 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.6         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.599       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.759       |
|    value_loss           | 1.2         |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=37.18 +/- 8.48
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 37.2        |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.057079464 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.732       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.756       |
|    value_loss           | 1.16        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -46.2    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 66555    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -40.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 66826       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.030324923 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.000129    |
|    learning_rate        | 0.0003      |
|    loss                 | 360         |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.756       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -40.8      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 67097      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.05368134 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | 0.0744     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.537      |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.755      |
|    value_loss           | 1.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | -35.5      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 67368      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.03902052 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.05      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.653      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.753      |
|    value_loss           | 1.27       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -30.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 107         |
|    time_elapsed         | 67641       |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.031572733 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.488       |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.751       |
|    value_loss           | 1.35        |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=43.68 +/- 8.02
Episode length: 3597.60 +/- 6.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 43.7       |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.04201886 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.776      |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.00962   |
|    std                  | 0.749      |
|    value_loss           | 1.31       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -32.9    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 69713    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -28         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 69984       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.016895879 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | -0.000997   |
|    learning_rate        | 0.0003      |
|    loss                 | 301         |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00788    |
|    std                  | 0.749       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | -28        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 70259      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.04467776 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.99      |
|    explained_variance   | -0.0842    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.643      |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.0263    |
|    std                  | 0.749      |
|    value_loss           | 1.41       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -23         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 70530       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.043250505 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.92        |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.75        |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -18.3       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 70803       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.051720634 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | 0.645       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.653       |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.748       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=246.82 +/- 382.51
Episode length: 3084.80 +/- 1032.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.08e+03    |
|    mean_reward          | 247         |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.036460586 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | 0.56        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.803       |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.744       |
|    value_loss           | 1.48        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -19.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 72617    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -14.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 72889       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.038794912 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.00433     |
|    learning_rate        | 0.0003      |
|    loss                 | 441         |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00465    |
|    std                  | 0.744       |
|    value_loss           | 766         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -9.92       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 73164       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.053751327 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.869       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00638    |
|    std                  | 0.745       |
|    value_loss           | 1.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -9.92       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 73438       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.043667812 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.317       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.22        |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.743       |
|    value_loss           | 3.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | -5.18       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 73708       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.068606295 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.471       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00886    |
|    std                  | 0.745       |
|    value_loss           | 1.07        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=84.27 +/- 10.53
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 84.3       |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.04197605 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.699      |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.742      |
|    value_loss           | 1.46       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | -7.14    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 75779    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | -2.65       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 76050       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.018526522 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.00219     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.16        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00306    |
|    std                  | 0.742       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 2.08        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 76321       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.051319893 |
|    clip_fraction        | 0.434       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.408       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.74        |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 2.08        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 76592       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.052700624 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.544       |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.741       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 6.98        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 76865       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.046289317 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 0.599       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.584       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00665    |
|    std                  | 0.736       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=261.26 +/- 399.27
Episode length: 3489.00 +/- 222.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.49e+03   |
|    mean_reward          | 261        |
| time/                   |            |
|    total_timesteps      | 250000     |
| train/                  |            |
|    approx_kl            | 0.05207893 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.563      |
|    n_updates            | 1220       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.735      |
|    value_loss           | 1.29       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 5.07     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 78884    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 13.7        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 79155       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.028799608 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.000424    |
|    learning_rate        | 0.0003      |
|    loss                 | 18.8        |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00455    |
|    std                  | 0.735       |
|    value_loss           | 986         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 22.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 79426       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.058946516 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.85       |
|    explained_variance   | 0.135       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.794       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.736       |
|    value_loss           | 1.29        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 22.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 126        |
|    time_elapsed         | 79696      |
|    total_timesteps      | 258048     |
| train/                  |            |
|    approx_kl            | 0.05308269 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.85      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.522      |
|    n_updates            | 1250       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.734      |
|    value_loss           | 1.23       |
----------------------------------------
Eval num_timesteps=260000, episode_reward=866.07 +/- 363.27
Episode length: 1800.40 +/- 1332.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.8e+03    |
|    mean_reward          | 866        |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.04242339 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.67       |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.00819   |
|    std                  | 0.734      |
|    value_loss           | 1.62       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 39.4     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 80868    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 39.4        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 81139       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.031847868 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.82       |
|    explained_variance   | 0.00421     |
|    learning_rate        | 0.0003      |
|    loss                 | 156         |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00732    |
|    std                  | 0.733       |
|    value_loss           | 266         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 47.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 81409      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.04884389 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.82      |
|    explained_variance   | 0.359      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.623      |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.00371   |
|    std                  | 0.732      |
|    value_loss           | 1.29       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 56.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 81680       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.056853894 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.612       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.501       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.73        |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.51e+03    |
|    ep_rew_mean          | 63.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 81952       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.045751043 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00992    |
|    std                  | 0.728       |
|    value_loss           | 1.34        |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=1061.93 +/- 25.87
Episode length: 1355.20 +/- 779.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.36e+03   |
|    mean_reward          | 1.06e+03   |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.06495814 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.78      |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.442      |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.73       |
|    value_loss           | 1.18       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 72.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 82904    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 72.8        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 83175       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.027779276 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.0183      |
|    learning_rate        | 0.0003      |
|    loss                 | 217         |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.728       |
|    value_loss           | 148         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.5e+03     |
|    ep_rew_mean          | 80.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 134         |
|    time_elapsed         | 83447       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.061120413 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.646       |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00632    |
|    std                  | 0.725       |
|    value_loss           | 1.33        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.5e+03    |
|    ep_rew_mean          | 87.4       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 83718      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.06237406 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | 0.519      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.475      |
|    n_updates            | 1340       |
|    policy_gradient_loss | -0.00879   |
|    std                  | 0.721      |
|    value_loss           | 1.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.51e+03   |
|    ep_rew_mean          | 94.7       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 136        |
|    time_elapsed         | 83989      |
|    total_timesteps      | 278528     |
| train/                  |            |
|    approx_kl            | 0.04205226 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.505      |
|    n_updates            | 1350       |
|    policy_gradient_loss | -0.00923   |
|    std                  | 0.721      |
|    value_loss           | 1.49       |
----------------------------------------
Eval num_timesteps=280000, episode_reward=453.67 +/- 466.55
Episode length: 2425.00 +/- 1463.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.42e+03    |
|    mean_reward          | 454         |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.038024634 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.69       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.671       |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.72        |
|    value_loss           | 1.44        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.5e+03  |
|    ep_rew_mean     | 101      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 85472    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.49e+03    |
|    ep_rew_mean          | 116         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 85743       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.039183654 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.69       |
|    explained_variance   | 0.00479     |
|    learning_rate        | 0.0003      |
|    loss                 | 468         |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0048     |
|    std                  | 0.721       |
|    value_loss           | 470         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.49e+03   |
|    ep_rew_mean          | 123        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 139        |
|    time_elapsed         | 86015      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.02213511 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.68      |
|    explained_variance   | -0.0026    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.6e+03    |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.00881   |
|    std                  | 0.72       |
|    value_loss           | 4.1e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.49e+03   |
|    ep_rew_mean          | 123        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 140        |
|    time_elapsed         | 86286      |
|    total_timesteps      | 286720     |
| train/                  |            |
|    approx_kl            | 0.05998407 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | -1.76      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.887      |
|    n_updates            | 1390       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.722      |
|    value_loss           | 2.45       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.49e+03   |
|    ep_rew_mean          | 130        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 86559      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.04277519 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.67      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.449      |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.0131    |
|    std                  | 0.718      |
|    value_loss           | 1.56       |
----------------------------------------
Eval num_timesteps=290000, episode_reward=1063.19 +/- 14.78
Episode length: 2643.20 +/- 505.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.64e+03    |
|    mean_reward          | 1.06e+03    |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.053962387 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.567       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00945    |
|    std                  | 0.714       |
|    value_loss           | 1.26        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.47e+03 |
|    ep_rew_mean     | 139      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 88154    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 88426       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.024748608 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.000807    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+03    |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00466    |
|    std                  | 0.714       |
|    value_loss           | 570         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 146         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 88697       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.062700704 |
|    clip_fraction        | 0.397       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.557       |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.714       |
|    value_loss           | 1.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 153         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 88969       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.055791833 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.54        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.762       |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00653    |
|    std                  | 0.711       |
|    value_loss           | 1.53        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.48e+03   |
|    ep_rew_mean          | 163        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 89240      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.05929579 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.54      |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.351      |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.706      |
|    value_loss           | 0.966      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=656.02 +/- 460.95
Episode length: 2176.00 +/- 1539.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.18e+03    |
|    mean_reward          | 656         |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.046671923 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.49       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.654       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.702       |
|    value_loss           | 1.56        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.47e+03 |
|    ep_rew_mean     | 165      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 90605    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 172         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 90878       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.056056343 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | -0.000975   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.15        |
|    n_updates            | 1470        |
|    policy_gradient_loss | 0.00157     |
|    std                  | 0.701       |
|    value_loss           | 387         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.48e+03   |
|    ep_rew_mean          | 172        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 149        |
|    time_elapsed         | 91149      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.06436151 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.47      |
|    explained_variance   | -0.707     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.521      |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.703      |
|    value_loss           | 1.58       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.48e+03   |
|    ep_rew_mean          | 178        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 150        |
|    time_elapsed         | 91421      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.05096046 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.46      |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.378      |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.701      |
|    value_loss           | 1.29       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 189         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 91692       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.053934697 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | 0.526       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.717       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.697       |
|    value_loss           | 1.54        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=1038.34 +/- 17.30
Episode length: 1522.20 +/- 923.35
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.52e+03   |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 310000     |
| train/                  |            |
|    approx_kl            | 0.04845925 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.697      |
|    n_updates            | 1510       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.691      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.47e+03 |
|    ep_rew_mean     | 191      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 92724    |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.47e+03   |
|    ep_rew_mean          | 197        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 153        |
|    time_elapsed         | 92996      |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.09343286 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.36      |
|    explained_variance   | 0.00406    |
|    learning_rate        | 0.0003     |
|    loss                 | 93.8       |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.00214   |
|    std                  | 0.692      |
|    value_loss           | 186        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.47e+03    |
|    ep_rew_mean          | 197         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 93267       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.060341366 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.35       |
|    explained_variance   | 0.269       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.652       |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00805    |
|    std                  | 0.69        |
|    value_loss           | 1.54        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.48e+03   |
|    ep_rew_mean          | 202        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 155        |
|    time_elapsed         | 93537      |
|    total_timesteps      | 317440     |
| train/                  |            |
|    approx_kl            | 0.03744741 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.32      |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.791      |
|    n_updates            | 1540       |
|    policy_gradient_loss | -0.00825   |
|    std                  | 0.687      |
|    value_loss           | 1.34       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.48e+03   |
|    ep_rew_mean          | 212        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 93810      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.04318591 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.3       |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.479      |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.686      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=320000, episode_reward=650.45 +/- 453.19
Episode length: 2054.80 +/- 1293.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.05e+03   |
|    mean_reward          | 650        |
| time/                   |            |
|    total_timesteps      | 320000     |
| train/                  |            |
|    approx_kl            | 0.04549245 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.29      |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.502      |
|    n_updates            | 1560       |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.686      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.47e+03 |
|    ep_rew_mean     | 212      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 95112    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.47e+03    |
|    ep_rew_mean          | 217         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 95384       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.046864823 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.29       |
|    explained_variance   | 0.00571     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.24        |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00133    |
|    std                  | 0.687       |
|    value_loss           | 336         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 223         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 95655       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.048384495 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | 0.32        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.987       |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00561    |
|    std                  | 0.684       |
|    value_loss           | 1.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 223         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 95926       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.042234663 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | 0.539       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.539       |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.684       |
|    value_loss           | 1.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.48e+03    |
|    ep_rew_mean          | 233         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 96198       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.038718954 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.25       |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.549       |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.68        |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=121.44 +/- 13.54
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 121         |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.041718543 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | 0.556       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.678       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.47e+03 |
|    ep_rew_mean     | 231      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 98271    |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.47e+03    |
|    ep_rew_mean          | 235         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 163         |
|    time_elapsed         | 98542       |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.025974276 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.2        |
|    explained_variance   | 0.00104     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+03    |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00466    |
|    std                  | 0.677       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.45e+03    |
|    ep_rew_mean          | 263         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 98814       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.055604488 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.22       |
|    explained_variance   | 0.234       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.4         |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.68        |
|    value_loss           | 1.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.45e+03    |
|    ep_rew_mean          | 268         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 99086       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.018195312 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.23       |
|    explained_variance   | -0.00258    |
|    learning_rate        | 0.0003      |
|    loss                 | 80          |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.68        |
|    value_loss           | 8.12e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.45e+03   |
|    ep_rew_mean          | 268        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 99357      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.05947262 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.22      |
|    explained_variance   | -3.63      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13       |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.0242    |
|    std                  | 0.678      |
|    value_loss           | 5.75       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=301.50 +/- 357.61
Episode length: 2931.60 +/- 1338.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.93e+03   |
|    mean_reward          | 301        |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.05720098 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.18      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.749      |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.676      |
|    value_loss           | 1.76       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.45e+03 |
|    ep_rew_mean     | 267      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 101094   |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.45e+03    |
|    ep_rew_mean          | 271         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 101366      |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.054557074 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.17       |
|    explained_variance   | 0.00326     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00142    |
|    std                  | 0.675       |
|    value_loss           | 684         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.45e+03   |
|    ep_rew_mean          | 280        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 169        |
|    time_elapsed         | 101640     |
|    total_timesteps      | 346112     |
| train/                  |            |
|    approx_kl            | 0.08254196 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.14      |
|    explained_variance   | 0.298      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.918      |
|    n_updates            | 1680       |
|    policy_gradient_loss | -0.00737   |
|    std                  | 0.672      |
|    value_loss           | 1.81       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.45e+03    |
|    ep_rew_mean          | 284         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 101915      |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.044623893 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | 0.592       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.664       |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.0153     |
|    std                  | 0.671       |
|    value_loss           | 1.15        |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=713.79 +/- 478.94
Episode length: 2590.80 +/- 1061.62
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.59e+03    |
|    mean_reward          | 714         |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.049210634 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.561       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.556       |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.67        |
|    value_loss           | 1.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.45e+03 |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 103484   |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.44e+03    |
|    ep_rew_mean          | 296         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 103756      |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.036427684 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.09       |
|    explained_variance   | -0.000707   |
|    learning_rate        | 0.0003      |
|    loss                 | 273         |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00956    |
|    std                  | 0.669       |
|    value_loss           | 544         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.44e+03    |
|    ep_rew_mean          | 296         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 104028      |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.017054811 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.09       |
|    explained_variance   | 0.000989    |
|    learning_rate        | 0.0003      |
|    loss                 | 18.2        |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.0105     |
|    std                  | 0.669       |
|    value_loss           | 4.07e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.45e+03   |
|    ep_rew_mean          | 305        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 174        |
|    time_elapsed         | 104300     |
|    total_timesteps      | 356352     |
| train/                  |            |
|    approx_kl            | 0.07461918 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | -1.6       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.6        |
|    n_updates            | 1730       |
|    policy_gradient_loss | -0.0166    |
|    std                  | 0.667      |
|    value_loss           | 3.43       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.45e+03   |
|    ep_rew_mean          | 309        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 104572     |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.07382266 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.03      |
|    explained_variance   | 0.359      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.716      |
|    n_updates            | 1740       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.663      |
|    value_loss           | 2.04       |
----------------------------------------
Eval num_timesteps=360000, episode_reward=482.03 +/- 475.90
Episode length: 3010.40 +/- 970.94
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.01e+03   |
|    mean_reward          | 482        |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.06902285 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | 0.45       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.807      |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.661      |
|    value_loss           | 1.7        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.42e+03 |
|    ep_rew_mean     | 306      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 106351   |
|    total_timesteps | 360448   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.42e+03   |
|    ep_rew_mean          | 306        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 177        |
|    time_elapsed         | 106622     |
|    total_timesteps      | 362496     |
| train/                  |            |
|    approx_kl            | 0.05173187 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.00304    |
|    learning_rate        | 0.0003     |
|    loss                 | 70.3       |
|    n_updates            | 1760       |
|    policy_gradient_loss | 0.00261    |
|    std                  | 0.66       |
|    value_loss           | 734        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.43e+03    |
|    ep_rew_mean          | 316         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 106893      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.112393096 |
|    clip_fraction        | 0.449       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.98       |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.88        |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.0239     |
|    std                  | 0.661       |
|    value_loss           | 2.21        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.43e+03   |
|    ep_rew_mean          | 319        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 107164     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.05928371 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.477      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.903      |
|    n_updates            | 1780       |
|    policy_gradient_loss | -0.019     |
|    std                  | 0.662      |
|    value_loss           | 1.6        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.43e+03   |
|    ep_rew_mean          | 323        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 180        |
|    time_elapsed         | 107435     |
|    total_timesteps      | 368640     |
| train/                  |            |
|    approx_kl            | 0.04748979 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | 0.504      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.487      |
|    n_updates            | 1790       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 0.661      |
|    value_loss           | 1.44       |
----------------------------------------
Eval num_timesteps=370000, episode_reward=516.84 +/- 459.78
Episode length: 2886.80 +/- 883.14
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.89e+03   |
|    mean_reward          | 517        |
| time/                   |            |
|    total_timesteps      | 370000     |
| train/                  |            |
|    approx_kl            | 0.03521023 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8         |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.8        |
|    n_updates            | 1800       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.662      |
|    value_loss           | 1.44       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.4e+03  |
|    ep_rew_mean     | 334      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 109150   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.39e+03    |
|    ep_rew_mean          | 346         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 109425      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.019118786 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8          |
|    explained_variance   | -0.000429   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.22e+03    |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00765    |
|    std                  | 0.662       |
|    value_loss           | 4.76e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.39e+03    |
|    ep_rew_mean          | 359         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 109697      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.012006789 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8          |
|    explained_variance   | 0.000269    |
|    learning_rate        | 0.0003      |
|    loss                 | 11.2        |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.662       |
|    value_loss           | 4.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.39e+03   |
|    ep_rew_mean          | 362        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 109971     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.01371805 |
|    clip_fraction        | 0.165      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.99      |
|    explained_variance   | 0.00805    |
|    learning_rate        | 0.0003     |
|    loss                 | 11.5       |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.00787   |
|    std                  | 0.661      |
|    value_loss           | 4.02e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.39e+03   |
|    ep_rew_mean          | 362        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 185        |
|    time_elapsed         | 110242     |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.06203045 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.97      |
|    explained_variance   | -0.907     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.62       |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.0249    |
|    std                  | 0.658      |
|    value_loss           | 3.95       |
----------------------------------------
Eval num_timesteps=380000, episode_reward=885.17 +/- 373.18
Episode length: 2017.40 +/- 1214.71
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.02e+03    |
|    mean_reward          | 885         |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.057116874 |
|    clip_fraction        | 0.442       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.346       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.658       |
|    value_loss           | 2.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.37e+03 |
|    ep_rew_mean     | 367      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 111522   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.37e+03    |
|    ep_rew_mean          | 371         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 111792      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.031141989 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.00267     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.45        |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.658       |
|    value_loss           | 327         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.37e+03   |
|    ep_rew_mean          | 371        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 112064     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.06656635 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.122      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.85       |
|    n_updates            | 1870       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.655      |
|    value_loss           | 1.7        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.37e+03   |
|    ep_rew_mean          | 374        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 189        |
|    time_elapsed         | 112335     |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.05714947 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.495      |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.651      |
|    value_loss           | 1.7        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.38e+03   |
|    ep_rew_mean          | 384        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 112607     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.06268297 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.87      |
|    explained_variance   | 0.442      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.661      |
|    n_updates            | 1890       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.653      |
|    value_loss           | 1.55       |
----------------------------------------
Eval num_timesteps=390000, episode_reward=715.34 +/- 444.71
Episode length: 2415.00 +/- 1434.44
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 2.42e+03   |
|    mean_reward          | 715        |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.04357364 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.86      |
|    explained_variance   | 0.426      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.851      |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.0195    |
|    std                  | 0.649      |
|    value_loss           | 1.87       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.37e+03 |
|    ep_rew_mean     | 381      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 114086   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.37e+03    |
|    ep_rew_mean          | 384         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 114357      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.029043123 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.83       |
|    explained_variance   | 0.0108      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.17        |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.0103     |
|    std                  | 0.649       |
|    value_loss           | 470         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.37e+03    |
|    ep_rew_mean          | 384         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 114629      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.057891805 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.84       |
|    explained_variance   | 0.0856      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.649       |
|    value_loss           | 2.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.37e+03    |
|    ep_rew_mean          | 388         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 114901      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.043179028 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.84       |
|    explained_variance   | 0.425       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.883       |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.649       |
|    value_loss           | 1.7         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.38e+03   |
|    ep_rew_mean          | 397        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 195        |
|    time_elapsed         | 115178     |
|    total_timesteps      | 399360     |
| train/                  |            |
|    approx_kl            | 0.04740115 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.579      |
|    n_updates            | 1940       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.649      |
|    value_loss           | 1.69       |
----------------------------------------
Eval num_timesteps=400000, episode_reward=884.07 +/- 353.43
Episode length: 1477.60 +/- 1143.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.48e+03   |
|    mean_reward          | 884        |
| time/                   |            |
|    total_timesteps      | 400000     |
| train/                  |            |
|    approx_kl            | 0.05449327 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.82      |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17       |
|    n_updates            | 1950       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.647      |
|    value_loss           | 1.88       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.36e+03 |
|    ep_rew_mean     | 405      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 116191   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.36e+03    |
|    ep_rew_mean          | 405         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 116462      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.020093659 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | -9.62e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.83e+03    |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.0104     |
|    std                  | 0.647       |
|    value_loss           | 4.24e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.36e+03    |
|    ep_rew_mean          | 408         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 116734      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.047523092 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.76       |
|    explained_variance   | -0.909      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.656       |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.642       |
|    value_loss           | 2.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.36e+03    |
|    ep_rew_mean          | 417         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 199         |
|    time_elapsed         | 117005      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.051441193 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.71       |
|    explained_variance   | 0.407       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.94        |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.639       |
|    value_loss           | 2.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.36e+03   |
|    ep_rew_mean          | 420        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 117276     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.05754897 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.412      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09       |
|    n_updates            | 1990       |
|    policy_gradient_loss | -0.0186    |
|    std                  | 0.637      |
|    value_loss           | 1.99       |
----------------------------------------
Eval num_timesteps=410000, episode_reward=1057.17 +/- 23.32
Episode length: 965.60 +/- 526.21
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 966         |
|    mean_reward          | 1.06e+03    |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.043472007 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.64       |
|    explained_variance   | 0.42        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.764       |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.631       |
|    value_loss           | 1.92        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.35e+03 |
|    ep_rew_mean     | 417      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 118031   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.35e+03    |
|    ep_rew_mean          | 421         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 118303      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.034901388 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.0145      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.65        |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00955    |
|    std                  | 0.631       |
|    value_loss           | 79.7        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.35e+03   |
|    ep_rew_mean          | 440        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 118573     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.05398521 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 2020       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.627      |
|    value_loss           | 1.9        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.34e+03    |
|    ep_rew_mean          | 448         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 118845      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.023194069 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.54       |
|    explained_variance   | -0.00234    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.01e+03    |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.00847    |
|    std                  | 0.626       |
|    value_loss           | 4.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.33e+03    |
|    ep_rew_mean          | 461         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 119124      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.019892842 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.53       |
|    explained_variance   | 0.00212     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.52e+03    |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.625       |
|    value_loss           | 4.03e+03    |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=1077.86 +/- 45.70
Episode length: 973.60 +/- 548.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 974         |
|    mean_reward          | 1.08e+03    |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.030854572 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.53       |
|    explained_variance   | 0.00497     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.68e+03    |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.00684    |
|    std                  | 0.625       |
|    value_loss           | 4.01e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.3e+03  |
|    ep_rew_mean     | 531      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 119885   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.3e+03     |
|    ep_rew_mean          | 534         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 120158      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.020454964 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | -7.06e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.03e+05    |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.624       |
|    value_loss           | 1.41e+05    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.28e+03   |
|    ep_rew_mean          | 542        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 120429     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.06583621 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.5       |
|    explained_variance   | -4.6       |
|    learning_rate        | 0.0003     |
|    loss                 | 3.36       |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.619      |
|    value_loss           | 27.5       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.25e+03   |
|    ep_rew_mean          | 565        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 120700     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.03131319 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.00181    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.38e+03   |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.00912   |
|    std                  | 0.618      |
|    value_loss           | 3.92e+03   |
----------------------------------------
Eval num_timesteps=430000, episode_reward=1054.28 +/- 26.22
Episode length: 673.00 +/- 386.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 673         |
|    mean_reward          | 1.05e+03    |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.014939925 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.00594     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.77e+03    |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.617       |
|    value_loss           | 7.74e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.17e+03 |
|    ep_rew_mean     | 590      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 121308   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.16e+03    |
|    ep_rew_mean          | 599         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 121578      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.017124562 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.42       |
|    explained_variance   | 0.00843     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.617       |
|    value_loss           | 1.15e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.06e+03    |
|    ep_rew_mean          | 643         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121849      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.029741306 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.41       |
|    explained_variance   | -0.000185   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.66e+03    |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.614       |
|    value_loss           | 3.83e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | 662         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 122119      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.021082278 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.38       |
|    explained_variance   | 0.0043      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+04    |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.613       |
|    value_loss           | 1.85e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.02e+03   |
|    ep_rew_mean          | 664        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 122388     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.02358218 |
|    clip_fraction        | 0.238      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.00141    |
|    learning_rate        | 0.0003     |
|    loss                 | 2e+03      |
|    n_updates            | 2130       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.612      |
|    value_loss           | 7.4e+03    |
----------------------------------------
Eval num_timesteps=440000, episode_reward=1046.74 +/- 40.30
Episode length: 529.80 +/- 429.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 530        |
|    mean_reward          | 1.05e+03   |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.12508059 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | -1.06      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.18       |
|    n_updates            | 2140       |
|    policy_gradient_loss | 0.00479    |
|    std                  | 0.611      |
|    value_loss           | 12.1       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 677      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 122925   |
|    total_timesteps | 440320   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.94e+03   |
|    ep_rew_mean          | 698        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 216        |
|    time_elapsed         | 123199     |
|    total_timesteps      | 442368     |
| train/                  |            |
|    approx_kl            | 0.04759766 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | 0.00451    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83e+03   |
|    n_updates            | 2150       |
|    policy_gradient_loss | -0.00405   |
|    std                  | 0.609      |
|    value_loss           | 3.82e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.93e+03    |
|    ep_rew_mean          | 715         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 217         |
|    time_elapsed         | 123470      |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.013028662 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.00571     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.39e+03    |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.609       |
|    value_loss           | 1.11e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.93e+03   |
|    ep_rew_mean          | 724        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 123740     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.06261152 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | -0.00162   |
|    learning_rate        | 0.0003     |
|    loss                 | 995        |
|    n_updates            | 2170       |
|    policy_gradient_loss | -0.00813   |
|    std                  | 0.608      |
|    value_loss           | 3.74e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.87e+03    |
|    ep_rew_mean          | 750         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124011      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.040606465 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.00957     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.84e+03    |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.00868    |
|    std                  | 0.608       |
|    value_loss           | 3.77e+03    |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=1034.75 +/- 20.10
Episode length: 360.20 +/- 267.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 360         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.021599185 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.00961     |
|    learning_rate        | 0.0003      |
|    loss                 | 101         |
|    n_updates            | 2190        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.608       |
|    value_loss           | 7.87e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.82e+03 |
|    ep_rew_mean     | 772      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 124463   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.77e+03    |
|    ep_rew_mean          | 788         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 124735      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.012682943 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.3        |
|    explained_variance   | 0.0142      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.42e+03    |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.607       |
|    value_loss           | 1.1e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.76e+03    |
|    ep_rew_mean          | 796         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 125007      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.031145561 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.29       |
|    explained_variance   | 0.0058      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.48e+03    |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.607       |
|    value_loss           | 7.3e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.67e+03   |
|    ep_rew_mean          | 826        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 125277     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.05304206 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.28      |
|    explained_variance   | 0.00282    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.78e+03   |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.606      |
|    value_loss           | 3.71e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.58e+03    |
|    ep_rew_mean          | 869         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 125550      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.019097207 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | 0.0177      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.22e+03    |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.606       |
|    value_loss           | 1.79e+04    |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=1025.08 +/- 13.06
Episode length: 320.20 +/- 229.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 320        |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.02324111 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.27      |
|    explained_variance   | 0.00734    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.34e+04   |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.605      |
|    value_loss           | 1.75e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.49e+03 |
|    ep_rew_mean     | 896      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 125982   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.43e+03    |
|    ep_rew_mean          | 917         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 126254      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.024886366 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.00976     |
|    learning_rate        | 0.0003      |
|    loss                 | 133         |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.603       |
|    value_loss           | 1.4e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.31e+03    |
|    ep_rew_mean          | 951         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 126528      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.029202078 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | 0.011       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.96e+03    |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.602       |
|    value_loss           | 1.04e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.29e+03    |
|    ep_rew_mean          | 959         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 126799      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.016850766 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.00845     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.4e+04     |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.0219     |
|    std                  | 0.601       |
|    value_loss           | 2.04e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.21e+03    |
|    ep_rew_mean          | 988         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 127073      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.026900837 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | 0.00478     |
|    learning_rate        | 0.0003      |
|    loss                 | 54.3        |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.00906    |
|    std                  | 0.599       |
|    value_loss           | 6.9e+03     |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=1017.95 +/- 9.06
Episode length: 148.00 +/- 97.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 148         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.036857575 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.17       |
|    explained_variance   | 0.0159      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.09e+03    |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.597       |
|    value_loss           | 1.36e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.16e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 127419   |
|    total_timesteps | 471040   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.13e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 231        |
|    time_elapsed         | 127689     |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.03518246 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.15      |
|    explained_variance   | 0.0105     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.26e+03   |
|    n_updates            | 2300       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.596      |
|    value_loss           | 1.02e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.01e+03   |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 127962     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.03039315 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 0.0142     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.63e+03   |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.593      |
|    value_loss           | 1.02e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 886        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 128234     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.02354791 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | 0.0171     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.69e+04   |
|    n_updates            | 2320       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.591      |
|    value_loss           | 2.02e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 755         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 234         |
|    time_elapsed         | 128507      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.043422107 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.02       |
|    explained_variance   | 0.0106      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.55e+03    |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.584       |
|    value_loss           | 1.94e+04    |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=1025.57 +/- 15.11
Episode length: 222.00 +/- 161.92
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 222        |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.07226995 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.011      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.44e+04   |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.583      |
|    value_loss           | 2.22e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 650      |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 128890   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 650         |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 129161      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.022431199 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.96       |
|    explained_variance   | 0.00806     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.02e+03    |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.582       |
|    value_loss           | 1.62e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 621       |
|    ep_rew_mean          | 1.1e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 237       |
|    time_elapsed         | 129438    |
|    total_timesteps      | 485376    |
| train/                  |           |
|    approx_kl            | 0.3757981 |
|    clip_fraction        | 0.529     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.95     |
|    explained_variance   | -3.24     |
|    learning_rate        | 0.0003    |
|    loss                 | 3.71      |
|    n_updates            | 2360      |
|    policy_gradient_loss | 0.0377    |
|    std                  | 0.584     |
|    value_loss           | 84.8      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 592        |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 238        |
|    time_elapsed         | 129710     |
|    total_timesteps      | 487424     |
| train/                  |            |
|    approx_kl            | 0.06456669 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | 0.0133     |
|    learning_rate        | 0.0003     |
|    loss                 | 252        |
|    n_updates            | 2370       |
|    policy_gradient_loss | 0.001      |
|    std                  | 0.585      |
|    value_loss           | 1.31e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 574         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 239         |
|    time_elapsed         | 129982      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.015656391 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.98       |
|    explained_variance   | 0.0198      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.64e+03    |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.584       |
|    value_loss           | 1.61e+04    |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=1019.71 +/- 11.48
Episode length: 135.80 +/- 87.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 136         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.020302137 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.0206      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8e+03     |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.584       |
|    value_loss           | 1.18e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 561      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 130323   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 553        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 130595     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.01948607 |
|    clip_fraction        | 0.175      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.0194     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.28e+04   |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.582      |
|    value_loss           | 2.17e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 521        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 130870     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.07483657 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.94      |
|    explained_variance   | -0.00096   |
|    learning_rate        | 0.0003     |
|    loss                 | 570        |
|    n_updates            | 2410       |
|    policy_gradient_loss | -0.00817   |
|    std                  | 0.582      |
|    value_loss           | 3.32e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 506         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 131142      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.016920747 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.94       |
|    explained_variance   | 0.0322      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.83e+03    |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.581       |
|    value_loss           | 1.89e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 497        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 131415     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.07692825 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.93      |
|    explained_variance   | 0.0178     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.75e+03   |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.58       |
|    value_loss           | 6.46e+03   |
----------------------------------------
Eval num_timesteps=500000, episode_reward=1031.11 +/- 31.13
Episode length: 317.80 +/- 380.64
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 318         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.021078559 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.91       |
|    explained_variance   | 0.0288      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24e+04    |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.579       |
|    value_loss           | 1.57e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 452      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 131847   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 449         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 132120      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.025037277 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | 0.0327      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.02e+04    |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.577       |
|    value_loss           | 2.43e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 463        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 132393     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.03173317 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | 0.0209     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.58e+03   |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.576      |
|    value_loss           | 1.81e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 451         |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 132664      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.026072469 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.85       |
|    explained_variance   | 0.0143      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+04    |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.575       |
|    value_loss           | 1.21e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 451        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 249        |
|    time_elapsed         | 132937     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.17253226 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.82      |
|    explained_variance   | 0.00385    |
|    learning_rate        | 0.0003     |
|    loss                 | 62.8       |
|    n_updates            | 2480       |
|    policy_gradient_loss | 0.00532    |
|    std                  | 0.572      |
|    value_loss           | 3.21e+03   |
----------------------------------------
Eval num_timesteps=510000, episode_reward=1025.93 +/- 12.81
Episode length: 324.20 +/- 241.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 324         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.024501476 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.79       |
|    explained_variance   | 0.0408      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+04    |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.569       |
|    value_loss           | 2.38e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 417      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 133374   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 407         |
|    ep_rew_mean          | 1.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 133648      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.024891045 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | 0.0296      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.16e+04    |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.571       |
|    value_loss           | 2.61e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 417        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 252        |
|    time_elapsed         | 133919     |
|    total_timesteps      | 516096     |
| train/                  |            |
|    approx_kl            | 0.09596935 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.0165     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04e+04   |
|    n_updates            | 2510       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.569      |
|    value_loss           | 1.45e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 416        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 253        |
|    time_elapsed         | 134191     |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.03701528 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.74      |
|    explained_variance   | 0.0189     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.22e+03   |
|    n_updates            | 2520       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.567      |
|    value_loss           | 1.18e+04   |
----------------------------------------
Eval num_timesteps=520000, episode_reward=1029.83 +/- 22.81
Episode length: 321.00 +/- 281.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 321         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.024709538 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.035       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33e+04    |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.0193     |
|    std                  | 0.565       |
|    value_loss           | 2e+04       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 409      |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 134623   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 388         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 134897      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.033820353 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.68       |
|    explained_variance   | 0.0266      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8e+03     |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.563       |
|    value_loss           | 1.98e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 366         |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 256         |
|    time_elapsed         | 135170      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.031619668 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.65       |
|    explained_variance   | 0.0339      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04e+04    |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.561       |
|    value_loss           | 2.22e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 376         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 135443      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.029778384 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.63       |
|    explained_variance   | 0.0246      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+04    |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.561       |
|    value_loss           | 2.19e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 374         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 258         |
|    time_elapsed         | 135714      |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.030432109 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.62       |
|    explained_variance   | -0.00662    |
|    learning_rate        | 0.0003      |
|    loss                 | 368         |
|    n_updates            | 2570        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.56        |
|    value_loss           | 8.55e+03    |
-----------------------------------------
Eval num_timesteps=530000, episode_reward=1016.44 +/- 9.10
Episode length: 151.80 +/- 157.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 152         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.028293937 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.61       |
|    explained_variance   | 0.0438      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.25e+03    |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.559       |
|    value_loss           | 1.66e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 358      |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 136063   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 330         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 136337      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.029158693 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.6        |
|    explained_variance   | 0.0371      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.52e+03    |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.558       |
|    value_loss           | 1.4e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 329        |
|    ep_rew_mean          | 1.08e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 136609     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.02803611 |
|    clip_fraction        | 0.219      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | 0.0499     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.52e+04   |
|    n_updates            | 2600       |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.556      |
|    value_loss           | 2.68e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 338        |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 262        |
|    time_elapsed         | 136880     |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.04057055 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.0349     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.58e+04   |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.552      |
|    value_loss           | 2.16e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 297         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 137155      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.036501717 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.49       |
|    explained_variance   | 0.0169      |
|    learning_rate        | 0.0003      |
|    loss                 | 840         |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.00981    |
|    std                  | 0.55        |
|    value_loss           | 1.09e+04    |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=1018.43 +/- 8.51
Episode length: 255.20 +/- 140.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 255        |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.04423269 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.48      |
|    explained_variance   | 0.0392     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47e+04   |
|    n_updates            | 2630       |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.55       |
|    value_loss           | 2.84e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 294      |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 137558   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 296         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 137830      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.057025217 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.46       |
|    explained_variance   | 0.0279      |
|    learning_rate        | 0.0003      |
|    loss                 | 5.28e+03    |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.547       |
|    value_loss           | 2.29e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 263        |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 138103     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.05598763 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.42      |
|    explained_variance   | 0.0211     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.06e+03   |
|    n_updates            | 2650       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.545      |
|    value_loss           | 1.54e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 259        |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 138377     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.05697385 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.39      |
|    explained_variance   | 0.0442     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.82e+04   |
|    n_updates            | 2660       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.542      |
|    value_loss           | 3.62e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 248         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 138652      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.035243608 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.37       |
|    explained_variance   | 0.0164      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+04    |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.543       |
|    value_loss           | 2.18e+04    |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=1018.28 +/- 7.48
Episode length: 122.20 +/- 110.16
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 122        |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.04300031 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.37      |
|    explained_variance   | 0.0207     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.55e+04   |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.0158    |
|    std                  | 0.542      |
|    value_loss           | 2.18e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 252      |
|    ep_rew_mean     | 1.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 138984   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 243         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 139257      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.053521335 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.0269      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.49e+04    |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.541       |
|    value_loss           | 1.49e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 241         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 271         |
|    time_elapsed         | 139530      |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.041095026 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.33       |
|    explained_variance   | 0.0311      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.03e+03    |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.0157     |
|    std                  | 0.54        |
|    value_loss           | 1.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 240         |
|    ep_rew_mean          | 1.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 139805      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.025562875 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.32       |
|    explained_variance   | 0.0447      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.43e+03    |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.539       |
|    value_loss           | 1.94e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 222         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 273         |
|    time_elapsed         | 140078      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.022596506 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.3        |
|    explained_variance   | 0.0528      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.27e+04    |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.537       |
|    value_loss           | 2.84e+04    |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=1023.63 +/- 10.12
Episode length: 239.60 +/- 159.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 240         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.036927857 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | 0.0317      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.41e+04    |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.536       |
|    value_loss           | 2.56e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 218      |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 140472   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 216        |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 275        |
|    time_elapsed         | 140746     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.04528644 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.26      |
|    explained_variance   | 0.0335     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.37e+04   |
|    n_updates            | 2740       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.535      |
|    value_loss           | 2.72e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 212         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 276         |
|    time_elapsed         | 141022      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.057585143 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.23       |
|    explained_variance   | 0.026       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.81e+03    |
|    n_updates            | 2750        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.533       |
|    value_loss           | 2.07e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 217         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 277         |
|    time_elapsed         | 141299      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.034203347 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.21       |
|    explained_variance   | 0.0331      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.17e+04    |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.532       |
|    value_loss           | 3.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 220         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 278         |
|    time_elapsed         | 141575      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.028817615 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.19       |
|    explained_variance   | 0.0171      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.51e+03    |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.53        |
|    value_loss           | 1.81e+04    |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=1022.40 +/- 16.52
Episode length: 131.80 +/- 110.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 132         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.047794543 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.15       |
|    explained_variance   | 0.0351      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.88e+03    |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.527       |
|    value_loss           | 1.38e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 204      |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 279      |
|    time_elapsed    | 141914   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 186         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 280         |
|    time_elapsed         | 142190      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.030311111 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.12       |
|    explained_variance   | 0.0591      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39e+04    |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.527       |
|    value_loss           | 2.88e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 190         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 281         |
|    time_elapsed         | 142467      |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.031230919 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.11       |
|    explained_variance   | 0.0443      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.99e+04    |
|    n_updates            | 2800        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.526       |
|    value_loss           | 2.99e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 184        |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 282        |
|    time_elapsed         | 142742     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.03882408 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.08      |
|    explained_variance   | 0.0289     |
|    learning_rate        | 0.0003     |
|    loss                 | 5.98e+03   |
|    n_updates            | 2810       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.523      |
|    value_loss           | 1.96e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 179         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 283         |
|    time_elapsed         | 143020      |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.048947114 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.04       |
|    explained_variance   | 0.0426      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.28e+04    |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.521       |
|    value_loss           | 2.91e+04    |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=1029.23 +/- 21.41
Episode length: 153.40 +/- 161.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 153        |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.04441554 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.03      |
|    explained_variance   | 0.0371     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.65e+04   |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.522      |
|    value_loss           | 2.71e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 166      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 284      |
|    time_elapsed    | 143374   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 164         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 285         |
|    time_elapsed         | 143651      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.118153304 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.02       |
|    explained_variance   | 0.0481      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.35e+04    |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.519       |
|    value_loss           | 3.69e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 152         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 286         |
|    time_elapsed         | 143926      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.030362684 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.99       |
|    explained_variance   | 0.00224     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32e+04    |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.00916    |
|    std                  | 0.517       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 152         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 287         |
|    time_elapsed         | 144202      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.049498733 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.97       |
|    explained_variance   | 0.0328      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.518       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 153         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 288         |
|    time_elapsed         | 144479      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.041572727 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.98       |
|    explained_variance   | 0.0303      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 2870        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.518       |
|    value_loss           | 2.7e+04     |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=1021.04 +/- 9.58
Episode length: 139.00 +/- 118.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 139        |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.03884702 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.98      |
|    explained_variance   | 0.0215     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25e+04   |
|    n_updates            | 2880       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.518      |
|    value_loss           | 2.32e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 152      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 289      |
|    time_elapsed    | 144825   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 161         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 290         |
|    time_elapsed         | 145104      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.049364336 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.95       |
|    explained_variance   | 0.0187      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.94e+03    |
|    n_updates            | 2890        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.515       |
|    value_loss           | 3.03e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 158         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 291         |
|    time_elapsed         | 145383      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.029148832 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.92       |
|    explained_variance   | 0.0268      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.26e+03    |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.515       |
|    value_loss           | 1.75e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 164         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 292         |
|    time_elapsed         | 145659      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.037530437 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.91       |
|    explained_variance   | 0.0512      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.08e+03    |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.513       |
|    value_loss           | 2.79e+04    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=1018.14 +/- 8.13
Episode length: 97.40 +/- 60.37
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 97.4       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.04558581 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.89      |
|    explained_variance   | 0.043      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.31e+03   |
|    n_updates            | 2920       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.513      |
|    value_loss           | 2.57e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 169      |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 293      |
|    time_elapsed    | 145983   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 157         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 294         |
|    time_elapsed         | 146261      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.042408966 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.87       |
|    explained_variance   | 0.0354      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.59e+03    |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.511       |
|    value_loss           | 1.71e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 147        |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 295        |
|    time_elapsed         | 146540     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.03462199 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.86      |
|    explained_variance   | 0.067      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.88e+04   |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.511      |
|    value_loss           | 3.52e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 147         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 296         |
|    time_elapsed         | 146815      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.052200053 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.86       |
|    explained_variance   | 0.0404      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.22e+04    |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.512       |
|    value_loss           | 3.13e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 142        |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 297        |
|    time_elapsed         | 147092     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.06127384 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.87      |
|    explained_variance   | 0.0276     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.22e+03   |
|    n_updates            | 2960       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.512      |
|    value_loss           | 2.14e+04   |
----------------------------------------
Eval num_timesteps=610000, episode_reward=1025.78 +/- 11.64
Episode length: 127.20 +/- 75.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 127         |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.039548576 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.86       |
|    explained_variance   | 0.0393      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+04    |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.51        |
|    value_loss           | 2.3e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 144      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 298      |
|    time_elapsed    | 147432   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 142        |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 299        |
|    time_elapsed         | 147708     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.03736952 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.0408     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+04   |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.509      |
|    value_loss           | 2.26e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 134         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 300         |
|    time_elapsed         | 147986      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.034544636 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.82       |
|    explained_variance   | 0.0459      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41e+04    |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.508       |
|    value_loss           | 2.54e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 135        |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 301        |
|    time_elapsed         | 148263     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.03755056 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.046      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.24e+04   |
|    n_updates            | 3000       |
|    policy_gradient_loss | -0.0203    |
|    std                  | 0.508      |
|    value_loss           | 2.93e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 143         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 302         |
|    time_elapsed         | 148540      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.034892358 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.78       |
|    explained_variance   | 0.0556      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.64e+04    |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.504       |
|    value_loss           | 3.01e+04    |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=1013.31 +/- 5.45
Episode length: 62.80 +/- 36.48
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 62.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.035667557 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.76       |
|    explained_variance   | 0.028       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.47e+03    |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.505       |
|    value_loss           | 1.56e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 141      |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 303      |
|    time_elapsed    | 148849   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 137         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 304         |
|    time_elapsed         | 149129      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.031783674 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.75       |
|    explained_variance   | 0.069       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44e+04    |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.504       |
|    value_loss           | 2.44e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 140         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 305         |
|    time_elapsed         | 149406      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.043500535 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.72       |
|    explained_variance   | 0.0618      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17e+04    |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.501       |
|    value_loss           | 2.28e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 144         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 306         |
|    time_elapsed         | 149684      |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.051650513 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.7        |
|    explained_variance   | 0.0588      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24e+04    |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.501       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 152         |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 307         |
|    time_elapsed         | 149960      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.033218022 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.0655      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+04    |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.498       |
|    value_loss           | 2.12e+04    |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=1017.78 +/- 6.32
Episode length: 81.20 +/- 39.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 81.2        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.056359112 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.63       |
|    explained_variance   | 0.0698      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26e+04    |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.0145     |
|    std                  | 0.495       |
|    value_loss           | 1.84e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 146      |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 308      |
|    time_elapsed    | 150281   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 136         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 309         |
|    time_elapsed         | 150558      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.038793854 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.6        |
|    explained_variance   | 0.114       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+04    |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.494       |
|    value_loss           | 3.35e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 126         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 310         |
|    time_elapsed         | 150836      |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.034508422 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.58       |
|    explained_variance   | 0.0545      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.58e+03    |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.493       |
|    value_loss           | 2.52e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 114        |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 311        |
|    time_elapsed         | 151115     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.04966855 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.54      |
|    explained_variance   | 0.0694     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.57e+04   |
|    n_updates            | 3100       |
|    policy_gradient_loss | -0.00949   |
|    std                  | 0.49       |
|    value_loss           | 3.05e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 99.3       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 312        |
|    time_elapsed         | 151395     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.04021874 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.5       |
|    explained_variance   | 0.049      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.95e+03   |
|    n_updates            | 3110       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.488      |
|    value_loss           | 2.61e+04   |
----------------------------------------
Eval num_timesteps=640000, episode_reward=1017.68 +/- 5.91
Episode length: 71.60 +/- 27.02
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 71.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.037510008 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.46       |
|    explained_variance   | 0.0541      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83e+04    |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.486       |
|    value_loss           | 2.91e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 97.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 313      |
|    time_elapsed    | 151710   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 105         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 314         |
|    time_elapsed         | 151987      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.031793434 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.44       |
|    explained_variance   | 0.0398      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+04    |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.485       |
|    value_loss           | 2.44e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 106         |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 315         |
|    time_elapsed         | 152269      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.026420206 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.42       |
|    explained_variance   | 0.0524      |
|    learning_rate        | 0.0003      |
|    loss                 | 7.09e+03    |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.483       |
|    value_loss           | 2.38e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 111        |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 316        |
|    time_elapsed         | 152547     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.03358504 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.39      |
|    explained_variance   | 0.0691     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.26e+04   |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.0184    |
|    std                  | 0.481      |
|    value_loss           | 2.5e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 110        |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 317        |
|    time_elapsed         | 152825     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.03147498 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.37      |
|    explained_variance   | 0.0586     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+04   |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0222    |
|    std                  | 0.48       |
|    value_loss           | 2.15e+04   |
----------------------------------------
Eval num_timesteps=650000, episode_reward=1015.38 +/- 5.11
Episode length: 67.60 +/- 36.30
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 67.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.034098372 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.34       |
|    explained_variance   | 0.0798      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.83e+03    |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.0207     |
|    std                  | 0.478       |
|    value_loss           | 2.45e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 117      |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 318      |
|    time_elapsed    | 153140   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 103         |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 319         |
|    time_elapsed         | 153420      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.037704665 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.31       |
|    explained_variance   | 0.0743      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.77e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.477       |
|    value_loss           | 2.51e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 96.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 320         |
|    time_elapsed         | 153699      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.053172514 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.28       |
|    explained_variance   | 0.0669      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+04    |
|    n_updates            | 3190        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.475       |
|    value_loss           | 3.07e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 91.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 321         |
|    time_elapsed         | 153978      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.058244936 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.25       |
|    explained_variance   | 0.0805      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.41e+04    |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.473       |
|    value_loss           | 2.87e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 88          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 322         |
|    time_elapsed         | 154259      |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.059762325 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.24       |
|    explained_variance   | 0.0796      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+04    |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.473       |
|    value_loss           | 2.42e+04    |
-----------------------------------------
Eval num_timesteps=660000, episode_reward=1018.39 +/- 3.07
Episode length: 120.40 +/- 49.67
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 120         |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.033416048 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.23       |
|    explained_variance   | 0.0774      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55e+04    |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.472       |
|    value_loss           | 2.51e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 89.7     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 323      |
|    time_elapsed    | 154598   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 94.1        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 324         |
|    time_elapsed         | 154878      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.055185772 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.21       |
|    explained_variance   | 0.0582      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83e+04    |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.471       |
|    value_loss           | 2.76e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 94.7        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 325         |
|    time_elapsed         | 155158      |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.041000247 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.19       |
|    explained_variance   | 0.0782      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.44e+04    |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.469       |
|    value_loss           | 2.36e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 89.7        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 326         |
|    time_elapsed         | 155440      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.048862882 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.17       |
|    explained_variance   | 0.0948      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.41e+04    |
|    n_updates            | 3250        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.469       |
|    value_loss           | 2.42e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 92.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 327        |
|    time_elapsed         | 155721     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.03903185 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.16      |
|    explained_variance   | 0.101      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47e+04   |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.468      |
|    value_loss           | 2.59e+04   |
----------------------------------------
Eval num_timesteps=670000, episode_reward=1013.86 +/- 5.92
Episode length: 49.00 +/- 27.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 49          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.050777517 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.15       |
|    explained_variance   | 0.0865      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.12e+04    |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.468       |
|    value_loss           | 2.44e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 88.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 328      |
|    time_elapsed    | 156026   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 94.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 329        |
|    time_elapsed         | 156305     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.04214309 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.14      |
|    explained_variance   | 0.0917     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.28e+04   |
|    n_updates            | 3280       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.466      |
|    value_loss           | 2.51e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 88          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 330         |
|    time_elapsed         | 156586      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.035078697 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.12       |
|    explained_variance   | 0.0779      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.62e+03    |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.466       |
|    value_loss           | 2.06e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 83.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 331        |
|    time_elapsed         | 156872     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.11742133 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.12      |
|    explained_variance   | 0.111      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.31e+04   |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.00277    |
|    std                  | 0.466      |
|    value_loss           | 2.76e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78.1        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 332         |
|    time_elapsed         | 157156      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.030142136 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.11       |
|    explained_variance   | 0.0793      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.42e+04    |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.466       |
|    value_loss           | 2.7e+04     |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=1026.54 +/- 20.73
Episode length: 213.00 +/- 218.38
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 213        |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.17576091 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.0889     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.44e+04   |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.464      |
|    value_loss           | 2.53e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 70.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 333      |
|    time_elapsed    | 157542   |
|    total_timesteps | 681984   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 76.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 334         |
|    time_elapsed         | 157821      |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.036117036 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.08       |
|    explained_variance   | 0.0958      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5e+04     |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.464       |
|    value_loss           | 2.64e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 77.1       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 335        |
|    time_elapsed         | 158104     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.03190641 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.07      |
|    explained_variance   | 0.0786     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.09e+03   |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.463      |
|    value_loss           | 2.04e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 74.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 336        |
|    time_elapsed         | 158387     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.04090996 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.05      |
|    explained_variance   | 0.124      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+04   |
|    n_updates            | 3350       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.461      |
|    value_loss           | 2.53e+04   |
----------------------------------------
Eval num_timesteps=690000, episode_reward=1019.61 +/- 8.61
Episode length: 125.40 +/- 51.69
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 125        |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.03464825 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.03      |
|    explained_variance   | 0.109      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05e+04   |
|    n_updates            | 3360       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.461      |
|    value_loss           | 2.33e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 81       |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 337      |
|    time_elapsed    | 158729   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 78          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 338         |
|    time_elapsed         | 159010      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.034552447 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.03       |
|    explained_variance   | 0.0762      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+04    |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.461       |
|    value_loss           | 2.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 77.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 339         |
|    time_elapsed         | 159290      |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.032436445 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.02       |
|    explained_variance   | 0.118       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.22e+04    |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.46        |
|    value_loss           | 2.27e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 72          |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 340         |
|    time_elapsed         | 159571      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.051042788 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.01       |
|    explained_variance   | 0.126       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.05e+03    |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.46        |
|    value_loss           | 2.35e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 71.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 341        |
|    time_elapsed         | 159852     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.03466197 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5         |
|    explained_variance   | 0.134      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09e+04   |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.459      |
|    value_loss           | 2.46e+04   |
----------------------------------------
Eval num_timesteps=700000, episode_reward=1012.00 +/- 2.94
Episode length: 44.40 +/- 15.13
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 44.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 700000    |
| train/                  |           |
|    approx_kl            | 0.0381676 |
|    clip_fraction        | 0.273     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.99     |
|    explained_variance   | 0.0911    |
|    learning_rate        | 0.0003    |
|    loss                 | 7.5e+03   |
|    n_updates            | 3410      |
|    policy_gradient_loss | -0.0137   |
|    std                  | 0.459     |
|    value_loss           | 1.93e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 67.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 342      |
|    time_elapsed    | 160158   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 70.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 343         |
|    time_elapsed         | 160439      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.058539152 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.98       |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+04    |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.458       |
|    value_loss           | 2.63e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 66.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 344         |
|    time_elapsed         | 160722      |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.069615014 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.98       |
|    explained_variance   | 0.073       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.56e+03    |
|    n_updates            | 3430        |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.459       |
|    value_loss           | 1.85e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 67.5       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 345        |
|    time_elapsed         | 161003     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.09190293 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.97      |
|    explained_variance   | 0.134      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.81e+03   |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.457      |
|    value_loss           | 2.29e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 69.7        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 346         |
|    time_elapsed         | 161285      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.044082187 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.95       |
|    explained_variance   | 0.142       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+04    |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.457       |
|    value_loss           | 2.19e+04    |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=1010.67 +/- 0.45
Episode length: 27.00 +/- 3.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.04063023 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.94      |
|    explained_variance   | 0.103      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.15e+04   |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.455      |
|    value_loss           | 1.91e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 69.5     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 347      |
|    time_elapsed    | 161579   |
|    total_timesteps | 710656   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 68.2      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 348       |
|    time_elapsed         | 161863    |
|    total_timesteps      | 712704    |
| train/                  |           |
|    approx_kl            | 0.0616626 |
|    clip_fraction        | 0.31      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.91     |
|    explained_variance   | 0.148     |
|    learning_rate        | 0.0003    |
|    loss                 | 8.59e+03  |
|    n_updates            | 3470      |
|    policy_gradient_loss | -0.0174   |
|    std                  | 0.455     |
|    value_loss           | 2.03e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 70.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 349         |
|    time_elapsed         | 162157      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.066254765 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.89       |
|    explained_variance   | 0.156       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.35e+03    |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.0182     |
|    std                  | 0.453       |
|    value_loss           | 1.97e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 69.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 350         |
|    time_elapsed         | 162442      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.048488647 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.87       |
|    explained_variance   | 0.113       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.95e+03    |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.452       |
|    value_loss           | 1.78e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 73.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 351        |
|    time_elapsed         | 162724     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.06852199 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.86      |
|    explained_variance   | 0.157      |
|    learning_rate        | 0.0003     |
|    loss                 | 8.76e+03   |
|    n_updates            | 3500       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.452      |
|    value_loss           | 1.88e+04   |
----------------------------------------
Eval num_timesteps=720000, episode_reward=1013.13 +/- 2.93
Episode length: 47.00 +/- 19.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 47          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.053578135 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.85       |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.42e+03    |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.45        |
|    value_loss           | 1.66e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 70.8     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 352      |
|    time_elapsed    | 163031   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 66.2        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 353         |
|    time_elapsed         | 163313      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.047851525 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.82       |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.02e+04    |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.449       |
|    value_loss           | 2e+04       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 63.8        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 354         |
|    time_elapsed         | 163596      |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.084377855 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.81       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51e+04    |
|    n_updates            | 3530        |
|    policy_gradient_loss | -0.00676    |
|    std                  | 0.449       |
|    value_loss           | 2.03e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 57.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 355         |
|    time_elapsed         | 163881      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.055673115 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.82       |
|    explained_variance   | 0.168       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.27e+03    |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.449       |
|    value_loss           | 1.74e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 56.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 356        |
|    time_elapsed         | 164166     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.03936877 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.81      |
|    explained_variance   | 0.219      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.99e+03   |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.449      |
|    value_loss           | 2e+04      |
----------------------------------------
Eval num_timesteps=730000, episode_reward=1011.20 +/- 2.08
Episode length: 37.20 +/- 7.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 37.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.05175637 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.81      |
|    explained_variance   | 0.2        |
|    learning_rate        | 0.0003     |
|    loss                 | 8.76e+03   |
|    n_updates            | 3560       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.449      |
|    value_loss           | 1.77e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 58.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 357      |
|    time_elapsed    | 164468   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 60.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 358         |
|    time_elapsed         | 164754      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.051198855 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.8        |
|    explained_variance   | 0.155       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.64e+03    |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.448       |
|    value_loss           | 1.64e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 59.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 359         |
|    time_elapsed         | 165039      |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.037741568 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.79       |
|    explained_variance   | 0.172       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.76e+03    |
|    n_updates            | 3580        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.447       |
|    value_loss           | 1.67e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 56.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 360       |
|    time_elapsed         | 165322    |
|    total_timesteps      | 737280    |
| train/                  |           |
|    approx_kl            | 0.0953183 |
|    clip_fraction        | 0.328     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.76     |
|    explained_variance   | 0.233     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.24e+04  |
|    n_updates            | 3590      |
|    policy_gradient_loss | -0.0174   |
|    std                  | 0.445     |
|    value_loss           | 1.77e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 53.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 361         |
|    time_elapsed         | 165606      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.041709214 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.73       |
|    explained_variance   | 0.165       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.6e+03     |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.444       |
|    value_loss           | 1.68e+04    |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=1010.98 +/- 0.76
Episode length: 38.60 +/- 16.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 38.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.048003595 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.71       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 8.88e+03    |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.443       |
|    value_loss           | 1.65e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 54.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 362      |
|    time_elapsed    | 165909   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 363         |
|    time_elapsed         | 166200      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.050908692 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.68       |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 9.97e+03    |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.441       |
|    value_loss           | 1.67e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 49.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 364        |
|    time_elapsed         | 166486     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.17649865 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.66      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.19e+04   |
|    n_updates            | 3630       |
|    policy_gradient_loss | -0.00798   |
|    std                  | 0.44       |
|    value_loss           | 1.68e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 365        |
|    time_elapsed         | 166771     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.10198539 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.65      |
|    explained_variance   | 0.159      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.31e+03   |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.44       |
|    value_loss           | 1.57e+04   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 46.6     |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 4        |
|    iterations           | 366      |
|    time_elapsed         | 167057   |
|    total_timesteps      | 749568   |
| train/                  |          |
|    approx_kl            | 0.078978 |
|    clip_fraction        | 0.308    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.65    |
|    explained_variance   | 0.247    |
|    learning_rate        | 0.0003   |
|    loss                 | 6.94e+03 |
|    n_updates            | 3650     |
|    policy_gradient_loss | -0.0129  |
|    std                  | 0.44     |
|    value_loss           | 1.56e+04 |
--------------------------------------
Eval num_timesteps=750000, episode_reward=1017.55 +/- 5.27
Episode length: 54.20 +/- 20.09
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 54.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.07691273 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.64      |
|    explained_variance   | 0.174      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.87e+03   |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.44       |
|    value_loss           | 1.52e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 367      |
|    time_elapsed    | 167369   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 43.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 368        |
|    time_elapsed         | 167655     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.08171793 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.63      |
|    explained_variance   | 0.21       |
|    learning_rate        | 0.0003     |
|    loss                 | 7.02e+03   |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.438      |
|    value_loss           | 1.51e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 47.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 369        |
|    time_elapsed         | 167940     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.08124151 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.59      |
|    explained_variance   | 0.219      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.75e+03   |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.436      |
|    value_loss           | 1.44e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 48.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 370         |
|    time_elapsed         | 168224      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.063068956 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.57       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.92e+03    |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.436       |
|    value_loss           | 1.3e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 371         |
|    time_elapsed         | 168509      |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.102622375 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.57       |
|    explained_variance   | 0.283       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.4e+03     |
|    n_updates            | 3700        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.436       |
|    value_loss           | 1.3e+04     |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=1013.16 +/- 1.66
Episode length: 39.00 +/- 5.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.050419934 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.56       |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.27e+03    |
|    n_updates            | 3710        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.435       |
|    value_loss           | 1.35e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 372      |
|    time_elapsed    | 168814   |
|    total_timesteps | 761856   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 373        |
|    time_elapsed         | 169098     |
|    total_timesteps      | 763904     |
| train/                  |            |
|    approx_kl            | 0.08209635 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.55      |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.02e+03   |
|    n_updates            | 3720       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.435      |
|    value_loss           | 1.33e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 374        |
|    time_elapsed         | 169384     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.04099206 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.53      |
|    explained_variance   | 0.187      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.88e+03   |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.434      |
|    value_loss           | 1.22e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 375         |
|    time_elapsed         | 169668      |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.047125746 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.52       |
|    explained_variance   | 0.266       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.58e+03    |
|    n_updates            | 3740        |
|    policy_gradient_loss | -0.0259     |
|    std                  | 0.434       |
|    value_loss           | 1.23e+04    |
-----------------------------------------
Eval num_timesteps=770000, episode_reward=1012.22 +/- 3.93
Episode length: 36.60 +/- 12.24
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 36.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.06465493 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.51      |
|    explained_variance   | 0.26       |
|    learning_rate        | 0.0003     |
|    loss                 | 5.69e+03   |
|    n_updates            | 3750       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.433      |
|    value_loss           | 1.18e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 376      |
|    time_elapsed    | 169978   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45          |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 377         |
|    time_elapsed         | 170267      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.092068166 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.48       |
|    explained_variance   | 0.332       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.45e+03    |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.431       |
|    value_loss           | 1.25e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 45.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 378         |
|    time_elapsed         | 170553      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.063545845 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.45       |
|    explained_variance   | 0.269       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.33e+03    |
|    n_updates            | 3770        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.429       |
|    value_loss           | 1.07e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 379        |
|    time_elapsed         | 170838     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.16155925 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.43      |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.56e+03   |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.0152    |
|    std                  | 0.429      |
|    value_loss           | 1.01e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 380         |
|    time_elapsed         | 171125      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.044236306 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.43       |
|    explained_variance   | 0.324       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.3e+03     |
|    n_updates            | 3790        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.429       |
|    value_loss           | 1.06e+04    |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=1013.52 +/- 3.40
Episode length: 48.60 +/- 6.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 48.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.054906867 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.42       |
|    explained_variance   | 0.233       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.13e+03    |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.427       |
|    value_loss           | 1.02e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 49.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 381      |
|    time_elapsed    | 171436   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 382         |
|    time_elapsed         | 171722      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.039205827 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.39       |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.99e+03    |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.426       |
|    value_loss           | 1.04e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 47.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 383        |
|    time_elapsed         | 172008     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.11015022 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.37      |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.96e+03   |
|    n_updates            | 3820       |
|    policy_gradient_loss | -0.0211    |
|    std                  | 0.426      |
|    value_loss           | 9.81e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 47.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 384         |
|    time_elapsed         | 172293      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.050630547 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.35       |
|    explained_variance   | 0.311       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.81e+03    |
|    n_updates            | 3830        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.425       |
|    value_loss           | 9.39e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 385        |
|    time_elapsed         | 172580     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.07285877 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.33      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.91e+03   |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.424      |
|    value_loss           | 9.95e+03   |
----------------------------------------
Eval num_timesteps=790000, episode_reward=1011.43 +/- 2.30
Episode length: 42.40 +/- 11.59
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 42.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.047133036 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.31       |
|    explained_variance   | 0.354       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.4e+03     |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.422       |
|    value_loss           | 9.85e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 44.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 386      |
|    time_elapsed    | 172888   |
|    total_timesteps | 790528   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 387        |
|    time_elapsed         | 173173     |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.08185681 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.28      |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.27e+03   |
|    n_updates            | 3860       |
|    policy_gradient_loss | -0.00875   |
|    std                  | 0.421      |
|    value_loss           | 8.63e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 46.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 388         |
|    time_elapsed         | 173458      |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.044487424 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.26       |
|    explained_variance   | 0.338       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.95e+03    |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.42        |
|    value_loss           | 8.34e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 389        |
|    time_elapsed         | 173743     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.06087735 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.1e+03    |
|    n_updates            | 3880       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.419      |
|    value_loss           | 8.48e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 47.7      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 390       |
|    time_elapsed         | 174031    |
|    total_timesteps      | 798720    |
| train/                  |           |
|    approx_kl            | 0.0652639 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.24     |
|    explained_variance   | 0.4       |
|    learning_rate        | 0.0003    |
|    loss                 | 4e+03     |
|    n_updates            | 3890      |
|    policy_gradient_loss | -0.0141   |
|    std                  | 0.419     |
|    value_loss           | 7.54e+03  |
---------------------------------------
Eval num_timesteps=800000, episode_reward=1010.62 +/- 0.78
Episode length: 28.20 +/- 4.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.051843323 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.23       |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.0003      |
|    loss                 | 4.38e+03    |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.419       |
|    value_loss           | 8.29e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 45.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 391      |
|    time_elapsed    | 174333   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 44.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 392         |
|    time_elapsed         | 174618      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.070286155 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.24       |
|    explained_variance   | 0.454       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.36e+03    |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.419       |
|    value_loss           | 7.65e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 45.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 393        |
|    time_elapsed         | 174904     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.19791844 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.25      |
|    explained_variance   | 0.4        |
|    learning_rate        | 0.0003     |
|    loss                 | 3.4e+03    |
|    n_updates            | 3920       |
|    policy_gradient_loss | -0.00977   |
|    std                  | 0.42       |
|    value_loss           | 7.45e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 394        |
|    time_elapsed         | 175189     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.07282711 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.26      |
|    explained_variance   | 0.46       |
|    learning_rate        | 0.0003     |
|    loss                 | 3.12e+03   |
|    n_updates            | 3930       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.42       |
|    value_loss           | 6.9e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 395        |
|    time_elapsed         | 175474     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.06900019 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.25      |
|    explained_variance   | 0.45       |
|    learning_rate        | 0.0003     |
|    loss                 | 2.75e+03   |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.419      |
|    value_loss           | 6.8e+03    |
----------------------------------------
Eval num_timesteps=810000, episode_reward=1009.66 +/- 0.63
Episode length: 42.20 +/- 12.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 42.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.10567844 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.25      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.18e+03   |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.42       |
|    value_loss           | 6.39e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 41.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 396      |
|    time_elapsed    | 175781   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 41.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 397        |
|    time_elapsed         | 176067     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.06587431 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.26      |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.2e+03    |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0196    |
|    std                  | 0.42       |
|    value_loss           | 6.1e+03    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 398         |
|    time_elapsed         | 176352      |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.069040015 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.28       |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.04e+03    |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.421       |
|    value_loss           | 6.1e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 399         |
|    time_elapsed         | 176639      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.096256144 |
|    clip_fraction        | 0.364       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.28       |
|    explained_variance   | 0.517       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.05e+03    |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.0098     |
|    std                  | 0.421       |
|    value_loss           | 5.64e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 400        |
|    time_elapsed         | 176925     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.07919054 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.26      |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.56e+03   |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.42       |
|    value_loss           | 5.23e+03   |
----------------------------------------
Eval num_timesteps=820000, episode_reward=1014.07 +/- 3.23
Episode length: 50.00 +/- 13.83
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 50         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.03773219 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0.476      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.03e+03   |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.016     |
|    std                  | 0.419      |
|    value_loss           | 5.55e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 39.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 401      |
|    time_elapsed    | 177237   |
|    total_timesteps | 821248   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 38.1      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 402       |
|    time_elapsed         | 177524    |
|    total_timesteps      | 823296    |
| train/                  |           |
|    approx_kl            | 0.1223109 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.22     |
|    explained_variance   | 0.515     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.81e+03  |
|    n_updates            | 4010      |
|    policy_gradient_loss | -0.0198   |
|    std                  | 0.417     |
|    value_loss           | 4.89e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 41.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 403        |
|    time_elapsed         | 177815     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.11555332 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.2       |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.6e+03    |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.00897   |
|    std                  | 0.416      |
|    value_loss           | 4.95e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 43         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 404        |
|    time_elapsed         | 178105     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.05005199 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.44e+03   |
|    n_updates            | 4030       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.415      |
|    value_loss           | 5.25e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 41         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 405        |
|    time_elapsed         | 178391     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.20202275 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.19      |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.81e+03   |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.416      |
|    value_loss           | 5.17e+03   |
----------------------------------------
Eval num_timesteps=830000, episode_reward=1014.80 +/- 4.63
Episode length: 45.40 +/- 15.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 45.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.05967678 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.19      |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.35e+03   |
|    n_updates            | 4050       |
|    policy_gradient_loss | -0.0191    |
|    std                  | 0.417      |
|    value_loss           | 4.95e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 406      |
|    time_elapsed    | 178700   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 407        |
|    time_elapsed         | 178987     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.07599862 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.2       |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.98e+03   |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.417      |
|    value_loss           | 4.56e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 408         |
|    time_elapsed         | 179276      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.064478956 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.2        |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.89e+03    |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.416       |
|    value_loss           | 4.4e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.6        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 409         |
|    time_elapsed         | 179561      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.053866006 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.19       |
|    explained_variance   | 0.602       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0226     |
|    std                  | 0.416       |
|    value_loss           | 4.01e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 38.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 410         |
|    time_elapsed         | 179847      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.071715534 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.18       |
|    explained_variance   | 0.675       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56e+03    |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.416       |
|    value_loss           | 3.57e+03    |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=1012.20 +/- 2.92
Episode length: 38.60 +/- 10.46
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 38.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.051151916 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.16       |
|    explained_variance   | 0.606       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.47e+03    |
|    n_updates            | 4100        |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.414       |
|    value_loss           | 3.7e+03     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 411      |
|    time_elapsed    | 180153   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 412        |
|    time_elapsed         | 180441     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.28626862 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.15      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.95e+03   |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.000864  |
|    std                  | 0.414      |
|    value_loss           | 3.87e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 413         |
|    time_elapsed         | 180727      |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.068591505 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.15       |
|    explained_variance   | 0.525       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.81e+03    |
|    n_updates            | 4120        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.414       |
|    value_loss           | 4.1e+03     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 414         |
|    time_elapsed         | 181015      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.060539436 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.14       |
|    explained_variance   | 0.587       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.05e+03    |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.414       |
|    value_loss           | 3.74e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 40.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 415        |
|    time_elapsed         | 181303     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.10924927 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.12      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.48e+03   |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.0221    |
|    std                  | 0.412      |
|    value_loss           | 3.48e+03   |
----------------------------------------
Eval num_timesteps=850000, episode_reward=1011.22 +/- 0.66
Episode length: 36.80 +/- 10.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 36.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.098940216 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.11       |
|    explained_variance   | 0.552       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.57e+03    |
|    n_updates            | 4150        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.412       |
|    value_loss           | 4.16e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 416      |
|    time_elapsed    | 181612   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 417        |
|    time_elapsed         | 181901     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.09979194 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.11      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.89e+03   |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.412      |
|    value_loss           | 3.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 418        |
|    time_elapsed         | 182187     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.14386669 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.1       |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.15e+03   |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.00876   |
|    std                  | 0.411      |
|    value_loss           | 3.93e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 37.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 419       |
|    time_elapsed         | 182477    |
|    total_timesteps      | 858112    |
| train/                  |           |
|    approx_kl            | 0.1464618 |
|    clip_fraction        | 0.385     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.09     |
|    explained_variance   | 0.619     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.17e+03  |
|    n_updates            | 4180      |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.411     |
|    value_loss           | 3.17e+03  |
---------------------------------------
Eval num_timesteps=860000, episode_reward=1013.30 +/- 2.05
Episode length: 40.80 +/- 13.99
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 40.8      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 860000    |
| train/                  |           |
|    approx_kl            | 0.0676972 |
|    clip_fraction        | 0.305     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.08     |
|    explained_variance   | 0.652     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.67e+03  |
|    n_updates            | 4190      |
|    policy_gradient_loss | -0.0167   |
|    std                  | 0.41      |
|    value_loss           | 3.14e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 420      |
|    time_elapsed    | 182784   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 421        |
|    time_elapsed         | 183073     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.31997243 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.06      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.8e+03    |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.409      |
|    value_loss           | 2.96e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 422         |
|    time_elapsed         | 183362      |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.049092725 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.04       |
|    explained_variance   | 0.544       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.04e+03    |
|    n_updates            | 4210        |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.407       |
|    value_loss           | 3.75e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 423        |
|    time_elapsed         | 183650     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.10513519 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.02      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.22e+03   |
|    n_updates            | 4220       |
|    policy_gradient_loss | -0.00781   |
|    std                  | 0.407      |
|    value_loss           | 2.57e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 424         |
|    time_elapsed         | 183938      |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.071344346 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.03       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+03    |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.408       |
|    value_loss           | 2.19e+03    |
-----------------------------------------
Eval num_timesteps=870000, episode_reward=1012.14 +/- 1.90
Episode length: 38.60 +/- 10.59
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 38.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.09744255 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.04      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.68e+03   |
|    n_updates            | 4240       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.409      |
|    value_loss           | 2.75e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 425      |
|    time_elapsed    | 184246   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.9        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 426         |
|    time_elapsed         | 184533      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.056421686 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.05       |
|    explained_variance   | 0.618       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+03    |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.409       |
|    value_loss           | 2.97e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 427        |
|    time_elapsed         | 184820     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.11153732 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.04      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+03   |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.00886   |
|    std                  | 0.409      |
|    value_loss           | 2.15e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 35.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 428         |
|    time_elapsed         | 185108      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.112449996 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.04       |
|    explained_variance   | 0.736       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15e+03    |
|    n_updates            | 4270        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.409       |
|    value_loss           | 1.92e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 429        |
|    time_elapsed         | 185397     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.05744507 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.03      |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+03   |
|    n_updates            | 4280       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.407      |
|    value_loss           | 2.65e+03   |
----------------------------------------
Eval num_timesteps=880000, episode_reward=1015.47 +/- 4.78
Episode length: 50.40 +/- 19.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 50.4       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.06298587 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.02      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.39e+03   |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.00876   |
|    std                  | 0.408      |
|    value_loss           | 2.95e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 430      |
|    time_elapsed    | 185711   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 431        |
|    time_elapsed         | 186002     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.07737276 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.02      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.53e+03   |
|    n_updates            | 4300       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.407      |
|    value_loss           | 3.29e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 432        |
|    time_elapsed         | 186291     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.14935024 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.99      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.2e+03    |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.405      |
|    value_loss           | 2.56e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 433        |
|    time_elapsed         | 186579     |
|    total_timesteps      | 886784     |
| train/                  |            |
|    approx_kl            | 0.05661475 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.98      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 4320       |
|    policy_gradient_loss | -0.00913   |
|    std                  | 0.405      |
|    value_loss           | 2.86e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 434        |
|    time_elapsed         | 186866     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.12977177 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.96      |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.00862    |
|    std                  | 0.404      |
|    value_loss           | 2.1e+03    |
----------------------------------------
Eval num_timesteps=890000, episode_reward=1011.96 +/- 3.82
Episode length: 31.80 +/- 3.82
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 31.8        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.034604788 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.95       |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.09e+03    |
|    n_updates            | 4340        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.404       |
|    value_loss           | 2.3e+03     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 435      |
|    time_elapsed    | 187167   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 436        |
|    time_elapsed         | 187454     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.10728106 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.94      |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.0003     |
|    loss                 | 603        |
|    n_updates            | 4350       |
|    policy_gradient_loss | 0.000301   |
|    std                  | 0.403      |
|    value_loss           | 2.38e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 33.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 437       |
|    time_elapsed         | 187742    |
|    total_timesteps      | 894976    |
| train/                  |           |
|    approx_kl            | 0.2242484 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.93     |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.13e+03  |
|    n_updates            | 4360      |
|    policy_gradient_loss | 0.00668   |
|    std                  | 0.402     |
|    value_loss           | 2.13e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 35        |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 438       |
|    time_elapsed         | 188030    |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.1837724 |
|    clip_fraction        | 0.35      |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.91     |
|    explained_variance   | 0.689     |
|    learning_rate        | 0.0003    |
|    loss                 | 935       |
|    n_updates            | 4370      |
|    policy_gradient_loss | -0.0118   |
|    std                  | 0.402     |
|    value_loss           | 2.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 439        |
|    time_elapsed         | 188320     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.06711873 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.92      |
|    explained_variance   | 0.621      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.71e+03   |
|    n_updates            | 4380       |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.402      |
|    value_loss           | 2.74e+03   |
----------------------------------------
Eval num_timesteps=900000, episode_reward=1015.08 +/- 4.33
Episode length: 35.20 +/- 7.93
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 35.2      |
|    mean_reward          | 1.02e+03  |
| time/                   |           |
|    total_timesteps      | 900000    |
| train/                  |           |
|    approx_kl            | 0.0774391 |
|    clip_fraction        | 0.312     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.92     |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.01e+03  |
|    n_updates            | 4390      |
|    policy_gradient_loss | -0.0241   |
|    std                  | 0.402     |
|    value_loss           | 2.32e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 35.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 440      |
|    time_elapsed    | 188626   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 441        |
|    time_elapsed         | 188915     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.08880094 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.92      |
|    explained_variance   | 0.604      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36e+03   |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.402      |
|    value_loss           | 2.93e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 33.5      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 442       |
|    time_elapsed         | 189205    |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 0.0629146 |
|    clip_fraction        | 0.333     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.93     |
|    explained_variance   | 0.656     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.08e+03  |
|    n_updates            | 4410      |
|    policy_gradient_loss | -0.0179   |
|    std                  | 0.403     |
|    value_loss           | 2.47e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 33.2      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 443       |
|    time_elapsed         | 189496    |
|    total_timesteps      | 907264    |
| train/                  |           |
|    approx_kl            | 0.0610829 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.92     |
|    explained_variance   | 0.669     |
|    learning_rate        | 0.0003    |
|    loss                 | 899       |
|    n_updates            | 4420      |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.401     |
|    value_loss           | 2.27e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 444        |
|    time_elapsed         | 189790     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.14424542 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.9       |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+03   |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.402      |
|    value_loss           | 2.17e+03   |
----------------------------------------
Eval num_timesteps=910000, episode_reward=1011.61 +/- 2.03
Episode length: 29.20 +/- 4.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 29.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.09766872 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.9       |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.0003     |
|    loss                 | 983        |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.401      |
|    value_loss           | 1.93e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 445      |
|    time_elapsed    | 190094   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 34.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 446         |
|    time_elapsed         | 190383      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.045147058 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.9        |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.43e+03    |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.401       |
|    value_loss           | 1.92e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 37.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 447         |
|    time_elapsed         | 190671      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.048918907 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.91       |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.75e+03    |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.402       |
|    value_loss           | 2.82e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 448        |
|    time_elapsed         | 190960     |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.08360496 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.9       |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08e+03   |
|    n_updates            | 4470       |
|    policy_gradient_loss | -0.006     |
|    std                  | 0.401      |
|    value_loss           | 2.29e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 449        |
|    time_elapsed         | 191248     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.85538083 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.88      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01e+03   |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.4        |
|    value_loss           | 2.35e+03   |
----------------------------------------
Eval num_timesteps=920000, episode_reward=1011.95 +/- 2.23
Episode length: 32.00 +/- 6.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 32         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.04688236 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.87      |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17e+03   |
|    n_updates            | 4490       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.399      |
|    value_loss           | 2.79e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 450      |
|    time_elapsed    | 191552   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 451         |
|    time_elapsed         | 191840      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.059893683 |
|    clip_fraction        | 0.31        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.85       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+03    |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.399       |
|    value_loss           | 2.15e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 452         |
|    time_elapsed         | 192128      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.058627225 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.83       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 4510        |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.398       |
|    value_loss           | 2.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 453         |
|    time_elapsed         | 192417      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.075417385 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.82       |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.0003      |
|    loss                 | 826         |
|    n_updates            | 4520        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.398       |
|    value_loss           | 1.74e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 454        |
|    time_elapsed         | 192706     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.07150221 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.82      |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.0003     |
|    loss                 | 845        |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.398      |
|    value_loss           | 1.86e+03   |
----------------------------------------
Eval num_timesteps=930000, episode_reward=1012.82 +/- 3.93
Episode length: 28.20 +/- 5.27
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 28.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.092036486 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.82       |
|    explained_variance   | 0.773       |
|    learning_rate        | 0.0003      |
|    loss                 | 484         |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.398       |
|    value_loss           | 1.3e+03     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 455      |
|    time_elapsed    | 193009   |
|    total_timesteps | 931840   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 456        |
|    time_elapsed         | 193299     |
|    total_timesteps      | 933888     |
| train/                  |            |
|    approx_kl            | 0.05573023 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.81      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 4550       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.398      |
|    value_loss           | 2.15e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 457        |
|    time_elapsed         | 193590     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.07363235 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.81      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.0003     |
|    loss                 | 781        |
|    n_updates            | 4560       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.397      |
|    value_loss           | 1.95e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 458        |
|    time_elapsed         | 193879     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.11943725 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.8       |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.0003     |
|    loss                 | 856        |
|    n_updates            | 4570       |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.397      |
|    value_loss           | 1.77e+03   |
----------------------------------------
Eval num_timesteps=940000, episode_reward=1012.84 +/- 2.24
Episode length: 36.40 +/- 4.22
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 36.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.042527884 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.8        |
|    explained_variance   | 0.626       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+03    |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.0234     |
|    std                  | 0.398       |
|    value_loss           | 2.22e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 459      |
|    time_elapsed    | 194186   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 460        |
|    time_elapsed         | 194476     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.06487349 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.8       |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.0003     |
|    loss                 | 665        |
|    n_updates            | 4590       |
|    policy_gradient_loss | -0.0232    |
|    std                  | 0.398      |
|    value_loss           | 2.28e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 461        |
|    time_elapsed         | 194766     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.05784769 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.79      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.0003     |
|    loss                 | 759        |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.397      |
|    value_loss           | 1.54e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 462        |
|    time_elapsed         | 195054     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.27103877 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.77      |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.0003     |
|    loss                 | 663        |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.396      |
|    value_loss           | 1.34e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 463        |
|    time_elapsed         | 195343     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.08369436 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.76      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 855        |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0119    |
|    std                  | 0.396      |
|    value_loss           | 1.98e+03   |
----------------------------------------
Eval num_timesteps=950000, episode_reward=1018.55 +/- 5.78
Episode length: 46.80 +/- 17.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 46.8       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.14532444 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.75      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.0003     |
|    loss                 | 750        |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.0025    |
|    std                  | 0.395      |
|    value_loss           | 1.69e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 464      |
|    time_elapsed    | 195655   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 465        |
|    time_elapsed         | 195944     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.15791884 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.73      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.393      |
|    value_loss           | 2.12e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 466        |
|    time_elapsed         | 196235     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.21588847 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.14e+03   |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.393      |
|    value_loss           | 1.7e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 467        |
|    time_elapsed         | 196525     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.06925787 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.68      |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.0003     |
|    loss                 | 858        |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.00924   |
|    std                  | 0.39       |
|    value_loss           | 2.22e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 468        |
|    time_elapsed         | 196814     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.12262787 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.67      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.0003     |
|    loss                 | 675        |
|    n_updates            | 4670       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.392      |
|    value_loss           | 1.84e+03   |
----------------------------------------
Eval num_timesteps=960000, episode_reward=1010.61 +/- 1.03
Episode length: 30.00 +/- 2.28
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.08908139 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.68      |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.0003     |
|    loss                 | 847        |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.0135    |
|    std                  | 0.392      |
|    value_loss           | 1.67e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 469      |
|    time_elapsed    | 197118   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 470        |
|    time_elapsed         | 197408     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.05875498 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.68      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.0231    |
|    std                  | 0.392      |
|    value_loss           | 1.83e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 471        |
|    time_elapsed         | 197701     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.11857283 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.67      |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+03   |
|    n_updates            | 4700       |
|    policy_gradient_loss | -0.0133    |
|    std                  | 0.39       |
|    value_loss           | 2.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 31.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 472         |
|    time_elapsed         | 197990      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.055122033 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.63       |
|    explained_variance   | 0.699       |
|    learning_rate        | 0.0003      |
|    loss                 | 930         |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.388       |
|    value_loss           | 1.85e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 473        |
|    time_elapsed         | 198280     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.16730396 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.62      |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.0003     |
|    loss                 | 874        |
|    n_updates            | 4720       |
|    policy_gradient_loss | -0.00499   |
|    std                  | 0.388      |
|    value_loss           | 1.69e+03   |
----------------------------------------
Eval num_timesteps=970000, episode_reward=1013.76 +/- 4.85
Episode length: 39.00 +/- 12.70
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 39          |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.093999095 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.6        |
|    explained_variance   | 0.76        |
|    learning_rate        | 0.0003      |
|    loss                 | 660         |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.387       |
|    value_loss           | 1.27e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 474      |
|    time_elapsed    | 198591   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 475        |
|    time_elapsed         | 198880     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.06745472 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.57      |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.0003     |
|    loss                 | 487        |
|    n_updates            | 4740       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.385      |
|    value_loss           | 1.73e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 476        |
|    time_elapsed         | 199170     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.13635355 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.55      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.0003     |
|    loss                 | 847        |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.385      |
|    value_loss           | 1.42e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 477        |
|    time_elapsed         | 199458     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.06968279 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.54      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 995        |
|    n_updates            | 4760       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.385      |
|    value_loss           | 1.78e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 478        |
|    time_elapsed         | 199747     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.06087205 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.53      |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.31e+03   |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.00752   |
|    std                  | 0.384      |
|    value_loss           | 2.99e+03   |
----------------------------------------
Eval num_timesteps=980000, episode_reward=1011.00 +/- 1.02
Episode length: 31.40 +/- 6.62
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.22040975 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.51      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 886        |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.382      |
|    value_loss           | 2e+03      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 479      |
|    time_elapsed    | 200054   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 480        |
|    time_elapsed         | 200346     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.08495804 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.47      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09e+03   |
|    n_updates            | 4790       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.381      |
|    value_loss           | 1.78e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 481        |
|    time_elapsed         | 200636     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.07306219 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.44      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.0003     |
|    loss                 | 534        |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.379      |
|    value_loss           | 1.65e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 31.5      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 482       |
|    time_elapsed         | 200926    |
|    total_timesteps      | 987136    |
| train/                  |           |
|    approx_kl            | 0.1347228 |
|    clip_fraction        | 0.373     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.41     |
|    explained_variance   | 0.72      |
|    learning_rate        | 0.0003    |
|    loss                 | 638       |
|    n_updates            | 4810      |
|    policy_gradient_loss | -0.012    |
|    std                  | 0.378     |
|    value_loss           | 1.54e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 483        |
|    time_elapsed         | 201216     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.18726714 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.4       |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.0003     |
|    loss                 | 801        |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.379      |
|    value_loss           | 1.74e+03   |
----------------------------------------
Eval num_timesteps=990000, episode_reward=1010.35 +/- 0.70
Episode length: 30.40 +/- 3.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.06817634 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.41      |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.0003     |
|    loss                 | 918        |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.379      |
|    value_loss           | 1.73e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 484      |
|    time_elapsed    | 201522   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 485        |
|    time_elapsed         | 201814     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.14155763 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.41      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.0003     |
|    loss                 | 710        |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.38       |
|    value_loss           | 1.71e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 486        |
|    time_elapsed         | 202103     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.12192194 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.4       |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.0003     |
|    loss                 | 684        |
|    n_updates            | 4850       |
|    policy_gradient_loss | -0.0134    |
|    std                  | 0.378      |
|    value_loss           | 1.23e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 487        |
|    time_elapsed         | 202394     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.18105222 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.39      |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 4860       |
|    policy_gradient_loss | -0.00277   |
|    std                  | 0.379      |
|    value_loss           | 1.74e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 29.5      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 4         |
|    iterations           | 488       |
|    time_elapsed         | 202684    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.4555671 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.38     |
|    explained_variance   | 0.706     |
|    learning_rate        | 0.0003    |
|    loss                 | 735       |
|    n_updates            | 4870      |
|    policy_gradient_loss | 0.0306    |
|    std                  | 0.378     |
|    value_loss           | 1.7e+03   |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=1013.70 +/- 3.74
Episode length: 33.40 +/- 6.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 33.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.08371138 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.37      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.0003     |
|    loss                 | 780        |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.0138    |
|    std                  | 0.378      |
|    value_loss           | 1.59e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 4        |
|    iterations      | 489      |
|    time_elapsed    | 202995   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-31_11-20-05_llm_triton_qwen_32b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 2 days, 8:19:41 < 0:00:00 , 7 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-9.73871630e+01 -9.87946690e+01 -9.77217740e+01 -9.94669820e+01
  -8.74952010e+01]
 [-9.97063330e+01 -9.94644950e+01 -9.95576670e+01 -9.95405380e+01
  -9.95840510e+01]
 [-9.94190580e+01 -9.95770010e+01 -9.93387730e+01 -9.88734580e+01
  -9.96677980e+01]
 [-9.17244320e+01 -9.59992530e+01 -9.25552860e+01 -9.56957300e+01
  -9.56525580e+01]
 [-9.53893160e+01 -9.54447400e+01 -9.84226790e+01 -9.52635350e+01
  -9.42131910e+01]
 [-9.94522210e+01 -9.94714880e+01 -9.91753230e+01 -9.97334600e+01
  -9.80698120e+01]
 [-9.94559670e+01 -9.92641550e+01 -9.95209320e+01 -9.96568920e+01
  -9.94938730e+01]
 [-9.93593360e+01 -9.94185050e+01 -9.86870650e+01 -9.93228660e+01
  -9.54325800e+01]
 [-9.87014940e+01 -9.74425830e+01 -9.60170710e+01 -9.45479570e+01
  -9.06388700e+01]
 [-9.64397390e+01 -9.53561220e+01 -9.84948720e+01 -9.61878160e+01
  -9.64789780e+01]
 [-5.91699750e+01 -5.98614920e+01 -5.89872350e+01 -4.32811350e+01
  -4.39489290e+01]
 [-6.54886830e+01 -8.34351160e+01 -7.88302740e+01 -7.19101700e+01
  -8.57032840e+01]
 [-5.19195710e+01 -4.86059960e+01 -4.75013610e+01 -4.85067140e+01
  -4.29474880e+01]
 [-3.52089670e+01 -3.32047250e+01 -4.04300860e+01 -3.03364380e+01
  -5.14406920e+01]
 [-2.18660900e+00  1.06431000e+00 -1.38377380e+01 -1.44623090e+01
  -1.57720890e+01]
 [-3.48038940e+01 -2.65200200e+01 -2.46139850e+01 -3.57924420e+01
  -2.67575940e+01]
 [-3.88021460e+01 -2.69596360e+01 -3.69692660e+01 -7.80220800e+00
  -1.69731600e+01]
 [-1.56704060e+01 -3.00312610e+01 -1.69890690e+01 -2.01517230e+01
  -3.09484350e+01]
 [-1.39889490e+01 -2.79078000e+00  2.27124400e+00 -8.55078400e+00
   4.20652700e+00]
 [ 4.03097970e+01  6.69433780e+01  4.92717270e+01  5.23488600e+01
   2.70614390e+01]
 [ 4.41795400e+01  4.08337570e+01  4.62287250e+01  2.40961980e+01
   3.05595700e+01]
 [ 4.01192710e+01  3.37181170e+01  5.65438010e+01  3.93132740e+01
   4.86910300e+01]
 [ 5.51518740e+01  5.75802030e+01  1.01158418e+03  3.93070800e+01
   7.04732180e+01]
 [ 7.30945530e+01  9.72356510e+01  9.35317410e+01  7.11807990e+01
   8.63123000e+01]
 [ 6.79994830e+01  1.05976913e+03  5.91672230e+01  6.29615610e+01
   5.63966390e+01]
 [ 1.42483108e+02  1.07907005e+03  1.00853521e+03  1.01262664e+03
   1.08762270e+03]
 [ 1.08373648e+03  1.07283590e+03  1.02043456e+03  1.04406370e+03
   1.08858912e+03]
 [ 6.10102530e+01  8.34997130e+01  7.40351680e+01  1.01077545e+03
   1.03903100e+03]
 [ 1.05761678e+03  1.03913815e+03  1.08431985e+03  1.06694085e+03
   1.06795038e+03]
 [ 9.05927210e+01  9.33844590e+01  1.00980328e+03  1.01878868e+03
   1.06754914e+03]
 [ 1.01412442e+03  1.04673358e+03  1.03029660e+03  1.06592249e+03
   1.03463090e+03]
 [ 7.74978430e+01  1.13733084e+02  1.01881360e+03  1.02872891e+03
   1.01349293e+03]
 [ 1.37739442e+02  1.32566054e+02  1.00376297e+02  1.23902211e+02
   1.12622260e+02]
 [ 1.01559501e+03  1.28228062e+02  1.19863568e+02  9.04687630e+01
   1.53323482e+02]
 [ 1.16514516e+03  1.49596354e+02  1.06358293e+03  1.08238387e+03
   1.08247814e+02]
 [ 9.16834060e+01  6.84952600e+01  1.21701326e+02  1.09175253e+03
   1.03649566e+03]
 [ 1.43987723e+02  1.06815691e+03  1.34828933e+02  1.45652952e+02
   1.09154978e+03]
 [ 1.04293335e+03  1.12392166e+03  1.09830051e+03  1.01806001e+03
   1.42634443e+02]
 [ 1.61848527e+02  1.17313082e+03  1.01230413e+03  1.87803749e+02
   1.04159656e+03]
 [ 1.04858488e+03  1.09883414e+03  1.06298570e+03  1.78601226e+02
   1.03134791e+03]
 [ 1.02817630e+03  1.04613029e+03  1.04311146e+03  1.09112297e+03
   1.07732380e+03]
 [ 1.10366182e+03  1.07815196e+03  1.14851498e+03  1.03681235e+03
   1.02217446e+03]
 [ 1.05776922e+03  1.08843606e+03  1.06989482e+03  1.01035961e+03
   1.04494768e+03]
 [ 1.02898390e+03  1.03112777e+03  1.02966842e+03  1.12672653e+03
   1.01719016e+03]
 [ 1.01076420e+03  1.07155943e+03  1.03451190e+03  1.03083437e+03
   1.02607272e+03]
 [ 1.01926877e+03  1.01133971e+03  1.04514716e+03  1.01416649e+03
   1.03548354e+03]
 [ 1.00954954e+03  1.01576286e+03  1.03431908e+03  1.02010461e+03
   1.01003607e+03]
 [ 1.01140646e+03  1.04203297e+03  1.01347622e+03  1.01505980e+03
   1.04588721e+03]
 [ 1.00937007e+03  1.04073591e+03  1.01161748e+03  1.01390928e+03
   1.02291331e+03]
 [ 1.01463149e+03  1.09259981e+03  1.02469146e+03  1.00993276e+03
   1.01370718e+03]
 [ 1.02971952e+03  1.02754901e+03  1.01189701e+03  1.04711855e+03
   1.01335086e+03]
 [ 1.01175211e+03  1.03108807e+03  1.02253914e+03  1.01082783e+03
   1.07293252e+03]
 [ 1.03391584e+03  1.00984597e+03  1.01012892e+03  1.01139012e+03
   1.01689874e+03]
 [ 1.01412522e+03  1.01712617e+03  1.01225247e+03  1.03514134e+03
   1.01350085e+03]
 [ 1.01862873e+03  1.02167601e+03  1.03029635e+03  1.01044148e+03
   1.01037926e+03]
 [ 1.02870881e+03  1.02400928e+03  1.01377323e+03  1.03961496e+03
   1.01206280e+03]
 [ 1.00913064e+03  1.01575253e+03  1.01065447e+03  1.02233870e+03
   1.05410979e+03]
 [ 1.01238211e+03  1.01074606e+03  1.02664236e+03  1.02649947e+03
   1.06987734e+03]
 [ 1.02240478e+03  1.03851305e+03  1.01201231e+03  1.01948384e+03
   1.01280748e+03]
 [ 1.03090784e+03  1.02450361e+03  1.01108051e+03  1.01065764e+03
   1.01353390e+03]
 [ 1.01311514e+03  1.01073209e+03  1.03694294e+03  1.03789945e+03
   1.03020874e+03]
 [ 1.01199818e+03  1.01120274e+03  1.00939638e+03  1.00992087e+03
   1.02404903e+03]
 [ 1.02291995e+03  1.01071599e+03  1.02684808e+03  1.01140275e+03
   1.01699875e+03]
 [ 1.02375855e+03  1.02124894e+03  1.02229864e+03  1.01156853e+03
   1.00952298e+03]
 [ 1.01168642e+03  1.01060313e+03  1.01605064e+03  1.01364353e+03
   1.02490563e+03]
 [ 1.01943762e+03  1.01770990e+03  1.01941293e+03  1.01303725e+03
   1.02236396e+03]
 [ 1.01491076e+03  1.00980825e+03  1.00964181e+03  1.02501110e+03
   1.00994267e+03]
 [ 1.01057118e+03  1.04198948e+03  1.00971742e+03  1.01047388e+03
   1.05992326e+03]
 [ 1.03248422e+03  1.01362342e+03  1.02691619e+03  1.01526256e+03
   1.00976502e+03]
 [ 1.01754034e+03  1.00965223e+03  1.01171967e+03  1.00940156e+03
   1.01167679e+03]
 [ 1.01089550e+03  1.00977921e+03  1.01085651e+03  1.01100186e+03
   1.01081132e+03]
 [ 1.01057203e+03  1.01395116e+03  1.01176283e+03  1.01085880e+03
   1.01848574e+03]
 [ 1.00968168e+03  1.01059780e+03  1.00960635e+03  1.01086261e+03
   1.01523242e+03]
 [ 1.01076343e+03  1.00967889e+03  1.01166787e+03  1.01099923e+03
   1.01180747e+03]
 [ 1.01994208e+03  1.02626907e+03  1.01578852e+03  1.01517670e+03
   1.01058763e+03]
 [ 1.01433643e+03  1.01069006e+03  1.01162320e+03  1.01466665e+03
   1.01447857e+03]
 [ 1.02003406e+03  1.00986035e+03  1.01036683e+03  1.00980564e+03
   1.01105784e+03]
 [ 1.01041886e+03  1.01215704e+03  1.01256558e+03  1.02015191e+03
   1.01232007e+03]
 [ 1.00950725e+03  1.01579188e+03  1.01069654e+03  1.01149310e+03
   1.00967517e+03]
 [ 1.01178806e+03  1.00972044e+03  1.00978875e+03  1.01103958e+03
   1.01074172e+03]
 [ 1.00985539e+03  1.01072807e+03  1.00895507e+03  1.00967035e+03
   1.00909038e+03]
 [ 1.01434177e+03  1.01114406e+03  1.01080853e+03  1.01423825e+03
   1.01980926e+03]
 [ 1.01440457e+03  1.00973759e+03  1.02068011e+03  1.00975680e+03
   1.01943378e+03]
 [ 1.01479276e+03  1.00944679e+03  1.00920781e+03  1.01644235e+03
   1.01108904e+03]
 [ 1.01073994e+03  1.01046438e+03  1.01172809e+03  1.01223182e+03
   1.01093822e+03]
 [ 1.01580971e+03  1.01362369e+03  1.01246142e+03  1.00985419e+03
   1.01475285e+03]
 [ 1.01075180e+03  1.00969954e+03  1.01501161e+03  1.01180053e+03
   1.01345895e+03]
 [ 1.02223844e+03  1.00973047e+03  1.01545505e+03  1.01076509e+03
   1.01914032e+03]
 [ 1.01077994e+03  1.00978779e+03  1.01955940e+03  1.00988913e+03
   1.00977097e+03]
 [ 1.01947691e+03  1.01474803e+03  1.01079321e+03  1.00988358e+03
   1.02047569e+03]
 [ 1.01081879e+03  1.00987850e+03  1.01559474e+03  1.01099523e+03
   1.01077833e+03]
 [ 1.01553931e+03  1.00988061e+03  1.01080522e+03  1.01353275e+03
   1.00998036e+03]
 [ 1.01073365e+03  1.02058754e+03  1.01096702e+03  1.01186136e+03
   1.00995187e+03]
 [ 1.01068911e+03  1.01548233e+03  1.01475244e+03  1.00978480e+03
   1.01347405e+03]
 [ 1.01656300e+03  1.00991772e+03  1.02130174e+03  1.01747941e+03
   1.02748905e+03]
 [ 1.00982243e+03  1.01185392e+03  1.00967091e+03  1.00981838e+03
   1.01188354e+03]
 [ 1.01618226e+03  1.02219101e+03  1.00990583e+03  1.01105602e+03
   1.00944066e+03]
 [ 1.01001753e+03  1.01178012e+03  1.01248192e+03  1.01091531e+03
   1.00978966e+03]
 [ 1.01156650e+03  1.00978606e+03  1.00980782e+03  1.00986445e+03
   1.01074553e+03]
 [ 1.01345570e+03  1.01078362e+03  1.00989206e+03  1.02053992e+03
   1.01382490e+03]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3601 3580 3601 3601]
 [3601 3601 3601 3601 3579]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3597 3601 3600 3601]
 [3601 3601 3601 3592 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3585 3601 3601 3601]
 [3601 3601 3601 3574 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3597 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3586 3601 3601 3601]
 [3601 3600 3601 3585 3601]
 [3601 3601 1020 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3044 3601 3601 3601]
 [3601 2348  329  183 2541]
 [1783 1521  373  604 2495]
 [3601 3601 3601  248 1074]
 [1850 2343 3275 3038 2710]
 [3601 3600   30  613 3036]
 [ 342 2065  773 2941 1490]
 [3601 3596  792 1554  731]
 [3601 3601 3601 3601 3583]
 [ 254 3601 3601 3601 3601]
 [3083 3601 1022 1647 3601]
 [3601 3599 3587 3168 1097]
 [3601 1623 3601 3601 2008]
 [ 860 2353 2887  386 3601]
 [3601 3445  154 3601 1274]
 [ 842 1634 1008 3601  303]
 [ 275  712  677 1586 1578]
 [1393 1117 1654  541  163]
 [ 695 1178  942   49  501]
 [ 387  493  292 1353  124]
 [  29  843  369  249  311]
 [ 124  193  746  165  373]
 [  37  142  304  200   57]
 [  45  354  150   93  468]
 [  43  290  148   60  138]
 [  70 1062  253   25  179]
 [ 686  439   64  385   47]
 [ 103  275  369   28  830]
 [ 463   26   91   80   99]
 [ 162  239  158  531  186]
 [  73   74  341   43   80]
 [ 179  316  138  510   55]
 [  55   68   69  119  348]
 [  45   30  110  113  469]
 [  82  372   57  117   67]
 [ 172  115   21   33  146]
 [  57   32  212  211  124]
 [  58   55   44   25  132]
 [  98   31  140   42   95]
 [ 105   87   87   39   40]
 [  69   39   58   36  136]
 [  81  110  195   59  157]
 [  65   27   34   96   23]
 [  73  597   35   43  317]
 [ 117  146  171  164   29]
 [  74   35   34   43   36]
 [  27   29   26   22   31]
 [  37   59   31   29   79]
 [  34   37   38   27   50]
 [  32   33   71   25   32]
 [  60   89   31   52   39]
 [  49   32   37   35   42]
 [  57   29   43   32   22]
 [  43   55   39   57   49]
 [  39   65   33   40   35]
 [  28   30   32   20   31]
 [  27   35   59   35   55]
 [  45   55   27   54   69]
 [  46   33   73   29   46]
 [  32   44   52   43   22]
 [  32   42   34   54   22]
 [  67   36   42   27   32]
 [  31   31   58   31   42]
 [  86   34   45   31   56]
 [  32   30   39   28   30]
 [  44   30   32   25   45]
 [  30   25   36   23   32]
 [  40   29   29   38   24]
 [  31   37   26   25   22]
 [  34   41   33   32   42]
 [  37   24   51   45   77]
 [  28   30   33   32   27]
 [  54   51   27   22   41]
 [  24   32   43   26   32]
 [  36   30   27   29   30]
 [  41   29   26   42   29]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-31_11-20-05_llm_triton_qwen_32b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-31_11-20-05_llm_triton_qwen_32b_continuous_rewards_1_example_explanation_1000000-steps_5-obs_ep-time-360.0/model
