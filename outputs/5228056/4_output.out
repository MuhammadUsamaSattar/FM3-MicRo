####################
/var/spool/slurmd/job5276944/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_7B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-23_09-59-26_llm_triton_qwen_7b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the movement of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0. You have to output the following calculations:
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 Response: 1
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 211  |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.59e+03     |
|    ep_rew_mean          | 1.97e+03     |
| time/                   |              |
|    fps                  | 9            |
|    iterations           | 2            |
|    time_elapsed         | 417          |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0127288345 |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.469        |
|    learning_rate        | 0.0003       |
|    loss                 | 34.6         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.0206      |
|    std                  | 1            |
|    value_loss           | 81           |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | 1.97e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 622         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009859102 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.467       |
|    learning_rate        | 0.0003      |
|    loss                 | 26          |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0158     |
|    std                  | 1           |
|    value_loss           | 69          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 828         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.008461245 |
|    clip_fraction        | 0.0883      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.358       |
|    learning_rate        | 0.0003      |
|    loss                 | 22.1        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0177     |
|    std                  | 1           |
|    value_loss           | 65.1        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.67 +/- 0.06
Episode length: 3601.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.7        |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0090657715 |
|    clip_fraction        | 0.1          |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.439        |
|    learning_rate        | 0.0003       |
|    loss                 | 20.3         |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.0177      |
|    std                  | 1            |
|    value_loss           | 58.4         |
------------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2834     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3040        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.008094426 |
|    clip_fraction        | 0.0694      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.0302      |
|    learning_rate        | 0.0003      |
|    loss                 | 43.8        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00828    |
|    std                  | 1           |
|    value_loss           | 991         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3245        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008962537 |
|    clip_fraction        | 0.074       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.7        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0167     |
|    std                  | 1           |
|    value_loss           | 67.1        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3451        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.009188649 |
|    clip_fraction        | 0.0775      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.613       |
|    learning_rate        | 0.0003      |
|    loss                 | 14.6        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.999       |
|    value_loss           | 55.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.43e+03    |
|    ep_rew_mean          | 1.99e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3657        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.009832282 |
|    clip_fraction        | 0.1         |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.502       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.1        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.996       |
|    value_loss           | 46.7        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.82 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.009806158 |
|    clip_fraction        | 0.0888      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.0003      |
|    loss                 | 28          |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.994       |
|    value_loss           | 60.5        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5663     |
|    total_timesteps | 20480    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 11         |
|    time_elapsed         | 5868       |
|    total_timesteps      | 22528      |
| train/                  |            |
|    approx_kl            | 0.01096567 |
|    clip_fraction        | 0.0735     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.172      |
|    learning_rate        | 0.0003     |
|    loss                 | 131        |
|    n_updates            | 100        |
|    policy_gradient_loss | -0.00716   |
|    std                  | 0.995      |
|    value_loss           | 906        |
----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.37e+03     |
|    ep_rew_mean          | 1.98e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 12           |
|    time_elapsed         | 6074         |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0113034975 |
|    clip_fraction        | 0.126        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.257        |
|    learning_rate        | 0.0003       |
|    loss                 | 14.3         |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.0152      |
|    std                  | 0.994        |
|    value_loss           | 41.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6279        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.010575912 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.0003      |
|    loss                 | 12.2        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.014      |
|    std                  | 0.991       |
|    value_loss           | 40.8        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6485        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.020546548 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.0363      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11        |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00676    |
|    std                  | 0.984       |
|    value_loss           | 3.5         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.83 +/- 0.05
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.004240499 |
|    clip_fraction        | 0.0333      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.5        |
|    learning_rate        | 0.0003      |
|    loss                 | 7.35        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00151    |
|    std                  | 0.984       |
|    value_loss           | 32.9        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2e+03    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8492     |
|    total_timesteps | 30720    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 3.33e+03      |
|    ep_rew_mean          | 2e+03         |
| time/                   |               |
|    fps                  | 3             |
|    iterations           | 16            |
|    time_elapsed         | 8698          |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00015790985 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -11.2         |
|    explained_variance   | 0.00988       |
|    learning_rate        | 0.0003        |
|    loss                 | 2.87e+03      |
|    n_updates            | 150           |
|    policy_gradient_loss | -0.000712     |
|    std                  | 0.984         |
|    value_loss           | 1.06e+03      |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 2.06e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 17           |
|    time_elapsed         | 8904         |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0006315633 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.66         |
|    learning_rate        | 0.0003       |
|    loss                 | 8.2          |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00282     |
|    std                  | 0.984        |
|    value_loss           | 26.7         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9109        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.020601928 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.181      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.826       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.983       |
|    value_loss           | 3.32        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.38e+03     |
|    ep_rew_mean          | 2.11e+03     |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 19           |
|    time_elapsed         | 9315         |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0096260505 |
|    clip_fraction        | 0.0788       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | -0.337       |
|    learning_rate        | 0.0003       |
|    loss                 | 18.6         |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00923     |
|    std                  | 0.982        |
|    value_loss           | 26.9         |
------------------------------------------
Eval num_timesteps=40000, episode_reward=-99.82 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.016566087 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0266     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.798       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.981       |
|    value_loss           | 2.21        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11321    |
|    total_timesteps | 40960    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 21         |
|    time_elapsed         | 11527      |
|    total_timesteps      | 43008      |
| train/                  |            |
|    approx_kl            | 0.00727316 |
|    clip_fraction        | 0.0798     |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.0142     |
|    learning_rate        | 0.0003     |
|    loss                 | 53         |
|    n_updates            | 200        |
|    policy_gradient_loss | -0.00293   |
|    std                  | 0.981      |
|    value_loss           | 1.02e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11733       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.014509078 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.917      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.63        |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.982       |
|    value_loss           | 3.84        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11939       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.018479157 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.0254      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00788    |
|    std                  | 0.974       |
|    value_loss           | 2.31        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.37e+03   |
|    ep_rew_mean          | 2.16e+03   |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 24         |
|    time_elapsed         | 12144      |
|    total_timesteps      | 49152      |
| train/                  |            |
|    approx_kl            | 0.01265518 |
|    clip_fraction        | 0.168      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.0857     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.826      |
|    n_updates            | 230        |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.976      |
|    value_loss           | 1.87       |
----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.89 +/- 0.02
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.004021018 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.0003      |
|    loss                 | 11.3        |
|    n_updates            | 240         |
|    policy_gradient_loss | 0.0011      |
|    std                  | 0.975       |
|    value_loss           | 34.7        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14151    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.13e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 14356        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0001458037 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.153        |
|    learning_rate        | 0.0003       |
|    loss                 | 426          |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.000857    |
|    std                  | 0.975        |
|    value_loss           | 1.09e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14562       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.014050656 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -2.89       |
|    learning_rate        | 0.0003      |
|    loss                 | 9.18        |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00866    |
|    std                  | 0.976       |
|    value_loss           | 8.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14767       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.016082112 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00938     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.712       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00567    |
|    std                  | 0.976       |
|    value_loss           | 1.3         |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 2.2e+03      |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 29           |
|    time_elapsed         | 14975        |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0056135254 |
|    clip_fraction        | 0.0835       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.784        |
|    learning_rate        | 0.0003       |
|    loss                 | 10.5         |
|    n_updates            | 280          |
|    policy_gradient_loss | 0.00281      |
|    std                  | 0.976        |
|    value_loss           | 29.3         |
------------------------------------------
Eval num_timesteps=60000, episode_reward=-99.88 +/- 0.04
Episode length: 3599.80 +/- 1.47
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 3.6e+03      |
|    mean_reward          | -99.9        |
| time/                   |              |
|    total_timesteps      | 60000        |
| train/                  |              |
|    approx_kl            | 0.0004906495 |
|    clip_fraction        | 0.000879     |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.834        |
|    learning_rate        | 0.0003       |
|    loss                 | 15.3         |
|    n_updates            | 290          |
|    policy_gradient_loss | -0.00253     |
|    std                  | 0.976        |
|    value_loss           | 23.5         |
------------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16982    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17188       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.011806451 |
|    clip_fraction        | 0.0771      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.000629    |
|    learning_rate        | 0.0003      |
|    loss                 | 87.6        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.0048     |
|    std                  | 0.975       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17394       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.021130692 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.225      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.714       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.979       |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 33          |
|    time_elapsed         | 17599       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.007473352 |
|    clip_fraction        | 0.0892      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.367       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.65        |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.00295    |
|    std                  | 0.979       |
|    value_loss           | 27.7        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 2.22e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 34           |
|    time_elapsed         | 17805        |
|    total_timesteps      | 69632        |
| train/                  |              |
|    approx_kl            | 0.0039329436 |
|    clip_fraction        | 0.00581      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.435        |
|    learning_rate        | 0.0003       |
|    loss                 | 9.84         |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.00424     |
|    std                  | 0.978        |
|    value_loss           | 31.2         |
------------------------------------------
Eval num_timesteps=70000, episode_reward=-99.87 +/- 0.04
Episode length: 3598.60 +/- 3.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.015514482 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.539      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32        |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.974       |
|    value_loss           | 1.99        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19811    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20017       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.011268086 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.000141   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23e+03    |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00306    |
|    std                  | 0.974       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 2.22e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 37           |
|    time_elapsed         | 20223        |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0035640644 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.826        |
|    learning_rate        | 0.0003       |
|    loss                 | 33.2         |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00284     |
|    std                  | 0.974        |
|    value_loss           | 52.8         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20428       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.016732555 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.775      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.67        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0098     |
|    std                  | 0.974       |
|    value_loss           | 8.17        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.36e+03     |
|    ep_rew_mean          | 2.25e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 39           |
|    time_elapsed         | 20634        |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0018070774 |
|    clip_fraction        | 0.00322      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.375        |
|    learning_rate        | 0.0003       |
|    loss                 | 4.68         |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00244     |
|    std                  | 0.974        |
|    value_loss           | 35.3         |
------------------------------------------
Eval num_timesteps=80000, episode_reward=-99.97 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.01461456 |
|    clip_fraction        | 0.168      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.0469     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.63       |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.973      |
|    value_loss           | 4.86       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22640    |
|    total_timesteps | 81920    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.25e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 41       |
|    time_elapsed         | 22845    |
|    total_timesteps      | 83968    |
| train/                  |          |
|    approx_kl            | 0.013356 |
|    clip_fraction        | 0.122    |
|    clip_range           | 0.2      |
|    entropy_loss         | -11.1    |
|    explained_variance   | -0.00287 |
|    learning_rate        | 0.0003   |
|    loss                 | 6.78     |
|    n_updates            | 400      |
|    policy_gradient_loss | -0.008   |
|    std                  | 0.974    |
|    value_loss           | 1.05e+03 |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23052       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.020903394 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.159      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.742       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00442    |
|    std                  | 0.968       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23260       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.015095305 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0442      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.544       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00729    |
|    std                  | 0.971       |
|    value_loss           | 1.03        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.89 +/- 0.13
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.013095768 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.027       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.524       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.971       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.25e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25268    |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.25e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 45           |
|    time_elapsed         | 25473        |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0051701954 |
|    clip_fraction        | 0.0481       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | -0.011       |
|    learning_rate        | 0.0003       |
|    loss                 | 694          |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.000959    |
|    std                  | 0.971        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25679       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.017256439 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.807      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.759       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.97        |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25884       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.017156903 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0293      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.971       |
|    value_loss           | 1.21        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 2.29e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 48           |
|    time_elapsed         | 26090        |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0037544572 |
|    clip_fraction        | 0.0308       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.542        |
|    learning_rate        | 0.0003       |
|    loss                 | 20.7         |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.971        |
|    value_loss           | 20.5         |
------------------------------------------
Eval num_timesteps=100000, episode_reward=-99.98 +/- 0.05
Episode length: 3596.40 +/- 8.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.019008879 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.426      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.407       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.967       |
|    value_loss           | 4.24        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28096    |
|    total_timesteps | 100352   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.27e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 50           |
|    time_elapsed         | 28302        |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0051384824 |
|    clip_fraction        | 0.0489       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.1        |
|    explained_variance   | 0.0558       |
|    learning_rate        | 0.0003       |
|    loss                 | 1.24e+03     |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.0015      |
|    std                  | 0.967        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28507       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.006680875 |
|    clip_fraction        | 0.04        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.4         |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0084     |
|    std                  | 0.966       |
|    value_loss           | 12.7        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28713       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.010194206 |
|    clip_fraction        | 0.0728      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.81        |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.966       |
|    value_loss           | 10.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28919       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.022095315 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.316      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.615       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00802    |
|    std                  | 0.965       |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.85 +/- 0.10
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.010099758 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.11        |
|    n_updates            | 530         |
|    policy_gradient_loss | 0.00183     |
|    std                  | 0.964       |
|    value_loss           | 44.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30925    |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 55         |
|    time_elapsed         | 31130      |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.01848786 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.000536   |
|    learning_rate        | 0.0003     |
|    loss                 | 522        |
|    n_updates            | 540        |
|    policy_gradient_loss | -0.00506   |
|    std                  | 0.966      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31336       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.022186957 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.134      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.584       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00534    |
|    std                  | 0.96        |
|    value_loss           | 1.22        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31542       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.015859185 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -3.34       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.592       |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.962       |
|    value_loss           | 7.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31747       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.015355329 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0114     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.799       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0055     |
|    std                  | 0.962       |
|    value_loss           | 1.17        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.94 +/- 0.10
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.016928209 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.0191      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.381       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00794    |
|    std                  | 0.965       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33754    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 33959       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.006634999 |
|    clip_fraction        | 0.072       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0189      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54e+03    |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00154    |
|    std                  | 0.965       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34165       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.019350458 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0195     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.72        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00354    |
|    std                  | 0.958       |
|    value_loss           | 1.42        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 2.32e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 62           |
|    time_elapsed         | 34371        |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0136427805 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | -5.73        |
|    learning_rate        | 0.0003       |
|    loss                 | 2.34         |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.00603     |
|    std                  | 0.959        |
|    value_loss           | 5.5          |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34576       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.017434064 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0102     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.468       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00737    |
|    std                  | 0.962       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.96 +/- 0.09
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.012229143 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0003      |
|    loss                 | 10.8        |
|    n_updates            | 630         |
|    policy_gradient_loss | 0.000512    |
|    std                  | 0.962       |
|    value_loss           | 34.3        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36583    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.32e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 65           |
|    time_elapsed         | 36788        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0015944624 |
|    clip_fraction        | 0.0041       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11          |
|    explained_variance   | 0.0551       |
|    learning_rate        | 0.0003       |
|    loss                 | 14           |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.962        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.33e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 36994       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.018310811 |
|    clip_fraction        | 0.145       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -2.75       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.517       |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.00617    |
|    std                  | 0.966       |
|    value_loss           | 1.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37199       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.019550238 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8         |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00919    |
|    std                  | 0.966       |
|    value_loss           | 8.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37405       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.016895954 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.799      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00448    |
|    std                  | 0.966       |
|    value_loss           | 2.45        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.82 +/- 0.21
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.019363353 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.00382     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.718       |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.00629    |
|    std                  | 0.962       |
|    value_loss           | 1.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39412    |
|    total_timesteps | 141312   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 70         |
|    time_elapsed         | 39617      |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.01033285 |
|    clip_fraction        | 0.114      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | -0.00224   |
|    learning_rate        | 0.0003     |
|    loss                 | 18.6       |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.00393   |
|    std                  | 0.962      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39823       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.016522396 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.335      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19        |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.961       |
|    value_loss           | 2.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40029       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.021101749 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.163      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.531       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00571    |
|    std                  | 0.959       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40235       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.020459553 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.52        |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0039     |
|    std                  | 0.961       |
|    value_loss           | 2.06        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.81 +/- 0.18
Episode length: 3600.20 +/- 1.17
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.020304404 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.0126      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.413       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00661    |
|    std                  | 0.957       |
|    value_loss           | 0.941       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42244    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42450       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.012690845 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.00019    |
|    learning_rate        | 0.0003      |
|    loss                 | 139         |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00108    |
|    std                  | 0.957       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42655       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.022351876 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.941       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.758       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0066     |
|    std                  | 0.954       |
|    value_loss           | 2.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42861       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.018350996 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.793      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.96        |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.00128    |
|    std                  | 0.955       |
|    value_loss           | 3.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43066       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.006223618 |
|    clip_fraction        | 0.0494      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.621       |
|    learning_rate        | 0.0003      |
|    loss                 | 7.67        |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00744    |
|    std                  | 0.955       |
|    value_loss           | 21.9        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.97 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.021223586 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.0926     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.537       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.949       |
|    value_loss           | 1.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45072    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45278       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.012934488 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.00359     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.49        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00916    |
|    std                  | 0.951       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45484       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.025743663 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.481       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00766    |
|    std                  | 0.948       |
|    value_loss           | 1.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45689       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.021424517 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00508    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00717    |
|    std                  | 0.941       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45895       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.017779239 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -1.93       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.03        |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.00212    |
|    std                  | 0.944       |
|    value_loss           | 4.03        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.89 +/- 0.07
Episode length: 3598.00 +/- 4.65
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.022450812 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.497      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.471       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00872    |
|    std                  | 0.94        |
|    value_loss           | 1.26        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47901    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48107       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.003939004 |
|    clip_fraction        | 0.0286      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.0325      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.35e+03    |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00022    |
|    std                  | 0.94        |
|    value_loss           | 934         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.37e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48312       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.018609583 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.604       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00612    |
|    std                  | 0.935       |
|    value_loss           | 1.72        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 87         |
|    time_elapsed         | 48518      |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.02066189 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.00731   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.819      |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.00852   |
|    std                  | 0.936      |
|    value_loss           | 1.24       |
----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.96 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.014411004 |
|    clip_fraction        | 0.15        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.155      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.59        |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00906    |
|    std                  | 0.937       |
|    value_loss           | 3.69        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50525    |
|    total_timesteps | 180224   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 89         |
|    time_elapsed         | 50730      |
|    total_timesteps      | 182272     |
| train/                  |            |
|    approx_kl            | 0.00518078 |
|    clip_fraction        | 0.0421     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.00232    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.74e+03   |
|    n_updates            | 880        |
|    policy_gradient_loss | -0.00542   |
|    std                  | 0.936      |
|    value_loss           | 1.07e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 50936       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.013863975 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.715       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00818    |
|    std                  | 0.938       |
|    value_loss           | 1.96        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51141       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.021583416 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0216     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.457       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00582    |
|    std                  | 0.939       |
|    value_loss           | 0.966       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51347       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.013302346 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.76        |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.94        |
|    value_loss           | 2.84        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.96 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.02483756 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | -0.132     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.329      |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.00649   |
|    std                  | 0.934      |
|    value_loss           | 0.906      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53353    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 94          |
|    time_elapsed         | 53559       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.017161377 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0124     |
|    learning_rate        | 0.0003      |
|    loss                 | 274         |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.0056     |
|    std                  | 0.934       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53764       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.021234639 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.143      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.499       |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00567    |
|    std                  | 0.936       |
|    value_loss           | 0.973       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 53970       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.011631783 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.38        |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.936       |
|    value_loss           | 2.89        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54176       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.013683417 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.396       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.935       |
|    value_loss           | 2.28        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.94 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.013457468 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.628       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.591       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00725    |
|    std                  | 0.933       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56183    |
|    total_timesteps | 200704   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 99         |
|    time_elapsed         | 56389      |
|    total_timesteps      | 202752     |
| train/                  |            |
|    approx_kl            | 0.01811443 |
|    clip_fraction        | 0.121      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.000278   |
|    learning_rate        | 0.0003     |
|    loss                 | 490        |
|    n_updates            | 980        |
|    policy_gradient_loss | -0.00403   |
|    std                  | 0.932      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56594       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.037913606 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.184      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.501       |
|    n_updates            | 990         |
|    policy_gradient_loss | -0.00866    |
|    std                  | 0.93        |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56801       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.021488767 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.002      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.00493    |
|    std                  | 0.927       |
|    value_loss           | 0.883       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57008       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.022246305 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.101       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.006      |
|    std                  | 0.931       |
|    value_loss           | 0.928       |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.93 +/- 0.03
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.016427103 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.327       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.618       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.928       |
|    value_loss           | 1.63        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59014    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59219       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.008198162 |
|    clip_fraction        | 0.0774      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.000705    |
|    learning_rate        | 0.0003      |
|    loss                 | 84.7        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00534    |
|    std                  | 0.928       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59425       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.018525552 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0566     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.451       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00707    |
|    std                  | 0.926       |
|    value_loss           | 1.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 106         |
|    time_elapsed         | 59630       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.013091043 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.848       |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00718    |
|    std                  | 0.927       |
|    value_loss           | 2.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.4e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 59836      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.01960499 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.961      |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.00888   |
|    std                  | 0.924      |
|    value_loss           | 2.5        |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.95 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.029262211 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.0528     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.00508    |
|    std                  | 0.917       |
|    value_loss           | 0.994       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.39e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61842    |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.39e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 109       |
|    time_elapsed         | 62048     |
|    total_timesteps      | 223232    |
| train/                  |           |
|    approx_kl            | 0.0144305 |
|    clip_fraction        | 0.126     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.6     |
|    explained_variance   | -0.000629 |
|    learning_rate        | 0.0003    |
|    loss                 | 112       |
|    n_updates            | 1080      |
|    policy_gradient_loss | -0.00597  |
|    std                  | 0.917     |
|    value_loss           | 1.06e+03  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 110         |
|    time_elapsed         | 62253       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.020958323 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.411       |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.917       |
|    value_loss           | 1.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62459       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.024878373 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.362       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.703       |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00782    |
|    std                  | 0.911       |
|    value_loss           | 1.56        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 62665       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.029327273 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.0262     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.00796    |
|    std                  | 0.913       |
|    value_loss           | 0.942       |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.92 +/- 0.03
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 230000   |
| train/                  |          |
|    approx_kl            | 0.02566  |
|    clip_fraction        | 0.261    |
|    clip_range           | 0.2      |
|    entropy_loss         | -10.6    |
|    explained_variance   | 0.224    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.791    |
|    n_updates            | 1120     |
|    policy_gradient_loss | -0.0114  |
|    std                  | 0.91     |
|    value_loss           | 1.11     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.4e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64671    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.4e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64877       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.008021573 |
|    clip_fraction        | 0.0756      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00104    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.16e+03    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00297    |
|    std                  | 0.91        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65083       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.017093422 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.103      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00763    |
|    std                  | 0.913       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65288       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.018928818 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.588       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00803    |
|    std                  | 0.907       |
|    value_loss           | 1.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65494       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.017739648 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0413      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.532       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00702    |
|    std                  | 0.908       |
|    value_loss           | 0.896       |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.89 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.017591309 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.014      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.613       |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00454    |
|    std                  | 0.908       |
|    value_loss           | 1.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67500    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67706       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.013324662 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00119     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.7e+03     |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00731    |
|    std                  | 0.908       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.41e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67911       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.019522373 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.391       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00578    |
|    std                  | 0.906       |
|    value_loss           | 2           |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68117       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.022471242 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.202       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.778       |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.00943    |
|    std                  | 0.907       |
|    value_loss           | 1.63        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68323       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.017873451 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.0149      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.436       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.899       |
|    value_loss           | 0.903       |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.99 +/- 0.02
Episode length: 3599.40 +/- 2.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.023460332 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.057       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00878    |
|    std                  | 0.901       |
|    value_loss           | 1.17        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70329    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70534       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.013803361 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.00014    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.25e+03    |
|    n_updates            | 1230        |
|    policy_gradient_loss | -0.00377    |
|    std                  | 0.901       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70740       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.013200942 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.182      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.1         |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.00537    |
|    std                  | 0.899       |
|    value_loss           | 9.73        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70945       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.025899678 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0192     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.446       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00479    |
|    std                  | 0.897       |
|    value_loss           | 1.2         |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.98 +/- 0.06
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.014725549 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.539       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.498       |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.0074     |
|    std                  | 0.895       |
|    value_loss           | 2.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72952    |
|    total_timesteps | 260096   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 2.42e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 128          |
|    time_elapsed         | 73158        |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0065005184 |
|    clip_fraction        | 0.0723       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.4        |
|    explained_variance   | -0.000464    |
|    learning_rate        | 0.0003       |
|    loss                 | 6.27         |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.00138     |
|    std                  | 0.895        |
|    value_loss           | 1.06e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.43e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 73363      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.02076472 |
|    clip_fraction        | 0.233      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -1         |
|    learning_rate        | 0.0003     |
|    loss                 | 0.446      |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.00331   |
|    std                  | 0.898      |
|    value_loss           | 1.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73569       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.020824073 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.256       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79        |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00989    |
|    std                  | 0.897       |
|    value_loss           | 1.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 73776       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.021602914 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0149     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.476       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.89        |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.94 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.017196374 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.398       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00587    |
|    std                  | 0.883       |
|    value_loss           | 1.36        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.42e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75782    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.42e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 75988       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.012507911 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.000476    |
|    learning_rate        | 0.0003      |
|    loss                 | 948         |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00396    |
|    std                  | 0.883       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 134         |
|    time_elapsed         | 76193       |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.030062495 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00682    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.433       |
|    n_updates            | 1330        |
|    policy_gradient_loss | -0.00418    |
|    std                  | 0.892       |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76399       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.027307635 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.0557     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.558       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00599    |
|    std                  | 0.89        |
|    value_loss           | 1.33        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 76604       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.025587097 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.00251     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.492       |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00368    |
|    std                  | 0.883       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.97 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -100       |
| time/                   |            |
|    total_timesteps      | 280000     |
| train/                  |            |
|    approx_kl            | 0.01950987 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.00474    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.524      |
|    n_updates            | 1360       |
|    policy_gradient_loss | -0.0048    |
|    std                  | 0.874      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.43e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78610    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.43e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78816       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.015329687 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00164    |
|    learning_rate        | 0.0003      |
|    loss                 | 125         |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00417    |
|    std                  | 0.875       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 79022       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.018747535 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0121     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.47        |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00289    |
|    std                  | 0.88        |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79227       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.022122031 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.354       |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00381    |
|    std                  | 0.879       |
|    value_loss           | 0.816       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 141         |
|    time_elapsed         | 79433       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.019157145 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0168      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.449       |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.00709    |
|    std                  | 0.881       |
|    value_loss           | 0.953       |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.90 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.024675872 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -2.27       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.491       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.886       |
|    value_loss           | 0.963       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81439    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 81646       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.010432394 |
|    clip_fraction        | 0.0887      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.000326   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.76        |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00235    |
|    std                  | 0.885       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 81851       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.021133134 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0168     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.465       |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.00648    |
|    std                  | 0.884       |
|    value_loss           | 1.02        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82057       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.021351926 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.335       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.348       |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00931    |
|    std                  | 0.879       |
|    value_loss           | 1.62        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 82262      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.01878301 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.011      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.422      |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.00723   |
|    std                  | 0.877      |
|    value_loss           | 0.966      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.91 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.018983513 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -2.74       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.422       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00504    |
|    std                  | 0.877       |
|    value_loss           | 2.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84271    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.44e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 84476       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.009432562 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.000178   |
|    learning_rate        | 0.0003      |
|    loss                 | 270         |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00432    |
|    std                  | 0.877       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84682       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.021291208 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0848     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.537       |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.00259    |
|    std                  | 0.881       |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.45e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 150       |
|    time_elapsed         | 84887     |
|    total_timesteps      | 307200    |
| train/                  |           |
|    approx_kl            | 0.0203497 |
|    clip_fraction        | 0.222     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.3     |
|    explained_variance   | 0.336     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.451     |
|    n_updates            | 1490      |
|    policy_gradient_loss | -0.00543  |
|    std                  | 0.879     |
|    value_loss           | 1.34      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.45e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85093      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.02577003 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.191      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.481      |
|    n_updates            | 1500       |
|    policy_gradient_loss | -0.00821   |
|    std                  | 0.876      |
|    value_loss           | 0.952      |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.92 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.017326172 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0305      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.378       |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.00458    |
|    std                  | 0.877       |
|    value_loss           | 0.826       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.45e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87099    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87305       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.011355953 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00272    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.59        |
|    n_updates            | 1520        |
|    policy_gradient_loss | -0.00498    |
|    std                  | 0.877       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 87511       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.019251078 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0113      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00405    |
|    std                  | 0.872       |
|    value_loss           | 0.89        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 87717       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.019811204 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.105       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00611    |
|    std                  | 0.873       |
|    value_loss           | 0.968       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 87923       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.017058607 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.327       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.359       |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00593    |
|    std                  | 0.872       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.93 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.025029851 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0121      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00139    |
|    std                  | 0.872       |
|    value_loss           | 0.843       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.45e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89929    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90135       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.009211512 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00144    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.54        |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00287    |
|    std                  | 0.872       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90340       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.024456907 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0402      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.442       |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00914    |
|    std                  | 0.871       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 160         |
|    time_elapsed         | 90548       |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.025047217 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.0731     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.511       |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.872       |
|    value_loss           | 0.995       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 161        |
|    time_elapsed         | 90755      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.02047569 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.355      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 1600       |
|    policy_gradient_loss | -0.0122    |
|    std                  | 0.872      |
|    value_loss           | 1.44       |
----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.86 +/- 0.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.018782686 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0036      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00264    |
|    std                  | 0.875       |
|    value_loss           | 0.93        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.46e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92761    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 92967      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.01546547 |
|    clip_fraction        | 0.178      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.000645  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.99       |
|    n_updates            | 1620       |
|    policy_gradient_loss | -0.00494   |
|    std                  | 0.875      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.46e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93172       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.018021507 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.151      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.48        |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.00405    |
|    std                  | 0.876       |
|    value_loss           | 0.919       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93378       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.019581141 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.382       |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.00523    |
|    std                  | 0.875       |
|    value_loss           | 0.908       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.47e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 93584       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.020016968 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0337      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.529       |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.00804    |
|    std                  | 0.877       |
|    value_loss           | 1.05        |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.93 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.018161662 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0469      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.466       |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.874       |
|    value_loss           | 0.986       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.47e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95590    |
|    total_timesteps | 342016   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 168         |
|    time_elapsed         | 95795       |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.012663984 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.000414    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.94e+03    |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.873       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 96001       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.022046428 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.347      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.405       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.00703    |
|    std                  | 0.871       |
|    value_loss           | 0.945       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 96206       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.019737087 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0629      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.386       |
|    n_updates            | 1690        |
|    policy_gradient_loss | -0.00653    |
|    std                  | 0.867       |
|    value_loss           | 0.796       |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.94 +/- 0.06
Episode length: 3598.00 +/- 5.06
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 350000    |
| train/                  |           |
|    approx_kl            | 0.0205471 |
|    clip_fraction        | 0.231     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | 0.0119    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.455     |
|    n_updates            | 1700      |
|    policy_gradient_loss | -0.00717  |
|    std                  | 0.869     |
|    value_loss           | 1.01      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98213    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.49e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98418       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.011819718 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00111    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.59e+03    |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00596    |
|    std                  | 0.868       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 98624       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.021578591 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.0941     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.322       |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00329    |
|    std                  | 0.866       |
|    value_loss           | 0.82        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 98829       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.021716032 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.23        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.00753    |
|    std                  | 0.861       |
|    value_loss           | 0.869       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 175         |
|    time_elapsed         | 99035       |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.022738576 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0385      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.281       |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.00684    |
|    std                  | 0.857       |
|    value_loss           | 0.839       |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.89 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.028069906 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 1750        |
|    policy_gradient_loss | -0.009      |
|    std                  | 0.854       |
|    value_loss           | 1.46        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.5e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101041   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.5e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101246      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.017106568 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.00034    |
|    learning_rate        | 0.0003      |
|    loss                 | 167         |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00531    |
|    std                  | 0.854       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 178         |
|    time_elapsed         | 101452      |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.023925684 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.05       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.241       |
|    n_updates            | 1770        |
|    policy_gradient_loss | -0.00624    |
|    std                  | 0.854       |
|    value_loss           | 0.806       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 101660      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.019745838 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.325       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.453       |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.846       |
|    value_loss           | 1.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 101866      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.025367498 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.0405      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.509       |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00719    |
|    std                  | 0.846       |
|    value_loss           | 0.911       |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.90 +/- 0.05
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 370000    |
| train/                  |           |
|    approx_kl            | 0.0215673 |
|    clip_fraction        | 0.231     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.98     |
|    explained_variance   | 0.499     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.349     |
|    n_updates            | 1800      |
|    policy_gradient_loss | -0.00512  |
|    std                  | 0.85      |
|    value_loss           | 0.939     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.51e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103872   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.51e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104078      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.022481486 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | 0.000199    |
|    learning_rate        | 0.0003      |
|    loss                 | 661         |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00059    |
|    std                  | 0.85        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 183         |
|    time_elapsed         | 104283      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.038051732 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.0255     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.677       |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.00439    |
|    std                  | 0.847       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 184         |
|    time_elapsed         | 104489      |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.024938222 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.0316      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.376       |
|    n_updates            | 1830        |
|    policy_gradient_loss | 0.000386    |
|    std                  | 0.846       |
|    value_loss           | 0.794       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 104694      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.027012868 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.0124      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.273       |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.0052     |
|    std                  | 0.846       |
|    value_loss           | 0.707       |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.96 +/- 0.03
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.018219754 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.0401      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.491       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.00103    |
|    std                  | 0.848       |
|    value_loss           | 0.957       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.52e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106701   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.52e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 106906      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.012205857 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.000301   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.41        |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.00481    |
|    std                  | 0.848       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 188         |
|    time_elapsed         | 107112      |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.033206254 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | -0.0711     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.411       |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.00344    |
|    std                  | 0.852       |
|    value_loss           | 0.81        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.53e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107317      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.029233368 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.849      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.533       |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.00438    |
|    std                  | 0.85        |
|    value_loss           | 0.978       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 190         |
|    time_elapsed         | 107523      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.024286266 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.0452      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.5         |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.846       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.87 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.03179507 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.00115    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.432      |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.0054    |
|    std                  | 0.846      |
|    value_loss           | 0.687      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.53e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109530   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.53e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 109736     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.01949127 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.95      |
|    explained_variance   | 0.000635   |
|    learning_rate        | 0.0003     |
|    loss                 | 67.4       |
|    n_updates            | 1910       |
|    policy_gradient_loss | -0.00883   |
|    std                  | 0.847      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 193         |
|    time_elapsed         | 109942      |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.020820878 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | -0.126      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.000108   |
|    std                  | 0.847       |
|    value_loss           | 0.848       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110147      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.024687195 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.0013      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.479       |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.00624    |
|    std                  | 0.847       |
|    value_loss           | 0.883       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110353      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.021845452 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | -0.0231     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.244       |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00332    |
|    std                  | 0.845       |
|    value_loss           | 0.732       |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.89 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.020752817 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.0273      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.528       |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.00827    |
|    std                  | 0.841       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.54e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112359   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112564      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.017863194 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | 0.00109     |
|    learning_rate        | 0.0003      |
|    loss                 | 275         |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.00316    |
|    std                  | 0.841       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 198         |
|    time_elapsed         | 112770      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.024241647 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | -0.0419     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.303       |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0086     |
|    std                  | 0.84        |
|    value_loss           | 0.764       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 199         |
|    time_elapsed         | 112975      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.029656786 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.0728      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.441       |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.838       |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.55e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 200         |
|    time_elapsed         | 113181      |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.020703945 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -7.02       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.425       |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.838       |
|    value_loss           | 1.48        |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.88 +/- 0.05
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.022851868 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | 0.0543      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.486       |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00267    |
|    std                  | 0.84        |
|    value_loss           | 0.699       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.54e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115187   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 202         |
|    time_elapsed         | 115393      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.013610666 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.9        |
|    explained_variance   | -0.000256   |
|    learning_rate        | 0.0003      |
|    loss                 | 131         |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.842       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 203         |
|    time_elapsed         | 115598      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.026360597 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.88       |
|    explained_variance   | -0.0392     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.394       |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00913    |
|    std                  | 0.837       |
|    value_loss           | 0.886       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 115804      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.025591815 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.018       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.475       |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.00252    |
|    std                  | 0.838       |
|    value_loss           | 0.885       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 205         |
|    time_elapsed         | 116009      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.024252728 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.0346      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.477       |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00387    |
|    std                  | 0.838       |
|    value_loss           | 1.2         |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.87 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.017742435 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.0511      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.343       |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.00289    |
|    std                  | 0.837       |
|    value_loss           | 0.745       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.55e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118015   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118221      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.013809827 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.000174    |
|    learning_rate        | 0.0003      |
|    loss                 | 424         |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.0034     |
|    std                  | 0.837       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.56e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118427     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.02174428 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.88      |
|    explained_variance   | -0.0221    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.427      |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.00297   |
|    std                  | 0.841      |
|    value_loss           | 0.94       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 209         |
|    time_elapsed         | 118636      |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.026738593 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.0333      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.359       |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.00618    |
|    std                  | 0.844       |
|    value_loss           | 0.854       |
-----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.88 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.016656352 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | -4.25       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.449       |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.00387    |
|    std                  | 0.845       |
|    value_loss           | 2.76        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.56e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120644   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 120850      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.011508908 |
|    clip_fraction        | 0.164       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | -0.000334   |
|    learning_rate        | 0.0003      |
|    loss                 | 239         |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00665    |
|    std                  | 0.846       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 212         |
|    time_elapsed         | 121055      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.028009148 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.13       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.469       |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.00599    |
|    std                  | 0.85        |
|    value_loss           | 0.891       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121261      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.028478894 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.379       |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.00793    |
|    std                  | 0.849       |
|    value_loss           | 0.991       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 121466      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.022483319 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.0563      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.365       |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.00465    |
|    std                  | 0.85        |
|    value_loss           | 0.762       |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.93 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.029467119 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | 0.0351      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.387       |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.00191    |
|    std                  | 0.847       |
|    value_loss           | 0.816       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.56e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123473   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.56e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123678      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.015928058 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 0.000314    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.32e+03    |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00347    |
|    std                  | 0.846       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.57e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 217        |
|    time_elapsed         | 123884     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.03480797 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.91      |
|    explained_variance   | -0.0713    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.323      |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.00228   |
|    std                  | 0.843      |
|    value_loss           | 0.838      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.57e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 218       |
|    time_elapsed         | 124089    |
|    total_timesteps      | 446464    |
| train/                  |           |
|    approx_kl            | 0.0188393 |
|    clip_fraction        | 0.247     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.89     |
|    explained_variance   | -0.00144  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.678     |
|    n_updates            | 2170      |
|    policy_gradient_loss | -0.00636  |
|    std                  | 0.841     |
|    value_loss           | 0.88      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124295      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.020870317 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.0249      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.3         |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.0083     |
|    std                  | 0.836       |
|    value_loss           | 0.937       |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.94 +/- 0.09
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.03178847 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.83      |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.675      |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.00621   |
|    std                  | 0.838      |
|    value_loss           | 0.964      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.57e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126301   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 126507      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.023672905 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.000264   |
|    learning_rate        | 0.0003      |
|    loss                 | 806         |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00751    |
|    std                  | 0.838       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 222         |
|    time_elapsed         | 126713      |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.026463252 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -0.0625     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.317       |
|    n_updates            | 2210        |
|    policy_gradient_loss | 2.25e-05    |
|    std                  | 0.835       |
|    value_loss           | 0.966       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 126918      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.024753496 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | -1.16       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.483       |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.00588    |
|    std                  | 0.832       |
|    value_loss           | 4.33        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 224        |
|    time_elapsed         | 127124     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.02068706 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.8       |
|    explained_variance   | 0.00474    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.302      |
|    n_updates            | 2230       |
|    policy_gradient_loss | -0.00441   |
|    std                  | 0.833      |
|    value_loss           | 0.824      |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.90 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.027627576 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | 0.0211      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.309       |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.00527    |
|    std                  | 0.834       |
|    value_loss           | 0.853       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.57e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129130   |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.57e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 226        |
|    time_elapsed         | 129336     |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.02852222 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.84      |
|    explained_variance   | -0.000418  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.81       |
|    n_updates            | 2250       |
|    policy_gradient_loss | -0.00456   |
|    std                  | 0.837      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 227         |
|    time_elapsed         | 129541      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.024936715 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | -0.0729     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.321       |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0058     |
|    std                  | 0.836       |
|    value_loss           | 0.964       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 129747      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.020264834 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.311       |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.00282    |
|    std                  | 0.835       |
|    value_loss           | 0.818       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 129953      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.019942226 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.0618      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.567       |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.000689   |
|    std                  | 0.837       |
|    value_loss           | 0.844       |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.87 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.024861947 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | -9.74       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.00236    |
|    std                  | 0.836       |
|    value_loss           | 2.69        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131960   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 132165      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.015392226 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -0.000406   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.45        |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.00603    |
|    std                  | 0.835       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 232         |
|    time_elapsed         | 132371      |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.032519873 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | -0.136      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.324       |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.00479    |
|    std                  | 0.835       |
|    value_loss           | 0.905       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 233         |
|    time_elapsed         | 132578      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.023223076 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.83       |
|    explained_variance   | 0.0133      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.00831    |
|    std                  | 0.835       |
|    value_loss           | 0.813       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 234         |
|    time_elapsed         | 132784      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.021605313 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | 0.031       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.42        |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.0045     |
|    std                  | 0.832       |
|    value_loss           | 0.826       |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.84 +/- 0.03
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.024443047 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 0.0364      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.422       |
|    n_updates            | 2340        |
|    policy_gradient_loss | -0.00822    |
|    std                  | 0.831       |
|    value_loss           | 0.665       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134790   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 134995      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.012772567 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | 1.54e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+03    |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00325    |
|    std                  | 0.832       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 237         |
|    time_elapsed         | 135201      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.022957474 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.77       |
|    explained_variance   | -0.109      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.409       |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00498    |
|    std                  | 0.827       |
|    value_loss           | 0.869       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 135406      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.018176995 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | 0.0274      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.00557    |
|    std                  | 0.827       |
|    value_loss           | 0.881       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.59e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 239         |
|    time_elapsed         | 135613      |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.026248286 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | 0.0212      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.427       |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.000115   |
|    std                  | 0.824       |
|    value_loss           | 0.827       |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.94 +/- 0.08
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.021679195 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.0334      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.564       |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.000336    |
|    std                  | 0.82        |
|    value_loss           | 0.876       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137619   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.58e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 137825     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.01894174 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.69      |
|    explained_variance   | -1.05e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 21.9       |
|    n_updates            | 2400       |
|    policy_gradient_loss | -0.00562   |
|    std                  | 0.819      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 242         |
|    time_elapsed         | 138031      |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.020248089 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.66       |
|    explained_variance   | -0.0881     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.354       |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.815       |
|    value_loss           | 0.892       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 138236      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.020972114 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | -0.283      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.00975    |
|    std                  | 0.811       |
|    value_loss           | 2.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.6e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 244        |
|    time_elapsed         | 138442     |
|    total_timesteps      | 499712     |
| train/                  |            |
|    approx_kl            | 0.02981216 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | 0.136      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.35       |
|    n_updates            | 2430       |
|    policy_gradient_loss | -0.00415   |
|    std                  | 0.809      |
|    value_loss           | 0.836      |
----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.87 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.026472947 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.0314      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.00377    |
|    std                  | 0.807       |
|    value_loss           | 0.851       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.59e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140448   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 140653      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.018700069 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | -0.000547   |
|    learning_rate        | 0.0003      |
|    loss                 | 83.2        |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00124    |
|    std                  | 0.806       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 140859      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.030805584 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.48       |
|    explained_variance   | -0.047      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.343       |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.00153    |
|    std                  | 0.798       |
|    value_loss           | 0.822       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 141064      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.030547718 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | 0.00989     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.392       |
|    n_updates            | 2470        |
|    policy_gradient_loss | 0.00072     |
|    std                  | 0.801       |
|    value_loss           | 0.806       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141270      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.024249664 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | -0.989      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.345       |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.00429    |
|    std                  | 0.798       |
|    value_loss           | 1.56        |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.91 +/- 0.03
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.02616344 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | 0.0426     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 2490       |
|    policy_gradient_loss | -0.000787  |
|    std                  | 0.793      |
|    value_loss           | 0.647      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.59e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143276   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 143482      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.025780229 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | 2.09e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.51        |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00476    |
|    std                  | 0.793       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 143687      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.032167308 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | -4.37       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 2510        |
|    policy_gradient_loss | -8.9e-05    |
|    std                  | 0.791       |
|    value_loss           | 0.913       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 143893      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.029630423 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.016       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.438       |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.00147    |
|    std                  | 0.79        |
|    value_loss           | 0.803       |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.026182769 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.35       |
|    explained_variance   | 0.158       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.364       |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.00712    |
|    std                  | 0.787       |
|    value_loss           | 0.917       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145899   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146105      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.018739194 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | -0.000195   |
|    learning_rate        | 0.0003      |
|    loss                 | 348         |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00398    |
|    std                  | 0.787       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 256         |
|    time_elapsed         | 146311      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.032311913 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | -0.224      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.47        |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.00332    |
|    std                  | 0.791       |
|    value_loss           | 0.795       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 146516      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.021950811 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.4        |
|    explained_variance   | 0.0179      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.362       |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.000228   |
|    std                  | 0.794       |
|    value_loss           | 0.794       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 146722     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.02217833 |
|    clip_fraction        | 0.229      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.0255     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.421      |
|    n_updates            | 2570       |
|    policy_gradient_loss | -0.00323   |
|    std                  | 0.794      |
|    value_loss           | 0.848      |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.86 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.028760424 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.161       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.35        |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.00683    |
|    std                  | 0.791       |
|    value_loss           | 1.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148728   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 148933      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.013637403 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | 0.000393    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.43e+03    |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.00298    |
|    std                  | 0.79        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 149141      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.025079586 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | -0.0478     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.00212    |
|    std                  | 0.792       |
|    value_loss           | 0.82        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.61e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 262        |
|    time_elapsed         | 149348     |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.02671171 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.4       |
|    explained_variance   | 0.0947     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 2610       |
|    policy_gradient_loss | -0.0044    |
|    std                  | 0.794      |
|    value_loss           | 0.73       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 149554      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.028153237 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.0257      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.00025    |
|    std                  | 0.794       |
|    value_loss           | 0.926       |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.82 +/- 0.02
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.024508234 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -1.82       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.284       |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.000785   |
|    std                  | 0.799       |
|    value_loss           | 0.9         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151560   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.6e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 151765      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.024057971 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | -0.000643   |
|    learning_rate        | 0.0003      |
|    loss                 | 6.06        |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.00301    |
|    std                  | 0.797       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 266         |
|    time_elapsed         | 151971      |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.029332116 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | -0.22       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.377       |
|    n_updates            | 2650        |
|    policy_gradient_loss | 0.00116     |
|    std                  | 0.796       |
|    value_loss           | 0.817       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 152176      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.026942916 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.0603      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 2660        |
|    policy_gradient_loss | 0.00148     |
|    std                  | 0.795       |
|    value_loss           | 0.847       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 152383      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.029688384 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | 0.0455      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.326       |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.00568    |
|    std                  | 0.792       |
|    value_loss           | 0.868       |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-99.87 +/- 0.04
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.020237975 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.073       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.483       |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.0043     |
|    std                  | 0.792       |
|    value_loss           | 0.936       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154389   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 154594      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.019055787 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.37       |
|    explained_variance   | 0.00161     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.17e+03    |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00454    |
|    std                  | 0.793       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 271         |
|    time_elapsed         | 154801      |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.020866334 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.38       |
|    explained_variance   | -0.501      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.306       |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.00277    |
|    std                  | 0.794       |
|    value_loss           | 0.845       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 272         |
|    time_elapsed         | 155007      |
|    total_timesteps      | 557056      |
| train/                  |             |
|    approx_kl            | 0.025256857 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.39       |
|    explained_variance   | -7.98       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.322       |
|    n_updates            | 2710        |
|    policy_gradient_loss | -0.00171    |
|    std                  | 0.795       |
|    value_loss           | 4.8         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.62e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 155213     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.04845594 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.39      |
|    explained_variance   | -0.000267  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.248      |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.00358   |
|    std                  | 0.794      |
|    value_loss           | 0.683      |
----------------------------------------
Eval num_timesteps=560000, episode_reward=-99.85 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.035878077 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | 0.0225      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.49        |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.00379    |
|    std                  | 0.79        |
|    value_loss           | 0.846       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.61e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157219   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 157424      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.015750123 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | 0.000812    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.85        |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00208    |
|    std                  | 0.789       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 276         |
|    time_elapsed         | 157630      |
|    total_timesteps      | 565248      |
| train/                  |             |
|    approx_kl            | 0.020755827 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | -0.134      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.308       |
|    n_updates            | 2750        |
|    policy_gradient_loss | -0.000362   |
|    std                  | 0.791       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 157836      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.023693947 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | 0.251       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.707       |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.00965    |
|    std                  | 0.789       |
|    value_loss           | 1.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 158041      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.036137227 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.357       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.285       |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0068     |
|    std                  | 0.786       |
|    value_loss           | 1.07        |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.85 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.030261649 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | 0.121       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.507       |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.785       |
|    value_loss           | 0.89        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.62e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160047   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160253      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.017064527 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.00138     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.03        |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.00319    |
|    std                  | 0.785       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 281         |
|    time_elapsed         | 160459      |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.028380219 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | -0.0037     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.451       |
|    n_updates            | 2800        |
|    policy_gradient_loss | 0.000502    |
|    std                  | 0.779       |
|    value_loss           | 0.861       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 160664      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.033419892 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.2        |
|    explained_variance   | 0.0687      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.436       |
|    n_updates            | 2810        |
|    policy_gradient_loss | -0.002      |
|    std                  | 0.777       |
|    value_loss           | 0.81        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.63e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 160870     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.03010685 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | 0.0631     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.273      |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.00456   |
|    std                  | 0.772      |
|    value_loss           | 0.773      |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.85 +/- 0.04
Episode length: 3598.40 +/- 4.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.024345616 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.0332      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.287       |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0012     |
|    std                  | 0.774       |
|    value_loss           | 0.623       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.62e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162876   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163082      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.021871567 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | -0.000695   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+03    |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.00282    |
|    std                  | 0.773       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 286         |
|    time_elapsed         | 163287      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.038008645 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | -0.319      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.446       |
|    n_updates            | 2850        |
|    policy_gradient_loss | 0.00338     |
|    std                  | 0.767       |
|    value_loss           | 0.744       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.63e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163493     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.03094588 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.1       |
|    explained_variance   | 0.00319    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.387      |
|    n_updates            | 2860       |
|    policy_gradient_loss | -0.00405   |
|    std                  | 0.77       |
|    value_loss           | 0.854      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 288         |
|    time_elapsed         | 163698      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.022145044 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.0333      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.352       |
|    n_updates            | 2870        |
|    policy_gradient_loss | 0.000286    |
|    std                  | 0.772       |
|    value_loss           | 0.725       |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.87 +/- 0.02
Episode length: 3598.80 +/- 3.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.025866989 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.0624      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.768       |
|    value_loss           | 0.671       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.62e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165705   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 165910      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.016295027 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -0.00102    |
|    learning_rate        | 0.0003      |
|    loss                 | 89.8        |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.0047      |
|    std                  | 0.768       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 291         |
|    time_elapsed         | 166116      |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.032961786 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.1        |
|    explained_variance   | -0.183      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.33        |
|    n_updates            | 2900        |
|    policy_gradient_loss | 0.000588    |
|    std                  | 0.769       |
|    value_loss           | 0.759       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 292         |
|    time_elapsed         | 166321      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.026471624 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | 0.07        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.422       |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.00283    |
|    std                  | 0.774       |
|    value_loss           | 0.932       |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.88 +/- 0.07
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.025981618 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.418       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.367       |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.77        |
|    value_loss           | 0.745       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168328   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168533      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.021886908 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.000273    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.19        |
|    n_updates            | 2930        |
|    policy_gradient_loss | 0.000561    |
|    std                  | 0.77        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 168740     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.03840273 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.09      |
|    explained_variance   | 0.0628     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.368      |
|    n_updates            | 2940       |
|    policy_gradient_loss | 0.0026     |
|    std                  | 0.764      |
|    value_loss           | 0.729      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 296         |
|    time_elapsed         | 168945      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.025164898 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.02        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.493       |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.00469    |
|    std                  | 0.76        |
|    value_loss           | 0.986       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 297         |
|    time_elapsed         | 169151      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.026933882 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.03       |
|    explained_variance   | 0.0141      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 2960        |
|    policy_gradient_loss | 0.00365     |
|    std                  | 0.762       |
|    value_loss           | 0.814       |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.86 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 610000     |
| train/                  |            |
|    approx_kl            | 0.02777455 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | 0.0156     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.225      |
|    n_updates            | 2970       |
|    policy_gradient_loss | -0.00289   |
|    std                  | 0.762      |
|    value_loss           | 0.671      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171157   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 171362      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.025940094 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.000331    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.37e+03    |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00426    |
|    std                  | 0.762       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 300         |
|    time_elapsed         | 171568      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.028542096 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.109       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.391       |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.00378    |
|    std                  | 0.763       |
|    value_loss           | 0.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 171774      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.024436643 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | 0.055       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.459       |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.00488     |
|    std                  | 0.761       |
|    value_loss           | 0.721       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 171979      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.019988798 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | 0.0372      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.319       |
|    n_updates            | 3010        |
|    policy_gradient_loss | 0.000731    |
|    std                  | 0.757       |
|    value_loss           | 0.762       |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.83 +/- 0.02
Episode length: 3598.00 +/- 4.29
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.023668613 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.98       |
|    explained_variance   | -8.05       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.252       |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.00424    |
|    std                  | 0.757       |
|    value_loss           | 1.05        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 173985   |
|    total_timesteps | 620544   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 304         |
|    time_elapsed         | 174191      |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.039233055 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | -3.71e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 418         |
|    n_updates            | 3030        |
|    policy_gradient_loss | -0.00035    |
|    std                  | 0.758       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 305         |
|    time_elapsed         | 174396      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.020309921 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | -0.053      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.268       |
|    n_updates            | 3040        |
|    policy_gradient_loss | 0.00123     |
|    std                  | 0.759       |
|    value_loss           | 0.673       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.64e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 174602     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.03623513 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | 0.0141     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.404      |
|    n_updates            | 3050       |
|    policy_gradient_loss | -0.001     |
|    std                  | 0.761      |
|    value_loss           | 0.761      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 307         |
|    time_elapsed         | 174808      |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.025832467 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.0557      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.35        |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.00134    |
|    std                  | 0.76        |
|    value_loss           | 0.697       |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=-99.96 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.024452459 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | -1.45       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.421       |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.00482    |
|    std                  | 0.762       |
|    value_loss           | 0.781       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.63e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176814   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.63e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 177019      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.018584918 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | -0.000736   |
|    learning_rate        | 0.0003      |
|    loss                 | 44.4        |
|    n_updates            | 3080        |
|    policy_gradient_loss | -0.00383    |
|    std                  | 0.763       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 310         |
|    time_elapsed         | 177225      |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.035516515 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | -0.0266     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.748       |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.00174    |
|    std                  | 0.755       |
|    value_loss           | 0.925       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 311        |
|    time_elapsed         | 177430     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.02759832 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.98      |
|    explained_variance   | -0.229     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.512      |
|    n_updates            | 3100       |
|    policy_gradient_loss | 0.00232    |
|    std                  | 0.76       |
|    value_loss           | 0.75       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 177636      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.023334004 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.99       |
|    explained_variance   | 0.0243      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.28        |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.000272   |
|    std                  | 0.758       |
|    value_loss           | 0.758       |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.90 +/- 0.07
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.028598111 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | -11.2       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.27        |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.00456    |
|    std                  | 0.754       |
|    value_loss           | 3.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179642   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 179848      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.032688677 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.00117     |
|    learning_rate        | 0.0003      |
|    loss                 | 59.5        |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00105    |
|    std                  | 0.755       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 315        |
|    time_elapsed         | 180054     |
|    total_timesteps      | 645120     |
| train/                  |            |
|    approx_kl            | 0.02998311 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | -0.135     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.347      |
|    n_updates            | 3140       |
|    policy_gradient_loss | 0.00159    |
|    std                  | 0.76       |
|    value_loss           | 0.727      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 180259     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.02557785 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.97      |
|    explained_variance   | -8.71      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.358      |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.000863  |
|    std                  | 0.756      |
|    value_loss           | 1.48       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.65e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 180465     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.03411659 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.0238     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.34       |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.00222    |
|    std                  | 0.752      |
|    value_loss           | 0.736      |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.89 +/- 0.02
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.031046793 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.295       |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.00193    |
|    std                  | 0.75        |
|    value_loss           | 1.72        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182471   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182677      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.026401289 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 8.03e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 20          |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.00187     |
|    std                  | 0.752       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 320         |
|    time_elapsed         | 182882      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.025600256 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | -0.00143    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.267       |
|    n_updates            | 3190        |
|    policy_gradient_loss | 0.00639     |
|    std                  | 0.753       |
|    value_loss           | 0.745       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 183088      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.028770769 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.0562      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.263       |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.00453    |
|    std                  | 0.757       |
|    value_loss           | 0.698       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183293     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.02977404 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.96      |
|    explained_variance   | 0.0373     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.357      |
|    n_updates            | 3210       |
|    policy_gradient_loss | -0.00109   |
|    std                  | 0.755      |
|    value_loss           | 0.656      |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.87 +/- 0.02
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.023584226 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.0658      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.366       |
|    n_updates            | 3220        |
|    policy_gradient_loss | 0.000929    |
|    std                  | 0.752       |
|    value_loss           | 0.853       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185299   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 185505      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.021601541 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.00132     |
|    learning_rate        | 0.0003      |
|    loss                 | 82.9        |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.00144    |
|    std                  | 0.751       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 325         |
|    time_elapsed         | 185711      |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.036699302 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.00313     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.305       |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.00254    |
|    std                  | 0.755       |
|    value_loss           | 0.726       |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 2.66e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 326      |
|    time_elapsed         | 185916   |
|    total_timesteps      | 667648   |
| train/                  |          |
|    approx_kl            | 0.035623 |
|    clip_fraction        | 0.272    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.92    |
|    explained_variance   | -7.54    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.08     |
|    n_updates            | 3250     |
|    policy_gradient_loss | 0.000844 |
|    std                  | 0.752    |
|    value_loss           | 0.885    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 186122     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.02773413 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.91      |
|    explained_variance   | 0.0616     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.406      |
|    n_updates            | 3260       |
|    policy_gradient_loss | -0.00613   |
|    std                  | 0.754      |
|    value_loss           | 0.672      |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.021709844 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.0015      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.00196     |
|    std                  | 0.755       |
|    value_loss           | 0.853       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.65e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188128   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 188334      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.018802654 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | -2.15e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 8.34        |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.00118    |
|    std                  | 0.755       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 330         |
|    time_elapsed         | 188539      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.032839365 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.494       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.329       |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.00451    |
|    std                  | 0.756       |
|    value_loss           | 0.713       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 331         |
|    time_elapsed         | 188745      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.026784036 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.95       |
|    explained_variance   | 0.0023      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.402       |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.00309     |
|    std                  | 0.756       |
|    value_loss           | 0.857       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 188951     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.02745897 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | -1.76      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.205      |
|    n_updates            | 3310       |
|    policy_gradient_loss | 0.000135   |
|    std                  | 0.754      |
|    value_loss           | 0.651      |
----------------------------------------
Eval num_timesteps=680000, episode_reward=-99.92 +/- 0.03
Episode length: 3598.80 +/- 3.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.022623885 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 0.00153     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.266       |
|    n_updates            | 3320        |
|    policy_gradient_loss | 0.00198     |
|    std                  | 0.753       |
|    value_loss           | 0.664       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.65e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190957   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.66e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 191162     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.02659399 |
|    clip_fraction        | 0.256      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | -0.000142  |
|    learning_rate        | 0.0003     |
|    loss                 | 642        |
|    n_updates            | 3330       |
|    policy_gradient_loss | -0.00116   |
|    std                  | 0.752      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 335         |
|    time_elapsed         | 191368      |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.025111057 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 3.94e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.365       |
|    n_updates            | 3340        |
|    policy_gradient_loss | 0.00283     |
|    std                  | 0.753       |
|    value_loss           | 0.773       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 336         |
|    time_elapsed         | 191574      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.027427623 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | 2.6e-05     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.514       |
|    n_updates            | 3350        |
|    policy_gradient_loss | 0.00281     |
|    std                  | 0.756       |
|    value_loss           | 0.811       |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.95 +/- 0.04
Episode length: 3598.60 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.029484099 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | -3.45       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.368       |
|    n_updates            | 3360        |
|    policy_gradient_loss | 0.00225     |
|    std                  | 0.757       |
|    value_loss           | 3.16        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.65e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193580   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.65e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 193786      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.027049527 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | -0.0148     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.7         |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00373    |
|    std                  | 0.758       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 193992     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.03312914 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | -0.0345    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.355      |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.00165   |
|    std                  | 0.757      |
|    value_loss           | 0.778      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 194197      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.028512532 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | -0.0467     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.234       |
|    n_updates            | 3390        |
|    policy_gradient_loss | -0.00131    |
|    std                  | 0.756       |
|    value_loss           | 0.715       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 194403     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.02489014 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | -0.000481  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.00234    |
|    std                  | 0.759      |
|    value_loss           | 0.77       |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.91 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.032815352 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | -11.8       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.485       |
|    n_updates            | 3410        |
|    policy_gradient_loss | 0.00164     |
|    std                  | 0.758       |
|    value_loss           | 2.22        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.66e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196409   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 196616      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.018150566 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | -0.0116     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.15        |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0072     |
|    std                  | 0.759       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 196821     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.03915306 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.9       |
|    explained_variance   | 0.00185    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.302      |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.00105    |
|    std                  | 0.753      |
|    value_loss           | 0.727      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 345         |
|    time_elapsed         | 197027      |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.029447377 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.87       |
|    explained_variance   | 0.0374      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.578       |
|    n_updates            | 3440        |
|    policy_gradient_loss | -0.000549   |
|    std                  | 0.752       |
|    value_loss           | 0.797       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 197233      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.029170414 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.0499      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.262       |
|    n_updates            | 3450        |
|    policy_gradient_loss | -0.000131   |
|    std                  | 0.756       |
|    value_loss           | 0.711       |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.92 +/- 0.03
Episode length: 3597.60 +/- 5.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.034162834 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | -0.112      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.401       |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.00237    |
|    std                  | 0.756       |
|    value_loss           | 0.965       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.66e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199239   |
|    total_timesteps | 710656   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 348         |
|    time_elapsed         | 199446      |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.028381784 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.91       |
|    explained_variance   | -0.000396   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.71e+03    |
|    n_updates            | 3470        |
|    policy_gradient_loss | -0.00226    |
|    std                  | 0.757       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 349         |
|    time_elapsed         | 199652      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.024464447 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.000691    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 3480        |
|    policy_gradient_loss | 0.00507     |
|    std                  | 0.759       |
|    value_loss           | 0.852       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 350         |
|    time_elapsed         | 199857      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.066924684 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.93       |
|    explained_variance   | 0.0117      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.458       |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.00195    |
|    std                  | 0.759       |
|    value_loss           | 0.819       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 200063     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.03449048 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.93      |
|    explained_variance   | 0.00783    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.22       |
|    n_updates            | 3500       |
|    policy_gradient_loss | 0.00305    |
|    std                  | 0.759      |
|    value_loss           | 0.685      |
----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.90 +/- 0.07
Episode length: 3598.40 +/- 5.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.022517996 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.0103      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.279       |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.000719   |
|    std                  | 0.753       |
|    value_loss           | 0.779       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.66e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202070   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 202275      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.033124465 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.88       |
|    explained_variance   | 4.77e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 431         |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00554    |
|    std                  | 0.756       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.67e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 202482     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.03786262 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.89      |
|    explained_variance   | -0.00021   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.274      |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.00205    |
|    std                  | 0.756      |
|    value_loss           | 0.825      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.67e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 355       |
|    time_elapsed         | 202688    |
|    total_timesteps      | 727040    |
| train/                  |           |
|    approx_kl            | 0.0246723 |
|    clip_fraction        | 0.295     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.88     |
|    explained_variance   | 0.000386  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.491     |
|    n_updates            | 3540      |
|    policy_gradient_loss | -0.00213  |
|    std                  | 0.755     |
|    value_loss           | 0.806     |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 356         |
|    time_elapsed         | 202893      |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.028931892 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.87       |
|    explained_variance   | 0.025       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.313       |
|    n_updates            | 3550        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.755       |
|    value_loss           | 0.616       |
-----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.92 +/- 0.05
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.021330392 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.00518    |
|    std                  | 0.753       |
|    value_loss           | 4.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204901   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205106      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.030862404 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.85       |
|    explained_variance   | 0.00219     |
|    learning_rate        | 0.0003      |
|    loss                 | 42.9        |
|    n_updates            | 3570        |
|    policy_gradient_loss | 0.000735    |
|    std                  | 0.752       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 359         |
|    time_elapsed         | 205312      |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.036977068 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.81       |
|    explained_variance   | -0.00337    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.47        |
|    n_updates            | 3580        |
|    policy_gradient_loss | 0.00419     |
|    std                  | 0.747       |
|    value_loss           | 0.903       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 360         |
|    time_elapsed         | 205518      |
|    total_timesteps      | 737280      |
| train/                  |             |
|    approx_kl            | 0.036658294 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | -0.00567    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.335       |
|    n_updates            | 3590        |
|    policy_gradient_loss | 0.00221     |
|    std                  | 0.748       |
|    value_loss           | 0.767       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 205723      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.032832913 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.0201      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.333       |
|    n_updates            | 3600        |
|    policy_gradient_loss | 0.00094     |
|    std                  | 0.746       |
|    value_loss           | 0.664       |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.89 +/- 0.04
Episode length: 3598.60 +/- 4.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 740000     |
| train/                  |            |
|    approx_kl            | 0.02478615 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | 0.0234     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.372      |
|    n_updates            | 3610       |
|    policy_gradient_loss | 0.000602   |
|    std                  | 0.742      |
|    value_loss           | 0.723      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207730   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 207935      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.022534108 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | -0.000768   |
|    learning_rate        | 0.0003      |
|    loss                 | 213         |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.00586    |
|    std                  | 0.742       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 364         |
|    time_elapsed         | 208141      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.026718933 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.000196    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 3630        |
|    policy_gradient_loss | 0.00526     |
|    std                  | 0.738       |
|    value_loss           | 0.913       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 365         |
|    time_elapsed         | 208347      |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.025914092 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.72       |
|    explained_variance   | 0.00316     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.251       |
|    n_updates            | 3640        |
|    policy_gradient_loss | -0.00235    |
|    std                  | 0.744       |
|    value_loss           | 0.707       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 208552      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.022614837 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.000818    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.408       |
|    n_updates            | 3650        |
|    policy_gradient_loss | 0.0034      |
|    std                  | 0.746       |
|    value_loss           | 0.778       |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.92 +/- 0.04
Episode length: 3598.20 +/- 4.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.029840287 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | 0.0345      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.381       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.000539    |
|    std                  | 0.747       |
|    value_loss           | 0.785       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210558   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 368         |
|    time_elapsed         | 210764      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.032432035 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | -0.000802   |
|    learning_rate        | 0.0003      |
|    loss                 | 62.4        |
|    n_updates            | 3670        |
|    policy_gradient_loss | 0.00112     |
|    std                  | 0.748       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 369         |
|    time_elapsed         | 210969      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.030350957 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.507       |
|    n_updates            | 3680        |
|    policy_gradient_loss | -0.00427    |
|    std                  | 0.745       |
|    value_loss           | 0.913       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 211175      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.022383485 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.000438    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0022     |
|    std                  | 0.749       |
|    value_loss           | 0.663       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 371         |
|    time_elapsed         | 211381      |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.028572168 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.81       |
|    explained_variance   | -0.0206     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.318       |
|    n_updates            | 3700        |
|    policy_gradient_loss | -0.00146    |
|    std                  | 0.75        |
|    value_loss           | 0.696       |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=-99.90 +/- 0.04
Episode length: 3600.40 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.022829028 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.0234      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.492       |
|    n_updates            | 3710        |
|    policy_gradient_loss | 0.00246     |
|    std                  | 0.747       |
|    value_loss           | 0.906       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213387   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 213592      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.025948092 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | -4.79e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78e+03    |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00358    |
|    std                  | 0.746       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 374         |
|    time_elapsed         | 213798      |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.025251614 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.0542      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 3730        |
|    policy_gradient_loss | -0.000277   |
|    std                  | 0.742       |
|    value_loss           | 0.712       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 375         |
|    time_elapsed         | 214003      |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.033325918 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | -0.00686    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.397       |
|    n_updates            | 3740        |
|    policy_gradient_loss | 0.00476     |
|    std                  | 0.742       |
|    value_loss           | 0.826       |
-----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.93 +/- 0.06
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.030227706 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | 0.000485    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.446       |
|    n_updates            | 3750        |
|    policy_gradient_loss | 0.00245     |
|    std                  | 0.74        |
|    value_loss           | 0.901       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 216010   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216216      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.023615079 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.73       |
|    explained_variance   | -1.19e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 288         |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.00375    |
|    std                  | 0.741       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 378         |
|    time_elapsed         | 216421      |
|    total_timesteps      | 774144      |
| train/                  |             |
|    approx_kl            | 0.054197844 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.72       |
|    explained_variance   | 0.0395      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.483       |
|    n_updates            | 3770        |
|    policy_gradient_loss | 5.64e-05    |
|    std                  | 0.74        |
|    value_loss           | 0.785       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 379         |
|    time_elapsed         | 216627      |
|    total_timesteps      | 776192      |
| train/                  |             |
|    approx_kl            | 0.034969334 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.0021      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.34        |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.00358    |
|    std                  | 0.735       |
|    value_loss           | 0.889       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 216832     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.03437474 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.00822    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.362      |
|    n_updates            | 3790       |
|    policy_gradient_loss | -0.00216   |
|    std                  | 0.735      |
|    value_loss           | 0.716      |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.91 +/- 0.05
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.033748213 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.0669      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.316       |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.000144   |
|    std                  | 0.734       |
|    value_loss           | 0.851       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.67e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218839   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 219044      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.021514826 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 8.34e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 6           |
|    n_updates            | 3810        |
|    policy_gradient_loss | 0.000546    |
|    std                  | 0.734       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 383         |
|    time_elapsed         | 219250      |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.026330471 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | -0.00524    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.314       |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.00205    |
|    std                  | 0.731       |
|    value_loss           | 0.712       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 219456      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.028837405 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | -6.55       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.41        |
|    n_updates            | 3830        |
|    policy_gradient_loss | -0.000725   |
|    std                  | 0.732       |
|    value_loss           | 2.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 385         |
|    time_elapsed         | 219661      |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.033280626 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.00165     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.374       |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.00367    |
|    std                  | 0.733       |
|    value_loss           | 0.736       |
-----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.92 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.021849182 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | 0.00778     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.462       |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.00189    |
|    std                  | 0.727       |
|    value_loss           | 0.949       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221668   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 221873      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.018480647 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | -1.74e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 59.7        |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.00684    |
|    std                  | 0.728       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 388         |
|    time_elapsed         | 222079      |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.028064374 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | -0.0118     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.291       |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.0012     |
|    std                  | 0.73        |
|    value_loss           | 0.688       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 389         |
|    time_elapsed         | 222286      |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.025950115 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | -0.808      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.328       |
|    n_updates            | 3880        |
|    policy_gradient_loss | 0.00127     |
|    std                  | 0.729       |
|    value_loss           | 8.99        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 390         |
|    time_elapsed         | 222492      |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.033685878 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.6        |
|    explained_variance   | -0.00365    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.307       |
|    n_updates            | 3890        |
|    policy_gradient_loss | -0.00399    |
|    std                  | 0.732       |
|    value_loss           | 0.749       |
-----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.88 +/- 0.03
Episode length: 3598.80 +/- 3.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.029357621 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.000436    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.307       |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.732       |
|    value_loss           | 0.652       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224498   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 224707      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.020581195 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | -0.0236     |
|    learning_rate        | 0.0003      |
|    loss                 | 249         |
|    n_updates            | 3910        |
|    policy_gradient_loss | -1.56e-05   |
|    std                  | 0.733       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 393         |
|    time_elapsed         | 224913      |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.027170291 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.00256     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.379       |
|    n_updates            | 3920        |
|    policy_gradient_loss | -0.000392   |
|    std                  | 0.733       |
|    value_loss           | 0.741       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 394         |
|    time_elapsed         | 225118      |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.030240364 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | -0.451      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.348       |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.00526    |
|    std                  | 0.734       |
|    value_loss           | 1.37        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 225324     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.02446465 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.00261    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.417      |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.00502   |
|    std                  | 0.735      |
|    value_loss           | 0.737      |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.90 +/- 0.05
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.031478614 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | -0.000752   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.467       |
|    n_updates            | 3950        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.738       |
|    value_loss           | 0.933       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227330   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 227536     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.01904284 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | -0.000538  |
|    learning_rate        | 0.0003     |
|    loss                 | 5.37       |
|    n_updates            | 3960       |
|    policy_gradient_loss | -0.0033    |
|    std                  | 0.738      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 227741     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.03876949 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | 0.0134     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.324      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.00114    |
|    std                  | 0.737      |
|    value_loss           | 0.847      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 399         |
|    time_elapsed         | 227948      |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.023627128 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | -0.000919   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.42        |
|    n_updates            | 3980        |
|    policy_gradient_loss | 0.00275     |
|    std                  | 0.736       |
|    value_loss           | 0.858       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 400         |
|    time_elapsed         | 228153      |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.028557122 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | 0.0204      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.000215   |
|    std                  | 0.736       |
|    value_loss           | 0.752       |
-----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.92 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 820000      |
| train/                  |             |
|    approx_kl            | 0.028381154 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.0503      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.303       |
|    n_updates            | 4000        |
|    policy_gradient_loss | -0.000343   |
|    std                  | 0.739       |
|    value_loss           | 0.702       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230159   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 230365      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.025065504 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | -0.000207   |
|    learning_rate        | 0.0003      |
|    loss                 | 648         |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00279    |
|    std                  | 0.739       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 403         |
|    time_elapsed         | 230571      |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.022222904 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.0215      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.354       |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.00124    |
|    std                  | 0.738       |
|    value_loss           | 0.839       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 404         |
|    time_elapsed         | 230777      |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.027269866 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.36        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.379       |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.736       |
|    value_loss           | 1.25        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 230983     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.03373015 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.57      |
|    explained_variance   | 0.0203     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.34       |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.00166    |
|    std                  | 0.731      |
|    value_loss           | 0.689      |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.88 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.023588315 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | 0.0321      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.318       |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.000424   |
|    std                  | 0.726       |
|    value_loss           | 0.702       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 232989   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 233194     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.02324789 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | -0.000298  |
|    learning_rate        | 0.0003     |
|    loss                 | 6.27       |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.00838   |
|    std                  | 0.726      |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 408         |
|    time_elapsed         | 233400      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.021833498 |
|    clip_fraction        | 0.266       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | -0.0163     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 4070        |
|    policy_gradient_loss | 0.00188     |
|    std                  | 0.728       |
|    value_loss           | 1           |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 409         |
|    time_elapsed         | 233606      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.024224415 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.469       |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.00926    |
|    std                  | 0.729       |
|    value_loss           | 2.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 410         |
|    time_elapsed         | 233812      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.030423848 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | 0.0245      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.555       |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.733       |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.87 +/- 0.03
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.034669302 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.0105      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.456       |
|    n_updates            | 4100        |
|    policy_gradient_loss | -0.0012     |
|    std                  | 0.731       |
|    value_loss           | 0.878       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235819   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 236025      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.021217726 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | -0.0233     |
|    learning_rate        | 0.0003      |
|    loss                 | 107         |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00228    |
|    std                  | 0.731       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 413         |
|    time_elapsed         | 236231      |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.025727756 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | -0.162      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.371       |
|    n_updates            | 4120        |
|    policy_gradient_loss | 0.000541    |
|    std                  | 0.732       |
|    value_loss           | 0.849       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 414         |
|    time_elapsed         | 236437      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.030771201 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | -0.00228    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.294       |
|    n_updates            | 4130        |
|    policy_gradient_loss | 0.00162     |
|    std                  | 0.734       |
|    value_loss           | 0.718       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 415         |
|    time_elapsed         | 236642      |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.021176178 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | -1.03       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.337       |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.00254    |
|    std                  | 0.734       |
|    value_loss           | 0.771       |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.90 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.041561455 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.00687     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.347       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.00333     |
|    std                  | 0.738       |
|    value_loss           | 0.786       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238649   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 238854      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.022367781 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | -0.0039     |
|    learning_rate        | 0.0003      |
|    loss                 | 168         |
|    n_updates            | 4160        |
|    policy_gradient_loss | -0.00326    |
|    std                  | 0.739       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 418         |
|    time_elapsed         | 239060      |
|    total_timesteps      | 856064      |
| train/                  |             |
|    approx_kl            | 0.029389542 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.63       |
|    explained_variance   | -0.00194    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.366       |
|    n_updates            | 4170        |
|    policy_gradient_loss | -0.00402    |
|    std                  | 0.742       |
|    value_loss           | 0.898       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 239266     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.02581342 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | -0.00149   |
|    learning_rate        | 0.0003     |
|    loss                 | 0.299      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.000169   |
|    std                  | 0.743      |
|    value_loss           | 0.786      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.89 +/- 0.04
Episode length: 3600.60 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.025950942 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | -0.0897     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 4190        |
|    policy_gradient_loss | -0.00741    |
|    std                  | 0.745       |
|    value_loss           | 0.982       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241272   |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 421         |
|    time_elapsed         | 241479      |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.020100491 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | -0.00031    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.11e+03    |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.745       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 422         |
|    time_elapsed         | 241685      |
|    total_timesteps      | 864256      |
| train/                  |             |
|    approx_kl            | 0.035409115 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | -0.00252    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.239       |
|    n_updates            | 4210        |
|    policy_gradient_loss | 0.00177     |
|    std                  | 0.739       |
|    value_loss           | 0.565       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 423         |
|    time_elapsed         | 241891      |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.026119057 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.352       |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.00372    |
|    std                  | 0.74        |
|    value_loss           | 0.937       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 424         |
|    time_elapsed         | 242098      |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.024913356 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.61       |
|    explained_variance   | 0.0271      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.402       |
|    n_updates            | 4230        |
|    policy_gradient_loss | -0.00471    |
|    std                  | 0.736       |
|    value_loss           | 0.693       |
-----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.89 +/- 0.04
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.02151865 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.0434     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.426      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.737      |
|    value_loss           | 0.633      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244105   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244310     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.02406714 |
|    clip_fraction        | 0.232      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.61      |
|    explained_variance   | -0.000203  |
|    learning_rate        | 0.0003     |
|    loss                 | 10.1       |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.00571   |
|    std                  | 0.74       |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 427         |
|    time_elapsed         | 244517      |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.032873042 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.00121     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.61        |
|    n_updates            | 4260        |
|    policy_gradient_loss | 0.000315    |
|    std                  | 0.735       |
|    value_loss           | 0.884       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 428         |
|    time_elapsed         | 244723      |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.026175624 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.58       |
|    explained_variance   | 0.0154      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.403       |
|    n_updates            | 4270        |
|    policy_gradient_loss | -0.00184    |
|    std                  | 0.736       |
|    value_loss           | 0.798       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 244929     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.02164244 |
|    clip_fraction        | 0.249      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.0481     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.302      |
|    n_updates            | 4280       |
|    policy_gradient_loss | -0.00131   |
|    std                  | 0.735      |
|    value_loss           | 0.723      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.91 +/- 0.04
Episode length: 3600.00 +/- 1.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.02998722 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.56      |
|    explained_variance   | -0.0374    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.715      |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.733      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246935   |
|    total_timesteps | 880640   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 431         |
|    time_elapsed         | 247140      |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.025043214 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | -0.00137    |
|    learning_rate        | 0.0003      |
|    loss                 | 26.8        |
|    n_updates            | 4300        |
|    policy_gradient_loss | -0.00349    |
|    std                  | 0.735       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 432        |
|    time_elapsed         | 247346     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.05139176 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.00795    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.231      |
|    n_updates            | 4310       |
|    policy_gradient_loss | 0.000418   |
|    std                  | 0.736      |
|    value_loss           | 0.778      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 247552      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.040187128 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | -4.94       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.324       |
|    n_updates            | 4320        |
|    policy_gradient_loss | 0.00456     |
|    std                  | 0.736       |
|    value_loss           | 0.803       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 247757     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.02523667 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.58      |
|    explained_variance   | 0.0232     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.634      |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.000483  |
|    std                  | 0.733      |
|    value_loss           | 0.99       |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.89 +/- 0.03
Episode length: 3598.20 +/- 5.11
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.036155567 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 4340        |
|    policy_gradient_loss | -0.00114    |
|    std                  | 0.73        |
|    value_loss           | 0.899       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249763   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 249969      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.017571064 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | -8.58e-06   |
|    learning_rate        | 0.0003      |
|    loss                 | 29.1        |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.00206    |
|    std                  | 0.729       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 250175     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.02605332 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.51      |
|    explained_variance   | 0.0125     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.503      |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.00342   |
|    std                  | 0.729      |
|    value_loss           | 0.977      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 250380     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.02373067 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.51      |
|    explained_variance   | 0.244      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.327      |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.00508   |
|    std                  | 0.729      |
|    value_loss           | 0.787      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 439         |
|    time_elapsed         | 250586      |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.033847496 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.49       |
|    explained_variance   | 0.249       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.793       |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.00119    |
|    std                  | 0.726       |
|    value_loss           | 1.16        |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.87 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.031578396 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.0318      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.298       |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.00364    |
|    std                  | 0.724       |
|    value_loss           | 0.804       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252593   |
|    total_timesteps | 901120   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 441         |
|    time_elapsed         | 252798      |
|    total_timesteps      | 903168      |
| train/                  |             |
|    approx_kl            | 0.034235395 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | -0.000637   |
|    learning_rate        | 0.0003      |
|    loss                 | 89.8        |
|    n_updates            | 4400        |
|    policy_gradient_loss | -0.00571    |
|    std                  | 0.725       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 442         |
|    time_elapsed         | 253004      |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.039518654 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.00328     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 4410        |
|    policy_gradient_loss | 0.00262     |
|    std                  | 0.727       |
|    value_loss           | 0.609       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 443         |
|    time_elapsed         | 253209      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.034737118 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.0148      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.000601   |
|    std                  | 0.727       |
|    value_loss           | 0.759       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 253415     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.02493383 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.47      |
|    explained_variance   | -0.451     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.246      |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.00541   |
|    std                  | 0.726      |
|    value_loss           | 0.718      |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.88 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 910000      |
| train/                  |             |
|    approx_kl            | 0.022852235 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.000718    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.366       |
|    n_updates            | 4440        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.728       |
|    value_loss           | 0.807       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255421   |
|    total_timesteps | 911360   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 446         |
|    time_elapsed         | 255626      |
|    total_timesteps      | 913408      |
| train/                  |             |
|    approx_kl            | 0.029288305 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | -0.000158   |
|    learning_rate        | 0.0003      |
|    loss                 | 239         |
|    n_updates            | 4450        |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.728       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 447         |
|    time_elapsed         | 255832      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.021781422 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | 0.00235     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.315       |
|    n_updates            | 4460        |
|    policy_gradient_loss | 0.000199    |
|    std                  | 0.727       |
|    value_loss           | 0.741       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 448         |
|    time_elapsed         | 256038      |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.029111853 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.45       |
|    explained_variance   | 0.0166      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.571       |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.000465   |
|    std                  | 0.726       |
|    value_loss           | 0.901       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 449         |
|    time_elapsed         | 256244      |
|    total_timesteps      | 919552      |
| train/                  |             |
|    approx_kl            | 0.023042232 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.0175      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.236       |
|    n_updates            | 4480        |
|    policy_gradient_loss | -0.0023     |
|    std                  | 0.731       |
|    value_loss           | 0.721       |
-----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.89 +/- 0.02
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.024943028 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | 0.0019      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.206       |
|    n_updates            | 4490        |
|    policy_gradient_loss | 0.000198    |
|    std                  | 0.729       |
|    value_loss           | 0.684       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258250   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 258456      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.031047503 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | -0.00246    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+03    |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.00356    |
|    std                  | 0.729       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 258662      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.028356073 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.46       |
|    explained_variance   | 0.00615     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.496       |
|    n_updates            | 4510        |
|    policy_gradient_loss | 0.000887    |
|    std                  | 0.728       |
|    value_loss           | 0.912       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 453         |
|    time_elapsed         | 258867      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.038255155 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | 0.0281      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.34        |
|    n_updates            | 4520        |
|    policy_gradient_loss | -0.00228    |
|    std                  | 0.725       |
|    value_loss           | 0.688       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 454         |
|    time_elapsed         | 259073      |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.026488796 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | 0.0376      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.364       |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.00394    |
|    std                  | 0.721       |
|    value_loss           | 0.773       |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.89 +/- 0.05
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.030862916 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.36       |
|    explained_variance   | -0.00508    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.00161    |
|    std                  | 0.722       |
|    value_loss           | 1.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261079   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261285      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.022536315 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | -0.0013     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.09        |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.00545    |
|    std                  | 0.722       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 457         |
|    time_elapsed         | 261490      |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.031907864 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | 0.336       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.359       |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.00409    |
|    std                  | 0.726       |
|    value_loss           | 1.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 458         |
|    time_elapsed         | 261697      |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.027767595 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.00482     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.293       |
|    n_updates            | 4570        |
|    policy_gradient_loss | 0.00413     |
|    std                  | 0.726       |
|    value_loss           | 0.887       |
-----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.87 +/- 0.06
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.028976232 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.0017      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.000675   |
|    std                  | 0.725       |
|    value_loss           | 1.16        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263704   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 263910     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.03773751 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.41      |
|    explained_variance   | 1.91e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 817        |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.000849   |
|    std                  | 0.727      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 461         |
|    time_elapsed         | 264116      |
|    total_timesteps      | 944128      |
| train/                  |             |
|    approx_kl            | 0.032511797 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | -2.42e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 0.544       |
|    n_updates            | 4600        |
|    policy_gradient_loss | -0.00179    |
|    std                  | 0.725       |
|    value_loss           | 0.952       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264322     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.03250008 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.37      |
|    explained_variance   | 0.0154     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.367      |
|    n_updates            | 4610       |
|    policy_gradient_loss | -0.00135   |
|    std                  | 0.722      |
|    value_loss           | 0.938      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 463         |
|    time_elapsed         | 264527      |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.041342657 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.33       |
|    explained_variance   | 0.00602     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.349       |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.718       |
|    value_loss           | 0.764       |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.88 +/- 0.03
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.03217008 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.31      |
|    explained_variance   | -1.78      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.449      |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.00518   |
|    std                  | 0.717      |
|    value_loss           | 4.09       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266533   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 266740      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.021363351 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.000125    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.56        |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.00587    |
|    std                  | 0.717       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 266946     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.03282853 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.27      |
|    explained_variance   | 0.0252     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.00341   |
|    std                  | 0.714      |
|    value_loss           | 0.973      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 467         |
|    time_elapsed         | 267151      |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.022363588 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.28       |
|    explained_variance   | 0.64        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.00512    |
|    std                  | 0.717       |
|    value_loss           | 1.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 267357      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.044440858 |
|    clip_fraction        | 0.305       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.0137      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.388       |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.00644    |
|    std                  | 0.719       |
|    value_loss           | 0.895       |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.93 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.030250156 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.0128      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.00189    |
|    std                  | 0.721       |
|    value_loss           | 0.767       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269363   |
|    total_timesteps | 960512   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 470         |
|    time_elapsed         | 269569      |
|    total_timesteps      | 962560      |
| train/                  |             |
|    approx_kl            | 0.022167943 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | -0.000544   |
|    learning_rate        | 0.0003      |
|    loss                 | 13.8        |
|    n_updates            | 4690        |
|    policy_gradient_loss | -0.000213   |
|    std                  | 0.722       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 471         |
|    time_elapsed         | 269776      |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.032542653 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | -0.103      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.555       |
|    n_updates            | 4700        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.719       |
|    value_loss           | 0.951       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 269983     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.03295881 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.29      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.455      |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.00765   |
|    std                  | 0.717      |
|    value_loss           | 1.17       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 473         |
|    time_elapsed         | 270189      |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.023763498 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | -0.0056     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 4720        |
|    policy_gradient_loss | 0.000344    |
|    std                  | 0.711       |
|    value_loss           | 0.838       |
-----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.036969937 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | -0.0682     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.33        |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.00208    |
|    std                  | 0.709       |
|    value_loss           | 3.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272195   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 272401      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.023296347 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | -0.000249   |
|    learning_rate        | 0.0003      |
|    loss                 | 15.4        |
|    n_updates            | 4740        |
|    policy_gradient_loss | -0.0053     |
|    std                  | 0.71        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 476         |
|    time_elapsed         | 272607      |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.038061187 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.0264      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.307       |
|    n_updates            | 4750        |
|    policy_gradient_loss | 0.00246     |
|    std                  | 0.709       |
|    value_loss           | 0.762       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 477         |
|    time_elapsed         | 272812      |
|    total_timesteps      | 976896      |
| train/                  |             |
|    approx_kl            | 0.037907366 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.18       |
|    explained_variance   | 0.0289      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 4760        |
|    policy_gradient_loss | -0.00229    |
|    std                  | 0.709       |
|    value_loss           | 1.13        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 478         |
|    time_elapsed         | 273018      |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.042600647 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.0334      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.247       |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.00224    |
|    std                  | 0.706       |
|    value_loss           | 0.643       |
-----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.92 +/- 0.06
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.030054152 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.12       |
|    explained_variance   | -0.167      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.331       |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.00525    |
|    std                  | 0.703       |
|    value_loss           | 0.813       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 275024   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.7e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275230      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.028366847 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.000623    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.48e+03    |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.00703    |
|    std                  | 0.703       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 275435     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.03670206 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.0148     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.324      |
|    n_updates            | 4800       |
|    policy_gradient_loss | -0.00135   |
|    std                  | 0.702      |
|    value_loss           | 0.727      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275641     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.03092119 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.1       |
|    explained_variance   | 0.0194     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.405      |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.00155   |
|    std                  | 0.703      |
|    value_loss           | 0.823      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 483         |
|    time_elapsed         | 275847      |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.042741545 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.08       |
|    explained_variance   | 0.00546     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.301       |
|    n_updates            | 4820        |
|    policy_gradient_loss | 0.00016     |
|    std                  | 0.7         |
|    value_loss           | 0.728       |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.83 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 990000      |
| train/                  |             |
|    approx_kl            | 0.035839327 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.05       |
|    explained_variance   | -0.287      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.386       |
|    n_updates            | 4830        |
|    policy_gradient_loss | -0.000708   |
|    std                  | 0.698       |
|    value_loss           | 0.917       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277854   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.7e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 278059     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.02912747 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.05      |
|    explained_variance   | -2.41e-05  |
|    learning_rate        | 0.0003     |
|    loss                 | 56.5       |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.00576   |
|    std                  | 0.699      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 278265     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.03307935 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | -0.044     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.406      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.00214    |
|    std                  | 0.697      |
|    value_loss           | 0.793      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.71e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 278470     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.03439458 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | -5.02      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.74       |
|    n_updates            | 4860       |
|    policy_gradient_loss | 0.00561    |
|    std                  | 0.695      |
|    value_loss           | 2.98       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 488         |
|    time_elapsed         | 278676      |
|    total_timesteps      | 999424      |
| train/                  |             |
|    approx_kl            | 0.023202239 |
|    clip_fraction        | 0.261       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.03       |
|    explained_variance   | -0.487      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.313       |
|    n_updates            | 4870        |
|    policy_gradient_loss | 0.000696    |
|    std                  | 0.693       |
|    value_loss           | 0.724       |
-----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.84 +/- 0.02
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.028250918 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.03       |
|    explained_variance   | 0.0377      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.454       |
|    n_updates            | 4880        |
|    policy_gradient_loss | -0.00235    |
|    std                  | 0.694       |
|    value_loss           | 0.757       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.7e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280682   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-23_09-59-26_llm_triton_qwen_7b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 3 days, 5:55:28 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.72451   -99.70823   -99.712484  -99.657546  -99.551865]
 [ -99.85091   -99.818666  -99.8005    -99.847788  -99.765257]
 [ -99.780975  -99.810279  -99.9128    -99.795454  -99.84023 ]
 [ -99.871947  -99.823185  -99.785812  -99.783619  -99.844929]
 [ -99.921654  -99.872209  -99.888841  -99.864103  -99.882609]
 [ -99.892967  -99.892763  -99.803478  -99.921244  -99.865651]
 [ -99.893251  -99.909574  -99.805405  -99.88794   -99.842305]
 [ -99.931616  -99.992063  -99.967828  -99.971496  -99.99227 ]
 [ -99.938996  -99.980838  -99.670103  -99.800428 -100.039154]
 [-100.028585 -100.021548  -99.921666 -100.002664  -99.911038]
 [ -99.890219  -99.765692  -99.803577  -99.788727 -100.025958]
 [-100.015474  -99.738306  -99.985701  -99.995549  -99.978995]
 [-100.023567  -99.779471 -100.005491  -99.97623  -100.017803]
 [-100.031966  -99.880637 -100.028359  -99.656492  -99.507286]
 [ -99.902913  -99.984361  -99.895522  -99.8255    -99.461813]
 [ -99.924698  -99.9118    -99.986431 -100.072745  -99.940026]
 [ -99.838016  -99.830443  -99.894024  -99.843194 -100.021763]
 [-100.007256  -99.922441  -99.915502  -99.916694 -100.030887]
 [ -99.989749  -99.965792  -99.957605  -99.951293  -99.940308]
 [ -99.885421  -99.922752  -99.931687  -99.964465  -99.974996]
 [ -99.925025  -99.895098  -99.896214  -99.990133  -99.920497]
 [ -99.965866  -99.878821  -99.929818 -100.007822  -99.981711]
 [ -99.906529  -99.972151  -99.943959  -99.872405  -99.921931]
 [ -99.868593  -99.959317  -99.926258  -99.894491  -99.810492]
 [-100.008182  -99.998283  -99.978425  -99.941362 -100.006816]
 [ -99.988003  -99.940385  -99.926983 -100.085846  -99.960923]
 [ -99.968999  -99.963565  -99.938988  -99.947424  -99.872146]
 [-100.022274  -99.965477  -99.978979  -99.988265  -99.916232]
 [ -99.825074  -99.930371  -99.869612  -99.943369  -99.921564]
 [ -99.941261  -99.87339   -99.944914  -99.930421  -99.867208]
 [ -99.997064  -99.86145   -99.898802  -99.900291  -99.932597]
 [ -99.947304  -99.923964  -99.940785 -100.012622  -99.837142]
 [ -99.873132  -99.850095  -99.867131  -99.848107  -99.850304]
 [ -99.890285  -99.939097  -99.969349  -99.944014  -99.910265]
 [ -99.972419  -99.953219 -100.026126  -99.868584  -99.877061]
 [ -99.848782  -99.90379   -99.863741  -99.85111   -99.968654]
 [ -99.911103  -99.916518  -99.977896  -99.827953  -99.869688]
 [ -99.958977  -99.970177  -99.968591  -99.987028  -99.894852]
 [ -99.94621   -99.859845  -99.848558  -99.851822  -99.858491]
 [ -99.92133   -99.848686  -99.889152  -99.929078  -99.870859]
 [ -99.90654   -99.839612  -99.940567  -99.886719  -99.8127  ]
 [ -99.799105  -99.833408  -99.903649  -99.969001  -99.852727]
 [ -99.820479  -99.807541  -99.819801  -99.9626    -99.979179]
 [ -99.977423  -99.928299  -99.891908  -99.873742  -99.964802]
 [ -99.839855 -100.017485  -99.831819  -99.972692 -100.053575]
 [ -99.825488  -99.898423  -99.949646  -99.963573  -99.854628]
 [ -99.934307  -99.809952  -99.827912  -99.888168  -99.891849]
 [ -99.826081  -99.870585  -99.796758  -99.885371  -99.819806]
 [-100.032177  -99.830607  -99.886376 -100.027376  -99.927372]
 [ -99.803156  -99.91662   -99.836045  -99.919031  -99.870594]
 [ -99.954175  -99.890002  -99.941106  -99.906022  -99.881362]
 [ -99.848062  -99.882152  -99.934254  -99.865166  -99.89467 ]
 [ -99.776196  -99.88285   -99.91904   -99.840051  -99.866624]
 [ -99.804283  -99.85498   -99.8093    -99.815878  -99.82895 ]
 [ -99.862924  -99.814146  -99.933445  -99.859287  -99.857457]
 [ -99.854299  -99.79663   -99.794762  -99.958732  -99.857522]
 [ -99.783845  -99.822722  -99.910558  -99.871372  -99.848778]
 [ -99.859206  -99.857884  -99.819106  -99.911051  -99.785093]
 [ -99.885621  -99.849687  -99.832388  -99.882903  -99.879092]
 [ -99.888248  -99.803486  -99.956325  -99.953181  -99.804746]
 [ -99.919328  -99.911359  -99.857053  -99.833275  -99.780923]
 [ -99.820577  -99.817413  -99.800636  -99.858489  -99.850145]
 [ -99.910959 -100.002374 -100.005269  -99.927254  -99.941535]
 [ -99.812522 -100.004242  -99.975664  -99.864266  -99.862959]
 [ -99.924047  -99.879233  -99.88882   -99.901453  -99.862168]
 [ -99.902111  -99.883993  -99.868441  -99.842258  -99.874114]
 [ -99.876221  -99.874287  -99.942186  -99.854461  -99.850242]
 [ -99.933154  -99.892266  -99.888108  -99.928274  -99.955289]
 [ -99.933016  -99.97848   -99.87423   -99.994039  -99.970015]
 [ -99.831987  -99.971402  -99.910128  -99.899004  -99.920895]
 [ -99.898681  -99.947265  -99.878366  -99.92653   -99.944269]
 [ -99.833338  -99.969936  -99.816492  -99.980051  -99.924893]
 [ -99.909705  -99.993064  -99.873347  -99.845081  -99.962642]
 [ -99.905393  -99.948551  -99.875126  -99.894447  -99.835188]
 [ -99.91124   -99.97355   -99.913804  -99.854571  -99.935462]
 [ -99.847561  -99.958475  -99.938773  -99.886901  -99.872792]
 [ -99.893862  -99.88115   -99.871434  -99.981408 -100.010299]
 [ -99.834898  -99.933946  -99.917135  -99.889008  -99.986797]
 [ -99.839449  -99.975997  -99.897158  -99.950429  -99.914165]
 [ -99.870368  -99.841691  -99.875152  -99.931697  -99.890441]
 [ -99.89067   -99.907935  -99.920193  -99.979477  -99.826611]
 [ -99.879753  -99.963709  -99.836222  -99.904248 -100.000727]
 [ -99.952203  -99.797032  -99.899671  -99.83747   -99.922876]
 [ -99.877524  -99.918273  -99.86927   -99.825392  -99.858829]
 [ -99.807803  -99.906623  -99.931888  -99.880026  -99.959325]
 [ -99.892968  -99.872817  -99.905615  -99.820582  -99.945289]
 [ -99.934659  -99.855906  -99.934959  -99.899934  -99.827179]
 [ -99.869944  -99.911179  -99.93043   -99.976815  -99.879243]
 [ -99.865021  -99.900365  -99.888282  -99.937806  -99.868194]
 [ -99.935733  -99.834186  -99.928872  -99.807365  -99.841727]
 [ -99.950063  -99.801543  -99.849629  -99.924439  -99.866882]
 [ -99.879101  -99.88364   -99.914429  -99.927015  -99.868241]
 [ -99.952559  -99.893546  -99.855735  -99.92998   -99.815101]
 [ -99.96766   -99.857767  -99.857243  -99.891921  -99.781696]
 [ -99.833186  -99.910293  -99.894471  -99.912403  -99.861993]
 [ -99.983325  -99.938574  -99.956889  -99.975273  -99.816657]
 [ -99.806124  -99.834453  -99.890418  -99.853351  -99.784305]
 [ -99.842608  -99.979001  -99.900018  -99.867637  -99.991482]
 [ -99.864397  -99.799479  -99.838577  -99.875812  -99.767795]
 [ -99.838007  -99.874484  -99.852979  -99.800124  -99.847658]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3598 3597 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3598 3598 3601 3601 3601]
 [3601 3601 3592 3600 3599]
 [3601 3601 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3580 3601 3601 3599]
 [3601 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3598 3601]
 [3598 3601 3601 3601 3601]
 [3601 3600 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3589 3598 3601 3601 3601]
 [3601 3601 3601 3601 3600]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3597 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3600 3601 3595]
 [3601 3601 3601 3592 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3601 3601 3588 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3587 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3587 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3599 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3600 3601 3600]
 [3601 3601 3601 3601 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3601 3589 3600]
 [3601 3601 3600 3592 3600]
 [3601 3601 3601 3600 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3590 3601]
 [3601 3600 3601 3601 3601]
 [3601 3601 3600 3599 3601]
 [3601 3601 3592 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3599 3601 3601]
 [3601 3601 3600 3591 3601]
 [3601 3601 3597 3601 3593]
 [3601 3600 3601 3601 3601]
 [3601 3599 3586 3601 3601]
 [3601 3601 3601 3588 3601]
 [3601 3601 3601 3600 3599]
 [3601 3601 3589 3601 3601]
 [3590 3598 3601 3601 3601]
 [3601 3601 3601 3600 3599]
 [3600 3601 3601 3600 3601]
 [3601 3601 3591 3601 3601]
 [3601 3601 3600 3601 3601]
 [3600 3601 3601 3601 3591]
 [3601 3600 3601 3600 3601]
 [3600 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3600 3601 3601 3601]
 [3601 3600 3601 3601 3600]
 [3601 3601 3599 3601 3601]
 [3597 3601 3601 3600 3601]
 [3601 3588 3601 3601 3600]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3601 3600]
 [3601 3600 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3601 3599]
 [3598 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3593 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3601 3597 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-23_09-59-26_llm_triton_qwen_7b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-23_09-59-26_llm_triton_qwen_7b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
