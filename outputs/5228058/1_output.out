####################
/var/spool/slurmd/job5405767/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_32B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-31_07-47-37_llm_triton_qwen_32b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and 9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 9
 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 3
 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 1
 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0
 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (20.75, -250.00).
 What is the reward score?
 
 Response: -8
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2.05e+03 |
|    ep_rew_mean     | -413     |
| time/              |          |
|    fps             | 5        |
|    iterations      | 1        |
|    time_elapsed    | 367      |
|    total_timesteps | 2048     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -406        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 2           |
|    time_elapsed         | 728         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012238063 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.0092      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.72        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.999       |
|    value_loss           | 11.2        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -407        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 3           |
|    time_elapsed         | 1090        |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.008505976 |
|    clip_fraction        | 0.0845      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.0825     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.37        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.996       |
|    value_loss           | 7.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.04e+03    |
|    ep_rew_mean          | -399        |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 4           |
|    time_elapsed         | 1449        |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.010726716 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.223      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.995       |
|    value_loss           | 6.23        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-96.44 +/- 1.57
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.4       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.007939587 |
|    clip_fraction        | 0.0487      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.235      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.84        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.996       |
|    value_loss           | 4.67        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -485     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 5        |
|    time_elapsed    | 3613     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -464         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 6            |
|    time_elapsed         | 3971         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0021308654 |
|    clip_fraction        | 0.00322      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00631     |
|    learning_rate        | 0.0003       |
|    loss                 | 4.81         |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00438     |
|    std                  | 0.996        |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -449        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 7           |
|    time_elapsed         | 4329        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008980255 |
|    clip_fraction        | 0.079       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.496      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.968       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.993       |
|    value_loss           | 3.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -436        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 8           |
|    time_elapsed         | 4685        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.009508423 |
|    clip_fraction        | 0.0895      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.172      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.915       |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.992       |
|    value_loss           | 2.47        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.03e+03     |
|    ep_rew_mean          | -427         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 9            |
|    time_elapsed         | 5041         |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0096573215 |
|    clip_fraction        | 0.0829       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.0496       |
|    learning_rate        | 0.0003       |
|    loss                 | 0.947        |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.017       |
|    std                  | 0.992        |
|    value_loss           | 2.36         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-99.93 +/- 0.05
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.009697787 |
|    clip_fraction        | 0.0704      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.506       |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.992       |
|    value_loss           | 1.76        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -464     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 10       |
|    time_elapsed    | 7197     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2.01e+03     |
|    ep_rew_mean          | -457         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 11           |
|    time_elapsed         | 7556         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0030981293 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.00321      |
|    learning_rate        | 0.0003       |
|    loss                 | 148          |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00474     |
|    std                  | 0.992        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -448        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 12          |
|    time_elapsed         | 7914        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.008680968 |
|    clip_fraction        | 0.0814      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.923      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.24        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.99        |
|    value_loss           | 3.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -443        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 13          |
|    time_elapsed         | 8271        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.010519061 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.369      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.717       |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.992       |
|    value_loss           | 1.94        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.02e+03    |
|    ep_rew_mean          | -436        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 14          |
|    time_elapsed         | 8627        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.011008073 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.185       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.529       |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0187     |
|    std                  | 0.992       |
|    value_loss           | 1.38        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.63 +/- 0.11
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.013278929 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.362       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.73        |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.987       |
|    value_loss           | 1.49        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -461     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 15       |
|    time_elapsed    | 10784    |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -452        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 16          |
|    time_elapsed         | 11138       |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.009039396 |
|    clip_fraction        | 0.0667      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.00524     |
|    learning_rate        | 0.0003      |
|    loss                 | 180         |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00762    |
|    std                  | 0.987       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -445        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 11493       |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.014144204 |
|    clip_fraction        | 0.149       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.252      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.778       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.984       |
|    value_loss           | 2.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -439        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 18          |
|    time_elapsed         | 11848       |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.015297788 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.299       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.976       |
|    value_loss           | 1.37        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.02e+03   |
|    ep_rew_mean          | -432       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 19         |
|    time_elapsed         | 12202      |
|    total_timesteps      | 38912      |
| train/                  |            |
|    approx_kl            | 0.01705198 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.451      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.61       |
|    n_updates            | 180        |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.97       |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.90 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.015841074 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.97        |
|    value_loss           | 0.923       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -449     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 20       |
|    time_elapsed    | 14357    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -444        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 21          |
|    time_elapsed         | 14712       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.008485373 |
|    clip_fraction        | 0.0902      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00232    |
|    learning_rate        | 0.0003      |
|    loss                 | 38.7        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00683    |
|    std                  | 0.97        |
|    value_loss           | 1.02e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -438        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 22          |
|    time_elapsed         | 15066       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.013814168 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -2.61       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.726       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0163     |
|    std                  | 0.966       |
|    value_loss           | 2.1         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -433       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 23         |
|    time_elapsed         | 15420      |
|    total_timesteps      | 47104      |
| train/                  |            |
|    approx_kl            | 0.01636573 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.1      |
|    explained_variance   | 0.256      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.648      |
|    n_updates            | 220        |
|    policy_gradient_loss | -0.02      |
|    std                  | 0.964      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -428        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 24          |
|    time_elapsed         | 15774       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.018796355 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.343       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.321       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.963       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.31 +/- 0.43
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.015067887 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.505       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.964       |
|    value_loss           | 1.11        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -441     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 25       |
|    time_elapsed    | 17928    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -436        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 26          |
|    time_elapsed         | 18280       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.009362763 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.00524     |
|    learning_rate        | 0.0003      |
|    loss                 | 273         |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00649    |
|    std                  | 0.964       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -431        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 27          |
|    time_elapsed         | 18634       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.020046199 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.998      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.706       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.96        |
|    value_loss           | 2.21        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -427       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 28         |
|    time_elapsed         | 18987      |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.02305993 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.53       |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.956      |
|    value_loss           | 1.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -421        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 19339       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.016831033 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.463       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.626       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0183     |
|    std                  | 0.953       |
|    value_loss           | 0.971       |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.92 +/- 0.04
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.023857076 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.455       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.449       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.95        |
|    value_loss           | 0.853       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -431     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 30       |
|    time_elapsed    | 21492    |
|    total_timesteps | 61440    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -428         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 31           |
|    time_elapsed         | 21846        |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0062464797 |
|    clip_fraction        | 0.0635       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.9        |
|    explained_variance   | -0.00153     |
|    learning_rate        | 0.0003       |
|    loss                 | 12.3         |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00402     |
|    std                  | 0.95         |
|    value_loss           | 1.04e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -424        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 32          |
|    time_elapsed         | 22198       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.022516107 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.57       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.87        |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0186     |
|    std                  | 0.952       |
|    value_loss           | 1.79        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -420        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 33          |
|    time_elapsed         | 22552       |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.017601378 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.33        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.568       |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.947       |
|    value_loss           | 1.12        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -416        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 22905       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.021166451 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.59        |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.947       |
|    value_loss           | 1.32        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.57 +/- 0.07
Episode length: 3597.00 +/- 8.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.021413177 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.535       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.0235     |
|    std                  | 0.937       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -425     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 35       |
|    time_elapsed    | 25059    |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 2e+03        |
|    ep_rew_mean          | -422         |
| time/                   |              |
|    fps                  | 2            |
|    iterations           | 36           |
|    time_elapsed         | 25410        |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0074003516 |
|    clip_fraction        | 0.0792       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | -0.00192     |
|    learning_rate        | 0.0003       |
|    loss                 | 98.2         |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00559     |
|    std                  | 0.937        |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -417        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 37          |
|    time_elapsed         | 25762       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.021471452 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -1.04       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21        |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.934       |
|    value_loss           | 2.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -413        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 38          |
|    time_elapsed         | 26115       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.018646099 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.378       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.587       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.929       |
|    value_loss           | 1.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -411        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 26467       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.023885798 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.366       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.71        |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0213     |
|    std                  | 0.922       |
|    value_loss           | 1.29        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.76 +/- 0.19
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 80000      |
| train/                  |            |
|    approx_kl            | 0.02230283 |
|    clip_fraction        | 0.244      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 390        |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.914      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -418     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 40       |
|    time_elapsed    | 28619    |
|    total_timesteps | 81920    |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -415       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 41         |
|    time_elapsed         | 28972      |
|    total_timesteps      | 83968      |
| train/                  |            |
|    approx_kl            | 0.01922406 |
|    clip_fraction        | 0.2        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.00285   |
|    learning_rate        | 0.0003     |
|    loss                 | 244        |
|    n_updates            | 400        |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.914      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -411        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 42          |
|    time_elapsed         | 29321       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.030925244 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.253      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.673       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.91        |
|    value_loss           | 1.62        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -406       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 43         |
|    time_elapsed         | 29674      |
|    total_timesteps      | 88064      |
| train/                  |            |
|    approx_kl            | 0.03375437 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.386      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.624      |
|    n_updates            | 420        |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.905      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.67 +/- 0.12
Episode length: 3596.20 +/- 8.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.03153988 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.65       |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.901      |
|    value_loss           | 1.38       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -409     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 44       |
|    time_elapsed    | 31825    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -405        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 45          |
|    time_elapsed         | 32177       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.008294015 |
|    clip_fraction        | 0.0749      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.00419     |
|    learning_rate        | 0.0003      |
|    loss                 | 216         |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.901       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -401      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 46        |
|    time_elapsed         | 32527     |
|    total_timesteps      | 94208     |
| train/                  |           |
|    approx_kl            | 0.0320633 |
|    clip_fraction        | 0.289     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | -0.481    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.932     |
|    n_updates            | 450       |
|    policy_gradient_loss | -0.0188   |
|    std                  | 0.894     |
|    value_loss           | 1.79      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -401        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 47          |
|    time_elapsed         | 32877       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.027866919 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.473       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.884       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0228     |
|    std                  | 0.889       |
|    value_loss           | 1.53        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -398       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 48         |
|    time_elapsed         | 33226      |
|    total_timesteps      | 98304      |
| train/                  |            |
|    approx_kl            | 0.03362155 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.383      |
|    n_updates            | 470        |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.883      |
|    value_loss           | 0.962      |
----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.71 +/- 0.12
Episode length: 3596.60 +/- 6.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.036780335 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.502       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.408       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0159     |
|    std                  | 0.883       |
|    value_loss           | 1.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -399     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 49       |
|    time_elapsed    | 35377    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -395        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 50          |
|    time_elapsed         | 35727       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.012552269 |
|    clip_fraction        | 0.111       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.000786    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01e+03    |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00642    |
|    std                  | 0.881       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -391        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 51          |
|    time_elapsed         | 36076       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.023788724 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.538       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.879       |
|    value_loss           | 1.49        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -387        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 52          |
|    time_elapsed         | 36426       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.027751628 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.399       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.878       |
|    value_loss           | 0.984       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -383        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 53          |
|    time_elapsed         | 36774       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.033072386 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.515       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.682       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.877       |
|    value_loss           | 1.15        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.80 +/- 0.17
Episode length: 3599.20 +/- 3.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.030993028 |
|    clip_fraction        | 0.317       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.61        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.215       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.871       |
|    value_loss           | 0.841       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -388     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 54       |
|    time_elapsed    | 38925    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -384        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 55          |
|    time_elapsed         | 39274       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.011908456 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00089     |
|    learning_rate        | 0.0003      |
|    loss                 | 204         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.0056     |
|    std                  | 0.871       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -380        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 56          |
|    time_elapsed         | 39623       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.034552623 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -1.04       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.552       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.87        |
|    value_loss           | 1.41        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -376       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 57         |
|    time_elapsed         | 39971      |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.03879391 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.375      |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.868      |
|    value_loss           | 0.829      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -372        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 58          |
|    time_elapsed         | 40317       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.035906564 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.575       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.442       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.863       |
|    value_loss           | 0.97        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.84 +/- 0.13
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.034553707 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.636       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.0179     |
|    std                  | 0.865       |
|    value_loss           | 0.9         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -376     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 59       |
|    time_elapsed    | 42464    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -372        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 60          |
|    time_elapsed         | 42815       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.008923648 |
|    clip_fraction        | 0.081       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.00156    |
|    learning_rate        | 0.0003      |
|    loss                 | 9.69        |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00891    |
|    std                  | 0.865       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -368        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 61          |
|    time_elapsed         | 43164       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.036008753 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.0955     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.388       |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.859       |
|    value_loss           | 1.14        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -364       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 62         |
|    time_elapsed         | 43509      |
|    total_timesteps      | 126976     |
| train/                  |            |
|    approx_kl            | 0.03367257 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.415      |
|    n_updates            | 610        |
|    policy_gradient_loss | -0.0183    |
|    std                  | 0.852      |
|    value_loss           | 1.05       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -360       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 63         |
|    time_elapsed         | 43853      |
|    total_timesteps      | 129024     |
| train/                  |            |
|    approx_kl            | 0.04234782 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.591      |
|    n_updates            | 620        |
|    policy_gradient_loss | -0.017     |
|    std                  | 0.852      |
|    value_loss           | 1.16       |
----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.84 +/- 0.21
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 130000     |
| train/                  |            |
|    approx_kl            | 0.03414198 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.505      |
|    n_updates            | 630        |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.852      |
|    value_loss           | 1.24       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -363     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 64       |
|    time_elapsed    | 45999    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -359        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 65          |
|    time_elapsed         | 46344       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.017370086 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.00298    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.86        |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00462    |
|    std                  | 0.852       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -355       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 66         |
|    time_elapsed         | 46689      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.03809467 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.566      |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.844      |
|    value_loss           | 1.09       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -351        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 67          |
|    time_elapsed         | 47035       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.040670723 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.66        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.395       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.0174     |
|    std                  | 0.842       |
|    value_loss           | 0.898       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -346       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 68         |
|    time_elapsed         | 47378      |
|    total_timesteps      | 139264     |
| train/                  |            |
|    approx_kl            | 0.03913212 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.371      |
|    n_updates            | 670        |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.85       |
|    value_loss           | 0.893      |
----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.87 +/- 0.17
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.027731504 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.585       |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.843       |
|    value_loss           | 0.983       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -349     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 69       |
|    time_elapsed    | 49521    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -345        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 70          |
|    time_elapsed         | 49863       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.016146412 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.00271    |
|    learning_rate        | 0.0003      |
|    loss                 | 67.8        |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.842       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -340       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 71         |
|    time_elapsed         | 50206      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.03616432 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.97      |
|    explained_variance   | -0.373     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.54       |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.844      |
|    value_loss           | 1.16       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -336       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 72         |
|    time_elapsed         | 50551      |
|    total_timesteps      | 147456     |
| train/                  |            |
|    approx_kl            | 0.03444654 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.96      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.497      |
|    n_updates            | 710        |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.839      |
|    value_loss           | 1.03       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -332        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 73          |
|    time_elapsed         | 50895       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.036519572 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.91       |
|    explained_variance   | 0.622       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.834       |
|    value_loss           | 1.04        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.58 +/- 0.24
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.04081051 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.87      |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.387      |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.833      |
|    value_loss           | 0.849      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -334     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 74       |
|    time_elapsed    | 53037    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -330        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 75          |
|    time_elapsed         | 53378       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.015701769 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.00838     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95e+03    |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.0076     |
|    std                  | 0.833       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -326        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 76          |
|    time_elapsed         | 53720       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.039090425 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | -0.114      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.461       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.00823    |
|    std                  | 0.831       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -322        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 77          |
|    time_elapsed         | 54061       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.031358708 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.82       |
|    explained_variance   | 0.516       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.397       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.827       |
|    value_loss           | 1.17        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -317        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 78          |
|    time_elapsed         | 54403       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.038349137 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.583       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.684       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.823       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-100.10 +/- 0.19
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.040067583 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.73       |
|    explained_variance   | 0.641       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.397       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.817       |
|    value_loss           | 0.981       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -320     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 79       |
|    time_elapsed    | 56546    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -316        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 80          |
|    time_elapsed         | 56887       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.012481968 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.00198     |
|    learning_rate        | 0.0003      |
|    loss                 | 108         |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00314    |
|    std                  | 0.816       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -312       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 81         |
|    time_elapsed         | 57228      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.03691634 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.69      |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.214      |
|    n_updates            | 800        |
|    policy_gradient_loss | -0.00748   |
|    std                  | 0.814      |
|    value_loss           | 0.801      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -308        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 82          |
|    time_elapsed         | 57568       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.040559992 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.444       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.81        |
|    value_loss           | 1           |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -304        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 83          |
|    time_elapsed         | 57909       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.040274233 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.63       |
|    explained_variance   | 0.655       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.502       |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0198     |
|    std                  | 0.809       |
|    value_loss           | 0.965       |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.80 +/- 0.10
Episode length: 3598.00 +/- 5.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.030265268 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.62       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00712    |
|    std                  | 0.808       |
|    value_loss           | 1.01        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -306     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 84       |
|    time_elapsed    | 60049    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -302        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 85          |
|    time_elapsed         | 60390       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.037599612 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.6        |
|    explained_variance   | 0.00601     |
|    learning_rate        | 0.0003      |
|    loss                 | 348         |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.00166    |
|    std                  | 0.806       |
|    value_loss           | 925         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -298        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 86          |
|    time_elapsed         | 60730       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.062081605 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.53        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.491       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.802       |
|    value_loss           | 1.02        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2.01e+03   |
|    ep_rew_mean          | -295       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 87         |
|    time_elapsed         | 61070      |
|    total_timesteps      | 178176     |
| train/                  |            |
|    approx_kl            | 0.03866872 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.54      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.263      |
|    n_updates            | 860        |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.8        |
|    value_loss           | 0.818      |
----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.69 +/- 0.20
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.037541583 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.52       |
|    explained_variance   | 0.693       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.338       |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00964    |
|    std                  | 0.797       |
|    value_loss           | 0.95        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -293     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 88       |
|    time_elapsed    | 63211    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -289        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 89          |
|    time_elapsed         | 63550       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.015881674 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.00525     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.09        |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00354    |
|    std                  | 0.796       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -289        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 90          |
|    time_elapsed         | 63888       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.041310236 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.24        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.532       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00772    |
|    std                  | 0.791       |
|    value_loss           | 1.38        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -285        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 91          |
|    time_elapsed         | 64227       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.040626965 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.41       |
|    explained_variance   | 0.573       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.575       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00929    |
|    std                  | 0.787       |
|    value_loss           | 1.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -281        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 92          |
|    time_elapsed         | 64566       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.043460973 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | 0.691       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.396       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.782       |
|    value_loss           | 0.989       |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.69 +/- 0.22
Episode length: 3595.60 +/- 10.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.03759145 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.33      |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.593      |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.0103    |
|    std                  | 0.779      |
|    value_loss           | 1.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -279     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 93       |
|    time_elapsed    | 66704    |
|    total_timesteps | 190464   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -275        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 94          |
|    time_elapsed         | 67044       |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.024435911 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | -0.0011     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.56e+03    |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00603    |
|    std                  | 0.778       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -272        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 95          |
|    time_elapsed         | 67384       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.040749773 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.799       |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.774       |
|    value_loss           | 1.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -268        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 96          |
|    time_elapsed         | 67722       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.042023383 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | 0.577       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.575       |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00762    |
|    std                  | 0.772       |
|    value_loss           | 1.33        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -268        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 97          |
|    time_elapsed         | 68059       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.041135892 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.26       |
|    explained_variance   | 0.617       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.711       |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.775       |
|    value_loss           | 1.29        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.90 +/- 0.17
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.034059398 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.21       |
|    explained_variance   | 0.607       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.62        |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.765       |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -266     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 98       |
|    time_elapsed    | 70200    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -261        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 99          |
|    time_elapsed         | 70540       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.032036036 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.00358     |
|    learning_rate        | 0.0003      |
|    loss                 | 58          |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00444    |
|    std                  | 0.765       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -256       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 100        |
|    time_elapsed         | 70879      |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.03802333 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.2       |
|    explained_variance   | 0.475      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.545      |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0134    |
|    std                  | 0.768      |
|    value_loss           | 1.19       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -251        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 101         |
|    time_elapsed         | 71217       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.035557237 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.737       |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.763       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2.01e+03    |
|    ep_rew_mean          | -246        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 102         |
|    time_elapsed         | 71555       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.043778487 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.14       |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.894       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.761       |
|    value_loss           | 2.09        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.81 +/- 0.13
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.039150998 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.625       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.569       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0143     |
|    std                  | 0.76        |
|    value_loss           | 1.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -242     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 103      |
|    time_elapsed    | 73692    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -237        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 104         |
|    time_elapsed         | 74031       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.044169273 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.12       |
|    explained_variance   | 0.0029      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.42        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00572    |
|    std                  | 0.761       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | -232      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 105       |
|    time_elapsed         | 74370     |
|    total_timesteps      | 215040    |
| train/                  |           |
|    approx_kl            | 0.0753899 |
|    clip_fraction        | 0.347     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.09     |
|    explained_variance   | 0.491     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.494     |
|    n_updates            | 1040      |
|    policy_gradient_loss | -0.0167   |
|    std                  | 0.755     |
|    value_loss           | 1.25      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -227        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 106         |
|    time_elapsed         | 74706       |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.030157814 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.06       |
|    explained_variance   | 0.576       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.668       |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00875    |
|    std                  | 0.754       |
|    value_loss           | 1.54        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -222       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 107        |
|    time_elapsed         | 75044      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.03377544 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.654      |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.00889   |
|    std                  | 0.756      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-98.88 +/- 0.71
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.9       |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.045024972 |
|    clip_fraction        | 0.322       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.555       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.443       |
|    n_updates            | 1070        |
|    policy_gradient_loss | -0.0134     |
|    std                  | 0.752       |
|    value_loss           | 1.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -218     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 108      |
|    time_elapsed    | 77181    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -213        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 109         |
|    time_elapsed         | 77518       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.015452779 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.02       |
|    explained_variance   | 0.00842     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06e+03    |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00685    |
|    std                  | 0.751       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -208        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 110         |
|    time_elapsed         | 77854       |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.050077643 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9          |
|    explained_variance   | -0.439      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.63        |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.748       |
|    value_loss           | 1.67        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -203        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 111         |
|    time_elapsed         | 78193       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.037538413 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.97       |
|    explained_variance   | 0.614       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.37        |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.746       |
|    value_loss           | 1.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -198        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 112         |
|    time_elapsed         | 78531       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.044030912 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.92       |
|    explained_variance   | 0.658       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.41        |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0172     |
|    std                  | 0.742       |
|    value_loss           | 1.12        |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-97.38 +/- 1.32
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -97.4       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.037863985 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.625       |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.74        |
|    value_loss           | 1.48        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -193     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 113      |
|    time_elapsed    | 80669    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -188        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 114         |
|    time_elapsed         | 81006       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.039556794 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.9        |
|    explained_variance   | -0.00327    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.27        |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.000776   |
|    std                  | 0.741       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -183        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 115         |
|    time_elapsed         | 81341       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.051133376 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.383       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.739       |
|    value_loss           | 1.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -178        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 116         |
|    time_elapsed         | 81677       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.033343658 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.569       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.00328    |
|    std                  | 0.74        |
|    value_loss           | 1.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -173        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 117         |
|    time_elapsed         | 82015       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.032630593 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.87       |
|    explained_variance   | 0.571       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.594       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.00597    |
|    std                  | 0.737       |
|    value_loss           | 1.23        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-98.35 +/- 1.11
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -98.4     |
| time/                   |           |
|    total_timesteps      | 240000    |
| train/                  |           |
|    approx_kl            | 0.0417513 |
|    clip_fraction        | 0.331     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.85     |
|    explained_variance   | 0.388     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.388     |
|    n_updates            | 1170      |
|    policy_gradient_loss | -0.00883  |
|    std                  | 0.735     |
|    value_loss           | 2.56      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -169     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 118      |
|    time_elapsed    | 84151    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -164        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 119         |
|    time_elapsed         | 84486       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.030888805 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.85       |
|    explained_variance   | 0.00441     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.69        |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.00633    |
|    std                  | 0.737       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -158        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 120         |
|    time_elapsed         | 84820       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.040973447 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.84       |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.556       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00875    |
|    std                  | 0.736       |
|    value_loss           | 1.41        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -153       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 121        |
|    time_elapsed         | 85156      |
|    total_timesteps      | 247808     |
| train/                  |            |
|    approx_kl            | 0.04098376 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.642      |
|    n_updates            | 1200       |
|    policy_gradient_loss | -0.00884   |
|    std                  | 0.735      |
|    value_loss           | 1.24       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -148        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 122         |
|    time_elapsed         | 85492       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.042056993 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.8        |
|    explained_variance   | 0.507       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.596       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.0123     |
|    std                  | 0.73        |
|    value_loss           | 1.47        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-96.42 +/- 1.80
Episode length: 3596.00 +/- 10.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -96.4       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.035763837 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | 0.545       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.666       |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.0132     |
|    std                  | 0.727       |
|    value_loss           | 1.23        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -145     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 123      |
|    time_elapsed    | 87628    |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -140       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 124        |
|    time_elapsed         | 87964      |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.05787509 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.75      |
|    explained_variance   | 0.0023     |
|    learning_rate        | 0.0003     |
|    loss                 | 735        |
|    n_updates            | 1230       |
|    policy_gradient_loss | -0.000721  |
|    std                  | 0.726      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -135        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 125         |
|    time_elapsed         | 88301       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.043699086 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.312       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.453       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.722       |
|    value_loss           | 1.3         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -130        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 126         |
|    time_elapsed         | 88636       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.046970442 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.851       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.72        |
|    value_loss           | 1.51        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-95.28 +/- 1.15
Episode length: 3596.20 +/- 8.63
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -95.3      |
| time/                   |            |
|    total_timesteps      | 260000     |
| train/                  |            |
|    approx_kl            | 0.03875226 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.65      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.599      |
|    n_updates            | 1260       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.716      |
|    value_loss           | 1.29       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -122     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 127      |
|    time_elapsed    | 90773    |
|    total_timesteps | 260096   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -122       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 128        |
|    time_elapsed         | 91109      |
|    total_timesteps      | 262144     |
| train/                  |            |
|    approx_kl            | 0.04396373 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.64      |
|    explained_variance   | -0.00147   |
|    learning_rate        | 0.0003     |
|    loss                 | 438        |
|    n_updates            | 1270       |
|    policy_gradient_loss | 0.00215    |
|    std                  | 0.719      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -117        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 129         |
|    time_elapsed         | 91443       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.055029925 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.646       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.00931    |
|    std                  | 0.72        |
|    value_loss           | 2.75        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -112        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 130         |
|    time_elapsed         | 91777       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.042579215 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.58        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.483       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.719       |
|    value_loss           | 1.13        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -106       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 131        |
|    time_elapsed         | 92111      |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.05657904 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.66      |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.64       |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.719      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.71 +/- 0.50
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 270000     |
| train/                  |            |
|    approx_kl            | 0.04832531 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | 0.504      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.535      |
|    n_updates            | 1310       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.714      |
|    value_loss           | 1.34       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -98      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 132      |
|    time_elapsed    | 94247    |
|    total_timesteps | 270336   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 2e+03    |
|    ep_rew_mean          | -92.8    |
| time/                   |          |
|    fps                  | 2        |
|    iterations           | 133      |
|    time_elapsed         | 94580    |
|    total_timesteps      | 272384   |
| train/                  |          |
|    approx_kl            | 0.061442 |
|    clip_fraction        | 0.278    |
|    clip_range           | 0.2      |
|    entropy_loss         | -8.61    |
|    explained_variance   | 0.000491 |
|    learning_rate        | 0.0003   |
|    loss                 | 1.25e+03 |
|    n_updates            | 1320     |
|    policy_gradient_loss | -0.00466 |
|    std                  | 0.715    |
|    value_loss           | 1.04e+03 |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -88.3      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 134        |
|    time_elapsed         | 94915      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.05457683 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.6       |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.46       |
|    n_updates            | 1330       |
|    policy_gradient_loss | -0.015     |
|    std                  | 0.713      |
|    value_loss           | 1.19       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -88.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 135         |
|    time_elapsed         | 95252       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.038772892 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.57       |
|    explained_variance   | 0.502       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.494       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.71        |
|    value_loss           | 1.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -83.4       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 136         |
|    time_elapsed         | 95592       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.052651763 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | 0.578       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.551       |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00164    |
|    std                  | 0.71        |
|    value_loss           | 1.16        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.04 +/- 0.56
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99         |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.049787197 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.54       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.892       |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.00771    |
|    std                  | 0.708       |
|    value_loss           | 1.46        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -75.2    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 137      |
|    time_elapsed    | 97728    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -70.3       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 138         |
|    time_elapsed         | 98064       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.028893381 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | 0.00238     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+03    |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00471    |
|    std                  | 0.708       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -65.8      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 139        |
|    time_elapsed         | 98398      |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.06004472 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | 0.323      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.615      |
|    n_updates            | 1380       |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.705      |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -61.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 140         |
|    time_elapsed         | 98733       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.049860418 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | 0.5         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.63        |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.00402    |
|    std                  | 0.701       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -61.6       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 141         |
|    time_elapsed         | 99069       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.030222293 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.445       |
|    n_updates            | 1400        |
|    policy_gradient_loss | -0.00315    |
|    std                  | 0.7         |
|    value_loss           | 1.29        |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-91.75 +/- 2.71
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -91.8     |
| time/                   |           |
|    total_timesteps      | 290000    |
| train/                  |           |
|    approx_kl            | 0.0393629 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.44     |
|    explained_variance   | 0.431     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.46      |
|    n_updates            | 1410      |
|    policy_gradient_loss | -0.0115   |
|    std                  | 0.697     |
|    value_loss           | 1.58      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -54.1    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 142      |
|    time_elapsed    | 101209   |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -49.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 143         |
|    time_elapsed         | 101544      |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.050324596 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.42       |
|    explained_variance   | 0.00188     |
|    learning_rate        | 0.0003      |
|    loss                 | 794         |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00183    |
|    std                  | 0.697       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -45.3      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 144        |
|    time_elapsed         | 101877     |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.06637074 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.4       |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.901      |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.0124    |
|    std                  | 0.695      |
|    value_loss           | 1.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -40.8      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 145        |
|    time_elapsed         | 102212     |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.06194023 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.544      |
|    n_updates            | 1440       |
|    policy_gradient_loss | -0.00966   |
|    std                  | 0.691      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -36.5      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 146        |
|    time_elapsed         | 102545     |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.04143551 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.33      |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.643      |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.687      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.29 +/- 0.27
Episode length: 3596.60 +/- 7.39
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.049773768 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.643       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.592       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.0131     |
|    std                  | 0.687       |
|    value_loss           | 0.864       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -33.7    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 147      |
|    time_elapsed    | 104679   |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -29.2       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 148         |
|    time_elapsed         | 105012      |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.029715417 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.00257     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.67        |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00604    |
|    std                  | 0.686       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -24.8       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 149         |
|    time_elapsed         | 105345      |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.060097966 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.3        |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.688       |
|    value_loss           | 1.13        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -20.4      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 150        |
|    time_elapsed         | 105679     |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.06449428 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.3       |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.427      |
|    n_updates            | 1490       |
|    policy_gradient_loss | -0.0108    |
|    std                  | 0.686      |
|    value_loss           | 0.944      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -16.2       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 151         |
|    time_elapsed         | 106012      |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.056582917 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.26       |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.58        |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00959    |
|    std                  | 0.683       |
|    value_loss           | 1.23        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.62 +/- 0.10
Episode length: 3596.80 +/- 5.19
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.052821618 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.59        |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.00641    |
|    std                  | 0.682       |
|    value_loss           | 1.3         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | -13.4    |
| time/              |          |
|    fps             | 2        |
|    iterations      | 152      |
|    time_elapsed    | 108147   |
|    total_timesteps | 311296   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -9.19      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 153        |
|    time_elapsed         | 108481     |
|    total_timesteps      | 313344     |
| train/                  |            |
|    approx_kl            | 0.03281215 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.24      |
|    explained_variance   | -0.00108   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.35e+03   |
|    n_updates            | 1520       |
|    policy_gradient_loss | -0.00342   |
|    std                  | 0.682      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | -4.76      |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 154        |
|    time_elapsed         | 108815     |
|    total_timesteps      | 315392     |
| train/                  |            |
|    approx_kl            | 0.07819097 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.2       |
|    explained_variance   | 0.286      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.635      |
|    n_updates            | 1530       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.676      |
|    value_loss           | 1.1        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | -1.18       |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 155         |
|    time_elapsed         | 109149      |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.064097226 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.14       |
|    explained_variance   | 0.459       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.761       |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.673       |
|    value_loss           | 1.46        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 2.74       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 156        |
|    time_elapsed         | 109482     |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.03616769 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.13      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.74       |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.00635   |
|    std                  | 0.673      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-93.85 +/- 2.34
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -93.8       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.043624915 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | 0.527       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.552       |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.013      |
|    std                  | 0.675       |
|    value_loss           | 1.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 5.04     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 157      |
|    time_elapsed    | 111617   |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 8.62        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 158         |
|    time_elapsed         | 111952      |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.038797017 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.0107      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.03        |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00446    |
|    std                  | 0.676       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 12.5       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 159        |
|    time_elapsed         | 112286     |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.06384684 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.15      |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.617      |
|    n_updates            | 1580       |
|    policy_gradient_loss | -0.00321   |
|    std                  | 0.674      |
|    value_loss           | 1.56       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 16.3        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 160         |
|    time_elapsed         | 112620      |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.054499254 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.15       |
|    explained_variance   | 0.428       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.724       |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.676       |
|    value_loss           | 1.44        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 20.1        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 161         |
|    time_elapsed         | 112954      |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.056043558 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.16       |
|    explained_variance   | 0.502       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.871       |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.675       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.10 +/- 0.18
Episode length: 3598.60 +/- 4.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.04868398 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.12      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.497      |
|    n_updates            | 1610       |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.67       |
|    value_loss           | 1.19       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 22.3     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 162      |
|    time_elapsed    | 115090   |
|    total_timesteps | 331776   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 26.1        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 163         |
|    time_elapsed         | 115424      |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.031764522 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.09       |
|    explained_variance   | 0.00254     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+03    |
|    n_updates            | 1620        |
|    policy_gradient_loss | -0.00416    |
|    std                  | 0.67        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 30         |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 164        |
|    time_elapsed         | 115757     |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.06469098 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.203      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.509      |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.667      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 33.8        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 165         |
|    time_elapsed         | 116091      |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.056990147 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.491       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 1640        |
|    policy_gradient_loss | -0.00621    |
|    std                  | 0.668       |
|    value_loss           | 1.23        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 37         |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 166        |
|    time_elapsed         | 116427     |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.05500257 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.784      |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.00958   |
|    std                  | 0.666      |
|    value_loss           | 1.43       |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-16.98 +/- 14.35
Episode length: 3598.00 +/- 6.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -17         |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.042088762 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.323       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.914       |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.0155     |
|    std                  | 0.668       |
|    value_loss           | 1.83        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 38.5     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 167      |
|    time_elapsed    | 118566   |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 41.8       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 168        |
|    time_elapsed         | 118902     |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.03248722 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.07      |
|    explained_variance   | 0.000285   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.73e+03   |
|    n_updates            | 1670       |
|    policy_gradient_loss | -0.00659   |
|    std                  | 0.667      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 45.1        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 169         |
|    time_elapsed         | 119238      |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.052160405 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.04       |
|    explained_variance   | 0.285       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.664       |
|    value_loss           | 2.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 48.6       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 170        |
|    time_elapsed         | 119574     |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.04770043 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.01      |
|    explained_variance   | 0.322      |
|    learning_rate        | 0.0003     |
|    loss                 | 1          |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.661      |
|    value_loss           | 2.15       |
----------------------------------------
Eval num_timesteps=350000, episode_reward=37.82 +/- 9.41
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 37.8       |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.04371376 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.97      |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.715      |
|    n_updates            | 1700       |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.658      |
|    value_loss           | 1.7        |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 54       |
| time/              |          |
|    fps             | 2        |
|    iterations      | 171      |
|    time_elapsed    | 121710   |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 57.2        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 172         |
|    time_elapsed         | 122045      |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.033017736 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.96       |
|    explained_variance   | -0.00149    |
|    learning_rate        | 0.0003      |
|    loss                 | 360         |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00439    |
|    std                  | 0.658       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 57.2        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 173         |
|    time_elapsed         | 122382      |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.050407752 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.0114      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.882       |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.01       |
|    std                  | 0.655       |
|    value_loss           | 1.79        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 60.4        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 174         |
|    time_elapsed         | 122719      |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.051548924 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.91       |
|    explained_variance   | 0.346       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.63        |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0164     |
|    std                  | 0.653       |
|    value_loss           | 1.88        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 64.2        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 175         |
|    time_elapsed         | 123055      |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.043742128 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.9        |
|    explained_variance   | 0.382       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.649       |
|    n_updates            | 1740        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.653       |
|    value_loss           | 1.87        |
-----------------------------------------
Eval num_timesteps=360000, episode_reward=159.18 +/- 8.78
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 159        |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.04362759 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.89      |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.671      |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.652      |
|    value_loss           | 1.98       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 69.4     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 176      |
|    time_elapsed    | 125193   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 72.5        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 177         |
|    time_elapsed         | 125529      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.029111316 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | 0.00215     |
|    learning_rate        | 0.0003      |
|    loss                 | 672         |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00996    |
|    std                  | 0.653       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 75.9       |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 178        |
|    time_elapsed         | 125866     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.06709394 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.159      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.58       |
|    n_updates            | 1770       |
|    policy_gradient_loss | -0.00475   |
|    std                  | 0.651      |
|    value_loss           | 2.24       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 79.2      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 179       |
|    time_elapsed         | 126205    |
|    total_timesteps      | 366592    |
| train/                  |           |
|    approx_kl            | 0.0502031 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.88     |
|    explained_variance   | 0.329     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.747     |
|    n_updates            | 1780      |
|    policy_gradient_loss | -0.0139   |
|    std                  | 0.653     |
|    value_loss           | 1.89      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 79.2      |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 180       |
|    time_elapsed         | 126540    |
|    total_timesteps      | 368640    |
| train/                  |           |
|    approx_kl            | 0.0346219 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.85     |
|    explained_variance   | 0.364     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.06      |
|    n_updates            | 1790      |
|    policy_gradient_loss | -0.0145   |
|    std                  | 0.647     |
|    value_loss           | 1.9       |
---------------------------------------
Eval num_timesteps=370000, episode_reward=163.62 +/- 13.04
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 164         |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.034200832 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.33        |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.647       |
|    value_loss           | 2.32        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 84.6     |
| time/              |          |
|    fps             | 2        |
|    iterations      | 181      |
|    time_elapsed    | 128682   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 88.1        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 182         |
|    time_elapsed         | 129019      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.017689884 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | 0.00156     |
|    learning_rate        | 0.0003      |
|    loss                 | 430         |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00337    |
|    std                  | 0.647       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 91.9        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 183         |
|    time_elapsed         | 129356      |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.053083062 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.8        |
|    explained_variance   | 0.0752      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.836       |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.646       |
|    value_loss           | 2.71        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 95         |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 184        |
|    time_elapsed         | 129693     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.03993021 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.79      |
|    explained_variance   | 0.344      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.1        |
|    n_updates            | 1830       |
|    policy_gradient_loss | -0.00495   |
|    std                  | 0.644      |
|    value_loss           | 2.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 98.7        |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 185         |
|    time_elapsed         | 130030      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.045054354 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.74       |
|    explained_variance   | 0.262       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18        |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.0148     |
|    std                  | 0.639       |
|    value_loss           | 2.33        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=89.82 +/- 16.13
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 89.8       |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.04723785 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.7       |
|    explained_variance   | 0.298      |
|    learning_rate        | 0.0003     |
|    loss                 | 1          |
|    n_updates            | 1850       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.637      |
|    value_loss           | 2.34       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 291      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 186      |
|    time_elapsed    | 132166   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 295         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 187         |
|    time_elapsed         | 132502      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.024176048 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.69       |
|    explained_variance   | -2.66e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.83e+04    |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.000517    |
|    std                  | 0.637       |
|    value_loss           | 1.44e+06    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 298         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 188         |
|    time_elapsed         | 132839      |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.034437824 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.68       |
|    explained_variance   | -5.5        |
|    learning_rate        | 0.0003      |
|    loss                 | 2.43        |
|    n_updates            | 1870        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.635       |
|    value_loss           | 13.9        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 302         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 189         |
|    time_elapsed         | 133176      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.047962736 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.64       |
|    explained_variance   | -0.0538     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.39        |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.631       |
|    value_loss           | 3.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 305         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 190         |
|    time_elapsed         | 133514      |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.052275255 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.61       |
|    explained_variance   | 0.184       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.629       |
|    value_loss           | 3.32        |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=188.39 +/- 9.29
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 188        |
| time/                   |            |
|    total_timesteps      | 390000     |
| train/                  |            |
|    approx_kl            | 0.05492792 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.56      |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.25       |
|    n_updates            | 1900       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.625      |
|    value_loss           | 3.07       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 307      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 191      |
|    time_elapsed    | 135654   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 310         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 192         |
|    time_elapsed         | 135994      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.031000564 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.54       |
|    explained_variance   | 0.00174     |
|    learning_rate        | 0.0003      |
|    loss                 | 13.2        |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00876    |
|    std                  | 0.625       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 2e+03     |
|    ep_rew_mean          | 314       |
| time/                   |           |
|    fps                  | 2         |
|    iterations           | 193       |
|    time_elapsed         | 136333    |
|    total_timesteps      | 395264    |
| train/                  |           |
|    approx_kl            | 0.0411608 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.53     |
|    explained_variance   | -0.159    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.81      |
|    n_updates            | 1920      |
|    policy_gradient_loss | -0.0173   |
|    std                  | 0.623     |
|    value_loss           | 4.01      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.99e+03    |
|    ep_rew_mean          | 326         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 194         |
|    time_elapsed         | 136671      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.051545337 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.51       |
|    explained_variance   | 0.174       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.621       |
|    value_loss           | 3.55        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.99e+03    |
|    ep_rew_mean          | 330         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 195         |
|    time_elapsed         | 137010      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.017745018 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.5        |
|    explained_variance   | 0.00119     |
|    learning_rate        | 0.0003      |
|    loss                 | 510         |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.622       |
|    value_loss           | 4.04e+03    |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=274.17 +/- 12.75
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 274         |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.057548277 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.5        |
|    explained_variance   | -1.24       |
|    learning_rate        | 0.0003      |
|    loss                 | 3.18        |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.623       |
|    value_loss           | 6.82        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 334      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 196      |
|    time_elapsed    | 139151   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 2e+03      |
|    ep_rew_mean          | 337        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 197        |
|    time_elapsed         | 139490     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.02160057 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.51      |
|    explained_variance   | -0.000789  |
|    learning_rate        | 0.0003     |
|    loss                 | 1.71e+03   |
|    n_updates            | 1960       |
|    policy_gradient_loss | -0.00577   |
|    std                  | 0.622      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 342         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 198         |
|    time_elapsed         | 139832      |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.058715455 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.48       |
|    explained_variance   | -0.192      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.6         |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.0135     |
|    std                  | 0.619       |
|    value_loss           | 3.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 346         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 199         |
|    time_elapsed         | 140170      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.055088602 |
|    clip_fraction        | 0.431       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.0903      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.32        |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.0269     |
|    std                  | 0.616       |
|    value_loss           | 5.06        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 2e+03       |
|    ep_rew_mean          | 350         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 200         |
|    time_elapsed         | 140509      |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.057740577 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.42       |
|    explained_variance   | 0.0879      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01        |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.0136     |
|    std                  | 0.614       |
|    value_loss           | 3.77        |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=741.00 +/- 481.44
Episode length: 3424.80 +/- 317.63
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.42e+03    |
|    mean_reward          | 741         |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.041822653 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.39       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.56        |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.018      |
|    std                  | 0.612       |
|    value_loss           | 3.57        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 2e+03    |
|    ep_rew_mean     | 353      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 201      |
|    time_elapsed    | 142565   |
|    total_timesteps | 411648   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.99e+03    |
|    ep_rew_mean          | 379         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 202         |
|    time_elapsed         | 142904      |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.022583988 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.38       |
|    explained_variance   | 0.00373     |
|    learning_rate        | 0.0003      |
|    loss                 | 108         |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.007      |
|    std                  | 0.612       |
|    value_loss           | 949         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.99e+03    |
|    ep_rew_mean          | 383         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 203         |
|    time_elapsed         | 143245      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.008544581 |
|    clip_fraction        | 0.163       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.38       |
|    explained_variance   | 0.000998    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+03    |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00963    |
|    std                  | 0.612       |
|    value_loss           | 8.08e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.98e+03    |
|    ep_rew_mean          | 412         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 204         |
|    time_elapsed         | 143586      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.049790025 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.35       |
|    explained_variance   | -1.24       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.16        |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.609       |
|    value_loss           | 5.95        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.98e+03    |
|    ep_rew_mean          | 412         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 205         |
|    time_elapsed         | 143925      |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.011433322 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.33       |
|    explained_variance   | 0.00103     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8e+03     |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00771    |
|    std                  | 0.608       |
|    value_loss           | 7.93e+03    |
-----------------------------------------
Eval num_timesteps=420000, episode_reward=811.08 +/- 379.58
Episode length: 2161.60 +/- 1347.78
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.16e+03    |
|    mean_reward          | 811         |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.056080572 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | -1.7        |
|    learning_rate        | 0.0003      |
|    loss                 | 2.02        |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.602       |
|    value_loss           | 5.9         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.96e+03 |
|    ep_rew_mean     | 412      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 206      |
|    time_elapsed    | 145347   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.96e+03    |
|    ep_rew_mean          | 416         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 207         |
|    time_elapsed         | 145687      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.044834755 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.24       |
|    explained_variance   | 0.00584     |
|    learning_rate        | 0.0003      |
|    loss                 | 12.6        |
|    n_updates            | 2060        |
|    policy_gradient_loss | -0.00562    |
|    std                  | 0.602       |
|    value_loss           | 378         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.96e+03   |
|    ep_rew_mean          | 420        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 208        |
|    time_elapsed         | 146027     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.05673028 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | -0.528     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.81       |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.602      |
|    value_loss           | 4.9        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.96e+03   |
|    ep_rew_mean          | 443        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 209        |
|    time_elapsed         | 146370     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.04853919 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.22      |
|    explained_variance   | 0.068      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9        |
|    n_updates            | 2080       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.599      |
|    value_loss           | 4.33       |
----------------------------------------
Eval num_timesteps=430000, episode_reward=531.78 +/- 361.68
Episode length: 3271.40 +/- 658.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.27e+03    |
|    mean_reward          | 532         |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.021319946 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 1.34e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.68e+03    |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.6         |
|    value_loss           | 3.99e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.93e+03 |
|    ep_rew_mean     | 449      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 210      |
|    time_elapsed    | 148347   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.93e+03    |
|    ep_rew_mean          | 449         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 211         |
|    time_elapsed         | 148688      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.037532166 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 0.00113     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.5e+03     |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00923    |
|    std                  | 0.6         |
|    value_loss           | 4.87e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.93e+03    |
|    ep_rew_mean          | 453         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 212         |
|    time_elapsed         | 149030      |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.062396705 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | -0.547      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.15        |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.0231     |
|    std                  | 0.596       |
|    value_loss           | 5.01        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.93e+03   |
|    ep_rew_mean          | 473        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 213        |
|    time_elapsed         | 149371     |
|    total_timesteps      | 436224     |
| train/                  |            |
|    approx_kl            | 0.06340715 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.12      |
|    explained_variance   | 0.0944     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.42       |
|    n_updates            | 2120       |
|    policy_gradient_loss | -0.0265    |
|    std                  | 0.591      |
|    value_loss           | 5.48       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.91e+03    |
|    ep_rew_mean          | 497         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 214         |
|    time_elapsed         | 149714      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.017937385 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.08       |
|    explained_variance   | 0.000525    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.8        |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.00842    |
|    std                  | 0.59        |
|    value_loss           | 3.99e+03    |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=393.12 +/- 21.33
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | 393         |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.011572434 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | 0.00373     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.9e+03     |
|    n_updates            | 2140        |
|    policy_gradient_loss | -0.0119     |
|    std                  | 0.589       |
|    value_loss           | 7.78e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.9e+03  |
|    ep_rew_mean     | 693      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 215      |
|    time_elapsed    | 151859   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.9e+03     |
|    ep_rew_mean          | 698         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 216         |
|    time_elapsed         | 152199      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.030135944 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | -0.000119   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8e+05     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00175    |
|    std                  | 0.589       |
|    value_loss           | 1.44e+06    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.9e+03    |
|    ep_rew_mean          | 703        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 217        |
|    time_elapsed         | 152542     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.07246771 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.04      |
|    explained_variance   | -3.11      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.87       |
|    n_updates            | 2160       |
|    policy_gradient_loss | -0.0126    |
|    std                  | 0.585      |
|    value_loss           | 10.8       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.9e+03     |
|    ep_rew_mean          | 703         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 218         |
|    time_elapsed         | 152883      |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.060285468 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.98       |
|    explained_variance   | -0.000669   |
|    learning_rate        | 0.0003      |
|    loss                 | 2.92        |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.00558    |
|    std                  | 0.58        |
|    value_loss           | 6.33        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.87e+03   |
|    ep_rew_mean          | 732        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 219        |
|    time_elapsed         | 153226     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.05998139 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.26       |
|    n_updates            | 2180       |
|    policy_gradient_loss | -0.0248    |
|    std                  | 0.576      |
|    value_loss           | 5.74       |
----------------------------------------
Eval num_timesteps=450000, episode_reward=466.21 +/- 37.89
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | 466        |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.01179675 |
|    clip_fraction        | 0.177      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | 2.43e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.2e+03    |
|    n_updates            | 2190       |
|    policy_gradient_loss | -0.00796   |
|    std                  | 0.576      |
|    value_loss           | 7.71e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.81e+03 |
|    ep_rew_mean     | 954      |
| time/              |          |
|    fps             | 2        |
|    iterations      | 220      |
|    time_elapsed    | 155370   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.8e+03     |
|    ep_rew_mean          | 969         |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 221         |
|    time_elapsed         | 155711      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.008671236 |
|    clip_fraction        | 0.0418      |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | 9.07e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46e+05    |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00502    |
|    std                  | 0.576       |
|    value_loss           | 1.45e+06    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.78e+03   |
|    ep_rew_mean          | 977        |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 222        |
|    time_elapsed         | 156053     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.01439195 |
|    clip_fraction        | 0.117      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.89      |
|    explained_variance   | -0.00622   |
|    learning_rate        | 0.0003     |
|    loss                 | 88.2       |
|    n_updates            | 2210       |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.575      |
|    value_loss           | 3.78e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.76e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 223        |
|    time_elapsed         | 156396     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.05167351 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | 0.00102    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.05       |
|    n_updates            | 2220       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.572      |
|    value_loss           | 1.17e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.74e+03    |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 224         |
|    time_elapsed         | 156738      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.012406781 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.84       |
|    explained_variance   | 0.00283     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.95e+03    |
|    n_updates            | 2230        |
|    policy_gradient_loss | -0.00836    |
|    std                  | 0.572       |
|    value_loss           | 7.52e+03    |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=1136.25 +/- 301.55
Episode length: 2095.00 +/- 844.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 2.1e+03     |
|    mean_reward          | 1.14e+03    |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.015318865 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.83       |
|    explained_variance   | -0.00299    |
|    learning_rate        | 0.0003      |
|    loss                 | 143         |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.0175     |
|    std                  | 0.571       |
|    value_loss           | 7.48e+03    |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.7e+03  |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 225      |
|    time_elapsed    | 158131   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.66e+03    |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 226         |
|    time_elapsed         | 158473      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.018865343 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.82       |
|    explained_variance   | 0.00278     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.83e+03    |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.0151     |
|    std                  | 0.57        |
|    value_loss           | 7.81e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.6e+03     |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 227         |
|    time_elapsed         | 158816      |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.020485057 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.81       |
|    explained_variance   | 0.00175     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+03    |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.569       |
|    value_loss           | 1.1e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.6e+03    |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 228        |
|    time_elapsed         | 159160     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.02206975 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.79      |
|    explained_variance   | 0.00127    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+04   |
|    n_updates            | 2270       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.568      |
|    value_loss           | 1.43e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.6e+03     |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 229         |
|    time_elapsed         | 159502      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.078978986 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.77       |
|    explained_variance   | -0.554      |
|    learning_rate        | 0.0003      |
|    loss                 | 4.03        |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.00811    |
|    std                  | 0.566       |
|    value_loss           | 24.4        |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=1161.64 +/- 130.76
Episode length: 817.00 +/- 654.16
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 817         |
|    mean_reward          | 1.16e+03    |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.062515825 |
|    clip_fraction        | 0.44        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.73       |
|    explained_variance   | -0.469      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.45        |
|    n_updates            | 2290        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.562       |
|    value_loss           | 15          |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.52e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 230      |
|    time_elapsed    | 160254   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.53e+03    |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 231         |
|    time_elapsed         | 160596      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.010880033 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 0.0035      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.84e+04    |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.562       |
|    value_loss           | 1.46e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.53e+03   |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 232        |
|    time_elapsed         | 160938     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.09415305 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.68      |
|    explained_variance   | -0.846     |
|    learning_rate        | 0.0003     |
|    loss                 | 4.04       |
|    n_updates            | 2310       |
|    policy_gradient_loss | -0.0205    |
|    std                  | 0.56       |
|    value_loss           | 15.2       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.51e+03    |
|    ep_rew_mean          | 1.22e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 233         |
|    time_elapsed         | 161280      |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.033967122 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.66       |
|    explained_variance   | -0.00185    |
|    learning_rate        | 0.0003      |
|    loss                 | 405         |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.00491    |
|    std                  | 0.559       |
|    value_loss           | 3.69e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.47e+03    |
|    ep_rew_mean          | 1.26e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 234         |
|    time_elapsed         | 161623      |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.022985458 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.65       |
|    explained_variance   | 0.00237     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83e+03    |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.558       |
|    value_loss           | 3.72e+03    |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=1009.62 +/- 134.14
Episode length: 1026.60 +/- 1297.88
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 1.03e+03   |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.01090645 |
|    clip_fraction        | 0.105      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.63      |
|    explained_variance   | 0.00567    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.68e+03   |
|    n_updates            | 2340       |
|    policy_gradient_loss | -0.0136    |
|    std                  | 0.557      |
|    value_loss           | 1.1e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.42e+03 |
|    ep_rew_mean     | 1.27e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 235      |
|    time_elapsed    | 162482   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.41e+03    |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 236         |
|    time_elapsed         | 162825      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.012755023 |
|    clip_fraction        | 0.109       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.62       |
|    explained_variance   | 0.00231     |
|    learning_rate        | 0.0003      |
|    loss                 | 890         |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.557       |
|    value_loss           | 7.38e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.34e+03    |
|    ep_rew_mean          | 1.34e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 237         |
|    time_elapsed         | 163170      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.011666899 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.61       |
|    explained_variance   | 0.00184     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.59e+03    |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.556       |
|    value_loss           | 7.21e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.34e+03    |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 238         |
|    time_elapsed         | 163513      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.014143307 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.6        |
|    explained_variance   | 0.00703     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.14e+04    |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.555       |
|    value_loss           | 1.39e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.27e+03   |
|    ep_rew_mean          | 1.4e+03    |
| time/                   |            |
|    fps                  | 2          |
|    iterations           | 239        |
|    time_elapsed         | 163857     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.03810748 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.58      |
|    explained_variance   | 0.00659    |
|    learning_rate        | 0.0003     |
|    loss                 | 127        |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.00999   |
|    std                  | 0.554      |
|    value_loss           | 3.61e+03   |
----------------------------------------
Eval num_timesteps=490000, episode_reward=1117.33 +/- 47.89
Episode length: 474.40 +/- 161.69
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 474         |
|    mean_reward          | 1.12e+03    |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.014808383 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.00567     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+04    |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.553       |
|    value_loss           | 1.75e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1.19e+03 |
|    ep_rew_mean     | 1.45e+03 |
| time/              |          |
|    fps             | 2        |
|    iterations      | 240      |
|    time_elapsed    | 164438   |
|    total_timesteps | 491520   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.19e+03    |
|    ep_rew_mean          | 1.46e+03    |
| time/                   |             |
|    fps                  | 2           |
|    iterations           | 241         |
|    time_elapsed         | 164781      |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.021163207 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.00398     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.36e+03    |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.553       |
|    value_loss           | 1.7e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 1.13e+03   |
|    ep_rew_mean          | 1.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 165125     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.11263126 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.57      |
|    explained_variance   | -0.64      |
|    learning_rate        | 0.0003     |
|    loss                 | 6.27       |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.00385    |
|    std                  | 0.554      |
|    value_loss           | 44.3       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1.01e+03    |
|    ep_rew_mean          | 1.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 165470      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.021429539 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.57       |
|    explained_variance   | 0.00494     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.5e+04     |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.00668    |
|    std                  | 0.552       |
|    value_loss           | 1.37e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 950         |
|    ep_rew_mean          | 1.39e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 165816      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.016575838 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.56       |
|    explained_variance   | 0.00929     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.58e+03    |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0209     |
|    std                  | 0.552       |
|    value_loss           | 2.33e+04    |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=1044.58 +/- 21.48
Episode length: 180.00 +/- 97.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 180        |
|    mean_reward          | 1.04e+03   |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.01891482 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.55      |
|    explained_variance   | 0.00139    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.02e+03   |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.551      |
|    value_loss           | 1.32e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 837      |
|    ep_rew_mean     | 1.41e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 166254   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 738         |
|    ep_rew_mean          | 1.45e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 166599      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.027263753 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.53       |
|    explained_variance   | 0.00501     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.84e+03    |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.0259     |
|    std                  | 0.55        |
|    value_loss           | 2.58e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 660        |
|    ep_rew_mean          | 1.46e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 166944     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.02466707 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.51      |
|    explained_variance   | 0.00465    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.79e+03   |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.0227    |
|    std                  | 0.548      |
|    value_loss           | 2.26e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 614         |
|    ep_rew_mean          | 1.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 167290      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.034727313 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.49       |
|    explained_variance   | 0.00451     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.45e+03    |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.023      |
|    std                  | 0.547       |
|    value_loss           | 1.89e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 592         |
|    ep_rew_mean          | 1.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 167634      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.020877898 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.47       |
|    explained_variance   | 0.00242     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 2480        |
|    policy_gradient_loss | -0.0177     |
|    std                  | 0.546       |
|    value_loss           | 1.26e+04    |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=1081.71 +/- 31.81
Episode length: 304.40 +/- 117.47
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 304         |
|    mean_reward          | 1.08e+03    |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.025729448 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.45       |
|    explained_variance   | 0.00484     |
|    learning_rate        | 0.0003      |
|    loss                 | 8.27e+03    |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.0212     |
|    std                  | 0.544       |
|    value_loss           | 1.86e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 538      |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 168132   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 507        |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 168479     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.02122917 |
|    clip_fraction        | 0.225      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.43      |
|    explained_variance   | 0.00438    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.17e+03   |
|    n_updates            | 2500       |
|    policy_gradient_loss | -0.0226    |
|    std                  | 0.543      |
|    value_loss           | 1.9e+04    |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 463         |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 168824      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.036500517 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.42       |
|    explained_variance   | 0.00373     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.73e+03    |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.0237     |
|    std                  | 0.544       |
|    value_loss           | 2.4e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 421         |
|    ep_rew_mean          | 1.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 169171      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.041601732 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.41       |
|    explained_variance   | 0.00319     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.49e+04    |
|    n_updates            | 2520        |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.541       |
|    value_loss           | 1.8e+04     |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=1048.43 +/- 20.55
Episode length: 179.40 +/- 73.25
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 179         |
|    mean_reward          | 1.05e+03    |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.028356202 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.38       |
|    explained_variance   | 0.00372     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.83e+03    |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.019      |
|    std                  | 0.54        |
|    value_loss           | 2.06e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 371      |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 169610   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 318         |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 169956      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.035651825 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.37       |
|    explained_variance   | 0.00504     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51e+04    |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.0168     |
|    std                  | 0.54        |
|    value_loss           | 2.6e+04     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 275        |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 170303     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.02490368 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.0105     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.48e+03   |
|    n_updates            | 2550       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.54       |
|    value_loss           | 3.41e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 256        |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 170649     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.05968571 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.36      |
|    explained_variance   | 0.000175   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.33e+04   |
|    n_updates            | 2560       |
|    policy_gradient_loss | -0.0144    |
|    std                  | 0.538      |
|    value_loss           | 3.07e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 236        |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 170997     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.04922629 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.32      |
|    explained_variance   | 0.00211    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.35e+04   |
|    n_updates            | 2570       |
|    policy_gradient_loss | -0.0242    |
|    std                  | 0.535      |
|    value_loss           | 3.82e+04   |
----------------------------------------
Eval num_timesteps=530000, episode_reward=1023.45 +/- 11.07
Episode length: 71.60 +/- 28.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 71.6        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.038106587 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.3        |
|    explained_variance   | 0.00195     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.62e+04    |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.535       |
|    value_loss           | 3.25e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 220      |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 171379   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 194         |
|    ep_rew_mean          | 1.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 171727      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.046916686 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.28       |
|    explained_variance   | -0.00298    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.52e+04    |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.0165     |
|    std                  | 0.533       |
|    value_loss           | 2.95e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 167         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 172076      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.057683334 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.24       |
|    explained_variance   | 0.00294     |
|    learning_rate        | 0.0003      |
|    loss                 | 9.45e+03    |
|    n_updates            | 2600        |
|    policy_gradient_loss | -0.0215     |
|    std                  | 0.53        |
|    value_loss           | 3.41e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 156         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 172424      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.028158974 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.2        |
|    explained_variance   | 0.00753     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.19e+04    |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.0211     |
|    std                  | 0.527       |
|    value_loss           | 4.64e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 153         |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 172771      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.029354274 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.16       |
|    explained_variance   | 0.00893     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.21e+04    |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.026      |
|    std                  | 0.525       |
|    value_loss           | 3.82e+04    |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=1025.96 +/- 9.81
Episode length: 75.20 +/- 24.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 75.2        |
|    mean_reward          | 1.03e+03    |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.056467634 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.14       |
|    explained_variance   | 0.00594     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.9e+04     |
|    n_updates            | 2630        |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.524       |
|    value_loss           | 3.28e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 147      |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 173157   |
|    total_timesteps | 540672   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 132       |
|    ep_rew_mean          | 1.07e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 265       |
|    time_elapsed         | 173505    |
|    total_timesteps      | 542720    |
| train/                  |           |
|    approx_kl            | 0.0432535 |
|    clip_fraction        | 0.31      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.14     |
|    explained_variance   | 0.00776   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.67e+04  |
|    n_updates            | 2640      |
|    policy_gradient_loss | -0.0198   |
|    std                  | 0.524     |
|    value_loss           | 4.18e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 119        |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 173853     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.03220273 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.13      |
|    explained_variance   | 0.00651    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72e+04   |
|    n_updates            | 2650       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.523      |
|    value_loss           | 4.38e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 110         |
|    ep_rew_mean          | 1.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 174200      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.043731228 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.09       |
|    explained_variance   | 0.00649     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.71e+04    |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.0281     |
|    std                  | 0.519       |
|    value_loss           | 5.01e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 99.5       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 268        |
|    time_elapsed         | 174549     |
|    total_timesteps      | 548864     |
| train/                  |            |
|    approx_kl            | 0.03594323 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | 0.00822    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.66e+04   |
|    n_updates            | 2670       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.517      |
|    value_loss           | 5.43e+04   |
----------------------------------------
Eval num_timesteps=550000, episode_reward=1027.99 +/- 10.42
Episode length: 72.00 +/- 25.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 72         |
|    mean_reward          | 1.03e+03   |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.03479832 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.01      |
|    explained_variance   | 0.00365    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.14e+04   |
|    n_updates            | 2680       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.516      |
|    value_loss           | 4.86e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 93       |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 174944   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 90.9        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 175290      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.045981184 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6          |
|    explained_variance   | 0.00695     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.01e+04    |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.0206     |
|    std                  | 0.516       |
|    value_loss           | 5.48e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 86.7       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 175638     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.13556272 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.99      |
|    explained_variance   | 0.00402    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.04e+04   |
|    n_updates            | 2700       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.514      |
|    value_loss           | 5.15e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 91.6       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 175985     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.04676813 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.95      |
|    explained_variance   | 0.00171    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.16e+04   |
|    n_updates            | 2710       |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.511      |
|    value_loss           | 5.48e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 96.4       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 273        |
|    time_elapsed         | 176332     |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.07302743 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.92      |
|    explained_variance   | 0.00469    |
|    learning_rate        | 0.0003     |
|    loss                 | 2e+04      |
|    n_updates            | 2720       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.51       |
|    value_loss           | 3.69e+04   |
----------------------------------------
Eval num_timesteps=560000, episode_reward=1021.33 +/- 9.80
Episode length: 47.00 +/- 17.05
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 47          |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.047314312 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.87       |
|    explained_variance   | 0.00316     |
|    learning_rate        | 0.0003      |
|    loss                 | 2e+04       |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.505       |
|    value_loss           | 3.86e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 92.3     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 176703   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 93.2       |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 177050     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.08852728 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.81      |
|    explained_variance   | 0.00816    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.97e+04   |
|    n_updates            | 2740       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.502      |
|    value_loss           | 5.47e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 90.7       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 177399     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.07992175 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.79      |
|    explained_variance   | 0.00323    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.61e+04   |
|    n_updates            | 2750       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.502      |
|    value_loss           | 4.52e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 80.7       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 177747     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.06318468 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.77      |
|    explained_variance   | 0.00724    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.7e+04    |
|    n_updates            | 2760       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.499      |
|    value_loss           | 5.04e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 80.4        |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 178096      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.040560864 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.74       |
|    explained_variance   | 0.00951     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.92e+04    |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.0267     |
|    std                  | 0.499       |
|    value_loss           | 5.54e+04    |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=1015.69 +/- 5.94
Episode length: 41.40 +/- 17.78
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 41.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.048582446 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.73       |
|    explained_variance   | 0.00881     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.59e+04    |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.497       |
|    value_loss           | 5.28e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 76.8     |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 178465   |
|    total_timesteps | 571392   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 75.2       |
|    ep_rew_mean          | 1.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 280        |
|    time_elapsed         | 178820     |
|    total_timesteps      | 573440     |
| train/                  |            |
|    approx_kl            | 0.26605117 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.69      |
|    explained_variance   | 0.0039     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.97e+04   |
|    n_updates            | 2790       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.495      |
|    value_loss           | 4.86e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 70.3        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 281         |
|    time_elapsed         | 179173      |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.052070558 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.00314     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.66e+04    |
|    n_updates            | 2800        |
|    policy_gradient_loss | -0.022      |
|    std                  | 0.493       |
|    value_loss           | 6.18e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 61          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 282         |
|    time_elapsed         | 179524      |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.050631393 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.63       |
|    explained_variance   | 0.00364     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.04e+04    |
|    n_updates            | 2810        |
|    policy_gradient_loss | -0.0223     |
|    std                  | 0.491       |
|    value_loss           | 5.37e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 62.3       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 179875     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.06243086 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.6       |
|    explained_variance   | 0.00198    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.08e+04   |
|    n_updates            | 2820       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.489      |
|    value_loss           | 6.85e+04   |
----------------------------------------
Eval num_timesteps=580000, episode_reward=1015.05 +/- 4.03
Episode length: 43.40 +/- 17.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 43.4        |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 580000      |
| train/                  |             |
|    approx_kl            | 0.044972986 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.54       |
|    explained_variance   | 0.00204     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.61e+04    |
|    n_updates            | 2830        |
|    policy_gradient_loss | -0.0199     |
|    std                  | 0.485       |
|    value_loss           | 5.48e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 60.8     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 180246   |
|    total_timesteps | 581632   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 62.2       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 285        |
|    time_elapsed         | 180595     |
|    total_timesteps      | 583680     |
| train/                  |            |
|    approx_kl            | 0.11083384 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.51      |
|    explained_variance   | 0.0036     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.5e+04    |
|    n_updates            | 2840       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.484      |
|    value_loss           | 5.43e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 62.4        |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 286         |
|    time_elapsed         | 180946      |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.107183665 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.5        |
|    explained_variance   | 0.00875     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.47e+04    |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.485       |
|    value_loss           | 5.87e+04    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 57          |
|    ep_rew_mean          | 1.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 287         |
|    time_elapsed         | 181294      |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.047642536 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.49       |
|    explained_variance   | 0.00326     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+04    |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.483       |
|    value_loss           | 5.45e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 60.6       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 181644     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.08942582 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.47      |
|    explained_variance   | 0.00612    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.73e+04   |
|    n_updates            | 2870       |
|    policy_gradient_loss | -0.0241    |
|    std                  | 0.482      |
|    value_loss           | 6.77e+04   |
----------------------------------------
Eval num_timesteps=590000, episode_reward=1011.29 +/- 1.15
Episode length: 28.40 +/- 3.72
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 28.4     |
|    mean_reward          | 1.01e+03 |
| time/                   |          |
|    total_timesteps      | 590000   |
| train/                  |          |
|    approx_kl            | 0.054143 |
|    clip_fraction        | 0.386    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.48    |
|    explained_variance   | 0.00384  |
|    learning_rate        | 0.0003   |
|    loss                 | 2.48e+04 |
|    n_updates            | 2880     |
|    policy_gradient_loss | -0.0181  |
|    std                  | 0.483    |
|    value_loss           | 4.58e+04 |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 59.4     |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 182009   |
|    total_timesteps | 591872   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 65         |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 290        |
|    time_elapsed         | 182359     |
|    total_timesteps      | 593920     |
| train/                  |            |
|    approx_kl            | 0.05824482 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.49      |
|    explained_variance   | 0.0156     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.97e+04   |
|    n_updates            | 2890       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.483      |
|    value_loss           | 5.69e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52.9       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 182714     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.14063767 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.00328    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.43e+04   |
|    n_updates            | 2900       |
|    policy_gradient_loss | -0.0233    |
|    std                  | 0.481      |
|    value_loss           | 5.02e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 52.5       |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 183064     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.33039337 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | 0.00879    |
|    learning_rate        | 0.0003     |
|    loss                 | 4.32e+04   |
|    n_updates            | 2910       |
|    policy_gradient_loss | -0.0125    |
|    std                  | 0.482      |
|    value_loss           | 6.78e+04   |
----------------------------------------
Eval num_timesteps=600000, episode_reward=1012.37 +/- 2.31
Episode length: 31.80 +/- 6.18
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 31.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.58179796 |
|    clip_fraction        | 0.57       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.45      |
|    explained_variance   | 9.89e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.89e+04   |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.00723    |
|    std                  | 0.481      |
|    value_loss           | 5.51e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 52.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 183430   |
|    total_timesteps | 600064   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 54.5      |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 294       |
|    time_elapsed         | 183781    |
|    total_timesteps      | 602112    |
| train/                  |           |
|    approx_kl            | 0.5791987 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.43     |
|    explained_variance   | 0.00425   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.4e+04   |
|    n_updates            | 2930      |
|    policy_gradient_loss | 0.00278   |
|    std                  | 0.479     |
|    value_loss           | 5.32e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 53.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 295        |
|    time_elapsed         | 184133     |
|    total_timesteps      | 604160     |
| train/                  |            |
|    approx_kl            | 0.17244703 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.00869    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.63e+04   |
|    n_updates            | 2940       |
|    policy_gradient_loss | -0.0168    |
|    std                  | 0.476      |
|    value_loss           | 5.91e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 51.6        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 296         |
|    time_elapsed         | 184487      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.096431136 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.33       |
|    explained_variance   | 0.00229     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.01e+04    |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.0218     |
|    std                  | 0.473       |
|    value_loss           | 5.1e+04     |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 52.5        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 297         |
|    time_elapsed         | 184839      |
|    total_timesteps      | 608256      |
| train/                  |             |
|    approx_kl            | 0.051591028 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.28       |
|    explained_variance   | 0.0155      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.5e+04     |
|    n_updates            | 2960        |
|    policy_gradient_loss | -0.0276     |
|    std                  | 0.47        |
|    value_loss           | 5.69e+04    |
-----------------------------------------
Eval num_timesteps=610000, episode_reward=1020.40 +/- 11.67
Episode length: 45.00 +/- 11.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 45          |
|    mean_reward          | 1.02e+03    |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.054684542 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.24       |
|    explained_variance   | 0.0164      |
|    learning_rate        | 0.0003      |
|    loss                 | 3.14e+04    |
|    n_updates            | 2970        |
|    policy_gradient_loss | -0.0242     |
|    std                  | 0.468       |
|    value_loss           | 5.38e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 51.9     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 185213   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 49.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 185565     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.06135273 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.23      |
|    explained_variance   | 0.00894    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.31e+04   |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.469      |
|    value_loss           | 5.37e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 46.9      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 300       |
|    time_elapsed         | 185916    |
|    total_timesteps      | 614400    |
| train/                  |           |
|    approx_kl            | 3.0284147 |
|    clip_fraction        | 0.584     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.25     |
|    explained_variance   | 0.0121    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.46e+04  |
|    n_updates            | 2990      |
|    policy_gradient_loss | -0.00268  |
|    std                  | 0.47      |
|    value_loss           | 5.93e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 49.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 301       |
|    time_elapsed         | 186268    |
|    total_timesteps      | 616448    |
| train/                  |           |
|    approx_kl            | 0.1083519 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.25     |
|    explained_variance   | 0.0014    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.61e+04  |
|    n_updates            | 3000      |
|    policy_gradient_loss | -0.00928  |
|    std                  | 0.47      |
|    value_loss           | 5.31e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48.7       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 186623     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.06110891 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.24      |
|    explained_variance   | 0.00207    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.2e+04    |
|    n_updates            | 3010       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.468      |
|    value_loss           | 5.32e+04   |
----------------------------------------
Eval num_timesteps=620000, episode_reward=1016.33 +/- 6.51
Episode length: 47.20 +/- 20.51
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 47.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.09184426 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.22      |
|    explained_variance   | 0.00568    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.63e+04   |
|    n_updates            | 3020       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.467      |
|    value_loss           | 5.12e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 49.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 186997   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 48.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 187349     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.13326733 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.19      |
|    explained_variance   | 0.00111    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.44e+04   |
|    n_updates            | 3030       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.466      |
|    value_loss           | 5.07e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 48.4      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 305       |
|    time_elapsed         | 187700    |
|    total_timesteps      | 624640    |
| train/                  |           |
|    approx_kl            | 0.1879763 |
|    clip_fraction        | 0.361     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.15     |
|    explained_variance   | 0.00692   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.83e+04  |
|    n_updates            | 3040      |
|    policy_gradient_loss | -0.0158   |
|    std                  | 0.462     |
|    value_loss           | 5.15e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 48.6      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 306       |
|    time_elapsed         | 188050    |
|    total_timesteps      | 626688    |
| train/                  |           |
|    approx_kl            | 0.3741113 |
|    clip_fraction        | 0.404     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.12     |
|    explained_variance   | 0.0118    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.4e+04   |
|    n_updates            | 3050      |
|    policy_gradient_loss | -0.01     |
|    std                  | 0.462     |
|    value_loss           | 4.97e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 47.1      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 307       |
|    time_elapsed         | 188401    |
|    total_timesteps      | 628736    |
| train/                  |           |
|    approx_kl            | 0.5328926 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.11     |
|    explained_variance   | 0.00538   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.02e+04  |
|    n_updates            | 3060      |
|    policy_gradient_loss | -0.0131   |
|    std                  | 0.46      |
|    value_loss           | 4.84e+04  |
---------------------------------------
Eval num_timesteps=630000, episode_reward=1011.99 +/- 2.09
Episode length: 32.00 +/- 4.10
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 32        |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 630000    |
| train/                  |           |
|    approx_kl            | 0.2738629 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.07     |
|    explained_variance   | 0.00244   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.96e+04  |
|    n_updates            | 3070      |
|    policy_gradient_loss | -0.0124   |
|    std                  | 0.458     |
|    value_loss           | 4.8e+04   |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 48.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 188768   |
|    total_timesteps | 630784   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 51.7      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 309       |
|    time_elapsed         | 189118    |
|    total_timesteps      | 632832    |
| train/                  |           |
|    approx_kl            | 0.5849278 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.05     |
|    explained_variance   | 0.00702   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.02e+04  |
|    n_updates            | 3080      |
|    policy_gradient_loss | 0.0236    |
|    std                  | 0.457     |
|    value_loss           | 4.31e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 52.8      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 310       |
|    time_elapsed         | 189469    |
|    total_timesteps      | 634880    |
| train/                  |           |
|    approx_kl            | 0.0698889 |
|    clip_fraction        | 0.277     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.02     |
|    explained_variance   | 0.0192    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.6e+04   |
|    n_updates            | 3090      |
|    policy_gradient_loss | -0.0235   |
|    std                  | 0.456     |
|    value_loss           | 4.25e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 51.2      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 311       |
|    time_elapsed         | 189820    |
|    total_timesteps      | 636928    |
| train/                  |           |
|    approx_kl            | 0.5090828 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5        |
|    explained_variance   | 0.0103    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.45e+04  |
|    n_updates            | 3100      |
|    policy_gradient_loss | -0.000703 |
|    std                  | 0.455     |
|    value_loss           | 4.12e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 51.2      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 312       |
|    time_elapsed         | 190169    |
|    total_timesteps      | 638976    |
| train/                  |           |
|    approx_kl            | 0.1754925 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.98     |
|    explained_variance   | 0.0104    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.2e+04   |
|    n_updates            | 3110      |
|    policy_gradient_loss | -0.0104   |
|    std                  | 0.454     |
|    value_loss           | 4.3e+04   |
---------------------------------------
Eval num_timesteps=640000, episode_reward=1022.22 +/- 13.19
Episode length: 51.40 +/- 27.68
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 51.4      |
|    mean_reward          | 1.02e+03  |
| time/                   |           |
|    total_timesteps      | 640000    |
| train/                  |           |
|    approx_kl            | 0.1290125 |
|    clip_fraction        | 0.329     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.97     |
|    explained_variance   | 0.00614   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.01e+04  |
|    n_updates            | 3120      |
|    policy_gradient_loss | -0.0188   |
|    std                  | 0.453     |
|    value_loss           | 4.56e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.2     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 190549   |
|    total_timesteps | 641024   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50         |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 314        |
|    time_elapsed         | 190900     |
|    total_timesteps      | 643072     |
| train/                  |            |
|    approx_kl            | 0.15134472 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.97      |
|    explained_variance   | 0.0118     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47e+04   |
|    n_updates            | 3130       |
|    policy_gradient_loss | -0.000109  |
|    std                  | 0.454      |
|    value_loss           | 4.78e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 49.2      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 315       |
|    time_elapsed         | 191251    |
|    total_timesteps      | 645120    |
| train/                  |           |
|    approx_kl            | 0.3899627 |
|    clip_fraction        | 0.59      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.96     |
|    explained_variance   | 0.00783   |
|    learning_rate        | 0.0003    |
|    loss                 | 8.57e+03  |
|    n_updates            | 3140      |
|    policy_gradient_loss | 0.056     |
|    std                  | 0.452     |
|    value_loss           | 3.3e+04   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 46.8       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 191603     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.34236598 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.93      |
|    explained_variance   | 0.0219     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.03e+04   |
|    n_updates            | 3150       |
|    policy_gradient_loss | -0.00525   |
|    std                  | 0.451      |
|    value_loss           | 4.73e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 44.9       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 191955     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.10886474 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.92      |
|    explained_variance   | 0.0111     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.08e+04   |
|    n_updates            | 3160       |
|    policy_gradient_loss | -0.0229    |
|    std                  | 0.451      |
|    value_loss           | 4.22e+04   |
----------------------------------------
Eval num_timesteps=650000, episode_reward=794.71 +/- 447.40
Episode length: 758.00 +/- 1421.81
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 758       |
|    mean_reward          | 795       |
| time/                   |           |
|    total_timesteps      | 650000    |
| train/                  |           |
|    approx_kl            | 0.3526764 |
|    clip_fraction        | 0.388     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.9      |
|    explained_variance   | 0.00989   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.92e+04  |
|    n_updates            | 3170      |
|    policy_gradient_loss | -0.0142   |
|    std                  | 0.45      |
|    value_loss           | 4.42e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.8     |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 192687   |
|    total_timesteps | 651264   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 41.5       |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 319        |
|    time_elapsed         | 193039     |
|    total_timesteps      | 653312     |
| train/                  |            |
|    approx_kl            | 0.18442859 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.87      |
|    explained_variance   | 0.0152     |
|    learning_rate        | 0.0003     |
|    loss                 | 3.86e+04   |
|    n_updates            | 3180       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.448      |
|    value_loss           | 4.72e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 41.3      |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 320       |
|    time_elapsed         | 193391    |
|    total_timesteps      | 655360    |
| train/                  |           |
|    approx_kl            | 0.0817876 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.84     |
|    explained_variance   | 0.00339   |
|    learning_rate        | 0.0003    |
|    loss                 | 2.74e+04  |
|    n_updates            | 3190      |
|    policy_gradient_loss | -0.0184   |
|    std                  | 0.446     |
|    value_loss           | 3.98e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 321        |
|    time_elapsed         | 193743     |
|    total_timesteps      | 657408     |
| train/                  |            |
|    approx_kl            | 0.08410801 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.81      |
|    explained_variance   | 0.0219     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.73e+04   |
|    n_updates            | 3200       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.444      |
|    value_loss           | 4.65e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.4       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 194094     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.17144561 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.77      |
|    explained_variance   | 0.0114     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.73e+04   |
|    n_updates            | 3210       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.441      |
|    value_loss           | 4.43e+04   |
----------------------------------------
Eval num_timesteps=660000, episode_reward=1015.10 +/- 3.62
Episode length: 48.20 +/- 14.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 48.2       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.24800764 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.75      |
|    explained_variance   | 0.0106     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.9e+04    |
|    n_updates            | 3220       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.442      |
|    value_loss           | 4.21e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 40.7     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 194473   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 40.9        |
|    ep_rew_mean          | 1.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 194825      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.059226073 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.74       |
|    explained_variance   | 0.031       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.75e+04    |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.0254     |
|    std                  | 0.441       |
|    value_loss           | 4.05e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 37         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 195179     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.96742165 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.73      |
|    explained_variance   | 0.0121     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.13e+04   |
|    n_updates            | 3240       |
|    policy_gradient_loss | -0.0154    |
|    std                  | 0.44       |
|    value_loss           | 4.05e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 195535     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.75380486 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.71      |
|    explained_variance   | 0.0178     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.17e+04   |
|    n_updates            | 3250       |
|    policy_gradient_loss | -0.00685   |
|    std                  | 0.439      |
|    value_loss           | 4.44e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 38.6      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 327       |
|    time_elapsed         | 195892    |
|    total_timesteps      | 669696    |
| train/                  |           |
|    approx_kl            | 0.7032225 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.67     |
|    explained_variance   | 0.0106    |
|    learning_rate        | 0.0003    |
|    loss                 | 2.36e+04  |
|    n_updates            | 3260      |
|    policy_gradient_loss | -0.00679  |
|    std                  | 0.436     |
|    value_loss           | 4.14e+04  |
---------------------------------------
Eval num_timesteps=670000, episode_reward=1013.83 +/- 2.26
Episode length: 36.80 +/- 4.26
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 36.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.17634767 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.64      |
|    explained_variance   | 0.0147     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.82e+04   |
|    n_updates            | 3270       |
|    policy_gradient_loss | -0.0128    |
|    std                  | 0.435      |
|    value_loss           | 3.88e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 38.4     |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 196267   |
|    total_timesteps | 671744   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 39.2       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 329        |
|    time_elapsed         | 196625     |
|    total_timesteps      | 673792     |
| train/                  |            |
|    approx_kl            | 0.26365906 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.64      |
|    explained_variance   | 0.0226     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.09e+04   |
|    n_updates            | 3280       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.435      |
|    value_loss           | 4.07e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 40.6      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 330       |
|    time_elapsed         | 196983    |
|    total_timesteps      | 675840    |
| train/                  |           |
|    approx_kl            | 0.3503918 |
|    clip_fraction        | 0.514     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.63     |
|    explained_variance   | 0.00704   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.5e+04   |
|    n_updates            | 3290      |
|    policy_gradient_loss | -0.0114   |
|    std                  | 0.435     |
|    value_loss           | 3.59e+04  |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 39.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 331         |
|    time_elapsed         | 197340      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.085589126 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.62       |
|    explained_variance   | 0.0307      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.85e+04    |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.0194     |
|    std                  | 0.434       |
|    value_loss           | 3.49e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 36.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 332        |
|    time_elapsed         | 197695     |
|    total_timesteps      | 679936     |
| train/                  |            |
|    approx_kl            | 0.12462248 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.6       |
|    explained_variance   | 0.0347     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36e+04   |
|    n_updates            | 3310       |
|    policy_gradient_loss | -0.0185    |
|    std                  | 0.433      |
|    value_loss           | 3.63e+04   |
----------------------------------------
Eval num_timesteps=680000, episode_reward=1011.07 +/- 0.94
Episode length: 27.40 +/- 3.32
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.78262556 |
|    clip_fraction        | 0.552      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.58      |
|    explained_variance   | 0.0263     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5e+04    |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.431      |
|    value_loss           | 3.92e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 34.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 198066   |
|    total_timesteps | 681984   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 36        |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 334       |
|    time_elapsed         | 198423    |
|    total_timesteps      | 684032    |
| train/                  |           |
|    approx_kl            | 0.8602129 |
|    clip_fraction        | 0.553     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.57     |
|    explained_variance   | 0.0104    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.88e+04  |
|    n_updates            | 3330      |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.431     |
|    value_loss           | 3.91e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 198778     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.06336119 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.56      |
|    explained_variance   | 0.00544    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72e+04   |
|    n_updates            | 3340       |
|    policy_gradient_loss | -0.0156    |
|    std                  | 0.431      |
|    value_loss           | 3.32e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 38.6       |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 199132     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.23988429 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.56      |
|    explained_variance   | 0.0148     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.66e+04   |
|    n_updates            | 3350       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.431      |
|    value_loss           | 3.21e+04   |
----------------------------------------
Eval num_timesteps=690000, episode_reward=1011.21 +/- 1.70
Episode length: 30.40 +/- 2.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 30.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.089408815 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.55       |
|    explained_variance   | 0.0174      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+04    |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.0149     |
|    std                  | 0.43        |
|    value_loss           | 3.42e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 36.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 199502   |
|    total_timesteps | 690176   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 338        |
|    time_elapsed         | 199857     |
|    total_timesteps      | 692224     |
| train/                  |            |
|    approx_kl            | 0.13808417 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.54      |
|    explained_variance   | 0.0146     |
|    learning_rate        | 0.0003     |
|    loss                 | 2.16e+04   |
|    n_updates            | 3370       |
|    policy_gradient_loss | -0.0172    |
|    std                  | 0.43       |
|    value_loss           | 3.29e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 200212     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.21717522 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.54      |
|    explained_variance   | 0.0408     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.76e+04   |
|    n_updates            | 3380       |
|    policy_gradient_loss | -0.00968   |
|    std                  | 0.43       |
|    value_loss           | 3.19e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 200567     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.09875105 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.51      |
|    explained_variance   | 0.0232     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.83e+04   |
|    n_updates            | 3390       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.427      |
|    value_loss           | 3.25e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 200920     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.32056284 |
|    clip_fraction        | 0.535      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.5       |
|    explained_variance   | 0.0236     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.27e+04   |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.0033    |
|    std                  | 0.428      |
|    value_loss           | 3.6e+04    |
----------------------------------------
Eval num_timesteps=700000, episode_reward=1018.96 +/- 11.63
Episode length: 45.80 +/- 22.30
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 45.8      |
|    mean_reward          | 1.02e+03  |
| time/                   |           |
|    total_timesteps      | 700000    |
| train/                  |           |
|    approx_kl            | 0.5835756 |
|    clip_fraction        | 0.587     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.47     |
|    explained_variance   | 0.00353   |
|    learning_rate        | 0.0003    |
|    loss                 | 1.01e+04  |
|    n_updates            | 3410      |
|    policy_gradient_loss | -0.0221   |
|    std                  | 0.426     |
|    value_loss           | 3.08e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 37.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 201298   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.3        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 201652      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.056099854 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.45       |
|    explained_variance   | 0.034       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08e+04    |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.425       |
|    value_loss           | 2.68e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 35.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 202006     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.30580348 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.43      |
|    explained_variance   | 0.00653    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.96e+04   |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.00648   |
|    std                  | 0.424      |
|    value_loss           | 2.93e+04   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 36.3      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 345       |
|    time_elapsed         | 202361    |
|    total_timesteps      | 706560    |
| train/                  |           |
|    approx_kl            | 0.1941267 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.4      |
|    explained_variance   | 0.0178    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.12e+04  |
|    n_updates            | 3440      |
|    policy_gradient_loss | -0.00986  |
|    std                  | 0.422     |
|    value_loss           | 2.77e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 346        |
|    time_elapsed         | 202714     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.18011954 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.39      |
|    explained_variance   | 0.0231     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+04   |
|    n_updates            | 3450       |
|    policy_gradient_loss | -0.0175    |
|    std                  | 0.422      |
|    value_loss           | 2.77e+04   |
----------------------------------------
Eval num_timesteps=710000, episode_reward=1012.59 +/- 3.28
Episode length: 30.20 +/- 7.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 30.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.15994877 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.37      |
|    explained_variance   | 0.0501     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32e+04   |
|    n_updates            | 3460       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.421      |
|    value_loss           | 3.1e+04    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 203082   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 203435     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.27290282 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.35      |
|    explained_variance   | 0.0218     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.23e+04   |
|    n_updates            | 3470       |
|    policy_gradient_loss | 0.00444    |
|    std                  | 0.42       |
|    value_loss           | 2.8e+04    |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 34        |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 349       |
|    time_elapsed         | 203786    |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 0.6376656 |
|    clip_fraction        | 0.522     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.34     |
|    explained_variance   | 0.023     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.42e+04  |
|    n_updates            | 3480      |
|    policy_gradient_loss | -0.0144   |
|    std                  | 0.419     |
|    value_loss           | 2.78e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 34.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 204138     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.09048738 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.33      |
|    explained_variance   | 0.0133     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.17e+04   |
|    n_updates            | 3490       |
|    policy_gradient_loss | -0.0189    |
|    std                  | 0.419      |
|    value_loss           | 2.57e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 351        |
|    time_elapsed         | 204490     |
|    total_timesteps      | 718848     |
| train/                  |            |
|    approx_kl            | 0.32432795 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.31      |
|    explained_variance   | 0.036      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.5e+04    |
|    n_updates            | 3500       |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.418      |
|    value_loss           | 2.57e+04   |
----------------------------------------
Eval num_timesteps=720000, episode_reward=1015.95 +/- 7.12
Episode length: 38.80 +/- 13.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 38.8       |
|    mean_reward          | 1.02e+03   |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.11852037 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.29      |
|    explained_variance   | 0.0337     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.37e+04   |
|    n_updates            | 3510       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.417      |
|    value_loss           | 2.66e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 204862   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 205214     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.16473728 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.27      |
|    explained_variance   | 0.0199     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.11e+04   |
|    n_updates            | 3520       |
|    policy_gradient_loss | -0.0187    |
|    std                  | 0.415      |
|    value_loss           | 2.51e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 205564     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.41444778 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.23      |
|    explained_variance   | 0.0406     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01e+04   |
|    n_updates            | 3530       |
|    policy_gradient_loss | -0.000824  |
|    std                  | 0.414      |
|    value_loss           | 2.48e+04   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 30.8     |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 355      |
|    time_elapsed         | 205915   |
|    total_timesteps      | 727040   |
| train/                  |          |
|    approx_kl            | 0.253285 |
|    clip_fraction        | 0.416    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.21    |
|    explained_variance   | 0.0263   |
|    learning_rate        | 0.0003   |
|    loss                 | 1.56e+04 |
|    n_updates            | 3540     |
|    policy_gradient_loss | -0.0171  |
|    std                  | 0.412    |
|    value_loss           | 2.58e+04 |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 206267     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.27878416 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.2       |
|    explained_variance   | 0.0401     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+04   |
|    n_updates            | 3550       |
|    policy_gradient_loss | -0.00635   |
|    std                  | 0.413      |
|    value_loss           | 2.46e+04   |
----------------------------------------
Eval num_timesteps=730000, episode_reward=1010.37 +/- 0.44
Episode length: 24.80 +/- 2.93
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 24.8      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 730000    |
| train/                  |           |
|    approx_kl            | 1.0916767 |
|    clip_fraction        | 0.676     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.24     |
|    explained_variance   | 0.0213    |
|    learning_rate        | 0.0003    |
|    loss                 | 1.32e+04  |
|    n_updates            | 3560      |
|    policy_gradient_loss | 0.00399   |
|    std                  | 0.414     |
|    value_loss           | 2.49e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 206635   |
|    total_timesteps | 731136   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 358        |
|    time_elapsed         | 206987     |
|    total_timesteps      | 733184     |
| train/                  |            |
|    approx_kl            | 0.13730751 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0.00423    |
|    learning_rate        | 0.0003     |
|    loss                 | 9.21e+03   |
|    n_updates            | 3570       |
|    policy_gradient_loss | -0.0263    |
|    std                  | 0.414      |
|    value_loss           | 2.03e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 359        |
|    time_elapsed         | 207338     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.07985835 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.23      |
|    explained_variance   | 0.0516     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02e+04   |
|    n_updates            | 3580       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.414      |
|    value_loss           | 2.13e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 207692     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.30226946 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.23      |
|    explained_variance   | 0.0416     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.16e+04   |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.00644   |
|    std                  | 0.414      |
|    value_loss           | 2.19e+04   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 361         |
|    time_elapsed         | 208047      |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.047779705 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.23       |
|    explained_variance   | 0.0474      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.73e+03    |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.0203     |
|    std                  | 0.414       |
|    value_loss           | 2.01e+04    |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=1011.84 +/- 1.96
Episode length: 29.60 +/- 7.31
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 29.6        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.057648744 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.23       |
|    explained_variance   | 0.0894      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.85e+03    |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.0233     |
|    std                  | 0.414       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 33.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 208416   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 32.2        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 208771      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.042042624 |
|    clip_fraction        | 0.238       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.22       |
|    explained_variance   | 0.0538      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.8e+03     |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.0246     |
|    std                  | 0.413       |
|    value_loss           | 1.99e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 33         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 364        |
|    time_elapsed         | 209123     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.09830901 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.2       |
|    explained_variance   | 0.0732     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.09e+04   |
|    n_updates            | 3630       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.412      |
|    value_loss           | 2.02e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 209477     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.17665991 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.19      |
|    explained_variance   | 0.0549     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.37e+03   |
|    n_updates            | 3640       |
|    policy_gradient_loss | -0.00444   |
|    std                  | 0.412      |
|    value_loss           | 1.93e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 209830     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.13854505 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.18      |
|    explained_variance   | 0.0807     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.11e+04   |
|    n_updates            | 3650       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.411      |
|    value_loss           | 1.95e+04   |
----------------------------------------
Eval num_timesteps=750000, episode_reward=1011.09 +/- 1.46
Episode length: 27.00 +/- 3.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.07611589 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.17      |
|    explained_variance   | 0.0627     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.97e+03   |
|    n_updates            | 3660       |
|    policy_gradient_loss | -0.0201    |
|    std                  | 0.411      |
|    value_loss           | 1.84e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210200   |
|    total_timesteps | 751616   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 32.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 368        |
|    time_elapsed         | 210555     |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.04816676 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.15      |
|    explained_variance   | 0.0609     |
|    learning_rate        | 0.0003     |
|    loss                 | 9.16e+03   |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.0277    |
|    std                  | 0.41       |
|    value_loss           | 1.8e+04    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 369        |
|    time_elapsed         | 210909     |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.06260727 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.13      |
|    explained_variance   | 0.0652     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.64e+03   |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.0266    |
|    std                  | 0.409      |
|    value_loss           | 1.75e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 211262     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.49006206 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.1       |
|    explained_variance   | 0.0956     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.82e+03   |
|    n_updates            | 3690       |
|    policy_gradient_loss | -0.00502   |
|    std                  | 0.407      |
|    value_loss           | 1.86e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 31.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 211615     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.10778897 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.08      |
|    explained_variance   | 0.0504     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.59e+03   |
|    n_updates            | 3700       |
|    policy_gradient_loss | -0.0181    |
|    std                  | 0.407      |
|    value_loss           | 1.63e+04   |
----------------------------------------
Eval num_timesteps=760000, episode_reward=1012.89 +/- 2.39
Episode length: 28.00 +/- 4.15
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.20351245 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.06      |
|    explained_variance   | 0.132      |
|    learning_rate        | 0.0003     |
|    loss                 | 8.52e+03   |
|    n_updates            | 3710       |
|    policy_gradient_loss | -0.0238    |
|    std                  | 0.405      |
|    value_loss           | 1.71e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 211983   |
|    total_timesteps | 761856   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 29.5     |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 373      |
|    time_elapsed         | 212336   |
|    total_timesteps      | 763904   |
| train/                  |          |
|    approx_kl            | 0.586949 |
|    clip_fraction        | 0.395    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.04    |
|    explained_variance   | 0.0746   |
|    learning_rate        | 0.0003   |
|    loss                 | 8.32e+03 |
|    n_updates            | 3720     |
|    policy_gradient_loss | -0.00839 |
|    std                  | 0.405    |
|    value_loss           | 1.8e+04  |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 212690     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.28702903 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.04      |
|    explained_variance   | 0.0566     |
|    learning_rate        | 0.0003     |
|    loss                 | 7.41e+03   |
|    n_updates            | 3730       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.405      |
|    value_loss           | 1.65e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 213044     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.23290884 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.04      |
|    explained_variance   | 0.0865     |
|    learning_rate        | 0.0003     |
|    loss                 | 6.77e+03   |
|    n_updates            | 3740       |
|    policy_gradient_loss | -0.023     |
|    std                  | 0.405      |
|    value_loss           | 1.59e+04   |
----------------------------------------
Eval num_timesteps=770000, episode_reward=1011.31 +/- 1.76
Episode length: 26.40 +/- 4.72
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 26.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.091695905 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.04       |
|    explained_variance   | 0.0676      |
|    learning_rate        | 0.0003      |
|    loss                 | 6.35e+03    |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.405       |
|    value_loss           | 1.5e+04     |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 31.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 213411   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 213765      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.060135946 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.02       |
|    explained_variance   | 0.085       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.33e+03    |
|    n_updates            | 3760        |
|    policy_gradient_loss | -0.0289     |
|    std                  | 0.403       |
|    value_loss           | 1.43e+04    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 30        |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 378       |
|    time_elapsed         | 214119    |
|    total_timesteps      | 774144    |
| train/                  |           |
|    approx_kl            | 0.3893882 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4        |
|    explained_variance   | 0.129     |
|    learning_rate        | 0.0003    |
|    loss                 | 8.56e+03  |
|    n_updates            | 3770      |
|    policy_gradient_loss | -0.0246   |
|    std                  | 0.402     |
|    value_loss           | 1.49e+04  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 28.2      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 379       |
|    time_elapsed         | 214474    |
|    total_timesteps      | 776192    |
| train/                  |           |
|    approx_kl            | 0.5228338 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.97     |
|    explained_variance   | 0.0751    |
|    learning_rate        | 0.0003    |
|    loss                 | 7.13e+03  |
|    n_updates            | 3780      |
|    policy_gradient_loss | -0.0106   |
|    std                  | 0.4       |
|    value_loss           | 1.35e+04  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 214827     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.30484563 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.93      |
|    explained_variance   | 0.106      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.69e+03   |
|    n_updates            | 3790       |
|    policy_gradient_loss | -0.0161    |
|    std                  | 0.399      |
|    value_loss           | 1.34e+04   |
----------------------------------------
Eval num_timesteps=780000, episode_reward=1012.22 +/- 3.75
Episode length: 29.20 +/- 5.67
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 29.2      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 780000    |
| train/                  |           |
|    approx_kl            | 0.2690896 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.91     |
|    explained_variance   | 0.107     |
|    learning_rate        | 0.0003    |
|    loss                 | 8.34e+03  |
|    n_updates            | 3800      |
|    policy_gradient_loss | -0.0234   |
|    std                  | 0.398     |
|    value_loss           | 1.27e+04  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 215195   |
|    total_timesteps | 780288   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 382        |
|    time_elapsed         | 215553     |
|    total_timesteps      | 782336     |
| train/                  |            |
|    approx_kl            | 0.16551715 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.9       |
|    explained_variance   | 0.11       |
|    learning_rate        | 0.0003     |
|    loss                 | 8.34e+03   |
|    n_updates            | 3810       |
|    policy_gradient_loss | -0.0256    |
|    std                  | 0.398      |
|    value_loss           | 1.23e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 383        |
|    time_elapsed         | 215907     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.26219463 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.89      |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.0003     |
|    loss                 | 7.03e+03   |
|    n_updates            | 3820       |
|    policy_gradient_loss | -0.0145    |
|    std                  | 0.397      |
|    value_loss           | 1.17e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 216259     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.17255278 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.87      |
|    explained_variance   | 0.157      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.3e+03    |
|    n_updates            | 3830       |
|    policy_gradient_loss | -0.00487   |
|    std                  | 0.396      |
|    value_loss           | 1.11e+04   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 216611     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.10853073 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.84      |
|    explained_variance   | 0.175      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.95e+03   |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.0284    |
|    std                  | 0.395      |
|    value_loss           | 1.04e+04   |
----------------------------------------
Eval num_timesteps=790000, episode_reward=1010.36 +/- 0.51
Episode length: 25.20 +/- 3.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 25.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.30093718 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.82      |
|    explained_variance   | 0.169      |
|    learning_rate        | 0.0003     |
|    loss                 | 5.92e+03   |
|    n_updates            | 3850       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.394      |
|    value_loss           | 1.05e+04   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 216975   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 217326      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.089850664 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.81       |
|    explained_variance   | 0.187       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.9e+03     |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.0192     |
|    std                  | 0.393       |
|    value_loss           | 1.07e+04    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 217680     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.08170342 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.79      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.0003     |
|    loss                 | 4.89e+03   |
|    n_updates            | 3870       |
|    policy_gradient_loss | -0.0252    |
|    std                  | 0.393      |
|    value_loss           | 9.7e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 389        |
|    time_elapsed         | 218033     |
|    total_timesteps      | 796672     |
| train/                  |            |
|    approx_kl            | 0.47448155 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.79      |
|    explained_variance   | 0.13       |
|    learning_rate        | 0.0003     |
|    loss                 | 5.79e+03   |
|    n_updates            | 3880       |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.393      |
|    value_loss           | 9.43e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.8      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 390       |
|    time_elapsed         | 218385    |
|    total_timesteps      | 798720    |
| train/                  |           |
|    approx_kl            | 0.3446628 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.78     |
|    explained_variance   | 0.162     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.03e+03  |
|    n_updates            | 3890      |
|    policy_gradient_loss | -0.00364  |
|    std                  | 0.393     |
|    value_loss           | 9.17e+03  |
---------------------------------------
Eval num_timesteps=800000, episode_reward=1012.68 +/- 1.66
Episode length: 27.80 +/- 2.32
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 27.8     |
|    mean_reward          | 1.01e+03 |
| time/                   |          |
|    total_timesteps      | 800000   |
| train/                  |          |
|    approx_kl            | 0.885664 |
|    clip_fraction        | 0.48     |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.76    |
|    explained_variance   | 0.213    |
|    learning_rate        | 0.0003   |
|    loss                 | 5.68e+03 |
|    n_updates            | 3900     |
|    policy_gradient_loss | -0.02    |
|    std                  | 0.391    |
|    value_loss           | 8.66e+03 |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 218753   |
|    total_timesteps | 800768   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 28.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 392       |
|    time_elapsed         | 219107    |
|    total_timesteps      | 802816    |
| train/                  |           |
|    approx_kl            | 0.1589846 |
|    clip_fraction        | 0.385     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.73     |
|    explained_variance   | 0.17      |
|    learning_rate        | 0.0003    |
|    loss                 | 4.53e+03  |
|    n_updates            | 3910      |
|    policy_gradient_loss | -0.00614  |
|    std                  | 0.391     |
|    value_loss           | 7.97e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 393       |
|    time_elapsed         | 219461    |
|    total_timesteps      | 804864    |
| train/                  |           |
|    approx_kl            | 0.1699482 |
|    clip_fraction        | 0.354     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.73     |
|    explained_variance   | 0.233     |
|    learning_rate        | 0.0003    |
|    loss                 | 4.12e+03  |
|    n_updates            | 3920      |
|    policy_gradient_loss | -0.0241   |
|    std                  | 0.391     |
|    value_loss           | 7.7e+03   |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 219823     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.54812855 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.72      |
|    explained_variance   | 0.22       |
|    learning_rate        | 0.0003     |
|    loss                 | 2.41e+03   |
|    n_updates            | 3930       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.39       |
|    value_loss           | 7.48e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 220180     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.16320878 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.72      |
|    explained_variance   | 0.212      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.82e+03   |
|    n_updates            | 3940       |
|    policy_gradient_loss | -0.0239    |
|    std                  | 0.39       |
|    value_loss           | 7.21e+03   |
----------------------------------------
Eval num_timesteps=810000, episode_reward=1010.76 +/- 0.70
Episode length: 24.40 +/- 2.73
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.13637817 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.72      |
|    explained_variance   | 0.225      |
|    learning_rate        | 0.0003     |
|    loss                 | 3.16e+03   |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.0171    |
|    std                  | 0.391      |
|    value_loss           | 6.81e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 220544   |
|    total_timesteps | 811008   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.4      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 397       |
|    time_elapsed         | 220896    |
|    total_timesteps      | 813056    |
| train/                  |           |
|    approx_kl            | 0.2311278 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.72     |
|    explained_variance   | 0.249     |
|    learning_rate        | 0.0003    |
|    loss                 | 2.8e+03   |
|    n_updates            | 3960      |
|    policy_gradient_loss | -0.0134   |
|    std                  | 0.39      |
|    value_loss           | 6.43e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 221248     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.39670077 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.71      |
|    explained_variance   | 0.278      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.66e+03   |
|    n_updates            | 3970       |
|    policy_gradient_loss | -0.0179    |
|    std                  | 0.39       |
|    value_loss           | 6.12e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 221599     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.15501967 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.7       |
|    explained_variance   | 0.242      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.52e+03   |
|    n_updates            | 3980       |
|    policy_gradient_loss | -0.0134    |
|    std                  | 0.39       |
|    value_loss           | 6.2e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 221951     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.12126829 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.7       |
|    explained_variance   | 0.271      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.75e+03   |
|    n_updates            | 3990       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.389      |
|    value_loss           | 5.45e+03   |
----------------------------------------
Eval num_timesteps=820000, episode_reward=1011.04 +/- 0.99
Episode length: 28.20 +/- 3.66
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.20347035 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.68      |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.67e+03   |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.389      |
|    value_loss           | 5.29e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 29.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 222316   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 222667     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.11386747 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.68      |
|    explained_variance   | 0.337      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.21e+03   |
|    n_updates            | 4010       |
|    policy_gradient_loss | -0.0244    |
|    std                  | 0.389      |
|    value_loss           | 4.99e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 403        |
|    time_elapsed         | 223018     |
|    total_timesteps      | 825344     |
| train/                  |            |
|    approx_kl            | 0.28635105 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.66      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.31e+03   |
|    n_updates            | 4020       |
|    policy_gradient_loss | -0.000598  |
|    std                  | 0.388      |
|    value_loss           | 4.7e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 223369     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.14588352 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.66      |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.0003     |
|    loss                 | 2e+03      |
|    n_updates            | 4030       |
|    policy_gradient_loss | -0.0235    |
|    std                  | 0.388      |
|    value_loss           | 4.64e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 223724     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.10332133 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.66      |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.11e+03   |
|    n_updates            | 4040       |
|    policy_gradient_loss | -0.0225    |
|    std                  | 0.388      |
|    value_loss           | 4.27e+03   |
----------------------------------------
Eval num_timesteps=830000, episode_reward=1010.94 +/- 1.19
Episode length: 25.40 +/- 4.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 25.4        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.086491995 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.65       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 2.19e+03    |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.0173     |
|    std                  | 0.387       |
|    value_loss           | 3.94e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 32.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 224088   |
|    total_timesteps | 831488   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 407        |
|    time_elapsed         | 224440     |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.12529385 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.62      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.94e+03   |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.0207    |
|    std                  | 0.386      |
|    value_loss           | 3.63e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 30.1        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 408         |
|    time_elapsed         | 224792      |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.112566024 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.62       |
|    explained_variance   | 0.412       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.85e+03    |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.0184     |
|    std                  | 0.387       |
|    value_loss           | 4.15e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 409         |
|    time_elapsed         | 225145      |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.111424364 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.62       |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.65e+03    |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.386       |
|    value_loss           | 3.74e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 410        |
|    time_elapsed         | 225497     |
|    total_timesteps      | 839680     |
| train/                  |            |
|    approx_kl            | 0.17024714 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.62      |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.0003     |
|    loss                 | 2.01e+03   |
|    n_updates            | 4090       |
|    policy_gradient_loss | -0.013     |
|    std                  | 0.386      |
|    value_loss           | 3.78e+03   |
----------------------------------------
Eval num_timesteps=840000, episode_reward=1012.27 +/- 2.55
Episode length: 28.00 +/- 3.41
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 28         |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.14461643 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.61      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.49e+03   |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.386      |
|    value_loss           | 3.21e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 225868   |
|    total_timesteps | 841728   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 412        |
|    time_elapsed         | 226224     |
|    total_timesteps      | 843776     |
| train/                  |            |
|    approx_kl            | 0.29228497 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.6       |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.35e+03   |
|    n_updates            | 4110       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.385      |
|    value_loss           | 3.1e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 226577     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.19165546 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.58      |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+03   |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.0194    |
|    std                  | 0.384      |
|    value_loss           | 3.37e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.7      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 414       |
|    time_elapsed         | 226928    |
|    total_timesteps      | 847872    |
| train/                  |           |
|    approx_kl            | 0.2824239 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.56     |
|    explained_variance   | 0.502     |
|    learning_rate        | 0.0003    |
|    loss                 | 918       |
|    n_updates            | 4130      |
|    policy_gradient_loss | -0.00902  |
|    std                  | 0.384     |
|    value_loss           | 2.66e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 227280     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.13161127 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.57      |
|    explained_variance   | 0.542      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+03   |
|    n_updates            | 4140       |
|    policy_gradient_loss | -0.018     |
|    std                  | 0.384      |
|    value_loss           | 2.6e+03    |
----------------------------------------
Eval num_timesteps=850000, episode_reward=1012.31 +/- 1.70
Episode length: 26.40 +/- 2.73
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.13814983 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.56      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0003     |
|    loss                 | 935        |
|    n_updates            | 4150       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.383      |
|    value_loss           | 2.05e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 227649   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 228005     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.36240405 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.54      |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.05e+03   |
|    n_updates            | 4160       |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.383      |
|    value_loss           | 2.27e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 418        |
|    time_elapsed         | 228358     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.06840753 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.51      |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.31e+03   |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.0224    |
|    std                  | 0.381      |
|    value_loss           | 2.21e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 228712     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.09263143 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.48      |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.16e+03   |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.379      |
|    value_loss           | 2.09e+03   |
----------------------------------------
Eval num_timesteps=860000, episode_reward=1011.08 +/- 0.70
Episode length: 27.20 +/- 3.92
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 27.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 860000     |
| train/                  |            |
|    approx_kl            | 0.15543482 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.46      |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.11e+03   |
|    n_updates            | 4190       |
|    policy_gradient_loss | -0.0127    |
|    std                  | 0.379      |
|    value_loss           | 2.08e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.3     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 229078   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 229430     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.20750776 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.46      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 942        |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.379      |
|    value_loss           | 2.35e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 229785     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.19542283 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.45      |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 810        |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.0237    |
|    std                  | 0.378      |
|    value_loss           | 2.03e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 27.4        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 423         |
|    time_elapsed         | 230138      |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.058490694 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.44       |
|    explained_variance   | 0.443       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+03    |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.0185     |
|    std                  | 0.377       |
|    value_loss           | 2.68e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 230491     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.07998743 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.42      |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.0003     |
|    loss                 | 983        |
|    n_updates            | 4230       |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.377      |
|    value_loss           | 2.13e+03   |
----------------------------------------
Eval num_timesteps=870000, episode_reward=1011.31 +/- 1.71
Episode length: 26.00 +/- 3.03
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 26        |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 870000    |
| train/                  |           |
|    approx_kl            | 0.2045353 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.41     |
|    explained_variance   | 0.551     |
|    learning_rate        | 0.0003    |
|    loss                 | 929       |
|    n_updates            | 4240      |
|    policy_gradient_loss | -0.00956  |
|    std                  | 0.377     |
|    value_loss           | 1.98e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 230856   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 231208     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.07746905 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.4       |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.0003     |
|    loss                 | 855        |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.376      |
|    value_loss           | 1.87e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 231563     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.07624236 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.39      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.12e+03   |
|    n_updates            | 4260       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.375      |
|    value_loss           | 2e+03      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 26.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 428       |
|    time_elapsed         | 231914    |
|    total_timesteps      | 876544    |
| train/                  |           |
|    approx_kl            | 2.3166444 |
|    clip_fraction        | 0.625     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.38     |
|    explained_variance   | 0.633     |
|    learning_rate        | 0.0003    |
|    loss                 | 867       |
|    n_updates            | 4270      |
|    policy_gradient_loss | 0.13      |
|    std                  | 0.375     |
|    value_loss           | 1.56e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 232264     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.08243876 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.38      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.26e+03   |
|    n_updates            | 4280       |
|    policy_gradient_loss | -0.0139    |
|    std                  | 0.376      |
|    value_loss           | 2.29e+03   |
----------------------------------------
Eval num_timesteps=880000, episode_reward=1011.87 +/- 2.92
Episode length: 26.60 +/- 3.38
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.08062058 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.39      |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.72e+03   |
|    n_updates            | 4290       |
|    policy_gradient_loss | -0.0246    |
|    std                  | 0.376      |
|    value_loss           | 2.5e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.7     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 232629   |
|    total_timesteps | 880640   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 28.4     |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 431      |
|    time_elapsed         | 232980   |
|    total_timesteps      | 882688   |
| train/                  |          |
|    approx_kl            | 0.258237 |
|    clip_fraction        | 0.375    |
|    clip_range           | 0.2      |
|    entropy_loss         | -3.39    |
|    explained_variance   | 0.555    |
|    learning_rate        | 0.0003   |
|    loss                 | 1.07e+03 |
|    n_updates            | 4300     |
|    policy_gradient_loss | -0.00852 |
|    std                  | 0.376    |
|    value_loss           | 2.21e+03 |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 29.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 432        |
|    time_elapsed         | 233331     |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.09571284 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.38      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.44e+03   |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.00672   |
|    std                  | 0.375      |
|    value_loss           | 2.19e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.5        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 233686      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.091791466 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.37       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+03    |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.0214     |
|    std                  | 0.375       |
|    value_loss           | 2.13e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 30         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 234037     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.16594894 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.36      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 860        |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.0109    |
|    std                  | 0.374      |
|    value_loss           | 2.18e+03   |
----------------------------------------
Eval num_timesteps=890000, episode_reward=1012.17 +/- 2.91
Episode length: 24.40 +/- 3.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.37678975 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.35      |
|    explained_variance   | 0.559      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.06e+03   |
|    n_updates            | 4340       |
|    policy_gradient_loss | -0.00543   |
|    std                  | 0.374      |
|    value_loss           | 2.16e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 28.2     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 234401   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.9       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 234752     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.05157458 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.35      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.0003     |
|    loss                 | 670        |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.0178    |
|    std                  | 0.374      |
|    value_loss           | 2.15e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 235102     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.39455545 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.35      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.2e+03    |
|    n_updates            | 4360       |
|    policy_gradient_loss | -0.000759  |
|    std                  | 0.374      |
|    value_loss           | 2.16e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 235456     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.12949374 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.35      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.0003     |
|    loss                 | 870        |
|    n_updates            | 4370       |
|    policy_gradient_loss | -0.00673   |
|    std                  | 0.374      |
|    value_loss           | 1.68e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 235808     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.04354696 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.34      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.0003     |
|    loss                 | 917        |
|    n_updates            | 4380       |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.373      |
|    value_loss           | 1.92e+03   |
----------------------------------------
Eval num_timesteps=900000, episode_reward=1011.68 +/- 2.03
Episode length: 35.20 +/- 22.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 35.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.08854965 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.33      |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.0003     |
|    loss                 | 893        |
|    n_updates            | 4390       |
|    policy_gradient_loss | -0.0188    |
|    std                  | 0.373      |
|    value_loss           | 1.7e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 236175   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 236525     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.10488446 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.31      |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.0003     |
|    loss                 | 623        |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.372      |
|    value_loss           | 1.38e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27         |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 236879     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.17526674 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.29      |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.0003     |
|    loss                 | 673        |
|    n_updates            | 4410       |
|    policy_gradient_loss | -0.000572  |
|    std                  | 0.371      |
|    value_loss           | 1.56e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 237232     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.16800997 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.29      |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.1e+03    |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.371      |
|    value_loss           | 2e+03      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 237587     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.09580209 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.29      |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.04e+03   |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.0164    |
|    std                  | 0.371      |
|    value_loss           | 1.94e+03   |
----------------------------------------
Eval num_timesteps=910000, episode_reward=1012.44 +/- 1.50
Episode length: 29.20 +/- 6.71
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 29.2      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 910000    |
| train/                  |           |
|    approx_kl            | 0.1500799 |
|    clip_fraction        | 0.359     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.3      |
|    explained_variance   | 0.708     |
|    learning_rate        | 0.0003    |
|    loss                 | 595       |
|    n_updates            | 4440      |
|    policy_gradient_loss | -0.0109   |
|    std                  | 0.372     |
|    value_loss           | 1.46e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.9     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 237954   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 238307     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.08296907 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.31      |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0003     |
|    loss                 | 593        |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.00617   |
|    std                  | 0.372      |
|    value_loss           | 1.54e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 28.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 447        |
|    time_elapsed         | 238660     |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.24611782 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.31      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01e+03   |
|    n_updates            | 4460       |
|    policy_gradient_loss | 0.0061     |
|    std                  | 0.372      |
|    value_loss           | 2.02e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 27.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 448       |
|    time_elapsed         | 239012    |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 1.0870249 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.3      |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.0003    |
|    loss                 | 586       |
|    n_updates            | 4470      |
|    policy_gradient_loss | -0.00335  |
|    std                  | 0.371     |
|    value_loss           | 1.61e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 239365     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.16429166 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.29      |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.02e+03   |
|    n_updates            | 4480       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.371      |
|    value_loss           | 1.84e+03   |
----------------------------------------
Eval num_timesteps=920000, episode_reward=1010.69 +/- 0.47
Episode length: 27.40 +/- 4.03
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 27.4      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 920000    |
| train/                  |           |
|    approx_kl            | 0.1662777 |
|    clip_fraction        | 0.347     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.29     |
|    explained_variance   | 0.682     |
|    learning_rate        | 0.0003    |
|    loss                 | 820       |
|    n_updates            | 4490      |
|    policy_gradient_loss | -0.0171   |
|    std                  | 0.371     |
|    value_loss           | 1.42e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 27.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 239732   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 451        |
|    time_elapsed         | 240083     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.28934526 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.28      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | 539        |
|    n_updates            | 4500       |
|    policy_gradient_loss | 0.00825    |
|    std                  | 0.37       |
|    value_loss           | 1.61e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 25.7        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 452         |
|    time_elapsed         | 240433      |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.075567976 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.26       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.0003      |
|    loss                 | 683         |
|    n_updates            | 4510        |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.369       |
|    value_loss           | 1.31e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 453        |
|    time_elapsed         | 240783     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.08116028 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.25      |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.0003     |
|    loss                 | 671        |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.0215    |
|    std                  | 0.368      |
|    value_loss           | 1.52e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.6       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 241134     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.18235648 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.24      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.0003     |
|    loss                 | 729        |
|    n_updates            | 4530       |
|    policy_gradient_loss | -0.00912   |
|    std                  | 0.369      |
|    value_loss           | 1.62e+03   |
----------------------------------------
Eval num_timesteps=930000, episode_reward=1010.48 +/- 0.57
Episode length: 27.60 +/- 3.38
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 27.6      |
|    mean_reward          | 1.01e+03  |
| time/                   |           |
|    total_timesteps      | 930000    |
| train/                  |           |
|    approx_kl            | 0.4306516 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.24     |
|    explained_variance   | 0.653     |
|    learning_rate        | 0.0003    |
|    loss                 | 859       |
|    n_updates            | 4540      |
|    policy_gradient_loss | 0.00448   |
|    std                  | 0.368     |
|    value_loss           | 1.51e+03  |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.6     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 241502   |
|    total_timesteps | 931840   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25.7      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 456       |
|    time_elapsed         | 241854    |
|    total_timesteps      | 933888    |
| train/                  |           |
|    approx_kl            | 0.1795246 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.22     |
|    explained_variance   | 0.642     |
|    learning_rate        | 0.0003    |
|    loss                 | 789       |
|    n_updates            | 4550      |
|    policy_gradient_loss | -0.0118   |
|    std                  | 0.367     |
|    value_loss           | 1.64e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 242212     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.19511285 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.21      |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.0003     |
|    loss                 | 642        |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.00398    |
|    std                  | 0.367      |
|    value_loss           | 1.33e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 28.6      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 458       |
|    time_elapsed         | 242567    |
|    total_timesteps      | 937984    |
| train/                  |           |
|    approx_kl            | 0.2942537 |
|    clip_fraction        | 0.388     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.21     |
|    explained_variance   | 0.731     |
|    learning_rate        | 0.0003    |
|    loss                 | 439       |
|    n_updates            | 4570      |
|    policy_gradient_loss | -0.00534  |
|    std                  | 0.367     |
|    value_loss           | 1.12e+03  |
---------------------------------------
Eval num_timesteps=940000, episode_reward=1010.92 +/- 0.78
Episode length: 26.20 +/- 5.84
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 26.2       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.13408968 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.21      |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0003     |
|    loss                 | 884        |
|    n_updates            | 4580       |
|    policy_gradient_loss | -0.0141    |
|    std                  | 0.367      |
|    value_loss           | 1.85e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 242929   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 243282     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.16083995 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.21      |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.0003     |
|    loss                 | 616        |
|    n_updates            | 4590       |
|    policy_gradient_loss | -0.00669   |
|    std                  | 0.367      |
|    value_loss           | 1.46e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 243634     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.13741644 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.19      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.0003     |
|    loss                 | 435        |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.00422   |
|    std                  | 0.366      |
|    value_loss           | 1.08e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 27.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 243985     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.29204118 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.15      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 707        |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.363      |
|    value_loss           | 1.25e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 25.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 244338     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.12920345 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.11      |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.0003     |
|    loss                 | 820        |
|    n_updates            | 4620       |
|    policy_gradient_loss | -0.0176    |
|    std                  | 0.362      |
|    value_loss           | 1.32e+03   |
----------------------------------------
Eval num_timesteps=950000, episode_reward=1011.70 +/- 0.96
Episode length: 27.20 +/- 0.75
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 27.2        |
|    mean_reward          | 1.01e+03    |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.108801186 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.1        |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.0003      |
|    loss                 | 588         |
|    n_updates            | 4630        |
|    policy_gradient_loss | -0.0171     |
|    std                  | 0.363       |
|    value_loss           | 1.32e+03    |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 25       |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 244702   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 26.8        |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 245051      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.060851127 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -3.09       |
|    explained_variance   | 0.632       |
|    learning_rate        | 0.0003      |
|    loss                 | 883         |
|    n_updates            | 4640        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.361       |
|    value_loss           | 1.5e+03     |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 245404     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.13683294 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.05      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 691        |
|    n_updates            | 4650       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.36       |
|    value_loss           | 1.46e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 245757     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.47146937 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.02      |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.0003     |
|    loss                 | 660        |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.358      |
|    value_loss           | 1.35e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 468        |
|    time_elapsed         | 246113     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.19182065 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3         |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.0003     |
|    loss                 | 801        |
|    n_updates            | 4670       |
|    policy_gradient_loss | -0.00113   |
|    std                  | 0.357      |
|    value_loss           | 1.65e+03   |
----------------------------------------
Eval num_timesteps=960000, episode_reward=1010.79 +/- 0.38
Episode length: 23.60 +/- 1.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 960000     |
| train/                  |            |
|    approx_kl            | 0.13906908 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 525        |
|    n_updates            | 4680       |
|    policy_gradient_loss | -0.0193    |
|    std                  | 0.357      |
|    value_loss           | 1.43e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.5     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 246476   |
|    total_timesteps | 960512   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.2      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 470       |
|    time_elapsed         | 246828    |
|    total_timesteps      | 962560    |
| train/                  |           |
|    approx_kl            | 0.0791848 |
|    clip_fraction        | 0.324     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.99     |
|    explained_variance   | 0.701     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.01e+03  |
|    n_updates            | 4690      |
|    policy_gradient_loss | -0.00875  |
|    std                  | 0.358     |
|    value_loss           | 1.24e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 26.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 471        |
|    time_elapsed         | 247180     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.29346132 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.0003     |
|    loss                 | 576        |
|    n_updates            | 4700       |
|    policy_gradient_loss | -0.00987   |
|    std                  | 0.358      |
|    value_loss           | 910        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.8       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 472        |
|    time_elapsed         | 247534     |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.67628264 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3.01      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.0003     |
|    loss                 | 725        |
|    n_updates            | 4710       |
|    policy_gradient_loss | 0.00387    |
|    std                  | 0.358      |
|    value_loss           | 1.41e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.7       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 247887     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.11285147 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -3         |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.0003     |
|    loss                 | 505        |
|    n_updates            | 4720       |
|    policy_gradient_loss | -0.0094    |
|    std                  | 0.357      |
|    value_loss           | 1.37e+03   |
----------------------------------------
Eval num_timesteps=970000, episode_reward=1010.72 +/- 0.70
Episode length: 24.80 +/- 1.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.20414458 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.99      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 519        |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.000541   |
|    std                  | 0.357      |
|    value_loss           | 1.2e+03    |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 26.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 248251   |
|    total_timesteps | 970752   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 25        |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 475       |
|    time_elapsed         | 248611    |
|    total_timesteps      | 972800    |
| train/                  |           |
|    approx_kl            | 0.1842913 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.98     |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.0003    |
|    loss                 | 603       |
|    n_updates            | 4740      |
|    policy_gradient_loss | -0.00449  |
|    std                  | 0.356     |
|    value_loss           | 1.38e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 476        |
|    time_elapsed         | 248966     |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.30717024 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.96      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 509        |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.000721  |
|    std                  | 0.356      |
|    value_loss           | 1.21e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.9      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 477       |
|    time_elapsed         | 249316    |
|    total_timesteps      | 976896    |
| train/                  |           |
|    approx_kl            | 0.4893624 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.94     |
|    explained_variance   | 0.706     |
|    learning_rate        | 0.0003    |
|    loss                 | 511       |
|    n_updates            | 4760      |
|    policy_gradient_loss | -0.00333  |
|    std                  | 0.355     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 249669     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.20192218 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.92      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 617        |
|    n_updates            | 4770       |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.354      |
|    value_loss           | 1.1e+03    |
----------------------------------------
Eval num_timesteps=980000, episode_reward=1010.98 +/- 0.66
Episode length: 24.80 +/- 1.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.8       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.13839394 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.88      |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0003     |
|    loss                 | 367        |
|    n_updates            | 4780       |
|    policy_gradient_loss | -0.00682   |
|    std                  | 0.352      |
|    value_loss           | 1.07e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.4     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 250034   |
|    total_timesteps | 980992   |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 24.3     |
|    ep_rew_mean          | 1.02e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 480      |
|    time_elapsed         | 250386   |
|    total_timesteps      | 983040   |
| train/                  |          |
|    approx_kl            | 0.169902 |
|    clip_fraction        | 0.385    |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.86    |
|    explained_variance   | 0.75     |
|    learning_rate        | 0.0003   |
|    loss                 | 367      |
|    n_updates            | 4790     |
|    policy_gradient_loss | -0.00344 |
|    std                  | 0.351    |
|    value_loss           | 884      |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 23.5       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 250738     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.39967412 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.84      |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 612        |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.0259     |
|    std                  | 0.351      |
|    value_loss           | 1.01e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.7      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 482       |
|    time_elapsed         | 251095    |
|    total_timesteps      | 987136    |
| train/                  |           |
|    approx_kl            | 0.6201918 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.84     |
|    explained_variance   | 0.719     |
|    learning_rate        | 0.0003    |
|    loss                 | 446       |
|    n_updates            | 4810      |
|    policy_gradient_loss | -0.00259  |
|    std                  | 0.351     |
|    value_loss           | 947       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.2       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 251450     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.38585955 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.84      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 342        |
|    n_updates            | 4820       |
|    policy_gradient_loss | -0.0074    |
|    std                  | 0.351      |
|    value_loss           | 1.04e+03   |
----------------------------------------
Eval num_timesteps=990000, episode_reward=1010.76 +/- 0.74
Episode length: 23.40 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 23.4       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.16112712 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.83      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.0003     |
|    loss                 | 499        |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.0143    |
|    std                  | 0.35       |
|    value_loss           | 1.21e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.8     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 251816   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.1       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 252170     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.36902475 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.83      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.0003     |
|    loss                 | 437        |
|    n_updates            | 4840       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.351      |
|    value_loss           | 1.1e+03    |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.3       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 252526     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.14206208 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.85      |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.0003     |
|    loss                 | 635        |
|    n_updates            | 4850       |
|    policy_gradient_loss | -0.0165    |
|    std                  | 0.351      |
|    value_loss           | 1.22e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 24.1      |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 252881    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.1403547 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.85     |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.0003    |
|    loss                 | 441       |
|    n_updates            | 4860      |
|    policy_gradient_loss | -0.0129   |
|    std                  | 0.351     |
|    value_loss           | 1.02e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 24.4       |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 253235     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.06797145 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.83      |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.0003     |
|    loss                 | 674        |
|    n_updates            | 4870       |
|    policy_gradient_loss | -0.0157    |
|    std                  | 0.35       |
|    value_loss           | 1.24e+03   |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=1010.95 +/- 1.08
Episode length: 24.60 +/- 3.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 24.6       |
|    mean_reward          | 1.01e+03   |
| time/                   |            |
|    total_timesteps      | 1000000    |
| train/                  |            |
|    approx_kl            | 0.20009404 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.82      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.0003     |
|    loss                 | 677        |
|    n_updates            | 4880       |
|    policy_gradient_loss | -0.0149    |
|    std                  | 0.35       |
|    value_loss           | 1.07e+03   |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 24.1     |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 253600   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-31_07-47-37_llm_triton_qwen_32b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 2 days, 22:22:21 < 0:00:00 , 6 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -96.59974   -95.655495  -97.099898  -98.790314  -94.040026]
 [ -99.971807  -99.855819  -99.977195  -99.933278  -99.900003]
 [ -99.531003  -99.77913   -99.594835  -99.724062  -99.505806]
 [ -99.950826  -99.865893  -99.87365   -99.923419  -99.883756]
 [ -99.485731  -99.666092  -98.458467  -99.490768  -99.439484]
 [ -99.896461  -99.866869  -99.958125  -99.898696  -99.95818 ]
 [ -99.524597  -99.516788  -99.634144  -99.488513  -99.678001]
 [-100.087897  -99.774215  -99.51965   -99.763044  -99.636327]
 [ -99.795923  -99.501585  -99.828752  -99.607395  -99.611507]
 [ -99.819524  -99.725762  -99.733441  -99.800107  -99.473775]
 [ -99.736107  -99.728054 -100.041542  -99.559591  -99.917523]
 [ -99.619973  -99.941565  -99.856504  -99.982082  -99.789459]
 [-100.150423  -99.970141  -99.610198  -99.866747  -99.605116]
 [ -99.563385  -99.834555  -99.91703  -100.017853 -100.029422]
 [ -99.744941  -99.312065  -99.788121  -99.26      -99.809309]
 [-100.236367  -99.945186 -100.302018 -100.203942  -99.798548]
 [ -99.635438  -99.749994  -99.891258  -99.92838   -99.791205]
 [ -99.546683  -99.92818   -99.394085  -99.875819  -99.69783 ]
 [ -99.459199  -99.569462 -100.004431  -99.515966  -99.919006]
 [-100.087171  -99.725137  -99.897442 -100.077058  -99.6914  ]
 [ -99.675232 -100.001712  -99.701721  -99.734788  -99.93314 ]
 [ -99.156471  -99.177644  -98.938567  -97.534097  -99.608242]
 [ -95.455229  -98.57773   -96.137052  -98.28658   -98.461262]
 [ -97.243329  -99.702571  -99.670789  -97.851651  -97.306333]
 [ -98.484585  -98.046176  -96.552841  -95.530268  -93.5052  ]
 [ -94.33905   -95.648581  -95.887505  -96.866934  -93.647767]
 [-100.139681  -99.841612  -98.736133  -99.975702  -99.848369]
 [ -98.29665   -99.283644  -99.571804  -98.456178  -99.596853]
 [ -91.756618  -87.451196  -95.576893  -90.679876  -93.293356]
 [ -99.193491  -98.872899  -99.696611  -99.389342  -99.27481 ]
 [ -99.676094  -99.681829  -99.653801  -99.408537  -99.656351]
 [ -95.893907  -89.949199  -96.530784  -92.994109  -93.862912]
 [ -99.356613  -99.204617  -99.00561   -99.10479   -98.834846]
 [  -9.865327   -2.956686   -3.796869  -37.245603  -31.054589]
 [  35.560003   25.258213   38.973898   35.043425   54.287891]
 [ 173.042481  160.052248  147.03988   162.465925  153.323598]
 [ 167.203804  158.01596   147.420116  186.472063  158.976742]
 [ 100.072561   84.753419   90.959363  110.632836   62.688232]
 [ 199.186648  174.034198  197.436062  183.193343  188.113493]
 [ 262.879979  258.61707   283.941587  272.635267  292.7535  ]
 [1290.752941  365.580335  390.676609  291.61308  1366.379202]
 [ 363.828324  339.774329 1223.530087 1058.309884 1069.965874]
 [ 336.859913  393.815506  342.838699 1253.773284  331.592116]
 [ 413.922074  401.044243  364.056724  414.925524  371.673054]
 [ 487.288624  512.336379  429.048914  413.947423  488.414815]
 [1317.554516  540.194423 1238.414113 1232.466502 1352.627207]
 [1055.13732  1250.41949  1018.104432 1114.474203 1370.067852]
 [1120.97627  1083.961484 1072.467679  748.95207  1021.738739]
 [1092.315051 1067.192168 1205.408709 1095.283541 1126.472575]
 [1020.207352 1039.494762 1024.690124 1063.207933 1075.30208 ]
 [1059.588858 1085.163815 1044.480037 1081.294535 1138.041474]
 [1059.113671 1065.730499 1015.65706  1068.322696 1033.303071]
 [1044.072843 1018.757237 1020.671437 1010.913454 1022.831179]
 [1013.520419 1040.006448 1024.322026 1033.931854 1018.039261]
 [1037.60873  1015.653549 1017.687248 1027.14467  1041.839616]
 [1009.775999 1025.899355 1026.941038 1034.130322 1009.921016]
 [1023.275176 1022.648703 1010.97294  1010.718102 1010.822581]
 [1013.712126 1022.62755  1015.221129 1012.768179 1010.937662]
 [1012.912356 1011.887937 1011.700519 1010.04049  1009.901543]
 [1010.820684 1014.592897 1010.996935 1015.651397 1009.775502]
 [1014.276915 1011.513137 1041.975832 1023.335361 1010.894028]
 [1011.098821 1010.740983 1012.458608 1019.811759 1027.559561]
 [1012.758552 1009.887442 1015.719954 1010.686135 1010.884911]
 [1015.691416 1009.850426 1042.118041 1009.938164 1033.518269]
 [ -99.78748  1040.796993 1010.906655 1011.742319 1009.873938]
 [1011.069815 1011.054716 1018.32177  1019.834263 1015.218999]
 [1011.495887 1016.490969 1012.825582 1016.582236 1011.73168 ]
 [1010.01168  1010.856942 1012.844869 1010.88161  1010.738058]
 [1009.911029 1009.831002 1012.812173 1009.77553  1013.695363]
 [1009.931096 1010.567791 1019.600833 1013.495137 1041.192088]
 [1018.546772 1009.797226 1011.040815 1013.596701 1009.955219]
 [1011.644897 1009.877461 1020.36191  1009.946871 1027.903637]
 [1009.984916 1010.0263   1010.910892 1010.89205  1010.020789]
 [1014.603437 1013.733591 1009.947849 1010.962893 1009.946322]
 [1009.91972  1013.906215 1010.917584 1010.775402 1009.951377]
 [1009.992791 1010.11249  1013.855217 1014.775982 1015.728125]
 [1010.881937 1009.961705 1009.986973 1011.000411 1014.712635]
 [1019.684038 1009.883381 1010.962656 1010.59508  1009.963122]
 [1010.018643 1009.870654 1011.11076  1010.840334 1009.972967]
 [1011.882555 1012.940011 1011.947108 1015.747745 1010.907207]
 [1011.020796 1010.002056 1011.896545 1010.026523 1010.868111]
 [1009.708094 1009.9463   1011.751874 1011.908292 1011.871244]
 [1012.792656 1010.088415 1009.890118 1009.99792  1011.923751]
 [1010.883732 1014.868862 1015.82152  1010.006072 1009.788282]
 [1012.803233 1010.032508 1010.903207 1014.870404 1012.950753]
 [1011.715095 1011.958978 1009.998577 1010.864289 1010.878491]
 [1009.963655 1012.940761 1009.902789 1013.829245 1009.933578]
 [1009.838423 1010.961612 1009.964368 1017.640206 1010.958943]
 [1009.8572   1012.007007 1017.783379 1010.103251 1011.119802]
 [1011.074668 1010.105281 1009.988895 1011.683054 1015.536361]
 [1011.001865 1013.688627 1011.041427 1014.715024 1011.743757]
 [1009.756765 1010.865868 1010.949663 1011.041828 1010.857932]
 [1010.859205 1011.004688 1009.796773 1010.962924 1009.77793 ]
 [1011.708168 1010.069733 1010.859009 1010.082888 1011.902118]
 [1011.873274 1011.860117 1011.865114 1009.962672 1012.92001 ]
 [1010.038207 1011.016972 1011.02767  1010.984734 1010.902764]
 [1010.909917 1009.939352 1010.978146 1009.9822   1011.813422]
 [1011.072854 1010.990323 1009.870946 1011.950796 1011.018689]
 [1010.002173 1011.956354 1009.937259 1010.942616 1010.947329]
 [1010.851256 1010.114945 1012.99531  1010.817795 1009.980234]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3583]
 [3582 3601 3601 3601 3601]
 [3601 3584 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3581 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3598 3580 3601 3601]
 [3601 3601 3601 3583 3597]
 [3601 3601 3601 3601 3592]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3600 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3599 3588 3601 3601 3601]
 [3601 3601 3585 3601 3601]
 [3601 3601 3601 3574 3601]
 [3601 3601 3601 3601 3585]
 [3597 3601 3601 3601 3601]
 [3601 3601 3601 3601 3591]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3576 3601 3601 3601 3601]
 [3599 3579 3601 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3582 3598 3601 3601]
 [3600 3587 3596 3600 3601]
 [3601 3601 3583 3601 3601]
 [3601 3601 3601 3590 3600]
 [3601 3601 3601 3601 3586]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3585 3601 3601]
 [3601 3601 3601 3601 3582]
 [3597 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [2792 3601 3601 3601 3529]
 [3601 3601 2394  456  756]
 [3600 3601 3601 1955 3600]
 [3601 3601 3601 3601 3601]
 [3601 3584 3601 3601 3601]
 [1899 3601 1415 1232 2328]
 [ 313 1270   58  599 1845]
 [ 623  428  378 3601  103]
 [ 420  273  756  400  523]
 [  87  152   73  275  313]
 [ 261  315  157  274  515]
 [ 205  224   71  275  122]
 [  95   66  108   25   64]
 [  37   96   85  101   57]
 [ 113   37   75   55   80]
 [  27   65   62   55   26]
 [  48   73   23   33   30]
 [  35   74   52   30   26]
 [  30   29   34   23   26]
 [  28   39   22   37   33]
 [  49   42   60   49   25]
 [  19   32   45   66   74]
 [  35   27   35   36   27]
 [  34   28   93   26   76]
 [3601  105   26   31   27]
 [  58   23   45   65   50]
 [  41   42   32   37   32]
 [  22   26   29   28   32]
 [  29   27   32   31   33]
 [  25   36   37   42   89]
 [  40   28   20   38   25]
 [  34   27   48   24   61]
 [  24   21   25   30   24]
 [  41   35   26   21   25]
 [  24   29   26   32   24]
 [  26   21   30   30   33]
 [  27   25   21   24   35]
 [  35   26   23   37   25]
 [  22   27   21   30   26]
 [  28   27   27   32   25]
 [  24   21   27   22   28]
 [  34   23   30   27   27]
 [  33   21   27   21   25]
 [  27   29   32   22   30]
 [  30   24   26   29   23]
 [  34   25   23   29   25]
 [  22   27   24   31   26]
 [  26   23   26   33   25]
 [  25   23   31   22   21]
 [  21   19   24   34   78]
 [  21   35   21   34   35]
 [  34   29   25   22   27]
 [  26   25   28   25   34]
 [  36   21   29   20   25]
 [  27   27   28   26   28]
 [  22   24   23   23   26]
 [  24   25   23   24   28]
 [  22   25   26   27   24]
 [  22   23   24   24   24]
 [  29   21   24   27   22]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-31_07-47-37_llm_triton_qwen_32b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-31_07-47-37_llm_triton_qwen_32b_continuous_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
