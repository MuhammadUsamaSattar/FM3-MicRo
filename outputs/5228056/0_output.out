####################
/var/spool/slurmd/job5248568/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_7B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_continuous_rewards_zero_shot.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the actions of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. You can output a value between -9 and +9 with an accuracy of 1. Actions that are harmful for achievement of the goal position should have a value closer to -9 while actions that are beneficial for the achievement of the goal should have a value closer to +9.
 
 You must only output a single float value. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 213  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | -279        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 419         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012190222 |
|    clip_fraction        | 0.11        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.313       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0172     |
|    std                  | 1           |
|    value_loss           | 2.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | -279        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 624         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009741675 |
|    clip_fraction        | 0.0866      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.665       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.856       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0194     |
|    std                  | 1           |
|    value_loss           | 2.28        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.59e+03    |
|    ep_rew_mean          | -140        |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 4           |
|    time_elapsed         | 830         |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.011504769 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.722       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.565       |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0238     |
|    std                  | 0.998       |
|    value_loss           | 2.12        |
-----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.95 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -100        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.012790614 |
|    clip_fraction        | 0.142       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.654       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.59        |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0237     |
|    std                  | 1           |
|    value_loss           | 1.58        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -239     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2836     |
|    total_timesteps | 10240    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | -239         |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 6            |
|    time_elapsed         | 3041         |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0054688454 |
|    clip_fraction        | 0.024        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | -0.00242     |
|    learning_rate        | 0.0003       |
|    loss                 | 924          |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00438     |
|    std                  | 1            |
|    value_loss           | 1.03e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -152        |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3247        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.013578592 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.639       |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0213     |
|    std                  | 1           |
|    value_loss           | 1.36        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.4e+03      |
|    ep_rew_mean          | -152         |
| time/                   |              |
|    fps                  | 4            |
|    iterations           | 8            |
|    time_elapsed         | 3452         |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0132177975 |
|    clip_fraction        | 0.165        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | 0.553        |
|    learning_rate        | 0.0003       |
|    loss                 | 0.522        |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.02        |
|    std                  | 0.998        |
|    value_loss           | 1.15         |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.44e+03    |
|    ep_rew_mean          | -96.4       |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3658        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.017925408 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.499       |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0222     |
|    std                  | 0.992       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.89 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.9      |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.01457531 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | 0.185      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.652      |
|    n_updates            | 90         |
|    policy_gradient_loss | -0.0174    |
|    std                  | 0.988      |
|    value_loss           | 1.11       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -134     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5664     |
|    total_timesteps | 20480    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -134        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 11          |
|    time_elapsed         | 5869        |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.009144718 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.00171    |
|    learning_rate        | 0.0003      |
|    loss                 | 62.5        |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00707    |
|    std                  | 0.988       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.37e+03   |
|    ep_rew_mean          | -85.9      |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 12         |
|    time_elapsed         | 6074       |
|    total_timesteps      | 24576      |
| train/                  |            |
|    approx_kl            | 0.01470671 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.3      |
|    explained_variance   | -0.127     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.83       |
|    n_updates            | 110        |
|    policy_gradient_loss | -0.0148    |
|    std                  | 0.987      |
|    value_loss           | 1.28       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.37e+03   |
|    ep_rew_mean          | -85.9      |
| time/                   |            |
|    fps                  | 4          |
|    iterations           | 13         |
|    time_elapsed         | 6280       |
|    total_timesteps      | 26624      |
| train/                  |            |
|    approx_kl            | 0.01625313 |
|    clip_fraction        | 0.192      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.404      |
|    n_updates            | 120        |
|    policy_gradient_loss | -0.0202    |
|    std                  | 0.983      |
|    value_loss           | 1.17       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | -46.8       |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6485        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.014680451 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.7         |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0208     |
|    std                  | 0.978       |
|    value_loss           | 1.5         |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.90 +/- 0.02
Episode length: 3596.00 +/- 8.15
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.018406997 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.523       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.597       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.973       |
|    value_loss           | 1.36        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -79.5    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8497     |
|    total_timesteps | 30720    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -79.5       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 16          |
|    time_elapsed         | 8703        |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.011723926 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -5.29e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 44.9        |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00477    |
|    std                  | 0.974       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -50         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 8909        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.015612219 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.344       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.516       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.973       |
|    value_loss           | 1.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | -50         |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9114        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.017012224 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.278       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.897       |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0181     |
|    std                  | 0.973       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | -23.6       |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9320        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.016760621 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.375       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.743       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.0216     |
|    std                  | 0.97        |
|    value_loss           | 1.33        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.80 +/- 0.12
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.013994208 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.905       |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.0176     |
|    std                  | 0.963       |
|    value_loss           | 1.39        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -49.7    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11326    |
|    total_timesteps | 40960    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -49.7       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 21          |
|    time_elapsed         | 11531       |
|    total_timesteps      | 43008       |
| train/                  |             |
|    approx_kl            | 0.008525232 |
|    clip_fraction        | 0.0431      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.00202    |
|    learning_rate        | 0.0003      |
|    loss                 | 18.3        |
|    n_updates            | 200         |
|    policy_gradient_loss | -0.00311    |
|    std                  | 0.963       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -27.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 22          |
|    time_elapsed         | 11740       |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.019961454 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0857     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.347       |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.0204     |
|    std                  | 0.96        |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -27.4       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11945       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.020779133 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.509       |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.957       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | -8.33       |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12151       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.018867508 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.749       |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.02       |
|    std                  | 0.951       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.79 +/- 0.06
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.017215252 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.353       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.694       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0208     |
|    std                  | 0.947       |
|    value_loss           | 1.3         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -26.8    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14158    |
|    total_timesteps | 51200    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -26.8       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 26          |
|    time_elapsed         | 14363       |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.012450583 |
|    clip_fraction        | 0.0954      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.00124    |
|    learning_rate        | 0.0003      |
|    loss                 | 86.6        |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.00295    |
|    std                  | 0.947       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | -7.17       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 27          |
|    time_elapsed         | 14569       |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.021565348 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.255       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.473       |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.947       |
|    value_loss           | 1.15        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 11.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 28         |
|    time_elapsed         | 14774      |
|    total_timesteps      | 57344      |
| train/                  |            |
|    approx_kl            | 0.01757636 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.299      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.752      |
|    n_updates            | 270        |
|    policy_gradient_loss | -0.0162    |
|    std                  | 0.947      |
|    value_loss           | 1.32       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 11.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14980       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.018513478 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.122       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.464       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0169     |
|    std                  | 0.949       |
|    value_loss           | 1.21        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.88 +/- 0.06
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.018119298 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.216       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.627       |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0196     |
|    std                  | 0.95        |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | -6.86    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 16991    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | -6.86       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17198       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.010606974 |
|    clip_fraction        | 0.0997      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000669   |
|    learning_rate        | 0.0003      |
|    loss                 | 129         |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00606    |
|    std                  | 0.949       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 9.12        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 32          |
|    time_elapsed         | 17404       |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.017943561 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.182      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.561       |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.0141     |
|    std                  | 0.951       |
|    value_loss           | 1.56        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 22.3       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 33         |
|    time_elapsed         | 17609      |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.02759249 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.214      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.507      |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.0198    |
|    std                  | 0.955      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 22.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17815       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.026767898 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.485       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.954       |
|    value_loss           | 1.17        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.81 +/- 0.04
Episode length: 3598.80 +/- 4.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 70000      |
| train/                  |            |
|    approx_kl            | 0.02190443 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11        |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.368      |
|    n_updates            | 340        |
|    policy_gradient_loss | -0.01      |
|    std                  | 0.954      |
|    value_loss           | 0.989      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 6.71     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19826    |
|    total_timesteps | 71680    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 18.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 36          |
|    time_elapsed         | 20033       |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.026611999 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.000672   |
|    learning_rate        | 0.0003      |
|    loss                 | 539         |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.954       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 18.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 37          |
|    time_elapsed         | 20238       |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.024559326 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.125       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.441       |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.95        |
|    value_loss           | 1.04        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 30.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20443       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.019877726 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.424       |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.943       |
|    value_loss           | 1.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 30.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20649       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.022954758 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.294       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.581       |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.0158     |
|    std                  | 0.933       |
|    value_loss           | 1.17        |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.74 +/- 0.04
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 80000     |
| train/                  |           |
|    approx_kl            | 0.0213062 |
|    clip_fraction        | 0.236     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.8     |
|    explained_variance   | 0.197     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.453     |
|    n_updates            | 390       |
|    policy_gradient_loss | -0.0182   |
|    std                  | 0.933     |
|    value_loss           | 1.13      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 16.7     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22656    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 28.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22861       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.008741992 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.0011     |
|    learning_rate        | 0.0003      |
|    loss                 | 36.6        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.00539    |
|    std                  | 0.933       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 28.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23067       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.023319775 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.249      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.898       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.931       |
|    value_loss           | 1.82        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 38.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23274       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.023233265 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.415       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.928       |
|    value_loss           | 0.817       |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-80.21 +/- 5.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -80.2      |
| time/                   |            |
|    total_timesteps      | 90000      |
| train/                  |            |
|    approx_kl            | 0.02747881 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.41       |
|    n_updates            | 430        |
|    policy_gradient_loss | -0.0212    |
|    std                  | 0.93       |
|    value_loss           | 1.15       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 27.2     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25284    |
|    total_timesteps | 90112    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 27.2         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 45           |
|    time_elapsed         | 25490        |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0077450085 |
|    clip_fraction        | 0.0835       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | 9.01e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 472          |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00639     |
|    std                  | 0.93         |
|    value_loss           | 1.04e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 38.1       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 46         |
|    time_elapsed         | 25696      |
|    total_timesteps      | 94208      |
| train/                  |            |
|    approx_kl            | 0.02323331 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.0481     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.559      |
|    n_updates            | 450        |
|    policy_gradient_loss | -0.0213    |
|    std                  | 0.923      |
|    value_loss           | 1.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 38.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25901       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.017850239 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.593       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.0124     |
|    std                  | 0.926       |
|    value_loss           | 0.992       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 47.4        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26107       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.023272093 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.366       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.564       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.0161     |
|    std                  | 0.924       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-88.78 +/- 4.55
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -88.8      |
| time/                   |            |
|    total_timesteps      | 100000     |
| train/                  |            |
|    approx_kl            | 0.02363197 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.429      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.445      |
|    n_updates            | 480        |
|    policy_gradient_loss | -0.0199    |
|    std                  | 0.923      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 37.6     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28117    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 37.6        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 28324       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.007431958 |
|    clip_fraction        | 0.0835      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.00125    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.923       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 46.9        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28529       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.031157356 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.0371      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.407       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.921       |
|    value_loss           | 1.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 46.9       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 52         |
|    time_elapsed         | 28735      |
|    total_timesteps      | 106496     |
| train/                  |            |
|    approx_kl            | 0.02923075 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.7      |
|    explained_variance   | 0.238      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.677      |
|    n_updates            | 510        |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.921      |
|    value_loss           | 1.13       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 55.4        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28940       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.026408464 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.501       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.672       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.0188     |
|    std                  | 0.919       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.33 +/- 0.87
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.3       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.027090808 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.395       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.915       |
|    value_loss           | 1.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 45.8     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30949    |
|    total_timesteps | 110592   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 45.8        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 55          |
|    time_elapsed         | 31155       |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.010678567 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.00431     |
|    learning_rate        | 0.0003      |
|    loss                 | 346         |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00548    |
|    std                  | 0.915       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 55.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 56          |
|    time_elapsed         | 31360       |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.027685128 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.104       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.639       |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.0259     |
|    std                  | 0.915       |
|    value_loss           | 1.74        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 55.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 57          |
|    time_elapsed         | 31565       |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.020187754 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.477       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.61        |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.0144     |
|    std                  | 0.918       |
|    value_loss           | 1.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 64.2        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31771       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.018270336 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.616       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00864    |
|    std                  | 0.913       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.73 +/- 0.06
Episode length: 3598.80 +/- 3.12
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.020365626 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.647       |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00857    |
|    std                  | 0.908       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 57.3     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33780    |
|    total_timesteps | 120832   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 57.3        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 60          |
|    time_elapsed         | 33987       |
|    total_timesteps      | 122880      |
| train/                  |             |
|    approx_kl            | 0.010879586 |
|    clip_fraction        | 0.0819      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0041      |
|    learning_rate        | 0.0003      |
|    loss                 | 9.61        |
|    n_updates            | 590         |
|    policy_gradient_loss | -0.00381    |
|    std                  | 0.907       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 66.5       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 61         |
|    time_elapsed         | 34192      |
|    total_timesteps      | 124928     |
| train/                  |            |
|    approx_kl            | 0.02398952 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | -0.19      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.378      |
|    n_updates            | 600        |
|    policy_gradient_loss | -0.00385   |
|    std                  | 0.907      |
|    value_loss           | 1.4        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 66.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 62          |
|    time_elapsed         | 34398       |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.029112764 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.445       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.355       |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0109     |
|    std                  | 0.909       |
|    value_loss           | 1.03        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 75.4        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34604       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.028811213 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.468       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.734       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.908       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-82.69 +/- 1.75
Episode length: 3600.00 +/- 1.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -82.7       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.022467947 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.455       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00615    |
|    std                  | 0.906       |
|    value_loss           | 1.15        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 69.5     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36612    |
|    total_timesteps | 131072   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 69.5         |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 65           |
|    time_elapsed         | 36818        |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0102353785 |
|    clip_fraction        | 0.0983       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.5        |
|    explained_variance   | -0.0032      |
|    learning_rate        | 0.0003       |
|    loss                 | 560          |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00798     |
|    std                  | 0.907        |
|    value_loss           | 1.05e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 78.6       |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 66         |
|    time_elapsed         | 37024      |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.04306201 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.191     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.00811   |
|    std                  | 0.907      |
|    value_loss           | 1.42       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 86.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37229       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.038973026 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.451       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.611       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.012      |
|    std                  | 0.9         |
|    value_loss           | 1.1         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 86.1        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37434       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.034402546 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.505       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.899       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-80.22 +/- 5.22
Episode length: 3598.00 +/- 6.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -80.2      |
| time/                   |            |
|    total_timesteps      | 140000     |
| train/                  |            |
|    approx_kl            | 0.04927403 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.58       |
|    n_updates            | 680        |
|    policy_gradient_loss | -0.014     |
|    std                  | 0.895      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 80.5     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39440    |
|    total_timesteps | 141312   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 80.5        |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 70          |
|    time_elapsed         | 39646       |
|    total_timesteps      | 143360      |
| train/                  |             |
|    approx_kl            | 0.015728189 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00203     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.31e+03    |
|    n_updates            | 690         |
|    policy_gradient_loss | -0.00595    |
|    std                  | 0.895       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 89         |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 71         |
|    time_elapsed         | 39851      |
|    total_timesteps      | 145408     |
| train/                  |            |
|    approx_kl            | 0.04001099 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.0339    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.444      |
|    n_updates            | 700        |
|    policy_gradient_loss | -0.00621   |
|    std                  | 0.898      |
|    value_loss           | 1.19       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 98          |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40057       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.045284256 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.0118     |
|    std                  | 0.897       |
|    value_loss           | 1.07        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 98          |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40262       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.027197417 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.471       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.465       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0133     |
|    std                  | 0.897       |
|    value_loss           | 1.39        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.12 +/- 1.22
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.1      |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.03493514 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.655      |
|    n_updates            | 730        |
|    policy_gradient_loss | -0.00874   |
|    std                  | 0.896      |
|    value_loss           | 1.29       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 93.1     |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42268    |
|    total_timesteps | 151552   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 75          |
|    time_elapsed         | 42474       |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.011138213 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.00476    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.25        |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00271    |
|    std                  | 0.895       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 101         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 76          |
|    time_elapsed         | 42679       |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.035242327 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.015       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.804       |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0113     |
|    std                  | 0.899       |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 77          |
|    time_elapsed         | 42885       |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.029875554 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.424       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 760         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.899       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 110         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43091       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.031999912 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.431       |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00834    |
|    std                  | 0.893       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-93.08 +/- 3.46
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -93.1       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.022341691 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.422       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00751    |
|    std                  | 0.891       |
|    value_loss           | 1.08        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 106      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45098    |
|    total_timesteps | 161792   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 114         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 80          |
|    time_elapsed         | 45303       |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.009801757 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00611     |
|    learning_rate        | 0.0003      |
|    loss                 | 49.3        |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.00712    |
|    std                  | 0.892       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 114         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 81          |
|    time_elapsed         | 45508       |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.028965889 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.12       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.844       |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.888       |
|    value_loss           | 2.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 124         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45714       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.023291262 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.41        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00938    |
|    std                  | 0.887       |
|    value_loss           | 1.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 124         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 83          |
|    time_elapsed         | 45920       |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.027305882 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.547       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.84        |
|    n_updates            | 820         |
|    policy_gradient_loss | -0.0062     |
|    std                  | 0.884       |
|    value_loss           | 1.81        |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-98.16 +/- 0.99
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.2       |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.020496462 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.512       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.464       |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.006      |
|    std                  | 0.883       |
|    value_loss           | 1.23        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 121      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47926    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48131       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.025874028 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00406    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.566       |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.000569   |
|    std                  | 0.882       |
|    value_loss           | 927         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 129         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48337       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.032790784 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.414       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00125    |
|    std                  | 0.878       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 138         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48542       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.033253044 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.42        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.494       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00415    |
|    std                  | 0.876       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.76 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.018244734 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.372       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.397       |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00493    |
|    std                  | 0.876       |
|    value_loss           | 1.02        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 136      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50552    |
|    total_timesteps | 180224   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 89          |
|    time_elapsed         | 50757       |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.035778373 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.00087    |
|    learning_rate        | 0.0003      |
|    loss                 | 909         |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.00227     |
|    std                  | 0.878       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 50963       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.046003297 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.303      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.562       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00299    |
|    std                  | 0.885       |
|    value_loss           | 1.4         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 145         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51168       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.036568217 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.305       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.63        |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.0093     |
|    std                  | 0.878       |
|    value_loss           | 1.51        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 153         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51373       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.028187905 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.688       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.00608    |
|    std                  | 0.877       |
|    value_loss           | 1.67        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.02 +/- 0.55
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99         |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.030496215 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.47        |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.0162     |
|    std                  | 0.872       |
|    value_loss           | 1.57        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 151      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53379    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 151        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 94         |
|    time_elapsed         | 53585      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.03996218 |
|    clip_fraction        | 0.188      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.00162   |
|    learning_rate        | 0.0003     |
|    loss                 | 9.45       |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.00326   |
|    std                  | 0.873      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 160         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53790       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.031908665 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.0757      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.842       |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00861    |
|    std                  | 0.872       |
|    value_loss           | 1.5         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 160         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 53996       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.030373074 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.271       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.563       |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00732    |
|    std                  | 0.867       |
|    value_loss           | 1.45        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 168         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 97          |
|    time_elapsed         | 54201       |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.040286608 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.772       |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.0062     |
|    std                  | 0.867       |
|    value_loss           | 1.39        |
-----------------------------------------
Eval num_timesteps=200000, episode_reward=-98.53 +/- 0.94
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.5       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.034199286 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.424       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.614       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.0167     |
|    std                  | 0.865       |
|    value_loss           | 1.52        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 165      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56208    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 165         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56413       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.025201354 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.00624     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.54e+03    |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.867       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 100        |
|    time_elapsed         | 56619      |
|    total_timesteps      | 204800     |
| train/                  |            |
|    approx_kl            | 0.04006923 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.00192    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.89       |
|    n_updates            | 990        |
|    policy_gradient_loss | -0.0121    |
|    std                  | 0.87       |
|    value_loss           | 1.6        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 173        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 101        |
|    time_elapsed         | 56825      |
|    total_timesteps      | 206848     |
| train/                  |            |
|    approx_kl            | 0.03206182 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.369      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.435      |
|    n_updates            | 1000       |
|    policy_gradient_loss | -0.00739   |
|    std                  | 0.866      |
|    value_loss           | 1.24       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 181         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57030       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.026300624 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.714       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00699    |
|    std                  | 0.867       |
|    value_loss           | 1.31        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.75 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.022616424 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.357       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.694       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00769    |
|    std                  | 0.868       |
|    value_loss           | 1.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 179      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59036    |
|    total_timesteps | 210944   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 179         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 104         |
|    time_elapsed         | 59242       |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.022215322 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000284   |
|    learning_rate        | 0.0003      |
|    loss                 | 59.1        |
|    n_updates            | 1030        |
|    policy_gradient_loss | -0.00558    |
|    std                  | 0.868       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 187        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 105        |
|    time_elapsed         | 59449      |
|    total_timesteps      | 215040     |
| train/                  |            |
|    approx_kl            | 0.03040813 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.0394    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.651      |
|    n_updates            | 1040       |
|    policy_gradient_loss | -0.00779   |
|    std                  | 0.875      |
|    value_loss           | 1.39       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 187        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 59654      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.03204385 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.845      |
|    n_updates            | 1050       |
|    policy_gradient_loss | -0.0129    |
|    std                  | 0.871      |
|    value_loss           | 1.64       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 194        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 59859      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.04039067 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.46       |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.00278   |
|    std                  | 0.872      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.55 +/- 0.53
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 220000    |
| train/                  |           |
|    approx_kl            | 0.0325516 |
|    clip_fraction        | 0.293     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | 0.377     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.539     |
|    n_updates            | 1070      |
|    policy_gradient_loss | -0.00871  |
|    std                  | 0.866     |
|    value_loss           | 1.26      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 192      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61865    |
|    total_timesteps | 221184   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 192         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 109         |
|    time_elapsed         | 62071       |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.006669584 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.000327   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.23        |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00134    |
|    std                  | 0.866       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 199        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 62276      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.03169559 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.0442     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.629      |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.864      |
|    value_loss           | 1.25       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 207        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 111        |
|    time_elapsed         | 62482      |
|    total_timesteps      | 227328     |
| train/                  |            |
|    approx_kl            | 0.02212782 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.361      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.68       |
|    n_updates            | 1100       |
|    policy_gradient_loss | -0.00746   |
|    std                  | 0.865      |
|    value_loss           | 1.3        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 207         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 112         |
|    time_elapsed         | 62687       |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.029679036 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.015      |
|    std                  | 0.857       |
|    value_loss           | 1.53        |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.64 +/- 0.10
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 230000     |
| train/                  |            |
|    approx_kl            | 0.04052706 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.347      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.632      |
|    n_updates            | 1120       |
|    policy_gradient_loss | -0.0133    |
|    std                  | 0.854      |
|    value_loss           | 1.66       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 204      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64693    |
|    total_timesteps | 231424   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 204         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 114         |
|    time_elapsed         | 64898       |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.021108257 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.000431    |
|    learning_rate        | 0.0003      |
|    loss                 | 104         |
|    n_updates            | 1130        |
|    policy_gradient_loss | 0.000107    |
|    std                  | 0.855       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 211         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 115         |
|    time_elapsed         | 65104       |
|    total_timesteps      | 235520      |
| train/                  |             |
|    approx_kl            | 0.037708238 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0834      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.698       |
|    n_updates            | 1140        |
|    policy_gradient_loss | -0.00506    |
|    std                  | 0.856       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 218         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 116         |
|    time_elapsed         | 65309       |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.027592668 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.338       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.856       |
|    value_loss           | 1.27        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 218         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65515       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.029909514 |
|    clip_fraction        | 0.314       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.407       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.443       |
|    n_updates            | 1160        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.859       |
|    value_loss           | 1.11        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.49 +/- 0.38
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.027495105 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.345       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.628       |
|    n_updates            | 1170        |
|    policy_gradient_loss | -0.00728    |
|    std                  | 0.861       |
|    value_loss           | 1.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 217      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67521    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 225         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67726       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.028504996 |
|    clip_fraction        | 0.291       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.000774   |
|    learning_rate        | 0.0003      |
|    loss                 | 587         |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.00316     |
|    std                  | 0.861       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 225         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 67931       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.030900737 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.0497      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.761       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00414    |
|    std                  | 0.86        |
|    value_loss           | 1.65        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 232         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68137       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.030099824 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.293       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.606       |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.856       |
|    value_loss           | 1.43        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 232         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68342       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.027534034 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.336       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.55        |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00266    |
|    std                  | 0.851       |
|    value_loss           | 1.26        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.42 +/- 0.42
Episode length: 3597.80 +/- 6.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.044680744 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.351       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.693       |
|    n_updates            | 1220        |
|    policy_gradient_loss | -0.00418    |
|    std                  | 0.85        |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 231      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70348    |
|    total_timesteps | 251904   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 239        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 124        |
|    time_elapsed         | 70554      |
|    total_timesteps      | 253952     |
| train/                  |            |
|    approx_kl            | 0.02529498 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.00252   |
|    learning_rate        | 0.0003     |
|    loss                 | 771        |
|    n_updates            | 1230       |
|    policy_gradient_loss | 0.000117   |
|    std                  | 0.85       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 239         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70759       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.043864608 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.244      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.528       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.847       |
|    value_loss           | 1.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 246         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 70966       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.039255008 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.383       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.488       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00863    |
|    std                  | 0.841       |
|    value_loss           | 1.38        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-98.65 +/- 0.80
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.7       |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.033917323 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.94       |
|    explained_variance   | 0.449       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.523       |
|    n_updates            | 1260        |
|    policy_gradient_loss | -0.00458    |
|    std                  | 0.843       |
|    value_loss           | 1.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 244      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 72973    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 244         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73178       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.028036963 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | -0.00112    |
|    learning_rate        | 0.0003      |
|    loss                 | 357         |
|    n_updates            | 1270        |
|    policy_gradient_loss | 0.00133     |
|    std                  | 0.842       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 252         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 129         |
|    time_elapsed         | 73384       |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.041120157 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.93       |
|    explained_variance   | 3.85e-05    |
|    learning_rate        | 0.0003      |
|    loss                 | 0.497       |
|    n_updates            | 1280        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.839       |
|    value_loss           | 1.24        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 252         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 130         |
|    time_elapsed         | 73589       |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.033110768 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.89       |
|    explained_variance   | 0.492       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.409       |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00853    |
|    std                  | 0.833       |
|    value_loss           | 1.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 259         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 131         |
|    time_elapsed         | 73794       |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.033753783 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.481       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.438       |
|    n_updates            | 1300        |
|    policy_gradient_loss | -0.00139    |
|    std                  | 0.831       |
|    value_loss           | 1.09        |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.57 +/- 0.21
Episode length: 3597.00 +/- 7.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.036961377 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.86       |
|    explained_variance   | 0.465       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00479    |
|    std                  | 0.834       |
|    value_loss           | 0.897       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 258      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75801    |
|    total_timesteps | 270336   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 258         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 133         |
|    time_elapsed         | 76006       |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.017783469 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.00232     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.88e+03    |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00778    |
|    std                  | 0.834       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 265        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76211      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.03633342 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.82      |
|    explained_variance   | 0.132      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.634      |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.00395    |
|    std                  | 0.826      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 265        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 135        |
|    time_elapsed         | 76417      |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.07006848 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.628      |
|    n_updates            | 1340       |
|    policy_gradient_loss | 0.00292    |
|    std                  | 0.824      |
|    value_loss           | 1.04       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 273         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 136         |
|    time_elapsed         | 76622       |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.042705897 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.74       |
|    explained_variance   | 0.474       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.000111    |
|    std                  | 0.819       |
|    value_loss           | 0.79        |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-99.63 +/- 0.08
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.037874937 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.442       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.335       |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.00657     |
|    std                  | 0.819       |
|    value_loss           | 0.848       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 272      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78628    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 272         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78835       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.009479563 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | -0.000425   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.98e+03    |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.0038     |
|    std                  | 0.819       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 278         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 79041       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.050526954 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.69       |
|    explained_variance   | -0.651      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.484       |
|    n_updates            | 1380        |
|    policy_gradient_loss | 0.00109     |
|    std                  | 0.816       |
|    value_loss           | 1.16        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 278         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79246       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.047571883 |
|    clip_fraction        | 0.34        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.601       |
|    n_updates            | 1390        |
|    policy_gradient_loss | 0.00547     |
|    std                  | 0.815       |
|    value_loss           | 1.09        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 285         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 141         |
|    time_elapsed         | 79452       |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.052146547 |
|    clip_fraction        | 0.368       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.68       |
|    explained_variance   | 0.387       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.455       |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.815       |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.58 +/- 0.15
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 290000     |
| train/                  |            |
|    approx_kl            | 0.04254007 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.67      |
|    explained_variance   | 0.375      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.46       |
|    n_updates            | 1410       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.813      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 284      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81458    |
|    total_timesteps | 290816   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 284         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 143         |
|    time_elapsed         | 81663       |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.039946713 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.00397     |
|    learning_rate        | 0.0003      |
|    loss                 | 501         |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.00211    |
|    std                  | 0.813       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 291        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 144        |
|    time_elapsed         | 81869      |
|    total_timesteps      | 294912     |
| train/                  |            |
|    approx_kl            | 0.05858293 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | -0.0396    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.845      |
|    n_updates            | 1430       |
|    policy_gradient_loss | -0.0032    |
|    std                  | 0.81       |
|    value_loss           | 1.24       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 291        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 145        |
|    time_elapsed         | 82074      |
|    total_timesteps      | 296960     |
| train/                  |            |
|    approx_kl            | 0.06479453 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.62      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.626      |
|    n_updates            | 1440       |
|    policy_gradient_loss | 0.00548    |
|    std                  | 0.808      |
|    value_loss           | 0.99       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 297        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 146        |
|    time_elapsed         | 82279      |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.04412719 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.62      |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.247      |
|    n_updates            | 1450       |
|    policy_gradient_loss | 1.99e-05   |
|    std                  | 0.809      |
|    value_loss           | 0.725      |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.61 +/- 0.06
Episode length: 3596.40 +/- 7.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.056757852 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.533       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.451       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.000745   |
|    std                  | 0.807       |
|    value_loss           | 0.937       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 296      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84286    |
|    total_timesteps | 301056   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 296         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 148         |
|    time_elapsed         | 84491       |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.029929588 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.59       |
|    explained_variance   | 0.00613     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.11e+03    |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00332    |
|    std                  | 0.806       |
|    value_loss           | 1.03e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 302        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 149        |
|    time_elapsed         | 84697      |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.08715442 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | -0.972     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.743      |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.00606   |
|    std                  | 0.807      |
|    value_loss           | 1.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 309        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 150        |
|    time_elapsed         | 84902      |
|    total_timesteps      | 307200     |
| train/                  |            |
|    approx_kl            | 0.07230364 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | 0.44       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.586      |
|    n_updates            | 1490       |
|    policy_gradient_loss | 0.000712   |
|    std                  | 0.807      |
|    value_loss           | 0.944      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 309        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 151        |
|    time_elapsed         | 85107      |
|    total_timesteps      | 309248     |
| train/                  |            |
|    approx_kl            | 0.04723075 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.59      |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.526      |
|    n_updates            | 1500       |
|    policy_gradient_loss | 0.00414    |
|    std                  | 0.807      |
|    value_loss           | 0.994      |
----------------------------------------
Eval num_timesteps=310000, episode_reward=-98.61 +/- 0.74
Episode length: 3597.60 +/- 5.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.6       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.043590695 |
|    clip_fraction        | 0.367       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.58       |
|    explained_variance   | 0.433       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.518       |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.000623   |
|    std                  | 0.804       |
|    value_loss           | 1.04        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 308      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87114    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 308         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87319       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.020099703 |
|    clip_fraction        | 0.264       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -0.00129    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51e+03    |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.00291     |
|    std                  | 0.804       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 315         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 87524       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.065077595 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | -2.16       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.413       |
|    n_updates            | 1530        |
|    policy_gradient_loss | 0.0036      |
|    std                  | 0.805       |
|    value_loss           | 1.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 321         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 155         |
|    time_elapsed         | 87730       |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.056311376 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.424       |
|    n_updates            | 1540        |
|    policy_gradient_loss | 0.00282     |
|    std                  | 0.804       |
|    value_loss           | 0.932       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 321        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 156        |
|    time_elapsed         | 87935      |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.03294074 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.58      |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.517      |
|    n_updates            | 1550       |
|    policy_gradient_loss | 0.000968   |
|    std                  | 0.806      |
|    value_loss           | 0.923      |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-98.66 +/- 0.53
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.7       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.046030432 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.57       |
|    explained_variance   | 0.547       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.501       |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00248    |
|    std                  | 0.801       |
|    value_loss           | 0.936       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 320      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 89941    |
|    total_timesteps | 321536   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 320        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 158        |
|    time_elapsed         | 90147      |
|    total_timesteps      | 323584     |
| train/                  |            |
|    approx_kl            | 0.04724151 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.54      |
|    explained_variance   | 0.00385    |
|    learning_rate        | 0.0003     |
|    loss                 | 107        |
|    n_updates            | 1570       |
|    policy_gradient_loss | 0.00633    |
|    std                  | 0.802      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 327        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 159        |
|    time_elapsed         | 90354      |
|    total_timesteps      | 325632     |
| train/                  |            |
|    approx_kl            | 0.08946954 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.56      |
|    explained_variance   | 0.113      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.603      |
|    n_updates            | 1580       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.802      |
|    value_loss           | 1.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 333        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 160        |
|    time_elapsed         | 90560      |
|    total_timesteps      | 327680     |
| train/                  |            |
|    approx_kl            | 0.06005232 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.413      |
|    n_updates            | 1590       |
|    policy_gradient_loss | 0.00706    |
|    std                  | 0.794      |
|    value_loss           | 0.802      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 333         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 161         |
|    time_elapsed         | 90765       |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.048604257 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.45       |
|    explained_variance   | 0.489       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.557       |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00158    |
|    std                  | 0.79        |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-85.67 +/- 2.18
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -85.7      |
| time/                   |            |
|    total_timesteps      | 330000     |
| train/                  |            |
|    approx_kl            | 0.09481551 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 1610       |
|    policy_gradient_loss | 0.000727   |
|    std                  | 0.789      |
|    value_loss           | 0.952      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 332      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92771    |
|    total_timesteps | 331776   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 338       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 163       |
|    time_elapsed         | 92977     |
|    total_timesteps      | 333824    |
| train/                  |           |
|    approx_kl            | 0.0691385 |
|    clip_fraction        | 0.322     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.42     |
|    explained_variance   | -0.00309  |
|    learning_rate        | 0.0003    |
|    loss                 | 744       |
|    n_updates            | 1620      |
|    policy_gradient_loss | 0.00773   |
|    std                  | 0.79      |
|    value_loss           | 1.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 338        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 164        |
|    time_elapsed         | 93182      |
|    total_timesteps      | 335872     |
| train/                  |            |
|    approx_kl            | 0.05074539 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | -0.205     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 1630       |
|    policy_gradient_loss | -0.0017    |
|    std                  | 0.792      |
|    value_loss           | 1.3        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 350         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 165         |
|    time_elapsed         | 93388       |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.058601804 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.46       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.00367     |
|    std                  | 0.795       |
|    value_loss           | 0.902       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 350        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 166        |
|    time_elapsed         | 93593      |
|    total_timesteps      | 339968     |
| train/                  |            |
|    approx_kl            | 0.03559544 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.48      |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 1650       |
|    policy_gradient_loss | -0.00124   |
|    std                  | 0.794      |
|    value_loss           | 0.965      |
----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.35 +/- 0.50
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 340000     |
| train/                  |            |
|    approx_kl            | 0.03350533 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.44      |
|    explained_variance   | 0.437      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.465      |
|    n_updates            | 1660       |
|    policy_gradient_loss | -0.00166   |
|    std                  | 0.79       |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 353      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95599    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 367        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 168        |
|    time_elapsed         | 95804      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.06834296 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | -0.00193   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.36e+03   |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.00176    |
|    std                  | 0.792      |
|    value_loss           | 1.03e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 367         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 96010       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.051630065 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.44       |
|    explained_variance   | 0.161       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.634       |
|    n_updates            | 1680        |
|    policy_gradient_loss | 0.00323     |
|    std                  | 0.792       |
|    value_loss           | 1.26        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 376         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 96215       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.044816926 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | 0.393       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.615       |
|    n_updates            | 1690        |
|    policy_gradient_loss | 0.00375     |
|    std                  | 0.789       |
|    value_loss           | 1.11        |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-98.84 +/- 0.84
Episode length: 3597.00 +/- 6.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -98.8      |
| time/                   |            |
|    total_timesteps      | 350000     |
| train/                  |            |
|    approx_kl            | 0.09053753 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.37      |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.562      |
|    n_updates            | 1700       |
|    policy_gradient_loss | 0.00334    |
|    std                  | 0.781      |
|    value_loss           | 0.935      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 377      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98221    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 377         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98428       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.025889803 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.34       |
|    explained_variance   | 0.000911    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.51e+03    |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.000275   |
|    std                  | 0.781       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 391         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 98633       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.075728476 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | -0.328      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.538       |
|    n_updates            | 1720        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.78        |
|    value_loss           | 0.993       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 391         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 98838       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.047542036 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.31       |
|    explained_variance   | 0.456       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.522       |
|    n_updates            | 1730        |
|    policy_gradient_loss | 0.00496     |
|    std                  | 0.778       |
|    value_loss           | 0.952       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 399        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 175        |
|    time_elapsed         | 99044      |
|    total_timesteps      | 358400     |
| train/                  |            |
|    approx_kl            | 0.05543587 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.29      |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.78       |
|    n_updates            | 1740       |
|    policy_gradient_loss | 0.00638    |
|    std                  | 0.775      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=360000, episode_reward=-99.35 +/- 0.50
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.4       |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.058356605 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.26       |
|    explained_variance   | 0.521       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.376       |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.0048      |
|    std                  | 0.774       |
|    value_loss           | 0.895       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 399      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101050   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 399         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101255      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.035042405 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | -0.00158    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.28        |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.00603     |
|    std                  | 0.774       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 413        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 101461     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.08824089 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.27      |
|    explained_variance   | -0.19      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.37       |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.00969    |
|    std                  | 0.775      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 413         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 179         |
|    time_elapsed         | 101666      |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.083796315 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.27       |
|    explained_variance   | 0.44        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.414       |
|    n_updates            | 1780        |
|    policy_gradient_loss | 0.0119      |
|    std                  | 0.773       |
|    value_loss           | 0.891       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 420         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 101872      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.046650186 |
|    clip_fraction        | 0.371       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.24       |
|    explained_variance   | 0.392       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.572       |
|    n_updates            | 1790        |
|    policy_gradient_loss | 0.00103     |
|    std                  | 0.769       |
|    value_loss           | 1.19        |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-98.89 +/- 1.22
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.9       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.041862436 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.23       |
|    explained_variance   | 0.434       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.551       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.000857    |
|    std                  | 0.772       |
|    value_loss           | 1.06        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 421      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 103878   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 421         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104083      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.016003093 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | 0.00212     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.9         |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00113    |
|    std                  | 0.772       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 434        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 183        |
|    time_elapsed         | 104289     |
|    total_timesteps      | 374784     |
| train/                  |            |
|    approx_kl            | 0.07202336 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.27      |
|    explained_variance   | -0.283     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.422      |
|    n_updates            | 1820       |
|    policy_gradient_loss | 0.00999    |
|    std                  | 0.776      |
|    value_loss           | 0.975      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 434        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 104494     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.09461709 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.27      |
|    explained_variance   | 0.381      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.488      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.773      |
|    value_loss           | 1.07       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 441         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 104699      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.046842214 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | 0.351       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.501       |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.00924     |
|    std                  | 0.771       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.26 +/- 0.39
Episode length: 3596.80 +/- 6.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.3      |
| time/                   |            |
|    total_timesteps      | 380000     |
| train/                  |            |
|    approx_kl            | 0.05842142 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.19      |
|    explained_variance   | 0.297      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.772      |
|    n_updates            | 1850       |
|    policy_gradient_loss | 0.00705    |
|    std                  | 0.764      |
|    value_loss           | 1.16       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 441      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106706   |
|    total_timesteps | 380928   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 441        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 187        |
|    time_elapsed         | 106911     |
|    total_timesteps      | 382976     |
| train/                  |            |
|    approx_kl            | 0.03789564 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.16      |
|    explained_variance   | 0.000661   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.05       |
|    n_updates            | 1860       |
|    policy_gradient_loss | 0.00341    |
|    std                  | 0.764      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 454         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 188         |
|    time_elapsed         | 107116      |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.053640917 |
|    clip_fraction        | 0.414       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.18       |
|    explained_variance   | -0.355      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.601       |
|    n_updates            | 1870        |
|    policy_gradient_loss | 0.00966     |
|    std                  | 0.767       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 454         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 189         |
|    time_elapsed         | 107322      |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.052163456 |
|    clip_fraction        | 0.395       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.382       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.664       |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.00618     |
|    std                  | 0.767       |
|    value_loss           | 1.08        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 461        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 107527     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.03994925 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.18      |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.746      |
|    n_updates            | 1890       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.766      |
|    value_loss           | 0.965      |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-97.90 +/- 1.01
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -97.9       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.050259788 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | 0.365       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.501       |
|    n_updates            | 1900        |
|    policy_gradient_loss | 0.00855     |
|    std                  | 0.766       |
|    value_loss           | 1.13        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 461      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109534   |
|    total_timesteps | 391168   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 461         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 192         |
|    time_elapsed         | 109739      |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.009066404 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.17       |
|    explained_variance   | -0.000675   |
|    learning_rate        | 0.0003      |
|    loss                 | 531         |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.000908   |
|    std                  | 0.766       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 473        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 193        |
|    time_elapsed         | 109944     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.11597564 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.17      |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.392      |
|    n_updates            | 1920       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.766      |
|    value_loss           | 1.01       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 480        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 194        |
|    time_elapsed         | 110150     |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.20017481 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.15      |
|    explained_variance   | 0.438      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.322      |
|    n_updates            | 1930       |
|    policy_gradient_loss | 0.00938    |
|    std                  | 0.762      |
|    value_loss           | 1.13       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 480         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110356      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.055508576 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | 0.473       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.542       |
|    n_updates            | 1940        |
|    policy_gradient_loss | 0.00471     |
|    std                  | 0.762       |
|    value_loss           | 1.03        |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-93.67 +/- 2.21
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -93.7       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.060285233 |
|    clip_fraction        | 0.411       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.13       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.391       |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.0174      |
|    std                  | 0.762       |
|    value_loss           | 1           |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 480      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112362   |
|    total_timesteps | 401408   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 480        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 197        |
|    time_elapsed         | 112567     |
|    total_timesteps      | 403456     |
| train/                  |            |
|    approx_kl            | 0.10934426 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.13      |
|    explained_variance   | -0.00121   |
|    learning_rate        | 0.0003     |
|    loss                 | 15.3       |
|    n_updates            | 1960       |
|    policy_gradient_loss | 0.00868    |
|    std                  | 0.762      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 493      |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 198      |
|    time_elapsed         | 112773   |
|    total_timesteps      | 405504   |
| train/                  |          |
|    approx_kl            | 0.059422 |
|    clip_fraction        | 0.473    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.11    |
|    explained_variance   | -0.0948  |
|    learning_rate        | 0.0003   |
|    loss                 | 0.423    |
|    n_updates            | 1970     |
|    policy_gradient_loss | 0.0134   |
|    std                  | 0.758    |
|    value_loss           | 1.24     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 501         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 199         |
|    time_elapsed         | 112978      |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.054697275 |
|    clip_fraction        | 0.427       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.08       |
|    explained_variance   | 0.421       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.505       |
|    n_updates            | 1980        |
|    policy_gradient_loss | 0.0261      |
|    std                  | 0.757       |
|    value_loss           | 0.999       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 501        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 113183     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.11854097 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.07      |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.755      |
|    value_loss           | 0.894      |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-65.99 +/- 4.30
Episode length: 3597.00 +/- 6.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -66         |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.067132145 |
|    clip_fraction        | 0.443       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.05       |
|    explained_variance   | 0.472       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.512       |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.0194      |
|    std                  | 0.755       |
|    value_loss           | 0.967       |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 501      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115190   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 514        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 115396     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.04088061 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.04      |
|    explained_variance   | -0.00321   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.86e+03   |
|    n_updates            | 2010       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.754      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 514        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 203        |
|    time_elapsed         | 115601     |
|    total_timesteps      | 415744     |
| train/                  |            |
|    approx_kl            | 0.07829189 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.06      |
|    explained_variance   | 0.17       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 2020       |
|    policy_gradient_loss | 0.00397    |
|    std                  | 0.758      |
|    value_loss           | 1.05       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 522         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 204         |
|    time_elapsed         | 115807      |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.057362117 |
|    clip_fraction        | 0.409       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.475       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.457       |
|    n_updates            | 2030        |
|    policy_gradient_loss | 0.00862     |
|    std                  | 0.755       |
|    value_loss           | 1.05        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 522        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 116012     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.05816116 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.03      |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.469      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.751      |
|    value_loss           | 1.01       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-93.19 +/- 1.49
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -93.2      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.08157981 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.243      |
|    n_updates            | 2050       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.751      |
|    value_loss           | 0.994      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 522      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118018   |
|    total_timesteps | 421888   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 535        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 207        |
|    time_elapsed         | 118224     |
|    total_timesteps      | 423936     |
| train/                  |            |
|    approx_kl            | 0.08451764 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | 0.000487   |
|    learning_rate        | 0.0003     |
|    loss                 | 648        |
|    n_updates            | 2060       |
|    policy_gradient_loss | 0.00821    |
|    std                  | 0.751      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 535        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118430     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.15108058 |
|    clip_fraction        | 0.523      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.01      |
|    explained_variance   | -0.247     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 2070       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.749      |
|    value_loss           | 1.1        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 541        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 118635     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.06712849 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.98      |
|    explained_variance   | 0.446      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.396      |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.746      |
|    value_loss           | 0.947      |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-94.76 +/- 1.77
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -94.8      |
| time/                   |            |
|    total_timesteps      | 430000     |
| train/                  |            |
|    approx_kl            | 0.13113913 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.92      |
|    explained_variance   | 0.446      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.365      |
|    n_updates            | 2090       |
|    policy_gradient_loss | 0.00159    |
|    std                  | 0.739      |
|    value_loss           | 0.87       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 541      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120641   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 541         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 120846      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.030963767 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.89       |
|    explained_variance   | -0.00131    |
|    learning_rate        | 0.0003      |
|    loss                 | 239         |
|    n_updates            | 2100        |
|    policy_gradient_loss | 0.00631     |
|    std                  | 0.739       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 555       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 212       |
|    time_elapsed         | 121052    |
|    total_timesteps      | 434176    |
| train/                  |           |
|    approx_kl            | 0.8111205 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.89     |
|    explained_variance   | 0.0548    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.514     |
|    n_updates            | 2110      |
|    policy_gradient_loss | 0.00876   |
|    std                  | 0.74      |
|    value_loss           | 0.919     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 555       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 213       |
|    time_elapsed         | 121257    |
|    total_timesteps      | 436224    |
| train/                  |           |
|    approx_kl            | 0.0420809 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.88     |
|    explained_variance   | 0.478     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.408     |
|    n_updates            | 2120      |
|    policy_gradient_loss | 0.00645   |
|    std                  | 0.737     |
|    value_loss           | 0.933     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 562        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 214        |
|    time_elapsed         | 121463     |
|    total_timesteps      | 438272     |
| train/                  |            |
|    approx_kl            | 0.06908323 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.85      |
|    explained_variance   | 0.48       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.483      |
|    n_updates            | 2130       |
|    policy_gradient_loss | 0.00082    |
|    std                  | 0.737      |
|    value_loss           | 0.965      |
----------------------------------------
Eval num_timesteps=440000, episode_reward=-91.54 +/- 3.16
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -91.5      |
| time/                   |            |
|    total_timesteps      | 440000     |
| train/                  |            |
|    approx_kl            | 0.07606159 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.86      |
|    explained_variance   | 0.512      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.544      |
|    n_updates            | 2140       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.737      |
|    value_loss           | 0.942      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 563      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123469   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 563         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123674      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.022932254 |
|    clip_fraction        | 0.252       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.86       |
|    explained_variance   | 0.000351    |
|    learning_rate        | 0.0003      |
|    loss                 | 872         |
|    n_updates            | 2150        |
|    policy_gradient_loss | 0.00828     |
|    std                  | 0.737       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 575       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 217       |
|    time_elapsed         | 123880    |
|    total_timesteps      | 444416    |
| train/                  |           |
|    approx_kl            | 0.4168154 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.85     |
|    explained_variance   | 0.223     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.551     |
|    n_updates            | 2160      |
|    policy_gradient_loss | 0.0298    |
|    std                  | 0.735     |
|    value_loss           | 1.17      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 575        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 218        |
|    time_elapsed         | 124085     |
|    total_timesteps      | 446464     |
| train/                  |            |
|    approx_kl            | 0.08002241 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.85      |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.631      |
|    n_updates            | 2170       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.738      |
|    value_loss           | 0.961      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 582        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 219        |
|    time_elapsed         | 124291     |
|    total_timesteps      | 448512     |
| train/                  |            |
|    approx_kl            | 0.06908311 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.85      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 2180       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.735      |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=450000, episode_reward=-94.37 +/- 1.30
Episode length: 3599.60 +/- 2.33
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -94.4      |
| time/                   |            |
|    total_timesteps      | 450000     |
| train/                  |            |
|    approx_kl            | 0.07170586 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.467      |
|    n_updates            | 2190       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.736      |
|    value_loss           | 0.936      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 582      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126297   |
|    total_timesteps | 450560   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 582        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 221        |
|    time_elapsed         | 126502     |
|    total_timesteps      | 452608     |
| train/                  |            |
|    approx_kl            | 0.07271379 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.00474    |
|    learning_rate        | 0.0003     |
|    loss                 | 310        |
|    n_updates            | 2200       |
|    policy_gradient_loss | -0.00153   |
|    std                  | 0.736      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 594        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 126708     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.09951683 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.84      |
|    explained_variance   | 0.283      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.703      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.736      |
|    value_loss           | 1.11       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 594        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 223        |
|    time_elapsed         | 126913     |
|    total_timesteps      | 456704     |
| train/                  |            |
|    approx_kl            | 0.06356628 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.81      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.45       |
|    n_updates            | 2220       |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.732      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 601        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 224        |
|    time_elapsed         | 127118     |
|    total_timesteps      | 458752     |
| train/                  |            |
|    approx_kl            | 0.09064808 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.78      |
|    explained_variance   | 0.484      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 2230       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.73       |
|    value_loss           | 0.978      |
----------------------------------------
Eval num_timesteps=460000, episode_reward=-77.19 +/- 6.33
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -77.2       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.069082245 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.413       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.815       |
|    n_updates            | 2240        |
|    policy_gradient_loss | 0.0174      |
|    std                  | 0.727       |
|    value_loss           | 1.29        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 601      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129124   |
|    total_timesteps | 460800   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 601        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 226        |
|    time_elapsed         | 129330     |
|    total_timesteps      | 462848     |
| train/                  |            |
|    approx_kl            | 0.01913653 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.74      |
|    explained_variance   | 0.00165    |
|    learning_rate        | 0.0003     |
|    loss                 | 681        |
|    n_updates            | 2250       |
|    policy_gradient_loss | 0.00816    |
|    std                  | 0.728      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 613        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 129535     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.13993812 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.76      |
|    explained_variance   | 0.0432     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.281      |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.728      |
|    value_loss           | 0.955      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 613         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 228         |
|    time_elapsed         | 129741      |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.051730476 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.75       |
|    explained_variance   | 0.521       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.589       |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.013       |
|    std                  | 0.726       |
|    value_loss           | 1.07        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 619        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 229        |
|    time_elapsed         | 129946     |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.06902058 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.355      |
|    n_updates            | 2280       |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.724      |
|    value_loss           | 0.712      |
----------------------------------------
Eval num_timesteps=470000, episode_reward=-82.34 +/- 1.86
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -82.3       |
| time/                   |             |
|    total_timesteps      | 470000      |
| train/                  |             |
|    approx_kl            | 0.047113877 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.469       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.336       |
|    n_updates            | 2290        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.723       |
|    value_loss           | 1.15        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 619      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 131952   |
|    total_timesteps | 471040   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 619       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 231       |
|    time_elapsed         | 132158    |
|    total_timesteps      | 473088    |
| train/                  |           |
|    approx_kl            | 0.0279679 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.71     |
|    explained_variance   | -0.00273  |
|    learning_rate        | 0.0003    |
|    loss                 | 21        |
|    n_updates            | 2300      |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.723     |
|    value_loss           | 1.04e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 632        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 232        |
|    time_elapsed         | 132363     |
|    total_timesteps      | 475136     |
| train/                  |            |
|    approx_kl            | 0.08806415 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | -0.308     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.744      |
|    n_updates            | 2310       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.724      |
|    value_loss           | 1.34       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 632        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 132569     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.12248544 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.72      |
|    explained_variance   | 0.474      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.725      |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 638        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 132774     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.06786798 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.73      |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.584      |
|    n_updates            | 2330       |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.724      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-87.47 +/- 2.65
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -87.5       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.079158336 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.71       |
|    explained_variance   | 0.397       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.52        |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.0121      |
|    std                  | 0.722       |
|    value_loss           | 1.17        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 637      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134780   |
|    total_timesteps | 481280   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 637        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 236        |
|    time_elapsed         | 134986     |
|    total_timesteps      | 483328     |
| train/                  |            |
|    approx_kl            | 0.14097106 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.69      |
|    explained_variance   | -0.00361   |
|    learning_rate        | 0.0003     |
|    loss                 | 10.2       |
|    n_updates            | 2350       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.722      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 649         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 237         |
|    time_elapsed         | 135191      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.105682075 |
|    clip_fraction        | 0.497       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | -0.27       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.574       |
|    n_updates            | 2360        |
|    policy_gradient_loss | 0.00528     |
|    std                  | 0.716       |
|    value_loss           | 1.3         |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 655       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 238       |
|    time_elapsed         | 135396    |
|    total_timesteps      | 487424    |
| train/                  |           |
|    approx_kl            | 0.0695072 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.63     |
|    explained_variance   | 0.427     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.486     |
|    n_updates            | 2370      |
|    policy_gradient_loss | 0.0223    |
|    std                  | 0.716     |
|    value_loss           | 1.22      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 655        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135602     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.04831174 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.534      |
|    n_updates            | 2380       |
|    policy_gradient_loss | 0.00372    |
|    std                  | 0.716      |
|    value_loss           | 1.2        |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.10 +/- 1.20
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.1     |
| time/                   |           |
|    total_timesteps      | 490000    |
| train/                  |           |
|    approx_kl            | 0.0917708 |
|    clip_fraction        | 0.416     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.62     |
|    explained_variance   | 0.44      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.573     |
|    n_updates            | 2390      |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.715     |
|    value_loss           | 1.37      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 653      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137608   |
|    total_timesteps | 491520   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 653        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 241        |
|    time_elapsed         | 137813     |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.07464516 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.62      |
|    explained_variance   | -0.00162   |
|    learning_rate        | 0.0003     |
|    loss                 | 96.8       |
|    n_updates            | 2400       |
|    policy_gradient_loss | 0.00236    |
|    std                  | 0.715      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 664        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 242        |
|    time_elapsed         | 138019     |
|    total_timesteps      | 495616     |
| train/                  |            |
|    approx_kl            | 0.12161183 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.59      |
|    explained_variance   | -0.131     |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01       |
|    n_updates            | 2410       |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.713      |
|    value_loss           | 1.72       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 669         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 243         |
|    time_elapsed         | 138224      |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.084062345 |
|    clip_fraction        | 0.437       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.59       |
|    explained_variance   | 0.446       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.8         |
|    n_updates            | 2420        |
|    policy_gradient_loss | 0.0101      |
|    std                  | 0.712       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 669         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 138429      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.046002302 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | 0.36        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.984       |
|    n_updates            | 2430        |
|    policy_gradient_loss | 0.00922     |
|    std                  | 0.71        |
|    value_loss           | 1.44        |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.79 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.06592743 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.54      |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.744      |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.706      |
|    value_loss           | 1.56       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 666      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140435   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 678         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 140641      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.121901646 |
|    clip_fraction        | 0.32        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | 0.00446     |
|    learning_rate        | 0.0003      |
|    loss                 | 499         |
|    n_updates            | 2450        |
|    policy_gradient_loss | 0.017       |
|    std                  | 0.706       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 678        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 247        |
|    time_elapsed         | 140846     |
|    total_timesteps      | 505856     |
| train/                  |            |
|    approx_kl            | 0.10012005 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | -0.255     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.592      |
|    n_updates            | 2460       |
|    policy_gradient_loss | -0.00738   |
|    std                  | 0.707      |
|    value_loss           | 1.5        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 683        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 248        |
|    time_elapsed         | 141052     |
|    total_timesteps      | 507904     |
| train/                  |            |
|    approx_kl            | 0.10773374 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.549      |
|    n_updates            | 2470       |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.702      |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 683        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 249        |
|    time_elapsed         | 141257     |
|    total_timesteps      | 509952     |
| train/                  |            |
|    approx_kl            | 0.17733172 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.46      |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.01       |
|    n_updates            | 2480       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.701      |
|    value_loss           | 1.37       |
----------------------------------------
Eval num_timesteps=510000, episode_reward=-95.55 +/- 2.08
Episode length: 3595.80 +/- 7.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -95.5      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.08164084 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.45      |
|    explained_variance   | 0.502      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.7        |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 681      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143263   |
|    total_timesteps | 512000   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 692        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 251        |
|    time_elapsed         | 143469     |
|    total_timesteps      | 514048     |
| train/                  |            |
|    approx_kl            | 0.16528846 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.43      |
|    explained_variance   | -0.00108   |
|    learning_rate        | 0.0003     |
|    loss                 | 45.1       |
|    n_updates            | 2500       |
|    policy_gradient_loss | 0.0053     |
|    std                  | 0.7        |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 692         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 143674      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.051326312 |
|    clip_fraction        | 0.486       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.43       |
|    explained_variance   | -0.0369     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.719       |
|    n_updates            | 2510        |
|    policy_gradient_loss | 0.00737     |
|    std                  | 0.699       |
|    value_loss           | 1.52        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 697         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 143879      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.079587184 |
|    clip_fraction        | 0.467       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | 0.483       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.757       |
|    n_updates            | 2520        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.696       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=-92.08 +/- 2.54
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -92.1       |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.099880956 |
|    clip_fraction        | 0.433       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.37       |
|    explained_variance   | 0.389       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.532       |
|    n_updates            | 2530        |
|    policy_gradient_loss | 0.0165      |
|    std                  | 0.692       |
|    value_loss           | 1.37        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 694      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 145885   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 694         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146091      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.011033382 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.35       |
|    explained_variance   | 0.00304     |
|    learning_rate        | 0.0003      |
|    loss                 | 775         |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.0041     |
|    std                  | 0.691       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 706        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 256        |
|    time_elapsed         | 146296     |
|    total_timesteps      | 524288     |
| train/                  |            |
|    approx_kl            | 0.08079396 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.34      |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.673      |
|    n_updates            | 2550       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.691      |
|    value_loss           | 1.64       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 706        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 257        |
|    time_elapsed         | 146502     |
|    total_timesteps      | 526336     |
| train/                  |            |
|    approx_kl            | 0.06873654 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.31      |
|    explained_variance   | 0.465      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.935      |
|    n_updates            | 2560       |
|    policy_gradient_loss | 0.00918    |
|    std                  | 0.686      |
|    value_loss           | 1.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 711        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 146707     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.13167201 |
|    clip_fraction        | 0.56       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.24      |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.61       |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.0447     |
|    std                  | 0.68       |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-82.04 +/- 1.79
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -82        |
| time/                   |            |
|    total_timesteps      | 530000     |
| train/                  |            |
|    approx_kl            | 0.09310363 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.2       |
|    explained_variance   | 0.51       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.378      |
|    n_updates            | 2580       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.68       |
|    value_loss           | 0.991      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 709      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148713   |
|    total_timesteps | 530432   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 709         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 260         |
|    time_elapsed         | 148919      |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.010321677 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | -0.00116    |
|    learning_rate        | 0.0003      |
|    loss                 | 32.4        |
|    n_updates            | 2590        |
|    policy_gradient_loss | 0.0089      |
|    std                  | 0.68        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 721        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 261        |
|    time_elapsed         | 149124     |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.07914661 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.2       |
|    explained_variance   | -0.765     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.797      |
|    n_updates            | 2600       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.68       |
|    value_loss           | 1.28       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 721        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 262        |
|    time_elapsed         | 149330     |
|    total_timesteps      | 536576     |
| train/                  |            |
|    approx_kl            | 0.06738495 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.2       |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.818      |
|    n_updates            | 2610       |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.679      |
|    value_loss           | 1.27       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 726        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 263        |
|    time_elapsed         | 149537     |
|    total_timesteps      | 538624     |
| train/                  |            |
|    approx_kl            | 0.14341658 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.533      |
|    n_updates            | 2620       |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.678      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=540000, episode_reward=-87.80 +/- 4.16
Episode length: 3599.80 +/- 2.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -87.8       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.074533805 |
|    clip_fraction        | 0.429       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.17       |
|    explained_variance   | 0.585       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.00939     |
|    std                  | 0.676       |
|    value_loss           | 0.876       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 723      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151543   |
|    total_timesteps | 540672   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 723        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 265        |
|    time_elapsed         | 151748     |
|    total_timesteps      | 542720     |
| train/                  |            |
|    approx_kl            | 0.14615722 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.16      |
|    explained_variance   | 0.00301    |
|    learning_rate        | 0.0003     |
|    loss                 | 273        |
|    n_updates            | 2640       |
|    policy_gradient_loss | 0.00623    |
|    std                  | 0.676      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 735        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 151954     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.09779401 |
|    clip_fraction        | 0.53       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.15      |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.51       |
|    n_updates            | 2650       |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.674      |
|    value_loss           | 1.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 735        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 267        |
|    time_elapsed         | 152159     |
|    total_timesteps      | 546816     |
| train/                  |            |
|    approx_kl            | 0.09692216 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.13      |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.594      |
|    n_updates            | 2660       |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.673      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 740         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 268         |
|    time_elapsed         | 152365      |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.114723794 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.571       |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.0156      |
|    std                  | 0.668       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-81.48 +/- 4.61
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -81.5      |
| time/                   |            |
|    total_timesteps      | 550000     |
| train/                  |            |
|    approx_kl            | 0.12595816 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.07      |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.592      |
|    n_updates            | 2680       |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.668      |
|    value_loss           | 1.07       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 739      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154371   |
|    total_timesteps | 550912   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 739        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 270        |
|    time_elapsed         | 154576     |
|    total_timesteps      | 552960     |
| train/                  |            |
|    approx_kl            | 0.01775855 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.07      |
|    explained_variance   | 0.000584   |
|    learning_rate        | 0.0003     |
|    loss                 | 6.88       |
|    n_updates            | 2690       |
|    policy_gradient_loss | -0.00237   |
|    std                  | 0.668      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 751        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 154782     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.19450636 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.06      |
|    explained_variance   | 0.22       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.416      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.666      |
|    value_loss           | 0.933      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 751        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 154987     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.08709157 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.04      |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.482      |
|    n_updates            | 2710       |
|    policy_gradient_loss | 0.00468    |
|    std                  | 0.666      |
|    value_loss           | 1.1        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 757         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 273         |
|    time_elapsed         | 155192      |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.053272635 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.01       |
|    explained_variance   | 0.563       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.64        |
|    n_updates            | 2720        |
|    policy_gradient_loss | 0.00904     |
|    std                  | 0.66        |
|    value_loss           | 1.02        |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-39.99 +/- 5.48
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -40        |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.05681663 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.94      |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.662      |
|    n_updates            | 2730       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.655      |
|    value_loss           | 1.06       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 754      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157199   |
|    total_timesteps | 561152   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 754        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 275        |
|    time_elapsed         | 157404     |
|    total_timesteps      | 563200     |
| train/                  |            |
|    approx_kl            | 0.03838025 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.00749    |
|    learning_rate        | 0.0003     |
|    loss                 | 67.2       |
|    n_updates            | 2740       |
|    policy_gradient_loss | -0.00265   |
|    std                  | 0.656      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 767       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 276       |
|    time_elapsed         | 157610    |
|    total_timesteps      | 565248    |
| train/                  |           |
|    approx_kl            | 0.1416232 |
|    clip_fraction        | 0.499     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.93     |
|    explained_variance   | -0.251    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.966     |
|    n_updates            | 2750      |
|    policy_gradient_loss | 0.0276    |
|    std                  | 0.657     |
|    value_loss           | 1.31      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 772        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 277        |
|    time_elapsed         | 157815     |
|    total_timesteps      | 567296     |
| train/                  |            |
|    approx_kl            | 0.12844121 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.568      |
|    n_updates            | 2760       |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.655      |
|    value_loss           | 1.17       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 772        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 278        |
|    time_elapsed         | 158020     |
|    total_timesteps      | 569344     |
| train/                  |            |
|    approx_kl            | 0.10797922 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.88      |
|    explained_variance   | 0.517      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.567      |
|    n_updates            | 2770       |
|    policy_gradient_loss | 0.0099     |
|    std                  | 0.651      |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=570000, episode_reward=-69.08 +/- 1.90
Episode length: 3597.40 +/- 6.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -69.1      |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.22767423 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.84      |
|    explained_variance   | 0.49       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.583      |
|    n_updates            | 2780       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.649      |
|    value_loss           | 1.15       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 770      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160027   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 770         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160232      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.028874306 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.82       |
|    explained_variance   | -0.000443   |
|    learning_rate        | 0.0003      |
|    loss                 | 120         |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.00693     |
|    std                  | 0.649       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 782        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 160437     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.07624754 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.8       |
|    explained_variance   | -0.695     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.87       |
|    n_updates            | 2800       |
|    policy_gradient_loss | -8.83e-05  |
|    std                  | 0.644      |
|    value_loss           | 1.82       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 787        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 160643     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.10432709 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.77      |
|    explained_variance   | 0.25       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.78       |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.0309     |
|    std                  | 0.646      |
|    value_loss           | 1.52       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 787        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 283        |
|    time_elapsed         | 160848     |
|    total_timesteps      | 579584     |
| train/                  |            |
|    approx_kl            | 0.16190892 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.79      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.417      |
|    n_updates            | 2820       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.646      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=580000, episode_reward=-54.71 +/- 2.74
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -54.7      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.14469326 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.77      |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.62       |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.643      |
|    value_loss           | 1.27       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 784      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 162854   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 796         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163060      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.029648112 |
|    clip_fraction        | 0.29        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | 0.00442     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.2         |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.000164   |
|    std                  | 0.643       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 796        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 163266     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.08855079 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.616      |
|    n_updates            | 2850       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.643      |
|    value_loss           | 1.42       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 801        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163471     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.20564622 |
|    clip_fraction        | 0.534      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.73      |
|    explained_variance   | 0.534      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.496      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0425     |
|    std                  | 0.64       |
|    value_loss           | 1.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 801        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 288        |
|    time_elapsed         | 163677     |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.43225756 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.72      |
|    explained_variance   | 0.584      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.55       |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.641      |
|    value_loss           | 1.05       |
----------------------------------------
Eval num_timesteps=590000, episode_reward=-69.86 +/- 2.50
Episode length: 3596.80 +/- 8.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -69.9       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.112322986 |
|    clip_fraction        | 0.467       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.7        |
|    explained_variance   | 0.607       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.555       |
|    n_updates            | 2880        |
|    policy_gradient_loss | 0.0376      |
|    std                  | 0.638       |
|    value_loss           | 1.06        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 799      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165683   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 811         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 165888      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.028690808 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.68       |
|    explained_variance   | 0.00672     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05e+03    |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.00116     |
|    std                  | 0.638       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 811        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166093     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.13421148 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | 0.047      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.857      |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.00862    |
|    std                  | 0.635      |
|    value_loss           | 1.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 817        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 292        |
|    time_elapsed         | 166299     |
|    total_timesteps      | 598016     |
| train/                  |            |
|    approx_kl            | 0.11078356 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.544      |
|    n_updates            | 2910       |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.634      |
|    value_loss           | 1.01       |
----------------------------------------
Eval num_timesteps=600000, episode_reward=-85.57 +/- 1.38
Episode length: 3597.80 +/- 5.04
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -85.6      |
| time/                   |            |
|    total_timesteps      | 600000     |
| train/                  |            |
|    approx_kl            | 0.12619685 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 2920       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.633      |
|    value_loss           | 0.978      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 814      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168305   |
|    total_timesteps | 600064   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 814        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 294        |
|    time_elapsed         | 168510     |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.19258265 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.00563    |
|    learning_rate        | 0.0003     |
|    loss                 | 37.7       |
|    n_updates            | 2930       |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.633      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 825       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 295       |
|    time_elapsed         | 168716    |
|    total_timesteps      | 604160    |
| train/                  |           |
|    approx_kl            | 0.3620456 |
|    clip_fraction        | 0.559     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.62     |
|    explained_variance   | 0.251     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.532     |
|    n_updates            | 2940      |
|    policy_gradient_loss | 0.0378    |
|    std                  | 0.635     |
|    value_loss           | 0.979     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 825        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 296        |
|    time_elapsed         | 168921     |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.20252015 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.61      |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.657      |
|    n_updates            | 2950       |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.631      |
|    value_loss           | 1.29       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 830        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 169127     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.13168868 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.632      |
|    value_loss           | 0.915      |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-89.77 +/- 4.95
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -89.8       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.061340827 |
|    clip_fraction        | 0.384       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.6        |
|    explained_variance   | 0.268       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.567       |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.00562     |
|    std                  | 0.631       |
|    value_loss           | 0.893       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 827      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171133   |
|    total_timesteps | 610304   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 827        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 299        |
|    time_elapsed         | 171338     |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.10413046 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.59      |
|    explained_variance   | 0.000347   |
|    learning_rate        | 0.0003     |
|    loss                 | 145        |
|    n_updates            | 2980       |
|    policy_gradient_loss | -9.46e-05  |
|    std                  | 0.631      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 838        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 300        |
|    time_elapsed         | 171544     |
|    total_timesteps      | 614400     |
| train/                  |            |
|    approx_kl            | 0.13013446 |
|    clip_fraction        | 0.5        |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.57      |
|    explained_variance   | -0.000294  |
|    learning_rate        | 0.0003     |
|    loss                 | 0.289      |
|    n_updates            | 2990       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.628      |
|    value_loss           | 0.891      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 838        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 301        |
|    time_elapsed         | 171750     |
|    total_timesteps      | 616448     |
| train/                  |            |
|    approx_kl            | 0.24029984 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.617      |
|    n_updates            | 3000       |
|    policy_gradient_loss | 0.0292     |
|    std                  | 0.624      |
|    value_loss           | 1.07       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 843        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 302        |
|    time_elapsed         | 171956     |
|    total_timesteps      | 618496     |
| train/                  |            |
|    approx_kl            | 0.50082195 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.48      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.382      |
|    n_updates            | 3010       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.621      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=620000, episode_reward=-92.73 +/- 1.23
Episode length: 3599.80 +/- 1.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -92.7      |
| time/                   |            |
|    total_timesteps      | 620000     |
| train/                  |            |
|    approx_kl            | 0.22090714 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.46      |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.328      |
|    n_updates            | 3020       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.619      |
|    value_loss           | 0.85       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 840      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 173962   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 840        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 174167     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.06715393 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.00505    |
|    learning_rate        | 0.0003     |
|    loss                 | 7.52       |
|    n_updates            | 3030       |
|    policy_gradient_loss | -0.00158   |
|    std                  | 0.618      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 852        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 305        |
|    time_elapsed         | 174373     |
|    total_timesteps      | 624640     |
| train/                  |            |
|    approx_kl            | 0.20997825 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.42      |
|    explained_variance   | 0.249      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.593      |
|    n_updates            | 3040       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.616      |
|    value_loss           | 1.14       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 852        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 174578     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.08715494 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.39      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.689      |
|    n_updates            | 3050       |
|    policy_gradient_loss | 0.00561    |
|    std                  | 0.613      |
|    value_loss           | 0.931      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 857        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 307        |
|    time_elapsed         | 174783     |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.15478662 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.37      |
|    explained_variance   | 0.632      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.411      |
|    n_updates            | 3060       |
|    policy_gradient_loss | 0.0293     |
|    std                  | 0.612      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=630000, episode_reward=-87.44 +/- 3.55
Episode length: 3597.20 +/- 7.11
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -87.4      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.14499067 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.756      |
|    n_updates            | 3070       |
|    policy_gradient_loss | 0.00182    |
|    std                  | 0.61       |
|    value_loss           | 1.22       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 854      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 176789   |
|    total_timesteps | 630784   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 854        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 309        |
|    time_elapsed         | 176995     |
|    total_timesteps      | 632832     |
| train/                  |            |
|    approx_kl            | 0.09348926 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | 0.00542    |
|    learning_rate        | 0.0003     |
|    loss                 | 8.1        |
|    n_updates            | 3080       |
|    policy_gradient_loss | 0.00441    |
|    std                  | 0.61       |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 866        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 310        |
|    time_elapsed         | 177200     |
|    total_timesteps      | 634880     |
| train/                  |            |
|    approx_kl            | 0.30210885 |
|    clip_fraction        | 0.55       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.34      |
|    explained_variance   | 0.0715     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.598      |
|    n_updates            | 3090       |
|    policy_gradient_loss | 0.0257     |
|    std                  | 0.611      |
|    value_loss           | 1.12       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 866        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 311        |
|    time_elapsed         | 177406     |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.17673692 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.33      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.439      |
|    n_updates            | 3100       |
|    policy_gradient_loss | 0.0259     |
|    std                  | 0.61       |
|    value_loss           | 0.982      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 871         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 312         |
|    time_elapsed         | 177611      |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.060236838 |
|    clip_fraction        | 0.464       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.33       |
|    explained_variance   | 0.642       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.294       |
|    n_updates            | 3110        |
|    policy_gradient_loss | 0.0255      |
|    std                  | 0.61        |
|    value_loss           | 0.963       |
-----------------------------------------
Eval num_timesteps=640000, episode_reward=-90.80 +/- 2.43
Episode length: 3597.60 +/- 5.43
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -90.8       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.061805137 |
|    clip_fraction        | 0.449       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.32       |
|    explained_variance   | 0.591       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.407       |
|    n_updates            | 3120        |
|    policy_gradient_loss | 0.029       |
|    std                  | 0.608       |
|    value_loss           | 0.974       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 868      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179618   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 868         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 179825      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.012562386 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.31       |
|    explained_variance   | 0.00263     |
|    learning_rate        | 0.0003      |
|    loss                 | 115         |
|    n_updates            | 3130        |
|    policy_gradient_loss | 0.0017      |
|    std                  | 0.608       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 880       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 315       |
|    time_elapsed         | 180031    |
|    total_timesteps      | 645120    |
| train/                  |           |
|    approx_kl            | 1.2452621 |
|    clip_fraction        | 0.609     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.31     |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.614     |
|    n_updates            | 3140      |
|    policy_gradient_loss | 0.0827    |
|    std                  | 0.608     |
|    value_loss           | 1.08      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 883        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 316        |
|    time_elapsed         | 180236     |
|    total_timesteps      | 647168     |
| train/                  |            |
|    approx_kl            | 0.25178438 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.679      |
|    n_updates            | 3150       |
|    policy_gradient_loss | 0.0242     |
|    std                  | 0.607      |
|    value_loss           | 1.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 883        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 317        |
|    time_elapsed         | 180442     |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.20621566 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.817      |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.608      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=650000, episode_reward=-56.11 +/- 7.19
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -56.1      |
| time/                   |            |
|    total_timesteps      | 650000     |
| train/                  |            |
|    approx_kl            | 0.14044504 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.545      |
|    n_updates            | 3170       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.607      |
|    value_loss           | 1.18       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 879      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182448   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 879         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182653      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.035133194 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.28       |
|    explained_variance   | -0.00307    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.08e+03    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.00141    |
|    std                  | 0.607       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 889        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 320        |
|    time_elapsed         | 182859     |
|    total_timesteps      | 655360     |
| train/                  |            |
|    approx_kl            | 0.16232489 |
|    clip_fraction        | 0.57       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.353      |
|    n_updates            | 3190       |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.609      |
|    value_loss           | 0.86       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 893       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 321       |
|    time_elapsed         | 183064    |
|    total_timesteps      | 657408    |
| train/                  |           |
|    approx_kl            | 0.5172172 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.3      |
|    explained_variance   | 0.425     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.413     |
|    n_updates            | 3200      |
|    policy_gradient_loss | 0.0198    |
|    std                  | 0.608     |
|    value_loss           | 1.06      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 893        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183270     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.08760506 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.29      |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.481      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0398     |
|    std                  | 0.606      |
|    value_loss           | 0.835      |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-70.54 +/- 5.93
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -70.5      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.19611062 |
|    clip_fraction        | 0.516      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.26      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.543      |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.0395     |
|    std                  | 0.604      |
|    value_loss           | 0.787      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 890      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185276   |
|    total_timesteps | 661504   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 890         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 324         |
|    time_elapsed         | 185481      |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.021852642 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.25       |
|    explained_variance   | 0.000699    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74e+03    |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.00289    |
|    std                  | 0.604       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 900        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 185687     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.25178868 |
|    clip_fraction        | 0.531      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | -0.479     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.337      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.00819    |
|    std                  | 0.6        |
|    value_loss           | 1.06       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 904        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 326        |
|    time_elapsed         | 185892     |
|    total_timesteps      | 667648     |
| train/                  |            |
|    approx_kl            | 0.14150181 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.457      |
|    n_updates            | 3250       |
|    policy_gradient_loss | 0.0373     |
|    std                  | 0.598      |
|    value_loss           | 0.895      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 904        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 327        |
|    time_elapsed         | 186097     |
|    total_timesteps      | 669696     |
| train/                  |            |
|    approx_kl            | 0.16709277 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.39       |
|    n_updates            | 3260       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.597      |
|    value_loss           | 0.864      |
----------------------------------------
Eval num_timesteps=670000, episode_reward=-91.83 +/- 1.67
Episode length: 3595.00 +/- 8.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -91.8      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.13743487 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.443      |
|    n_updates            | 3270       |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.6        |
|    value_loss           | 1.07       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 899      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 188105   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 910         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 188311      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.020158738 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | 0.00332     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.13e+03    |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.00194    |
|    std                  | 0.601       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 910        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 330        |
|    time_elapsed         | 188516     |
|    total_timesteps      | 675840     |
| train/                  |            |
|    approx_kl            | 0.28411937 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | -0.0226    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.512      |
|    n_updates            | 3290       |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.597      |
|    value_loss           | 1.09       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 914        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 331        |
|    time_elapsed         | 188722     |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.12578222 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.14      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.371      |
|    n_updates            | 3300       |
|    policy_gradient_loss | 0.0365     |
|    std                  | 0.595      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 914         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 332         |
|    time_elapsed         | 188927      |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.075683616 |
|    clip_fraction        | 0.432       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.12       |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 3310        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.595       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=680000, episode_reward=-93.70 +/- 0.61
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -93.7       |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.048017323 |
|    clip_fraction        | 0.418       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.11       |
|    explained_variance   | 0.504       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.776       |
|    n_updates            | 3320        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.593       |
|    value_loss           | 1.45        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 910      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 190933   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 921        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 191139     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.11251615 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | -0.00337   |
|    learning_rate        | 0.0003     |
|    loss                 | 285        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.00368    |
|    std                  | 0.593      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 921        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 191344     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.43333113 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.09      |
|    explained_variance   | 0.329      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.641      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.592      |
|    value_loss           | 1.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 924        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 336        |
|    time_elapsed         | 191549     |
|    total_timesteps      | 688128     |
| train/                  |            |
|    approx_kl            | 0.05713653 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.593      |
|    n_updates            | 3350       |
|    policy_gradient_loss | 0.00408    |
|    std                  | 0.591      |
|    value_loss           | 1.52       |
----------------------------------------
Eval num_timesteps=690000, episode_reward=-74.23 +/- 5.08
Episode length: 3596.00 +/- 10.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -74.2     |
| time/                   |           |
|    total_timesteps      | 690000    |
| train/                  |           |
|    approx_kl            | 0.3301546 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.05     |
|    explained_variance   | 0.628     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.569     |
|    n_updates            | 3360      |
|    policy_gradient_loss | 0.0197    |
|    std                  | 0.59      |
|    value_loss           | 1.25      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 920      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 193555   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 920         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 193761      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.023704022 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.05       |
|    explained_variance   | 0.00128     |
|    learning_rate        | 0.0003      |
|    loss                 | 392         |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.0053     |
|    std                  | 0.59        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 931       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 339       |
|    time_elapsed         | 193966    |
|    total_timesteps      | 694272    |
| train/                  |           |
|    approx_kl            | 0.2742027 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.05     |
|    explained_variance   | -0.603    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.788     |
|    n_updates            | 3380      |
|    policy_gradient_loss | 0.00695   |
|    std                  | 0.591     |
|    value_loss           | 1.78      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 931        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 340        |
|    time_elapsed         | 194172     |
|    total_timesteps      | 696320     |
| train/                  |            |
|    approx_kl            | 0.15915415 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.61       |
|    n_updates            | 3390       |
|    policy_gradient_loss | 0.0408     |
|    std                  | 0.591      |
|    value_loss           | 1.32       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 934        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 341        |
|    time_elapsed         | 194377     |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.17988025 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.06      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.571      |
|    n_updates            | 3400       |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.591      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=700000, episode_reward=-61.03 +/- 4.54
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -61        |
| time/                   |            |
|    total_timesteps      | 700000     |
| train/                  |            |
|    approx_kl            | 0.31770045 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.05      |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.639      |
|    n_updates            | 3410       |
|    policy_gradient_loss | 0.0435     |
|    std                  | 0.59       |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 930      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 196385   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 930         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 196590      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.050722845 |
|    clip_fraction        | 0.428       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.04       |
|    explained_variance   | 0.00269     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.11e+03    |
|    n_updates            | 3420        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.59        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 941        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 196796     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.19903727 |
|    clip_fraction        | 0.536      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.03      |
|    explained_variance   | -1.03      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.842      |
|    n_updates            | 3430       |
|    policy_gradient_loss | 0.033      |
|    std                  | 0.588      |
|    value_loss           | 1.58       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 941        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 197001     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.11935642 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.02      |
|    explained_variance   | 0.544      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.57       |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.587      |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 944         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 346         |
|    time_elapsed         | 197207      |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.066953704 |
|    clip_fraction        | 0.483       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7          |
|    explained_variance   | 0.595       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.356       |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.0276      |
|    std                  | 0.586       |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=710000, episode_reward=-66.40 +/- 3.93
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -66.4      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.15293783 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.715      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.584      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 939      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 199213   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 939        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 199418     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.03139354 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.000269   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.47e+03   |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.00373   |
|    std                  | 0.584      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 949        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 349        |
|    time_elapsed         | 199625     |
|    total_timesteps      | 714752     |
| train/                  |            |
|    approx_kl            | 0.31533122 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.97      |
|    explained_variance   | 0.0361     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.586      |
|    n_updates            | 3480       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.585      |
|    value_loss           | 1.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 949         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 350         |
|    time_elapsed         | 199831      |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.102767885 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | 0.482       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.591       |
|    n_updates            | 3490        |
|    policy_gradient_loss | 0.0184      |
|    std                  | 0.583       |
|    value_loss           | 1.56        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 952       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 351       |
|    time_elapsed         | 200036    |
|    total_timesteps      | 718848    |
| train/                  |           |
|    approx_kl            | 0.1598774 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.94     |
|    explained_variance   | 0.545     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.667     |
|    n_updates            | 3500      |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.582     |
|    value_loss           | 1.39      |
---------------------------------------
Eval num_timesteps=720000, episode_reward=-53.10 +/- 6.37
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -53.1      |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.07977225 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.94      |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.751      |
|    n_updates            | 3510       |
|    policy_gradient_loss | 0.0091     |
|    std                  | 0.584      |
|    value_loss           | 1.23       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 948      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 202042   |
|    total_timesteps | 720896   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 948        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 353        |
|    time_elapsed         | 202248     |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.19171411 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.96      |
|    explained_variance   | 0.00286    |
|    learning_rate        | 0.0003     |
|    loss                 | 256        |
|    n_updates            | 3520       |
|    policy_gradient_loss | 0.000126   |
|    std                  | 0.584      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 960       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 354       |
|    time_elapsed         | 202453    |
|    total_timesteps      | 724992    |
| train/                  |           |
|    approx_kl            | 0.2063929 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.95     |
|    explained_variance   | 0.0698    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.409     |
|    n_updates            | 3530      |
|    policy_gradient_loss | 0.028     |
|    std                  | 0.582     |
|    value_loss           | 1.25      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 960         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 355         |
|    time_elapsed         | 202659      |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.061664466 |
|    clip_fraction        | 0.436       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.93       |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.507       |
|    n_updates            | 3540        |
|    policy_gradient_loss | 0.00888     |
|    std                  | 0.582       |
|    value_loss           | 1.05        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 964        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 202864     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.05757928 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.92      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.48       |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.00379    |
|    std                  | 0.581      |
|    value_loss           | 1.05       |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-37.86 +/- 7.37
Episode length: 3596.60 +/- 8.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -37.9       |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.113295294 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.9        |
|    explained_variance   | 0.565       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.866       |
|    n_updates            | 3560        |
|    policy_gradient_loss | 0.0184      |
|    std                  | 0.579       |
|    value_loss           | 1.47        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 959      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 204871   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 959         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 205077      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.017491665 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.89       |
|    explained_variance   | 0.000906    |
|    learning_rate        | 0.0003      |
|    loss                 | 105         |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.000806   |
|    std                  | 0.579       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 970       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 359       |
|    time_elapsed         | 205282    |
|    total_timesteps      | 735232    |
| train/                  |           |
|    approx_kl            | 0.0507098 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.86     |
|    explained_variance   | 0.195     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.585     |
|    n_updates            | 3580      |
|    policy_gradient_loss | 0.0204    |
|    std                  | 0.576     |
|    value_loss           | 1.44      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 974        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 205488     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.14772189 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.82      |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.5        |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.167      |
|    std                  | 0.574      |
|    value_loss           | 1.05       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 974        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 205693     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.23485279 |
|    clip_fraction        | 0.516      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.83      |
|    explained_variance   | 0.637      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.605      |
|    n_updates            | 3600       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.575      |
|    value_loss           | 1.15       |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-71.19 +/- 9.46
Episode length: 3600.20 +/- 1.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -71.2     |
| time/                   |           |
|    total_timesteps      | 740000    |
| train/                  |           |
|    approx_kl            | 0.0467704 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.81     |
|    explained_variance   | 0.596     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.69      |
|    n_updates            | 3610      |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.573     |
|    value_loss           | 1.14      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 969      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 207699   |
|    total_timesteps | 741376   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 969        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 363        |
|    time_elapsed         | 207905     |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.06767546 |
|    clip_fraction        | 0.154      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.79      |
|    explained_variance   | -0.00255   |
|    learning_rate        | 0.0003     |
|    loss                 | 7.05       |
|    n_updates            | 3620       |
|    policy_gradient_loss | -0.000651  |
|    std                  | 0.573      |
|    value_loss           | 1.03e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 980        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 364        |
|    time_elapsed         | 208110     |
|    total_timesteps      | 745472     |
| train/                  |            |
|    approx_kl            | 0.25155044 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | -0.049     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.591      |
|    n_updates            | 3630       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.569      |
|    value_loss           | 1.41       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 983        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 208315     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.05294568 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.73      |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.62       |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.568      |
|    value_loss           | 1.37       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 983        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 366        |
|    time_elapsed         | 208521     |
|    total_timesteps      | 749568     |
| train/                  |            |
|    approx_kl            | 0.12610091 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.749      |
|    n_updates            | 3650       |
|    policy_gradient_loss | 0.00874    |
|    std                  | 0.567      |
|    value_loss           | 1.5        |
----------------------------------------
Eval num_timesteps=750000, episode_reward=-65.44 +/- 7.40
Episode length: 3595.80 +/- 9.91
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -65.4       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.058484867 |
|    clip_fraction        | 0.389       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | 0.639       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.0162      |
|    std                  | 0.569       |
|    value_loss           | 1.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 978      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 210527   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 988         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 368         |
|    time_elapsed         | 210732      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.020765431 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.73       |
|    explained_variance   | 0.000399    |
|    learning_rate        | 0.0003      |
|    loss                 | 635         |
|    n_updates            | 3670        |
|    policy_gradient_loss | 0.00733     |
|    std                  | 0.57        |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 988       |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 369       |
|    time_elapsed         | 210938    |
|    total_timesteps      | 755712    |
| train/                  |           |
|    approx_kl            | 0.2989081 |
|    clip_fraction        | 0.529     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.74     |
|    explained_variance   | 0.051     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.758     |
|    n_updates            | 3680      |
|    policy_gradient_loss | 0.0162    |
|    std                  | 0.57      |
|    value_loss           | 1.52      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 992         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 370         |
|    time_elapsed         | 211143      |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.052898474 |
|    clip_fraction        | 0.463       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.7        |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.575       |
|    n_updates            | 3690        |
|    policy_gradient_loss | 0.0155      |
|    std                  | 0.566       |
|    value_loss           | 1.09        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 992        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 371        |
|    time_elapsed         | 211349     |
|    total_timesteps      | 759808     |
| train/                  |            |
|    approx_kl            | 0.09899083 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.67      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.826      |
|    n_updates            | 3700       |
|    policy_gradient_loss | 0.00805    |
|    std                  | 0.565      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=760000, episode_reward=-39.87 +/- 3.36
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -39.9      |
| time/                   |            |
|    total_timesteps      | 760000     |
| train/                  |            |
|    approx_kl            | 0.18603852 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.64      |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.695      |
|    n_updates            | 3710       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.563      |
|    value_loss           | 1.21       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 987      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 213357   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 997         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 213562      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.023017649 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.63       |
|    explained_variance   | 0.00566     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.55e+03    |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.562       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 997        |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 374        |
|    time_elapsed         | 213768     |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.14594747 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.6       |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.659      |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.00229    |
|    std                  | 0.559      |
|    value_loss           | 1.82       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1e+03     |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 375       |
|    time_elapsed         | 213974    |
|    total_timesteps      | 768000    |
| train/                  |           |
|    approx_kl            | 0.1303865 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.56     |
|    explained_variance   | 0.599     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.591     |
|    n_updates            | 3740      |
|    policy_gradient_loss | 0.0242    |
|    std                  | 0.558     |
|    value_loss           | 1.21      |
---------------------------------------
Eval num_timesteps=770000, episode_reward=-66.56 +/- 3.67
Episode length: 3600.60 +/- 0.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -66.6      |
| time/                   |            |
|    total_timesteps      | 770000     |
| train/                  |            |
|    approx_kl            | 0.08040549 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.53      |
|    explained_variance   | 0.468      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.701      |
|    n_updates            | 3750       |
|    policy_gradient_loss | 0.00499    |
|    std                  | 0.556      |
|    value_loss           | 1.26       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 995      |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 215980   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 995         |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 216185      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.098196335 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.51       |
|    explained_variance   | -0.00392    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.8        |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00325     |
|    std                  | 0.556       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.01e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 378       |
|    time_elapsed         | 216391    |
|    total_timesteps      | 774144    |
| train/                  |           |
|    approx_kl            | 0.4280629 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.5      |
|    explained_variance   | 0.167     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.421     |
|    n_updates            | 3770      |
|    policy_gradient_loss | 0.0162    |
|    std                  | 0.554     |
|    value_loss           | 1.4       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 216598     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.09946221 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.45      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.42       |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.0254     |
|    std                  | 0.551      |
|    value_loss           | 1.1        |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 380         |
|    time_elapsed         | 216803      |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.111297466 |
|    clip_fraction        | 0.399       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.41       |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 3790        |
|    policy_gradient_loss | 0.00946     |
|    std                  | 0.548       |
|    value_loss           | 1.27        |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.62 +/- 0.03
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.089650236 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.35       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.675       |
|    n_updates            | 3800        |
|    policy_gradient_loss | 0.00705     |
|    std                  | 0.545       |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1e+03    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 218809   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1e+03       |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 219015      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.013490507 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.33       |
|    explained_variance   | 0.00209     |
|    learning_rate        | 0.0003      |
|    loss                 | 40.2        |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.0005     |
|    std                  | 0.545       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 383        |
|    time_elapsed         | 219221     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.13289121 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.29      |
|    explained_variance   | 0.318      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.571      |
|    n_updates            | 3820       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.541      |
|    value_loss           | 1.25       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 384        |
|    time_elapsed         | 219426     |
|    total_timesteps      | 786432     |
| train/                  |            |
|    approx_kl            | 0.12796262 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.25      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.636      |
|    n_updates            | 3830       |
|    policy_gradient_loss | 0.00874    |
|    std                  | 0.538      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 385       |
|    time_elapsed         | 219631    |
|    total_timesteps      | 788480    |
| train/                  |           |
|    approx_kl            | 0.1419718 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.21     |
|    explained_variance   | 0.622     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.676     |
|    n_updates            | 3840      |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.537     |
|    value_loss           | 1.18      |
---------------------------------------
Eval num_timesteps=790000, episode_reward=-93.15 +/- 3.14
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -93.2      |
| time/                   |            |
|    total_timesteps      | 790000     |
| train/                  |            |
|    approx_kl            | 0.24575527 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.19      |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.7        |
|    n_updates            | 3850       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.536      |
|    value_loss           | 1.25       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 221637   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 221843      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.028620923 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.18       |
|    explained_variance   | -0.00216    |
|    learning_rate        | 0.0003      |
|    loss                 | 122         |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.00411    |
|    std                  | 0.536       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 222049     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.18405025 |
|    clip_fraction        | 0.516      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.17      |
|    explained_variance   | 0.33       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.652      |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0294     |
|    std                  | 0.535      |
|    value_loss           | 1.23       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.02e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 389       |
|    time_elapsed         | 222254    |
|    total_timesteps      | 796672    |
| train/                  |           |
|    approx_kl            | 0.1909437 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.14     |
|    explained_variance   | 0.463     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.546     |
|    n_updates            | 3880      |
|    policy_gradient_loss | 0.00794   |
|    std                  | 0.532     |
|    value_loss           | 1.34      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 222460     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.23148824 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.12      |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.813      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.532      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.84 +/- 0.15
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.053202122 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.09       |
|    explained_variance   | 0.522       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.08        |
|    n_updates            | 3900        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.53        |
|    value_loss           | 1.71        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 224468   |
|    total_timesteps | 800768   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 392         |
|    time_elapsed         | 224675      |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.012918622 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.08       |
|    explained_variance   | 0.00353     |
|    learning_rate        | 0.0003      |
|    loss                 | 2.78        |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.000368   |
|    std                  | 0.53        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 224881     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.21593931 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.07      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.733      |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.53       |
|    value_loss           | 1.27       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.03e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 394       |
|    time_elapsed         | 225086    |
|    total_timesteps      | 806912    |
| train/                  |           |
|    approx_kl            | 0.0886457 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.07     |
|    explained_variance   | 0.687     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.579     |
|    n_updates            | 3930      |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.53      |
|    value_loss           | 1.12      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 225292     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.27570117 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.05      |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.625      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.527      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.00 +/- 1.17
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99        |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.21342787 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.753      |
|    n_updates            | 3950       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.527      |
|    value_loss           | 1.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 227298   |
|    total_timesteps | 811008   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 397        |
|    time_elapsed         | 227503     |
|    total_timesteps      | 813056     |
| train/                  |            |
|    approx_kl            | 0.06456408 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.02      |
|    explained_variance   | 0.00274    |
|    learning_rate        | 0.0003     |
|    loss                 | 2.8e+03    |
|    n_updates            | 3960       |
|    policy_gradient_loss | 0.000772   |
|    std                  | 0.527      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 398       |
|    time_elapsed         | 227709    |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 0.4443475 |
|    clip_fraction        | 0.541     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.02     |
|    explained_variance   | 0.24      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.685     |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.0298    |
|    std                  | 0.526     |
|    value_loss           | 1.36      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.04e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 399       |
|    time_elapsed         | 227914    |
|    total_timesteps      | 817152    |
| train/                  |           |
|    approx_kl            | 0.4530528 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6        |
|    explained_variance   | 0.638     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.539     |
|    n_updates            | 3980      |
|    policy_gradient_loss | 0.0195    |
|    std                  | 0.525     |
|    value_loss           | 1.17      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.05e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 400       |
|    time_elapsed         | 228119    |
|    total_timesteps      | 819200    |
| train/                  |           |
|    approx_kl            | 0.1461645 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.99     |
|    explained_variance   | 0.704     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.708     |
|    n_updates            | 3990      |
|    policy_gradient_loss | 0.0207    |
|    std                  | 0.524     |
|    value_loss           | 0.973     |
---------------------------------------
Eval num_timesteps=820000, episode_reward=-84.03 +/- 5.29
Episode length: 3597.20 +/- 6.21
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -84        |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.63250655 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.95      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.65       |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.00354    |
|    std                  | 0.521      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 230125   |
|    total_timesteps | 821248   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 402        |
|    time_elapsed         | 230331     |
|    total_timesteps      | 823296     |
| train/                  |            |
|    approx_kl            | 0.60180175 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.93      |
|    explained_variance   | -0.00364   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.46e+03   |
|    n_updates            | 4010       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.521      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.05e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 403       |
|    time_elapsed         | 230536    |
|    total_timesteps      | 825344    |
| train/                  |           |
|    approx_kl            | 0.2022587 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.93     |
|    explained_variance   | -0.147    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.592     |
|    n_updates            | 4020      |
|    policy_gradient_loss | 0.0256    |
|    std                  | 0.521     |
|    value_loss           | 1.43      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 404        |
|    time_elapsed         | 230742     |
|    total_timesteps      | 827392     |
| train/                  |            |
|    approx_kl            | 0.15874907 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.91      |
|    explained_variance   | 0.544      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.732      |
|    n_updates            | 4030       |
|    policy_gradient_loss | 0.0331     |
|    std                  | 0.519      |
|    value_loss           | 1.34       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 405        |
|    time_elapsed         | 230947     |
|    total_timesteps      | 829440     |
| train/                  |            |
|    approx_kl            | 0.60701835 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.87      |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.667      |
|    n_updates            | 4040       |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.516      |
|    value_loss           | 1.24       |
----------------------------------------
Eval num_timesteps=830000, episode_reward=-68.86 +/- 1.21
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -68.9      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.13579465 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.84      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.00459    |
|    std                  | 0.514      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 232955   |
|    total_timesteps | 831488   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 407         |
|    time_elapsed         | 233161      |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.024038833 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.81       |
|    explained_variance   | -0.00118    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.13e+03    |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.00304    |
|    std                  | 0.514       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.06e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 408       |
|    time_elapsed         | 233366    |
|    total_timesteps      | 835584    |
| train/                  |           |
|    approx_kl            | 1.6429179 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.81     |
|    explained_variance   | 0.336     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.82      |
|    n_updates            | 4070      |
|    policy_gradient_loss | 0.0025    |
|    std                  | 0.514     |
|    value_loss           | 1.5       |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 233572     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.32074863 |
|    clip_fraction        | 0.537      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.78      |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.368      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.0516     |
|    std                  | 0.512      |
|    value_loss           | 0.951      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.07e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 410       |
|    time_elapsed         | 233777    |
|    total_timesteps      | 839680    |
| train/                  |           |
|    approx_kl            | 0.2777614 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.73     |
|    explained_variance   | 0.597     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.413     |
|    n_updates            | 4090      |
|    policy_gradient_loss | 0.0355    |
|    std                  | 0.509     |
|    value_loss           | 1.06      |
---------------------------------------
Eval num_timesteps=840000, episode_reward=-99.82 +/- 0.12
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.66533506 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.69      |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.471      |
|    n_updates            | 4100       |
|    policy_gradient_loss | 0.0431     |
|    std                  | 0.507      |
|    value_loss           | 0.959      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 235783   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 235989      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.017780215 |
|    clip_fraction        | 0.277       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.69       |
|    explained_variance   | 0.00266     |
|    learning_rate        | 0.0003      |
|    loss                 | 136         |
|    n_updates            | 4110        |
|    policy_gradient_loss | 0.0017      |
|    std                  | 0.507       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.08e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 413       |
|    time_elapsed         | 236194    |
|    total_timesteps      | 845824    |
| train/                  |           |
|    approx_kl            | 1.3504792 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.69     |
|    explained_variance   | 0.139     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.692     |
|    n_updates            | 4120      |
|    policy_gradient_loss | 0.0301    |
|    std                  | 0.507     |
|    value_loss           | 1.33      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.08e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 414       |
|    time_elapsed         | 236399    |
|    total_timesteps      | 847872    |
| train/                  |           |
|    approx_kl            | 0.6273906 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.69     |
|    explained_variance   | 0.656     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.601     |
|    n_updates            | 4130      |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.508     |
|    value_loss           | 0.907     |
---------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.08e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 415      |
|    time_elapsed         | 236605   |
|    total_timesteps      | 849920   |
| train/                  |          |
|    approx_kl            | 1.256047 |
|    clip_fraction        | 0.416    |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.67    |
|    explained_variance   | 0.476    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.63     |
|    n_updates            | 4140     |
|    policy_gradient_loss | 0.027    |
|    std                  | 0.506    |
|    value_loss           | 0.975    |
--------------------------------------
Eval num_timesteps=850000, episode_reward=-99.79 +/- 0.05
Episode length: 3597.40 +/- 7.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.18243255 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.63      |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.451      |
|    n_updates            | 4150       |
|    policy_gradient_loss | 0.0383     |
|    std                  | 0.504      |
|    value_loss           | 0.698      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 238611   |
|    total_timesteps | 851968   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 417         |
|    time_elapsed         | 238816      |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.050747253 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.61       |
|    explained_variance   | -0.000353   |
|    learning_rate        | 0.0003      |
|    loss                 | 5.15        |
|    n_updates            | 4160        |
|    policy_gradient_loss | 0.00427     |
|    std                  | 0.504       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.09e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 418       |
|    time_elapsed         | 239022    |
|    total_timesteps      | 856064    |
| train/                  |           |
|    approx_kl            | 2.0080965 |
|    clip_fraction        | 0.571     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.58     |
|    explained_variance   | 0.431     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.63      |
|    n_updates            | 4170      |
|    policy_gradient_loss | 0.116     |
|    std                  | 0.501     |
|    value_loss           | 0.974     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 239227     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.37975672 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.53      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.538      |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0335     |
|    std                  | 0.499      |
|    value_loss           | 0.959      |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.81 +/- 0.06
Episode length: 3601.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.8    |
| time/                   |          |
|    total_timesteps      | 860000   |
| train/                  |          |
|    approx_kl            | 1.882637 |
|    clip_fraction        | 0.44     |
|    clip_range           | 0.2      |
|    entropy_loss         | -5.49    |
|    explained_variance   | 0.572    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.433    |
|    n_updates            | 4190     |
|    policy_gradient_loss | 0.0376   |
|    std                  | 0.495    |
|    value_loss           | 1.12     |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 241236   |
|    total_timesteps | 860160   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 421        |
|    time_elapsed         | 241442     |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.12270935 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.46      |
|    explained_variance   | -0.00138   |
|    learning_rate        | 0.0003     |
|    loss                 | 13.3       |
|    n_updates            | 4200       |
|    policy_gradient_loss | 0.00201    |
|    std                  | 0.495      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 241647     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.16866839 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.42      |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.542      |
|    n_updates            | 4210       |
|    policy_gradient_loss | 0.0527     |
|    std                  | 0.493      |
|    value_loss           | 0.934      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 241853     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.20577773 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.38      |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.409      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.49       |
|    value_loss           | 1.09       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.11e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 424       |
|    time_elapsed         | 242058    |
|    total_timesteps      | 868352    |
| train/                  |           |
|    approx_kl            | 1.5629014 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.35     |
|    explained_variance   | 0.605     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.625     |
|    n_updates            | 4230      |
|    policy_gradient_loss | 0.0297    |
|    std                  | 0.489     |
|    value_loss           | 0.948     |
---------------------------------------
Eval num_timesteps=870000, episode_reward=-99.86 +/- 0.10
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 870000    |
| train/                  |           |
|    approx_kl            | 1.4285134 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.33     |
|    explained_variance   | 0.561     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.597     |
|    n_updates            | 4240      |
|    policy_gradient_loss | 0.0195    |
|    std                  | 0.488     |
|    value_loss           | 1.23      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 244064   |
|    total_timesteps | 870400   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 426        |
|    time_elapsed         | 244270     |
|    total_timesteps      | 872448     |
| train/                  |            |
|    approx_kl            | 0.01853541 |
|    clip_fraction        | 0.181      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.31      |
|    explained_variance   | -0.00147   |
|    learning_rate        | 0.0003     |
|    loss                 | 216        |
|    n_updates            | 4250       |
|    policy_gradient_loss | -0.00528   |
|    std                  | 0.488      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 244475     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.16705367 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.31      |
|    explained_variance   | 0.266      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.34       |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.488      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 244680     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.19807343 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.28      |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.757      |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0351     |
|    std                  | 0.485      |
|    value_loss           | 1.04       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 244886     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.06173297 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.24      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.587      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0285     |
|    std                  | 0.483      |
|    value_loss           | 0.976      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.85 +/- 0.10
Episode length: 3596.60 +/- 8.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.9     |
| time/                   |           |
|    total_timesteps      | 880000    |
| train/                  |           |
|    approx_kl            | 0.3206252 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.2      |
|    explained_variance   | 0.494     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.367     |
|    n_updates            | 4290      |
|    policy_gradient_loss | 0.0232    |
|    std                  | 0.48      |
|    value_loss           | 0.94      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 246892   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 247097     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.31812686 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.17      |
|    explained_variance   | -0.00148   |
|    learning_rate        | 0.0003     |
|    loss                 | 171        |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.479      |
|    value_loss           | 1.04e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.12e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 432       |
|    time_elapsed         | 247303    |
|    total_timesteps      | 884736    |
| train/                  |           |
|    approx_kl            | 1.5718608 |
|    clip_fraction        | 0.491     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.15     |
|    explained_variance   | 0.56      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.408     |
|    n_updates            | 4310      |
|    policy_gradient_loss | 0.038     |
|    std                  | 0.478     |
|    value_loss           | 0.789     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.12e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 433       |
|    time_elapsed         | 247508    |
|    total_timesteps      | 886784    |
| train/                  |           |
|    approx_kl            | 1.4283073 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | -5.14     |
|    explained_variance   | 0.628     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.602     |
|    n_updates            | 4320      |
|    policy_gradient_loss | 0.0406    |
|    std                  | 0.478     |
|    value_loss           | 1.07      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 434        |
|    time_elapsed         | 247714     |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.16108184 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.12      |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.403      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 0.0375     |
|    std                  | 0.477      |
|    value_loss           | 0.894      |
----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.80 +/- 0.09
Episode length: 3598.60 +/- 4.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 890000     |
| train/                  |            |
|    approx_kl            | 0.21729526 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.1       |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.394      |
|    n_updates            | 4340       |
|    policy_gradient_loss | 0.0094     |
|    std                  | 0.476      |
|    value_loss           | 0.938      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 249721   |
|    total_timesteps | 890880   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 436         |
|    time_elapsed         | 249926      |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.013998961 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.09       |
|    explained_variance   | 0.00498     |
|    learning_rate        | 0.0003      |
|    loss                 | 6.46        |
|    n_updates            | 4350        |
|    policy_gradient_loss | -0.00502    |
|    std                  | 0.475       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 250132     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.14113818 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.07      |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.448      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.473      |
|    value_loss           | 0.981      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 438        |
|    time_elapsed         | 250337     |
|    total_timesteps      | 897024     |
| train/                  |            |
|    approx_kl            | 0.90371835 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.02      |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.47       |
|    n_updates            | 4370       |
|    policy_gradient_loss | 0.0352     |
|    std                  | 0.471      |
|    value_loss           | 0.826      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 439        |
|    time_elapsed         | 250542     |
|    total_timesteps      | 899072     |
| train/                  |            |
|    approx_kl            | 0.54849195 |
|    clip_fraction        | 0.539      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.96      |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.404      |
|    n_updates            | 4380       |
|    policy_gradient_loss | 0.0571     |
|    std                  | 0.466      |
|    value_loss           | 0.773      |
----------------------------------------
Eval num_timesteps=900000, episode_reward=-99.77 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 900000     |
| train/                  |            |
|    approx_kl            | 0.74527526 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.9       |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.413      |
|    n_updates            | 4390       |
|    policy_gradient_loss | 0.0276     |
|    std                  | 0.464      |
|    value_loss           | 0.743      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 252548   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 252754     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.04023707 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.89      |
|    explained_variance   | -0.00162   |
|    learning_rate        | 0.0003     |
|    loss                 | 6.43       |
|    n_updates            | 4400       |
|    policy_gradient_loss | 0.00205    |
|    std                  | 0.464      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.14e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 442       |
|    time_elapsed         | 252960    |
|    total_timesteps      | 905216    |
| train/                  |           |
|    approx_kl            | 0.5823746 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.88     |
|    explained_variance   | 0.483     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.483     |
|    n_updates            | 4410      |
|    policy_gradient_loss | 0.0458    |
|    std                  | 0.462     |
|    value_loss           | 0.87      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 443         |
|    time_elapsed         | 253166      |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.087381355 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.85       |
|    explained_variance   | 0.622       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 4420        |
|    policy_gradient_loss | 0.0153      |
|    std                  | 0.46        |
|    value_loss           | 1.06        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 253371     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.10799968 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.81      |
|    explained_variance   | 0.232      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.361      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.0259     |
|    std                  | 0.458      |
|    value_loss           | 1.33       |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.79 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.08320436 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.78      |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.575      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.456      |
|    value_loss           | 1.18       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 255377   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 255582     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.06893881 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.76      |
|    explained_variance   | 0.00199    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.22e+03   |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.457      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 447       |
|    time_elapsed         | 255788    |
|    total_timesteps      | 915456    |
| train/                  |           |
|    approx_kl            | 1.5073198 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.77     |
|    explained_variance   | 0.0814    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.399     |
|    n_updates            | 4460      |
|    policy_gradient_loss | 0.0242    |
|    std                  | 0.456     |
|    value_loss           | 1.17      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.15e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 448       |
|    time_elapsed         | 255993    |
|    total_timesteps      | 917504    |
| train/                  |           |
|    approx_kl            | 0.3169685 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.73     |
|    explained_variance   | 0.626     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.412     |
|    n_updates            | 4470      |
|    policy_gradient_loss | 0.0248    |
|    std                  | 0.454     |
|    value_loss           | 0.685     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 256199     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.98934734 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.68      |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.418      |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.0246     |
|    std                  | 0.451      |
|    value_loss           | 0.945      |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.87 +/- 0.11
Episode length: 3600.60 +/- 0.80
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 3.6e+03  |
|    mean_reward          | -99.9    |
| time/                   |          |
|    total_timesteps      | 920000   |
| train/                  |          |
|    approx_kl            | 0.149614 |
|    clip_fraction        | 0.385    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.67    |
|    explained_variance   | 0.671    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.503    |
|    n_updates            | 4490     |
|    policy_gradient_loss | 0.0209   |
|    std                  | 0.451    |
|    value_loss           | 0.766    |
--------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 258206   |
|    total_timesteps | 921600   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 451         |
|    time_elapsed         | 258412      |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.020469472 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.67       |
|    explained_variance   | 0.000813    |
|    learning_rate        | 0.0003      |
|    loss                 | 742         |
|    n_updates            | 4500        |
|    policy_gradient_loss | 0.00576     |
|    std                  | 0.451       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.16e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 452       |
|    time_elapsed         | 258617    |
|    total_timesteps      | 925696    |
| train/                  |           |
|    approx_kl            | 0.1043664 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.67     |
|    explained_variance   | 0.579     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.313     |
|    n_updates            | 4510      |
|    policy_gradient_loss | 0.00556   |
|    std                  | 0.452     |
|    value_loss           | 0.811     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 453        |
|    time_elapsed         | 258823     |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.26718077 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.68      |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.531      |
|    n_updates            | 4520       |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.453      |
|    value_loss           | 0.802      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 454         |
|    time_elapsed         | 259028      |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.053894084 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.65       |
|    explained_variance   | 0.476       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.389       |
|    n_updates            | 4530        |
|    policy_gradient_loss | 0.00814     |
|    std                  | 0.45        |
|    value_loss           | 0.891       |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=-98.79 +/- 0.89
Episode length: 3598.20 +/- 5.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -98.8       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.083021834 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.61       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.227       |
|    n_updates            | 4540        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.449       |
|    value_loss           | 0.657       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 261034   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 261240      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.093949705 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.6        |
|    explained_variance   | -0.00027    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21e+03    |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.00931     |
|    std                  | 0.449       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.17e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 457       |
|    time_elapsed         | 261445    |
|    total_timesteps      | 935936    |
| train/                  |           |
|    approx_kl            | 2.3703098 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.62     |
|    explained_variance   | -0.391    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.483     |
|    n_updates            | 4560      |
|    policy_gradient_loss | 0.00551   |
|    std                  | 0.449     |
|    value_loss           | 0.927     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 458        |
|    time_elapsed         | 261651     |
|    total_timesteps      | 937984     |
| train/                  |            |
|    approx_kl            | 0.11346259 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.61      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.229      |
|    n_updates            | 4570       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.448      |
|    value_loss           | 0.68       |
----------------------------------------
Eval num_timesteps=940000, episode_reward=-99.83 +/- 0.08
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.031753376 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.57       |
|    explained_variance   | 0.598       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.485       |
|    n_updates            | 4580        |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.446       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 263657   |
|    total_timesteps | 940032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 460         |
|    time_elapsed         | 263862      |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.067069806 |
|    clip_fraction        | 0.247       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.55       |
|    explained_variance   | 0.0033      |
|    learning_rate        | 0.0003      |
|    loss                 | 52.3        |
|    n_updates            | 4590        |
|    policy_gradient_loss | 0.00392     |
|    std                  | 0.446       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 461        |
|    time_elapsed         | 264067     |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.63799465 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.53      |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.404      |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.00629   |
|    std                  | 0.445      |
|    value_loss           | 1.05       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 462        |
|    time_elapsed         | 264273     |
|    total_timesteps      | 946176     |
| train/                  |            |
|    approx_kl            | 0.31978944 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.51      |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.318      |
|    n_updates            | 4610       |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.444      |
|    value_loss           | 0.69       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 463       |
|    time_elapsed         | 264478    |
|    total_timesteps      | 948224    |
| train/                  |           |
|    approx_kl            | 0.3370432 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.5      |
|    explained_variance   | 0.698     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.342     |
|    n_updates            | 4620      |
|    policy_gradient_loss | 0.0311    |
|    std                  | 0.443     |
|    value_loss           | 0.669     |
---------------------------------------
Eval num_timesteps=950000, episode_reward=-99.81 +/- 0.10
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 950000      |
| train/                  |             |
|    approx_kl            | 0.081851706 |
|    clip_fraction        | 0.468       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.47       |
|    explained_variance   | 0.694       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.344       |
|    n_updates            | 4630        |
|    policy_gradient_loss | 0.0328      |
|    std                  | 0.441       |
|    value_loss           | 0.777       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 266484   |
|    total_timesteps | 950272   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 465        |
|    time_elapsed         | 266690     |
|    total_timesteps      | 952320     |
| train/                  |            |
|    approx_kl            | 0.08914226 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.45      |
|    explained_variance   | -0.00164   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13e+03   |
|    n_updates            | 4640       |
|    policy_gradient_loss | 0.0095     |
|    std                  | 0.441      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 266895     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.10502404 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.45      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.377      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.44       |
|    value_loss           | 0.959      |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.19e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 467      |
|    time_elapsed         | 267101   |
|    total_timesteps      | 956416   |
| train/                  |          |
|    approx_kl            | 2.595949 |
|    clip_fraction        | 0.528    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.42    |
|    explained_variance   | 0.674    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.351    |
|    n_updates            | 4660     |
|    policy_gradient_loss | 0.0442   |
|    std                  | 0.437    |
|    value_loss           | 0.774    |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 468         |
|    time_elapsed         | 267306      |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.046537958 |
|    clip_fraction        | 0.448       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.39       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.36        |
|    n_updates            | 4670        |
|    policy_gradient_loss | 0.0321      |
|    std                  | 0.437       |
|    value_loss           | 0.661       |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.81 +/- 0.03
Episode length: 3599.00 +/- 4.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 960000    |
| train/                  |           |
|    approx_kl            | 1.4266165 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.36     |
|    explained_variance   | 0.624     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.311     |
|    n_updates            | 4680      |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.433     |
|    value_loss           | 0.785     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 269312   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 269518     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.25387102 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.33      |
|    explained_variance   | -0.00217   |
|    learning_rate        | 0.0003     |
|    loss                 | 40.1       |
|    n_updates            | 4690       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.433      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 471       |
|    time_elapsed         | 269723    |
|    total_timesteps      | 964608    |
| train/                  |           |
|    approx_kl            | 0.8643125 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.32     |
|    explained_variance   | 0.161     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.287     |
|    n_updates            | 4700      |
|    policy_gradient_loss | 0.0112    |
|    std                  | 0.433     |
|    value_loss           | 1.17      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.2e+03   |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 472       |
|    time_elapsed         | 269929    |
|    total_timesteps      | 966656    |
| train/                  |           |
|    approx_kl            | 0.3888321 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.33     |
|    explained_variance   | 0.652     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.31      |
|    n_updates            | 4710      |
|    policy_gradient_loss | 0.0193    |
|    std                  | 0.433     |
|    value_loss           | 0.699     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 270134     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.11345768 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.29      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.43       |
|    value_loss           | 0.987      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.79 +/- 0.08
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.8     |
| time/                   |           |
|    total_timesteps      | 970000    |
| train/                  |           |
|    approx_kl            | 0.3540003 |
|    clip_fraction        | 0.311     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.25     |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.17      |
|    n_updates            | 4730      |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.429     |
|    value_loss           | 1.47      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 272140   |
|    total_timesteps | 970752   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 475        |
|    time_elapsed         | 272346     |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.10312362 |
|    clip_fraction        | 0.134      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.25      |
|    explained_variance   | 0.0033     |
|    learning_rate        | 0.0003     |
|    loss                 | 38.1       |
|    n_updates            | 4740       |
|    policy_gradient_loss | 0.00134    |
|    std                  | 0.429      |
|    value_loss           | 1.05e+03   |
----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.21e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 476      |
|    time_elapsed         | 272554   |
|    total_timesteps      | 974848   |
| train/                  |          |
|    approx_kl            | 1.371193 |
|    clip_fraction        | 0.304    |
|    clip_range           | 0.2      |
|    entropy_loss         | -4.24    |
|    explained_variance   | 0.511    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.331    |
|    n_updates            | 4750     |
|    policy_gradient_loss | 0.00302  |
|    std                  | 0.429    |
|    value_loss           | 0.764    |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 272759     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.06242022 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.345      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.428      |
|    value_loss           | 0.878      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.22e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 478       |
|    time_elapsed         | 272964    |
|    total_timesteps      | 978944    |
| train/                  |           |
|    approx_kl            | 0.5174056 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.22     |
|    explained_variance   | 0.635     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.61      |
|    n_updates            | 4770      |
|    policy_gradient_loss | 0.0354    |
|    std                  | 0.428     |
|    value_loss           | 1.03      |
---------------------------------------
Eval num_timesteps=980000, episode_reward=-99.67 +/- 0.45
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 980000    |
| train/                  |           |
|    approx_kl            | 1.0350126 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.22     |
|    explained_variance   | 0.681     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.315     |
|    n_updates            | 4780      |
|    policy_gradient_loss | 0.0263    |
|    std                  | 0.426     |
|    value_loss           | 0.823     |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 274971   |
|    total_timesteps | 980992   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 480         |
|    time_elapsed         | 275176      |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.019378182 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.2        |
|    explained_variance   | 0.00543     |
|    learning_rate        | 0.0003      |
|    loss                 | 149         |
|    n_updates            | 4790        |
|    policy_gradient_loss | 0.00109     |
|    std                  | 0.427       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 481        |
|    time_elapsed         | 275381     |
|    total_timesteps      | 985088     |
| train/                  |            |
|    approx_kl            | 0.13597023 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.19      |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.726      |
|    n_updates            | 4800       |
|    policy_gradient_loss | 0.0329     |
|    std                  | 0.425      |
|    value_loss           | 0.905      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 275587     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.26171213 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.16      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.325      |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.423      |
|    value_loss           | 0.758      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 275792     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.23114373 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.13      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.359      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.028      |
|    std                  | 0.423      |
|    value_loss           | 0.717      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.60 +/- 0.39
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.17783843 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.1       |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.965      |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.42       |
|    value_loss           | 1.17       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 277798   |
|    total_timesteps | 991232   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 485         |
|    time_elapsed         | 278004      |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.017223367 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.08       |
|    explained_variance   | 0.00468     |
|    learning_rate        | 0.0003      |
|    loss                 | 28.6        |
|    n_updates            | 4840        |
|    policy_gradient_loss | 0.00987     |
|    std                  | 0.42        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 278209     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.14060497 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.05      |
|    explained_variance   | 0.241      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.454      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.417      |
|    value_loss           | 0.868      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.25e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 487       |
|    time_elapsed         | 278415    |
|    total_timesteps      | 997376    |
| train/                  |           |
|    approx_kl            | 0.3069126 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -4.03     |
|    explained_variance   | 0.547     |
|    learning_rate        | 0.0003    |
|    loss                 | 1.19      |
|    n_updates            | 4860      |
|    policy_gradient_loss | 0.00986   |
|    std                  | 0.417     |
|    value_loss           | 1.67      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 488        |
|    time_elapsed         | 278620     |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.52393913 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -4.01      |
|    explained_variance   | -0.048     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.409      |
|    n_updates            | 4870       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.416      |
|    value_loss           | 0.952      |
----------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.45 +/- 0.81
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.1138844 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -3.97     |
|    explained_variance   | 0.618     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.532     |
|    n_updates            | 4880      |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.414     |
|    value_loss           | 1.23      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 280627   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100% ━━━━━━━━━━━━━━━━ 1,001,472/1,000,… [ 3 days, 5:54:30 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[ -99.921903  -99.991912  -99.927254 -100.006158  -99.918801]
 [ -99.881051  -99.894779  -99.865531  -99.926894  -99.876113]
 [ -99.867493  -99.90494   -99.906519  -99.926206  -99.901291]
 [ -99.70271   -99.901992  -99.972555  -99.741955  -99.681109]
 [ -99.896161  -99.816822  -99.713508  -99.767969  -99.780274]
 [ -99.817013  -99.972062  -99.843779  -99.904136  -99.839008]
 [ -99.863125  -99.737591  -99.830274  -99.809369  -99.828656]
 [ -99.736852  -99.690484  -99.709323  -99.752278  -99.812969]
 [ -78.330387  -85.140849  -86.115677  -72.298404  -79.142756]
 [ -93.711166  -83.377962  -86.534877  -85.605935  -94.682759]
 [ -99.752938  -97.601283  -99.725529  -99.735145  -99.856894]
 [ -99.63845   -99.809347  -99.696407  -99.754986  -99.759345]
 [ -81.610528  -82.646385  -83.231578  -80.37245   -85.613531]
 [ -83.569615  -88.412306  -74.445265  -75.362977  -79.324979]
 [ -96.691808  -99.756162  -99.698676  -99.803267  -99.649109]
 [ -92.851366  -86.679349  -93.718072  -95.477065  -96.653035]
 [ -98.703661  -97.786122  -96.78334   -97.796733  -99.730164]
 [ -99.76214   -99.810895  -99.691358  -99.799885  -99.752081]
 [ -99.509907  -98.534344  -98.545643  -99.844201  -98.650023]
 [ -96.769365  -98.953446  -99.525304  -98.534824  -98.851465]
 [ -99.746315  -99.807488  -99.733341  -99.779179  -99.699858]
 [ -99.875365  -99.697316  -99.754875  -98.502401  -99.89994 ]
 [ -99.608307  -99.656217  -99.550653  -99.822438  -99.583785]
 [ -99.680481  -98.739016  -99.758571  -99.627931  -99.631236]
 [ -99.706873  -99.495047  -98.58093   -99.706017  -99.586843]
 [ -99.585681  -99.321524  -98.329019  -98.711982  -97.322352]
 [ -99.693151  -99.324046  -99.886373  -99.548329  -99.3739  ]
 [ -99.641459  -99.584771  -99.567493  -99.577766  -99.772563]
 [ -99.820296  -99.432815  -99.416817  -99.629181  -99.593945]
 [ -99.582581  -99.715098  -99.601343  -99.551834  -99.598481]
 [ -99.264982  -98.280553  -98.336478  -99.606087  -97.537741]
 [ -98.17854   -98.328607  -98.17768   -99.259478  -99.334982]
 [ -85.359527  -85.331116  -86.145934  -89.163998  -82.329387]
 [ -99.540094  -98.365487  -99.768332  -99.550253  -99.523054]
 [ -99.776517  -99.266277  -99.368382  -98.321403  -97.458576]
 [ -99.485206  -99.656037  -99.569353  -99.69708   -98.358747]
 [ -99.467448  -96.465431  -99.478391  -99.502057  -99.560498]
 [ -99.349153  -98.489642  -99.433608  -99.417665  -99.595286]
 [ -97.689514  -99.511176  -98.341727  -96.43059   -97.506921]
 [ -94.20421   -95.577108  -89.332613  -94.552023  -94.678345]
 [ -65.659074  -63.632594  -73.713455  -60.77988   -66.179408]
 [ -90.326357  -93.58059   -93.374687  -94.495871  -94.163125]
 [ -95.183144  -93.263458  -95.456559  -92.425779  -97.458991]
 [ -89.542784  -95.578778  -93.535789  -92.495673  -86.559442]
 [ -93.330248  -96.412251  -93.193865  -93.516894  -95.402757]
 [ -83.589001  -77.304471  -78.469409  -65.3213    -81.280371]
 [ -79.454662  -81.3466    -82.379634  -83.652787  -84.849387]
 [ -88.55434   -89.458513  -83.517358  -90.544605  -85.272787]
 [ -99.719211  -99.545548  -99.815945  -96.705095  -99.724181]
 [ -99.752903  -99.787048  -99.836162  -99.840617  -99.741381]
 [ -95.865529  -93.58694   -92.746999  -97.803304  -97.723155]
 [ -88.660131  -92.735367  -95.562736  -93.684116  -89.735304]
 [ -80.620935  -82.612451  -82.721112  -84.689506  -79.553495]
 [ -92.702544  -83.518045  -91.601998  -82.442573  -88.733809]
 [ -84.771881  -80.324295  -75.553121  -88.461466  -78.296973]
 [ -33.600691  -34.242944  -40.146921  -47.52475   -44.430869]
 [ -66.529416  -70.519695  -67.314395  -69.466198  -71.575629]
 [ -49.688646  -54.368537  -57.641755  -55.409158  -56.444254]
 [ -72.530672  -67.564073  -67.584917  -68.373378  -73.245771]
 [ -83.759053  -85.833387  -84.810619  -87.927396  -85.536096]
 [ -94.769792  -92.757977  -82.749859  -84.881463  -93.689331]
 [ -91.658007  -91.288131  -94.655321  -93.47521   -92.596268]
 [ -93.667912  -87.62807   -83.468588  -84.584481  -87.850808]
 [ -86.8388    -90.661107  -94.316627  -91.889565  -90.303817]
 [ -66.49832   -53.528995  -44.577267  -56.568679  -59.390328]
 [ -74.685825  -62.702414  -79.6372    -67.803258  -67.87024 ]
 [ -91.613037  -93.472268  -92.840902  -92.516273  -88.726193]
 [ -92.805552  -94.677458  -93.448566  -93.742308  -93.810911]
 [ -74.834823  -83.734168  -69.721683  -70.359214  -72.507337]
 [ -62.359713  -56.427368  -55.404486  -67.589104  -63.386471]
 [ -66.462783  -73.537758  -65.612602  -61.60485   -64.767543]
 [ -56.771484  -51.409884  -48.320571  -63.441769  -45.548961]
 [ -37.539752  -32.441214  -47.431938  -27.484201  -44.391923]
 [ -76.571459  -63.603313  -81.693485  -56.651901  -77.424879]
 [ -76.632455  -54.734358  -64.681534  -69.686705  -61.484249]
 [ -36.246352  -39.521086  -36.765483  -41.342249  -45.463246]
 [ -63.123931  -66.416362  -63.400419  -73.299955  -66.569725]
 [ -99.629874  -99.625582  -99.611321  -99.577924  -99.654981]
 [ -93.785825  -94.805168  -97.693348  -90.763643  -88.702317]
 [ -99.752205  -99.726157  -99.794818  -99.790647 -100.128799]
 [ -98.725465  -96.820669  -99.830141  -99.77728   -99.844555]
 [ -91.609582  -85.532047  -86.664687  -79.735021  -76.621137]
 [ -67.579495  -67.670518  -70.804869  -69.560338  -68.708076]
 [-100.024141  -99.780218  -99.658695  -99.858873  -99.753534]
 [ -99.85855   -99.769504  -99.844995  -99.722208  -99.764984]
 [ -99.814846  -99.923519  -99.774664  -99.80208   -99.745123]
 [ -99.853054  -99.988227  -99.756085  -99.752238  -99.939381]
 [ -99.941132  -99.728345  -99.893917  -99.731129  -99.964569]
 [ -99.783329  -99.891286  -99.745283  -99.913938  -99.661809]
 [ -99.749826  -99.701186  -99.830574  -99.812674  -99.77825 ]
 [ -99.747064  -99.738016  -99.815056  -99.784519  -99.872001]
 [ -99.972206  -99.813191 -100.015551  -99.697478  -99.830828]
 [ -99.710131  -97.831245  -97.700978  -99.803686  -98.889523]
 [ -99.795008  -99.718352  -99.881633  -99.778932  -99.951162]
 [ -99.682059  -99.942153  -99.905011  -99.765604  -99.771368]
 [ -99.760772  -99.785139  -99.816269  -99.831296  -99.842902]
 [ -99.861559  -99.745457  -99.877209  -99.781317  -99.667643]
 [ -99.964567  -99.951197  -99.875651  -98.784089  -99.753163]
 [ -99.925278  -98.839363  -99.656905  -99.85501   -99.702289]
 [ -99.834987  -99.867934  -99.780269  -99.930816  -97.841519]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3597 3580 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3597 3601]
 [3601 3595 3601 3601 3601]
 [3601 3601 3601 3601 3590]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3582 3601 3601]
 [3601 3601 3601 3601 3601]
 [3598 3593 3601 3601 3601]
 [3600 3601 3601 3597 3601]
 [3601 3601 3601 3586 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3601]
 [3601 3601 3583 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3601 3585]
 [3601 3601 3601 3601 3601]
 [3582 3601 3600 3601 3601]
 [3601 3601 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3581 3598 3601 3601 3601]
 [3601 3601 3601 3586 3599]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3584 3598 3601 3601]
 [3598 3601 3601 3601 3584]
 [3601 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3598 3601 3601 3599 3585]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3599 3600 3584 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3600 3595]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3593 3601 3601 3601 3583]
 [3601 3601 3601 3601 3601]
 [3582 3601 3601 3601 3601]
 [3601 3601 3601 3601 3595]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3598]
 [3601 3601 3601 3600 3584]
 [3601 3601 3601 3601 3601]
 [3580 3601 3601 3601 3601]
 [3601 3598 3601 3588 3601]
 [3601 3601 3601 3601 3598]
 [3598 3598 3601 3601 3601]
 [3600 3583 3601 3601 3601]
 [3598 3601 3601 3601 3587]
 [3601 3601 3601 3601 3601]
 [3588 3601 3601 3601 3601]
 [3597 3598 3601 3601 3578]
 [3601 3601 3601 3601 3598]
 [3576 3601 3601 3601 3601]
 [3601 3601 3601 3584 3601]
 [3601 3601 3600 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3579 3601 3601 3601]
 [3601 3601 3601 3601 3597]
 [3576 3601 3601 3601 3600]
 [3601 3601 3601 3588 3601]
 [3601 3601 3599 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3583 3601 3601 3601]
 [3601 3598 3601 3601 3597]
 [3601 3601 3601 3601 3598]
 [3585 3601 3601 3598 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3583 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3579 3601 3601 3601 3601]
 [3601 3601 3601 3589 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3599 3601 3601 3601]
 [3601 3601 3601 3601 3587]
 [3599 3601 3601 3601 3601]
 [3591 3601 3601 3601 3601]
 [3601 3601 3601 3591 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3588 3601 3601 3601]
 [3601 3601 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-21_11-13-25_llm_triton_qwen_7b_continuous_rewards_zero_shot_1000000-steps_5-obs_ep-time-360.0/model
