####################
/var/spool/slurmd/job5357319/slurm_script
####################
--batch-size 64 --exc train --goal-reset False --model-id TRITON_QWEN_14B --model-quant fp16 --num-eval 100 --prompt-file llm_prompt_binary_rewards_5_examples.yaml --reward-type llm --rollout-steps 2048 --text-verbosity True --total-timesteps 1000000 --train-episode-time-limit 360 --train-fps 10 --train-render-fps 120 --train-verbosity True
####################

Metadata saved to src/FM3_MicRo/control_models/2025-01-28_08-31-10_llm_triton_qwen_14b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/metadata.txt
Contextual prompt is:
You are provided description of a 2D workspace where location of each point can be represented as (x, y) where 'x' is the x-axis co-ordinate while 'y' is the y-axis co-ordinate. The center of the workspace is at (0,0) and the top-right corner is at (360,360).
 
 You need to critique the movement of the particle. You will be provided with the goal position, the previous position of the particle and the new position of the particle. If the particle moves in the direction of the goal, you assign a score of 1. If the particle either moves away from the goal or does not move closer to the goal, you assign a score of 0. You have to output the following calculations:
 
 Some examples of input data and scores are:
 
 The particle was located at (200.00, 150.00).
 The particle is currently located at (180.00, 120.00).
 The goal is currently located at (-20.00, -15.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (-250.00, -150.00).
 The particle is currently located at (-200.00, -150.00).
 The goal is currently located at (75.00, 10.00).
 What is the reward score?
 
 Response: 1 
 The particle was located at (50.00, -75.00).
 The particle is currently located at (50.00, -60.00).
 The goal is currently located at (-150.00, -125.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (-200.00, 150.00).
 The particle is currently located at (200.00, 150.00).
 The goal is currently located at (0.00, 0.00).
 What is the reward score?
 
 Response: 0 
 The particle was located at (17.25, -160.50).
 The particle is currently located at (16.50, -159.75).
 The goal is currently located at (5.75, -57.00).
 What is the reward score?
 
 Response: 1
 
 You must only output either a 0 or 1. Do not output any other text in your reponse. Do not output any code or explanation.

Using cpu device
-----------------------------
| time/              |      |
|    fps             | 9    |
|    iterations      | 1    |
|    time_elapsed    | 215  |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.56e+03    |
|    ep_rew_mean          | 1.57e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 2           |
|    time_elapsed         | 423         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.011548992 |
|    clip_fraction        | 0.128       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.00704     |
|    learning_rate        | 0.0003      |
|    loss                 | 28.7        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0207     |
|    std                  | 1           |
|    value_loss           | 50.5        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.56e+03    |
|    ep_rew_mean          | 1.57e+03    |
| time/                   |             |
|    fps                  | 9           |
|    iterations           | 3           |
|    time_elapsed         | 629         |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009281767 |
|    clip_fraction        | 0.0984      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.117       |
|    learning_rate        | 0.0003      |
|    loss                 | 18.3        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0164     |
|    std                  | 1           |
|    value_loss           | 44          |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.58e+03   |
|    ep_rew_mean          | 1.61e+03   |
| time/                   |            |
|    fps                  | 9          |
|    iterations           | 4          |
|    time_elapsed         | 834        |
|    total_timesteps      | 8192       |
| train/                  |            |
|    approx_kl            | 0.00971204 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.4      |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.0003     |
|    loss                 | 9.46       |
|    n_updates            | 30         |
|    policy_gradient_loss | -0.0185    |
|    std                  | 1          |
|    value_loss           | 35.2       |
----------------------------------------
Eval num_timesteps=10000, episode_reward=-99.91 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009690128 |
|    clip_fraction        | 0.0849      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.413       |
|    learning_rate        | 0.0003      |
|    loss                 | 18          |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0174     |
|    std                  | 1           |
|    value_loss           | 47          |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 5        |
|    time_elapsed    | 2841     |
|    total_timesteps | 10240    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.37e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 6           |
|    time_elapsed         | 3046        |
|    total_timesteps      | 12288       |
| train/                  |             |
|    approx_kl            | 0.006942576 |
|    clip_fraction        | 0.042       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.00952     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.79e+03    |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.00712    |
|    std                  | 1           |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.47e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 7           |
|    time_elapsed         | 3252        |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.006152874 |
|    clip_fraction        | 0.0329      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.131       |
|    learning_rate        | 0.0003      |
|    loss                 | 13.7        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0109     |
|    std                  | 1           |
|    value_loss           | 44          |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.47e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 8           |
|    time_elapsed         | 3457        |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.007055474 |
|    clip_fraction        | 0.0395      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.34        |
|    learning_rate        | 0.0003      |
|    loss                 | 11.3        |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00974    |
|    std                  | 1           |
|    value_loss           | 40.6        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.44e+03    |
|    ep_rew_mean          | 1.54e+03    |
| time/                   |             |
|    fps                  | 5           |
|    iterations           | 9           |
|    time_elapsed         | 3663        |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.008484193 |
|    clip_fraction        | 0.0703      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | -0.426      |
|    learning_rate        | 0.0003      |
|    loss                 | 8.31        |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.0122     |
|    std                  | 1           |
|    value_loss           | 19.5        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-99.93 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.010425698 |
|    clip_fraction        | 0.0573      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | -0.0601     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.81        |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00808    |
|    std                  | 1           |
|    value_loss           | 24.4        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.44e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 10       |
|    time_elapsed    | 5673     |
|    total_timesteps | 20480    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.44e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 11           |
|    time_elapsed         | 5879         |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0053302627 |
|    clip_fraction        | 0.051        |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | -0.00591     |
|    learning_rate        | 0.0003       |
|    loss                 | 2.01e+03     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00283     |
|    std                  | 1            |
|    value_loss           | 1.08e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.51e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 12          |
|    time_elapsed         | 6085        |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.010982834 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.78        |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 1           |
|    value_loss           | 8.95        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.51e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 13          |
|    time_elapsed         | 6291        |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.012106843 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.192       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.72        |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.0097     |
|    std                  | 1           |
|    value_loss           | 6.35        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.4e+03     |
|    ep_rew_mean          | 1.56e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 14          |
|    time_elapsed         | 6496        |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.018132748 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.0707      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.26        |
|    n_updates            | 130         |
|    policy_gradient_loss | 0.00529     |
|    std                  | 1           |
|    value_loss           | 4.31        |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-99.88 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.012106065 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | 0.0688      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.968       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.0121     |
|    std                  | 1.01        |
|    value_loss           | 4.19        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.49e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 15       |
|    time_elapsed    | 8503     |
|    total_timesteps | 30720    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.49e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 16           |
|    time_elapsed         | 8709         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0082181115 |
|    clip_fraction        | 0.0649       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.4        |
|    explained_variance   | 0.000239     |
|    learning_rate        | 0.0003       |
|    loss                 | 954          |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.00527     |
|    std                  | 1.01         |
|    value_loss           | 1.06e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.54e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 17          |
|    time_elapsed         | 8914        |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.019694839 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.4       |
|    explained_variance   | -0.223      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.964       |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.0154     |
|    std                  | 0.999       |
|    value_loss           | 3.01        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.54e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 18          |
|    time_elapsed         | 9120        |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.022268597 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.17        |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.0036     |
|    std                  | 0.993       |
|    value_loss           | 2.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.38e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 19          |
|    time_elapsed         | 9329        |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.012976287 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.658       |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00737    |
|    std                  | 0.996       |
|    value_loss           | 2.15        |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-99.86 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.9       |
| time/                   |             |
|    total_timesteps      | 40000       |
| train/                  |             |
|    approx_kl            | 0.008374341 |
|    clip_fraction        | 0.0831      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | 0.179       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.04        |
|    n_updates            | 190         |
|    policy_gradient_loss | -0.00975    |
|    std                  | 0.995       |
|    value_loss           | 3.1         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.53e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 20       |
|    time_elapsed    | 11337    |
|    total_timesteps | 40960    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.53e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 21           |
|    time_elapsed         | 11543        |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0037013853 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.3        |
|    explained_variance   | -0.00634     |
|    learning_rate        | 0.0003       |
|    loss                 | 117          |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00387     |
|    std                  | 0.995        |
|    value_loss           | 1.05e+03     |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.35e+03  |
|    ep_rew_mean          | 1.57e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 22        |
|    time_elapsed         | 11748     |
|    total_timesteps      | 45056     |
| train/                  |           |
|    approx_kl            | 0.0174595 |
|    clip_fraction        | 0.223     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.3     |
|    explained_variance   | -0.0438   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.733     |
|    n_updates            | 210       |
|    policy_gradient_loss | -0.0151   |
|    std                  | 0.992     |
|    value_loss           | 1.88      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.57e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 23          |
|    time_elapsed         | 11955       |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.011224801 |
|    clip_fraction        | 0.0891      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.3       |
|    explained_variance   | -0.194      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.15        |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.0126     |
|    std                  | 0.99        |
|    value_loss           | 2.69        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.37e+03    |
|    ep_rew_mean          | 1.59e+03    |
| time/                   |             |
|    fps                  | 4           |
|    iterations           | 24          |
|    time_elapsed         | 12161       |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.012241726 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.281       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.23        |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.0146     |
|    std                  | 0.987       |
|    value_loss           | 2.28        |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-99.84 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.011621713 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.18        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.671       |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0139     |
|    std                  | 0.983       |
|    value_loss           | 1.81        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.56e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 25       |
|    time_elapsed    | 14169    |
|    total_timesteps | 51200    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.56e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 26           |
|    time_elapsed         | 14375        |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0041422755 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 2.24e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.94e+03     |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00283     |
|    std                  | 0.983        |
|    value_loss           | 1.06e+03     |
------------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.59e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 27         |
|    time_elapsed         | 14581      |
|    total_timesteps      | 55296      |
| train/                  |            |
|    approx_kl            | 0.01641162 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | -0.235     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.828      |
|    n_updates            | 260        |
|    policy_gradient_loss | -0.0182    |
|    std                  | 0.984      |
|    value_loss           | 2.07       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 28          |
|    time_elapsed         | 14788       |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.020965736 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.976       |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.0125     |
|    std                  | 0.987       |
|    value_loss           | 1.54        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.61e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 29          |
|    time_elapsed         | 14996       |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.017604904 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.318       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.844       |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.977       |
|    value_loss           | 1.67        |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-99.72 +/- 0.06
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.018606024 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.233       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.5         |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.978       |
|    value_loss           | 1.46        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.58e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 30       |
|    time_elapsed    | 17005    |
|    total_timesteps | 61440    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.58e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 31          |
|    time_elapsed         | 17211       |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.007669759 |
|    clip_fraction        | 0.0471      |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.000105    |
|    learning_rate        | 0.0003      |
|    loss                 | 85.7        |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.978       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.35e+03   |
|    ep_rew_mean          | 1.6e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 32         |
|    time_elapsed         | 17416      |
|    total_timesteps      | 65536      |
| train/                  |            |
|    approx_kl            | 0.02035436 |
|    clip_fraction        | 0.265      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.0271     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.775      |
|    n_updates            | 310        |
|    policy_gradient_loss | -0.0169    |
|    std                  | 0.98       |
|    value_loss           | 1.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.36e+03   |
|    ep_rew_mean          | 1.62e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 33         |
|    time_elapsed         | 17622      |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.02099562 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -11.2      |
|    explained_variance   | 0.355      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.877      |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.0177    |
|    std                  | 0.979      |
|    value_loss           | 1.35       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.36e+03    |
|    ep_rew_mean          | 1.62e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 34          |
|    time_elapsed         | 17829       |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.015416641 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.0207     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.533       |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.0152     |
|    std                  | 0.978       |
|    value_loss           | 1.79        |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-99.76 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.021454714 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | 0.193       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.722       |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.017      |
|    std                  | 0.977       |
|    value_loss           | 1.59        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.6e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 35       |
|    time_elapsed    | 19838    |
|    total_timesteps | 71680    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.35e+03     |
|    ep_rew_mean          | 1.62e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 36           |
|    time_elapsed         | 20043        |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0052955383 |
|    clip_fraction        | 0.0492       |
|    clip_range           | 0.2          |
|    entropy_loss         | -11.2        |
|    explained_variance   | 0.0076       |
|    learning_rate        | 0.0003       |
|    loss                 | 6.51         |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00532     |
|    std                  | 0.977        |
|    value_loss           | 1.02e+03     |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.35e+03  |
|    ep_rew_mean          | 1.62e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 37        |
|    time_elapsed         | 20251     |
|    total_timesteps      | 75776     |
| train/                  |           |
|    approx_kl            | 0.0189411 |
|    clip_fraction        | 0.209     |
|    clip_range           | 0.2       |
|    entropy_loss         | -11.2     |
|    explained_variance   | -2.3      |
|    learning_rate        | 0.0003    |
|    loss                 | 0.914     |
|    n_updates            | 360       |
|    policy_gradient_loss | -0.0161   |
|    std                  | 0.976     |
|    value_loss           | 2.32      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 38          |
|    time_elapsed         | 20458       |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.023692634 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.145      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.62        |
|    n_updates            | 370         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.974       |
|    value_loss           | 1.61        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 39          |
|    time_elapsed         | 20663       |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.018651335 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.692      |
|    learning_rate        | 0.0003      |
|    loss                 | 1.2         |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00347    |
|    std                  | 0.975       |
|    value_loss           | 2.7         |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-99.78 +/- 0.03
Episode length: 3599.60 +/- 2.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.024619978 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.178       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.51        |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.977       |
|    value_loss           | 1.64        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.62e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 40       |
|    time_elapsed    | 22670    |
|    total_timesteps | 81920    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 41          |
|    time_elapsed         | 22876       |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.008371053 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -0.00221    |
|    learning_rate        | 0.0003      |
|    loss                 | 23.6        |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.004      |
|    std                  | 0.977       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 42          |
|    time_elapsed         | 23082       |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.010510846 |
|    clip_fraction        | 0.09        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.2       |
|    explained_variance   | -1.4        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.801       |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.977       |
|    value_loss           | 2.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 43          |
|    time_elapsed         | 23287       |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.014080416 |
|    clip_fraction        | 0.157       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.0972      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.832       |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.0147     |
|    std                  | 0.975       |
|    value_loss           | 1.69        |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-99.83 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.021748295 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | 0.292       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.619       |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.0128     |
|    std                  | 0.967       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.64e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 44       |
|    time_elapsed    | 25297    |
|    total_timesteps | 90112    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.64e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 45          |
|    time_elapsed         | 25502       |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.010925675 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -11.1       |
|    explained_variance   | -0.00138    |
|    learning_rate        | 0.0003      |
|    loss                 | 17.6        |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00225    |
|    std                  | 0.967       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 46          |
|    time_elapsed         | 25708       |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.024971642 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.0443     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.654       |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00335    |
|    std                  | 0.962       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 47          |
|    time_elapsed         | 25913       |
|    total_timesteps      | 96256       |
| train/                  |             |
|    approx_kl            | 0.017209306 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | -0.586      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.875       |
|    n_updates            | 460         |
|    policy_gradient_loss | -0.00936    |
|    std                  | 0.957       |
|    value_loss           | 3.48        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.67e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 48          |
|    time_elapsed         | 26121       |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.020990442 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -11         |
|    explained_variance   | 0.197       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.784       |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00448    |
|    std                  | 0.954       |
|    value_loss           | 1.41        |
-----------------------------------------
Eval num_timesteps=100000, episode_reward=-99.76 +/- 0.03
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.025568962 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.239       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.611       |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.95        |
|    value_loss           | 1.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.66e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 49       |
|    time_elapsed    | 28133    |
|    total_timesteps | 100352   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.66e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 50          |
|    time_elapsed         | 28339       |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.006633162 |
|    clip_fraction        | 0.114       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -0.000743   |
|    learning_rate        | 0.0003      |
|    loss                 | 34.8        |
|    n_updates            | 490         |
|    policy_gradient_loss | 0.0011      |
|    std                  | 0.95        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 51          |
|    time_elapsed         | 28544       |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.014965947 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.0921      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.921       |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.0178     |
|    std                  | 0.949       |
|    value_loss           | 1.72        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.68e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 52          |
|    time_elapsed         | 28750       |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.016908217 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.316       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.623       |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.0112     |
|    std                  | 0.951       |
|    value_loss           | 1.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.69e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 53          |
|    time_elapsed         | 28956       |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.020883646 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | 0.337       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.919       |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.016      |
|    std                  | 0.948       |
|    value_loss           | 1.53        |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-99.82 +/- 0.04
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.017468303 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.9       |
|    explained_variance   | -1.15       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.576       |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.945       |
|    value_loss           | 1.67        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.68e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 54       |
|    time_elapsed    | 30964    |
|    total_timesteps | 110592   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.68e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 55         |
|    time_elapsed         | 31169      |
|    total_timesteps      | 112640     |
| train/                  |            |
|    approx_kl            | 0.00739529 |
|    clip_fraction        | 0.0501     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -0.000444  |
|    learning_rate        | 0.0003     |
|    loss                 | 11.5       |
|    n_updates            | 540        |
|    policy_gradient_loss | 0.00358    |
|    std                  | 0.945      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 56         |
|    time_elapsed         | 31375      |
|    total_timesteps      | 114688     |
| train/                  |            |
|    approx_kl            | 0.02435967 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | -2.68      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.32       |
|    n_updates            | 550        |
|    policy_gradient_loss | -0.00839   |
|    std                  | 0.943      |
|    value_loss           | 1.7        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.69e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 57         |
|    time_elapsed         | 31580      |
|    total_timesteps      | 116736     |
| train/                  |            |
|    approx_kl            | 0.02934093 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.9      |
|    explained_variance   | 0.244      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.712      |
|    n_updates            | 560        |
|    policy_gradient_loss | -0.00706   |
|    std                  | 0.94       |
|    value_loss           | 1.34       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 58          |
|    time_elapsed         | 31786       |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.026195742 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | 0.388       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.905       |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.0191     |
|    std                  | 0.933       |
|    value_loss           | 1.69        |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-99.81 +/- 0.03
Episode length: 3596.80 +/- 6.58
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 120000     |
| train/                  |            |
|    approx_kl            | 0.03304015 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.8      |
|    explained_variance   | 0.219      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.678      |
|    n_updates            | 580        |
|    policy_gradient_loss | -0.0132    |
|    std                  | 0.929      |
|    value_loss           | 1.28       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.69e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 59       |
|    time_elapsed    | 33796    |
|    total_timesteps | 120832   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.69e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 60           |
|    time_elapsed         | 34006        |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0060710115 |
|    clip_fraction        | 0.0594       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.8        |
|    explained_variance   | -0.00477     |
|    learning_rate        | 0.0003       |
|    loss                 | 26.6         |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00406     |
|    std                  | 0.929        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 61          |
|    time_elapsed         | 34212       |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.027214289 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.8       |
|    explained_variance   | -0.258      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.84        |
|    n_updates            | 600         |
|    policy_gradient_loss | -0.00788    |
|    std                  | 0.932       |
|    value_loss           | 1.6         |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.71e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 62       |
|    time_elapsed         | 34417    |
|    total_timesteps      | 126976   |
| train/                  |          |
|    approx_kl            | 0.024836 |
|    clip_fraction        | 0.233    |
|    clip_range           | 0.2      |
|    entropy_loss         | -10.8    |
|    explained_variance   | 0.109    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.568    |
|    n_updates            | 610      |
|    policy_gradient_loss | -0.0156  |
|    std                  | 0.931    |
|    value_loss           | 2.12     |
--------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.35e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 63          |
|    time_elapsed         | 34623       |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.029640976 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.831       |
|    n_updates            | 620         |
|    policy_gradient_loss | -0.00761    |
|    std                  | 0.926       |
|    value_loss           | 1.21        |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-99.79 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.019517116 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.341       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.496       |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.0127     |
|    std                  | 0.926       |
|    value_loss           | 2.46        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.71e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 64       |
|    time_elapsed    | 36629    |
|    total_timesteps | 131072   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.71e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 65          |
|    time_elapsed         | 36840       |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.012128757 |
|    clip_fraction        | 0.0957      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.00316     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.95e+03    |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00466    |
|    std                  | 0.926       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.72e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 66          |
|    time_elapsed         | 37048       |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.029394403 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.0464      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.68        |
|    n_updates            | 650         |
|    policy_gradient_loss | 0.00453     |
|    std                  | 0.928       |
|    value_loss           | 1.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 67          |
|    time_elapsed         | 37254       |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.020915685 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | -0.159      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.607       |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00502    |
|    std                  | 0.927       |
|    value_loss           | 1.79        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.73e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 68          |
|    time_elapsed         | 37459       |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.029585596 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.198       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.472       |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.922       |
|    value_loss           | 1.28        |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-99.79 +/- 0.04
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.026635591 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.7       |
|    explained_variance   | 0.207       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.563       |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.0106     |
|    std                  | 0.919       |
|    value_loss           | 1.4         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.72e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 69       |
|    time_elapsed    | 39470    |
|    total_timesteps | 141312   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.72e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 70           |
|    time_elapsed         | 39677        |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0063275574 |
|    clip_fraction        | 0.0531       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.7        |
|    explained_variance   | -0.000195    |
|    learning_rate        | 0.0003       |
|    loss                 | 43           |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.000918    |
|    std                  | 0.919        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.74e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 71          |
|    time_elapsed         | 39884       |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.022352148 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.0695      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.882       |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.0122     |
|    std                  | 0.915       |
|    value_loss           | 1.79        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 72          |
|    time_elapsed         | 40090       |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.039795037 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.205       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.525       |
|    n_updates            | 710         |
|    policy_gradient_loss | -0.00927    |
|    std                  | 0.908       |
|    value_loss           | 1.18        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.75e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 73          |
|    time_elapsed         | 40295       |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.036752228 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.255       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.705       |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.0061     |
|    std                  | 0.905       |
|    value_loss           | 1.57        |
-----------------------------------------
Eval num_timesteps=150000, episode_reward=-99.78 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 150000      |
| train/                  |             |
|    approx_kl            | 0.030413052 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.215       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.598       |
|    n_updates            | 730         |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.901       |
|    value_loss           | 1.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.74e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 74       |
|    time_elapsed    | 42302    |
|    total_timesteps | 151552   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.34e+03     |
|    ep_rew_mean          | 1.75e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 75           |
|    time_elapsed         | 42507        |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0154368635 |
|    clip_fraction        | 0.196        |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.5        |
|    explained_variance   | -2.09e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 3.75         |
|    n_updates            | 740          |
|    policy_gradient_loss | 0.00129      |
|    std                  | 0.901        |
|    value_loss           | 1.05e+03     |
------------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.75e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 76        |
|    time_elapsed         | 42716     |
|    total_timesteps      | 155648    |
| train/                  |           |
|    approx_kl            | 0.0330796 |
|    clip_fraction        | 0.307     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | 0.902     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.534     |
|    n_updates            | 750       |
|    policy_gradient_loss | -0.00825  |
|    std                  | 0.904     |
|    value_loss           | 1.62      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.76e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 77        |
|    time_elapsed         | 42922     |
|    total_timesteps      | 157696    |
| train/                  |           |
|    approx_kl            | 0.0423123 |
|    clip_fraction        | 0.316     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.5     |
|    explained_variance   | -1.91     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.936     |
|    n_updates            | 760       |
|    policy_gradient_loss | -0.00671  |
|    std                  | 0.903     |
|    value_loss           | 2.02      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.76e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 78          |
|    time_elapsed         | 43129       |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.035816938 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.23        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.9         |
|    n_updates            | 770         |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.9         |
|    value_loss           | 1.37        |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-99.79 +/- 0.06
Episode length: 3596.60 +/- 6.97
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.025671177 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.448       |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00401    |
|    std                  | 0.898       |
|    value_loss           | 0.977       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.75e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 79       |
|    time_elapsed    | 45138    |
|    total_timesteps | 161792   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 80         |
|    time_elapsed         | 45346      |
|    total_timesteps      | 163840     |
| train/                  |            |
|    approx_kl            | 0.03754971 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -0.000752  |
|    learning_rate        | 0.0003     |
|    loss                 | 3.44       |
|    n_updates            | 790        |
|    policy_gradient_loss | 0.000957   |
|    std                  | 0.902      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.76e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 81         |
|    time_elapsed         | 45553      |
|    total_timesteps      | 165888     |
| train/                  |            |
|    approx_kl            | 0.03709103 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.5      |
|    explained_variance   | -2.31      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.42       |
|    n_updates            | 800        |
|    policy_gradient_loss | 0.00161    |
|    std                  | 0.906      |
|    value_loss           | 2.83       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 82          |
|    time_elapsed         | 45759       |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.022658968 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.721       |
|    n_updates            | 810         |
|    policy_gradient_loss | -0.00364    |
|    std                  | 0.909       |
|    value_loss           | 1.5         |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.77e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 83         |
|    time_elapsed         | 45964      |
|    total_timesteps      | 169984     |
| train/                  |            |
|    approx_kl            | 0.02262149 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.212      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.351      |
|    n_updates            | 820        |
|    policy_gradient_loss | -0.0042    |
|    std                  | 0.905      |
|    value_loss           | 1.16       |
----------------------------------------
Eval num_timesteps=170000, episode_reward=-99.73 +/- 0.06
Episode length: 3600.40 +/- 1.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 170000     |
| train/                  |            |
|    approx_kl            | 0.03387024 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.6      |
|    explained_variance   | 0.238      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.376      |
|    n_updates            | 830        |
|    policy_gradient_loss | -0.00878   |
|    std                  | 0.908      |
|    value_loss           | 1.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.76e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 84       |
|    time_elapsed    | 47974    |
|    total_timesteps | 172032   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 85          |
|    time_elapsed         | 48182       |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.034681886 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.6       |
|    explained_variance   | -0.00121    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.06e+03    |
|    n_updates            | 840         |
|    policy_gradient_loss | 0.00716     |
|    std                  | 0.909       |
|    value_loss           | 931         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.77e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 86          |
|    time_elapsed         | 48387       |
|    total_timesteps      | 176128      |
| train/                  |             |
|    approx_kl            | 0.029419404 |
|    clip_fraction        | 0.311       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.167       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.397       |
|    n_updates            | 850         |
|    policy_gradient_loss | -0.00354    |
|    std                  | 0.906       |
|    value_loss           | 0.995       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.78e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 87          |
|    time_elapsed         | 48593       |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.023334816 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.226       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.534       |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00901    |
|    std                  | 0.903       |
|    value_loss           | 1.11        |
-----------------------------------------
Eval num_timesteps=180000, episode_reward=-99.72 +/- 0.05
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.024722937 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | 0.263       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.586       |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00997    |
|    std                  | 0.901       |
|    value_loss           | 1.19        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.78e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 88       |
|    time_elapsed    | 50603    |
|    total_timesteps | 180224   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.78e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 89           |
|    time_elapsed         | 50809        |
|    total_timesteps      | 182272       |
| train/                  |              |
|    approx_kl            | 0.0033449535 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.2          |
|    entropy_loss         | -10.5        |
|    explained_variance   | -0.00699     |
|    learning_rate        | 0.0003       |
|    loss                 | 206          |
|    n_updates            | 880          |
|    policy_gradient_loss | -0.00166     |
|    std                  | 0.901        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 90          |
|    time_elapsed         | 51014       |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.018334728 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.5       |
|    explained_variance   | -0.0751     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.632       |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.0102     |
|    std                  | 0.898       |
|    value_loss           | 1.54        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.79e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 91          |
|    time_elapsed         | 51219       |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.025709985 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.307       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00654    |
|    std                  | 0.894       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 92          |
|    time_elapsed         | 51425       |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.024874195 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.277       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.603       |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.0047     |
|    std                  | 0.889       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=190000, episode_reward=-99.76 +/- 0.04
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 190000     |
| train/                  |            |
|    approx_kl            | 0.02267109 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -2.03      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.458      |
|    n_updates            | 920        |
|    policy_gradient_loss | -0.00681   |
|    std                  | 0.887      |
|    value_loss           | 3.72       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.79e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 93       |
|    time_elapsed    | 53434    |
|    total_timesteps | 190464   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.79e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 94         |
|    time_elapsed         | 53640      |
|    total_timesteps      | 192512     |
| train/                  |            |
|    approx_kl            | 0.00484774 |
|    clip_fraction        | 0.0457     |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | -0.00398   |
|    learning_rate        | 0.0003     |
|    loss                 | 122        |
|    n_updates            | 930        |
|    policy_gradient_loss | -0.00352   |
|    std                  | 0.887      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 95          |
|    time_elapsed         | 53845       |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.010483107 |
|    clip_fraction        | 0.0913      |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -5.15       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.52        |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.886       |
|    value_loss           | 1.8         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 96          |
|    time_elapsed         | 54054       |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.033355787 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.16        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.549       |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.000952   |
|    std                  | 0.885       |
|    value_loss           | 1.35        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.8e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 97         |
|    time_elapsed         | 54263      |
|    total_timesteps      | 198656     |
| train/                  |            |
|    approx_kl            | 0.04108349 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.4      |
|    explained_variance   | 0.193      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.464      |
|    n_updates            | 960        |
|    policy_gradient_loss | -0.00492   |
|    std                  | 0.885      |
|    value_loss           | 1.53       |
----------------------------------------
Eval num_timesteps=200000, episode_reward=-99.78 +/- 0.02
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.022985741 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -0.338      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.767       |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00251    |
|    std                  | 0.885       |
|    value_loss           | 4.2         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.8e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 98       |
|    time_elapsed    | 56270    |
|    total_timesteps | 200704   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.8e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 99          |
|    time_elapsed         | 56475       |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.021293225 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | 0.00147     |
|    learning_rate        | 0.0003      |
|    loss                 | 131         |
|    n_updates            | 980         |
|    policy_gradient_loss | -0.00583    |
|    std                  | 0.885       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 100         |
|    time_elapsed         | 56681       |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.062668815 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -1.05       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.624       |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.885       |
|    value_loss           | 1.71        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.81e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 101         |
|    time_elapsed         | 56887       |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.031806648 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.4       |
|    explained_variance   | -4.68       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.14        |
|    n_updates            | 1000        |
|    policy_gradient_loss | 0.00467     |
|    std                  | 0.884       |
|    value_loss           | 6.47        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 102         |
|    time_elapsed         | 57095       |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.032500718 |
|    clip_fraction        | 0.307       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.0845      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.537       |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00816    |
|    std                  | 0.882       |
|    value_loss           | 1.29        |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-99.71 +/- 0.04
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.025168765 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | 0.169       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.627       |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.878       |
|    value_loss           | 1.28        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.81e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 103      |
|    time_elapsed    | 59105    |
|    total_timesteps | 210944   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.81e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 104        |
|    time_elapsed         | 59310      |
|    total_timesteps      | 212992     |
| train/                  |            |
|    approx_kl            | 0.04796241 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | 0.00149    |
|    learning_rate        | 0.0003     |
|    loss                 | 17         |
|    n_updates            | 1030       |
|    policy_gradient_loss | -0.00413   |
|    std                  | 0.877      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.82e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 105         |
|    time_elapsed         | 59515       |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.032258697 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.3       |
|    explained_variance   | -0.0231     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.482       |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00629    |
|    std                  | 0.876       |
|    value_loss           | 1.11        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 106        |
|    time_elapsed         | 59721      |
|    total_timesteps      | 217088     |
| train/                  |            |
|    approx_kl            | 0.03161004 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.3      |
|    explained_variance   | -1.23      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.591      |
|    n_updates            | 1050       |
|    policy_gradient_loss | 0.00325    |
|    std                  | 0.872      |
|    value_loss           | 2.61       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 107        |
|    time_elapsed         | 59926      |
|    total_timesteps      | 219136     |
| train/                  |            |
|    approx_kl            | 0.03501893 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.572      |
|    n_updates            | 1060       |
|    policy_gradient_loss | -0.004     |
|    std                  | 0.868      |
|    value_loss           | 1.32       |
----------------------------------------
Eval num_timesteps=220000, episode_reward=-99.73 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 220000     |
| train/                  |            |
|    approx_kl            | 0.03860859 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.308     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.636      |
|    n_updates            | 1070       |
|    policy_gradient_loss | -0.00303   |
|    std                  | 0.865      |
|    value_loss           | 2.44       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 108      |
|    time_elapsed    | 61934    |
|    total_timesteps | 221184   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 1.82e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 109       |
|    time_elapsed         | 62140     |
|    total_timesteps      | 223232    |
| train/                  |           |
|    approx_kl            | 0.0081724 |
|    clip_fraction        | 0.0797    |
|    clip_range           | 0.2       |
|    entropy_loss         | -10.2     |
|    explained_variance   | -0.00894  |
|    learning_rate        | 0.0003    |
|    loss                 | 179       |
|    n_updates            | 1080      |
|    policy_gradient_loss | -0.00355  |
|    std                  | 0.865     |
|    value_loss           | 1.06e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 110        |
|    time_elapsed         | 62346      |
|    total_timesteps      | 225280     |
| train/                  |            |
|    approx_kl            | 0.02574046 |
|    clip_fraction        | 0.16       |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.935     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.76       |
|    n_updates            | 1090       |
|    policy_gradient_loss | -0.011     |
|    std                  | 0.865      |
|    value_loss           | 1.55       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.83e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 111         |
|    time_elapsed         | 62553       |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.029021863 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | -0.191      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.524       |
|    n_updates            | 1100        |
|    policy_gradient_loss | 0.00208     |
|    std                  | 0.864       |
|    value_loss           | 1.71        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 112        |
|    time_elapsed         | 62759      |
|    total_timesteps      | 229376     |
| train/                  |            |
|    approx_kl            | 0.08025199 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.146      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.577      |
|    n_updates            | 1110       |
|    policy_gradient_loss | 0.00642    |
|    std                  | 0.87       |
|    value_loss           | 1.3        |
----------------------------------------
Eval num_timesteps=230000, episode_reward=-99.71 +/- 0.05
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.050976075 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.2       |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.657       |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00381     |
|    std                  | 0.87        |
|    value_loss           | 1.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.82e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 113      |
|    time_elapsed    | 64765    |
|    total_timesteps | 231424   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.82e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 114        |
|    time_elapsed         | 64971      |
|    total_timesteps      | 233472     |
| train/                  |            |
|    approx_kl            | 0.03710126 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.0104    |
|    learning_rate        | 0.0003     |
|    loss                 | 1.74e+03   |
|    n_updates            | 1130       |
|    policy_gradient_loss | 0.00609    |
|    std                  | 0.869      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.83e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 115        |
|    time_elapsed         | 65176      |
|    total_timesteps      | 235520     |
| train/                  |            |
|    approx_kl            | 0.03781598 |
|    clip_fraction        | 0.263      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | -0.316     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.866      |
|    n_updates            | 1140       |
|    policy_gradient_loss | -0.0018    |
|    std                  | 0.869      |
|    value_loss           | 1.54       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.84e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 116        |
|    time_elapsed         | 65382      |
|    total_timesteps      | 237568     |
| train/                  |            |
|    approx_kl            | 0.03611981 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.2      |
|    explained_variance   | 0.143      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.616      |
|    n_updates            | 1150       |
|    policy_gradient_loss | 0.00241    |
|    std                  | 0.863      |
|    value_loss           | 1.26       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 117         |
|    time_elapsed         | 65587       |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.028890437 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.133       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.43        |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.00408     |
|    std                  | 0.862       |
|    value_loss           | 1.22        |
-----------------------------------------
Eval num_timesteps=240000, episode_reward=-99.78 +/- 0.04
Episode length: 3596.60 +/- 8.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.8      |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.03964028 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10.1      |
|    explained_variance   | 0.127      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.669      |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.00255   |
|    std                  | 0.86       |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.83e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 118      |
|    time_elapsed    | 67599    |
|    total_timesteps | 241664   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 119         |
|    time_elapsed         | 67807       |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.023708034 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.00767    |
|    learning_rate        | 0.0003      |
|    loss                 | 3.55        |
|    n_updates            | 1180        |
|    policy_gradient_loss | 0.0026      |
|    std                  | 0.86        |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 120         |
|    time_elapsed         | 68013       |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.017083406 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.669       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.718       |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.0059     |
|    std                  | 0.86        |
|    value_loss           | 2.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 121         |
|    time_elapsed         | 68218       |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.033402678 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.189       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.5         |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.0046     |
|    std                  | 0.858       |
|    value_loss           | 1.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 122         |
|    time_elapsed         | 68424       |
|    total_timesteps      | 249856      |
| train/                  |             |
|    approx_kl            | 0.024093855 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.371       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.955       |
|    n_updates            | 1210        |
|    policy_gradient_loss | -0.00244    |
|    std                  | 0.858       |
|    value_loss           | 3.86        |
-----------------------------------------
Eval num_timesteps=250000, episode_reward=-99.73 +/- 0.05
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.029501513 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.198       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.46        |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00175     |
|    std                  | 0.855       |
|    value_loss           | 1.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 123      |
|    time_elapsed    | 70433    |
|    total_timesteps | 251904   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 124         |
|    time_elapsed         | 70640       |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.021294788 |
|    clip_fraction        | 0.25        |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | -0.00456    |
|    learning_rate        | 0.0003      |
|    loss                 | 20.4        |
|    n_updates            | 1230        |
|    policy_gradient_loss | 4.78e-05    |
|    std                  | 0.855       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 125         |
|    time_elapsed         | 70846       |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.031526405 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10.1       |
|    explained_variance   | 0.103       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.591       |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.00126    |
|    std                  | 0.852       |
|    value_loss           | 1.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.85e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 126         |
|    time_elapsed         | 71051       |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.042772148 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.286       |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00209    |
|    std                  | 0.848       |
|    value_loss           | 1.02        |
-----------------------------------------
Eval num_timesteps=260000, episode_reward=-99.69 +/- 0.04
Episode length: 3600.40 +/- 1.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.7     |
| time/                   |           |
|    total_timesteps      | 260000    |
| train/                  |           |
|    approx_kl            | 0.0334938 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10       |
|    explained_variance   | 0.229     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.459     |
|    n_updates            | 1260      |
|    policy_gradient_loss | 0.00126   |
|    std                  | 0.85      |
|    value_loss           | 0.952     |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.84e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 127      |
|    time_elapsed    | 73061    |
|    total_timesteps | 260096   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.84e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 128         |
|    time_elapsed         | 73266       |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.011639308 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | -0.00362    |
|    learning_rate        | 0.0003      |
|    loss                 | 10.7        |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00112    |
|    std                  | 0.851       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 129        |
|    time_elapsed         | 73472      |
|    total_timesteps      | 264192     |
| train/                  |            |
|    approx_kl            | 0.03768254 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | -0.427     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.735      |
|    n_updates            | 1280       |
|    policy_gradient_loss | -0.00582   |
|    std                  | 0.852      |
|    value_loss           | 1.15       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 130        |
|    time_elapsed         | 73677      |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.03888455 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -10        |
|    explained_variance   | 0.161      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.544      |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.00315   |
|    std                  | 0.85       |
|    value_loss           | 1.28       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 131        |
|    time_elapsed         | 73884      |
|    total_timesteps      | 268288     |
| train/                  |            |
|    approx_kl            | 0.03562925 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.99      |
|    explained_variance   | 0.17       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.623      |
|    n_updates            | 1300       |
|    policy_gradient_loss | -0.00401   |
|    std                  | 0.844      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=270000, episode_reward=-99.75 +/- 0.04
Episode length: 3596.80 +/- 7.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.022179682 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.95       |
|    explained_variance   | -1.46       |
|    learning_rate        | 0.0003      |
|    loss                 | 5.86        |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00634    |
|    std                  | 0.841       |
|    value_loss           | 1.97        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.85e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 132      |
|    time_elapsed    | 75894    |
|    total_timesteps | 270336   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.85e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 133        |
|    time_elapsed         | 76100      |
|    total_timesteps      | 272384     |
| train/                  |            |
|    approx_kl            | 0.05735117 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.94      |
|    explained_variance   | -7.15e-06  |
|    learning_rate        | 0.0003     |
|    loss                 | 337        |
|    n_updates            | 1320       |
|    policy_gradient_loss | -0.00158   |
|    std                  | 0.842      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.86e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 134        |
|    time_elapsed         | 76306      |
|    total_timesteps      | 274432     |
| train/                  |            |
|    approx_kl            | 0.04812166 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.97      |
|    explained_variance   | -0.0287    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.414      |
|    n_updates            | 1330       |
|    policy_gradient_loss | 0.00143    |
|    std                  | 0.846      |
|    value_loss           | 1.08       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 135         |
|    time_elapsed         | 76511       |
|    total_timesteps      | 276480      |
| train/                  |             |
|    approx_kl            | 0.029416263 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | -0.543      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.517       |
|    n_updates            | 1340        |
|    policy_gradient_loss | -0.00768    |
|    std                  | 0.845       |
|    value_loss           | 3.43        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.86e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 136       |
|    time_elapsed         | 76717     |
|    total_timesteps      | 278528    |
| train/                  |           |
|    approx_kl            | 0.0325267 |
|    clip_fraction        | 0.373     |
|    clip_range           | 0.2       |
|    entropy_loss         | -10       |
|    explained_variance   | 0.152     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.601     |
|    n_updates            | 1350      |
|    policy_gradient_loss | -0.00227  |
|    std                  | 0.848     |
|    value_loss           | 1.19      |
---------------------------------------
Eval num_timesteps=280000, episode_reward=-99.75 +/- 0.04
Episode length: 3597.40 +/- 7.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.022971574 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -10         |
|    explained_variance   | 0.0398      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.823       |
|    n_updates            | 1360        |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.845       |
|    value_loss           | 2.61        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 137      |
|    time_elapsed    | 78728    |
|    total_timesteps | 280576   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 138         |
|    time_elapsed         | 78935       |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.009459194 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | -0.000114   |
|    learning_rate        | 0.0003      |
|    loss                 | 144         |
|    n_updates            | 1370        |
|    policy_gradient_loss | 0.00137     |
|    std                  | 0.845       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 139         |
|    time_elapsed         | 79141       |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.030411579 |
|    clip_fraction        | 0.24        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | 0.0575      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.794       |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00356    |
|    std                  | 0.847       |
|    value_loss           | 1.65        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.86e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 140         |
|    time_elapsed         | 79346       |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.019869236 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.0003      |
|    loss                 | 4.72        |
|    n_updates            | 1390        |
|    policy_gradient_loss | -0.0129     |
|    std                  | 0.845       |
|    value_loss           | 2.81        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 141        |
|    time_elapsed         | 79552      |
|    total_timesteps      | 288768     |
| train/                  |            |
|    approx_kl            | 0.04868699 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.98      |
|    explained_variance   | 0.141      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.611      |
|    n_updates            | 1400       |
|    policy_gradient_loss | -0.000871  |
|    std                  | 0.845      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=290000, episode_reward=-99.75 +/- 0.03
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.035058457 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.96       |
|    explained_variance   | 0.261       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.727       |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.841       |
|    value_loss           | 1.56        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.86e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 142      |
|    time_elapsed    | 81559    |
|    total_timesteps | 290816   |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 3.33e+03     |
|    ep_rew_mean          | 1.86e+03     |
| time/                   |              |
|    fps                  | 3            |
|    iterations           | 143          |
|    time_elapsed         | 81768        |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0088619385 |
|    clip_fraction        | 0.108        |
|    clip_range           | 0.2          |
|    entropy_loss         | -9.95        |
|    explained_variance   | -9.24e-05    |
|    learning_rate        | 0.0003       |
|    loss                 | 400          |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.000745    |
|    std                  | 0.841        |
|    value_loss           | 1.05e+03     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 144         |
|    time_elapsed         | 81973       |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.035678793 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | 0.1         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.42        |
|    n_updates            | 1430        |
|    policy_gradient_loss | 0.00157     |
|    std                  | 0.846       |
|    value_loss           | 1.23        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.87e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 145         |
|    time_elapsed         | 82179       |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.024534669 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.99       |
|    explained_variance   | -2.66       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.05        |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00162    |
|    std                  | 0.847       |
|    value_loss           | 2.05        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 146         |
|    time_elapsed         | 82385       |
|    total_timesteps      | 299008      |
| train/                  |             |
|    approx_kl            | 0.046581384 |
|    clip_fraction        | 0.313       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.98       |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.493       |
|    n_updates            | 1450        |
|    policy_gradient_loss | -0.000125   |
|    std                  | 0.845       |
|    value_loss           | 1.05        |
-----------------------------------------
Eval num_timesteps=300000, episode_reward=-99.60 +/- 0.07
Episode length: 3597.00 +/- 6.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.025180403 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.97       |
|    explained_variance   | -0.791      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.495       |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00785    |
|    std                  | 0.844       |
|    value_loss           | 1.37        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.87e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 147      |
|    time_elapsed    | 84395    |
|    total_timesteps | 301056   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.87e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 148        |
|    time_elapsed         | 84603      |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.05358659 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.97      |
|    explained_variance   | -0.000234  |
|    learning_rate        | 0.0003     |
|    loss                 | 361        |
|    n_updates            | 1470       |
|    policy_gradient_loss | -0.00261   |
|    std                  | 0.844      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 149         |
|    time_elapsed         | 84808       |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.046902195 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.92       |
|    explained_variance   | 0.0456      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.487       |
|    n_updates            | 1480        |
|    policy_gradient_loss | 0.00809     |
|    std                  | 0.836       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 150         |
|    time_elapsed         | 85014       |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.018776823 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.87       |
|    explained_variance   | 0.352       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.736       |
|    n_updates            | 1490        |
|    policy_gradient_loss | -0.0117     |
|    std                  | 0.833       |
|    value_loss           | 1.64        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 151         |
|    time_elapsed         | 85219       |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.043990925 |
|    clip_fraction        | 0.3         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.245       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.665       |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00786    |
|    std                  | 0.832       |
|    value_loss           | 1.23        |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-99.59 +/- 0.09
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.048496395 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.601       |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.00645     |
|    std                  | 0.831       |
|    value_loss           | 1.09        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 152      |
|    time_elapsed    | 87228    |
|    total_timesteps | 311296   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 153         |
|    time_elapsed         | 87433       |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.020849599 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.84       |
|    explained_variance   | 0.0037      |
|    learning_rate        | 0.0003      |
|    loss                 | 2.74        |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.00307     |
|    std                  | 0.831       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.88e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 154         |
|    time_elapsed         | 87639       |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.034094952 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.85       |
|    explained_variance   | 0.136       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.46        |
|    n_updates            | 1530        |
|    policy_gradient_loss | 7.04e-05    |
|    std                  | 0.831       |
|    value_loss           | 1.24        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.89e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 155       |
|    time_elapsed         | 87845     |
|    total_timesteps      | 317440    |
| train/                  |           |
|    approx_kl            | 0.0271811 |
|    clip_fraction        | 0.23      |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.83     |
|    explained_variance   | -1.55     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.693     |
|    n_updates            | 1540      |
|    policy_gradient_loss | -0.011    |
|    std                  | 0.829     |
|    value_loss           | 2.31      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 156         |
|    time_elapsed         | 88052       |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.033510916 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.81       |
|    explained_variance   | -0.826      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.587       |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00898    |
|    std                  | 0.825       |
|    value_loss           | 2.33        |
-----------------------------------------
Eval num_timesteps=320000, episode_reward=-99.66 +/- 0.06
Episode length: 3599.00 +/- 4.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.032255944 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | 0.238       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.385       |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00288    |
|    std                  | 0.826       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.88e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 157      |
|    time_elapsed    | 90063    |
|    total_timesteps | 321536   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 158         |
|    time_elapsed         | 90270       |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.010994798 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.8        |
|    explained_variance   | -8.44e-05   |
|    learning_rate        | 0.0003      |
|    loss                 | 508         |
|    n_updates            | 1570        |
|    policy_gradient_loss | 0.000237    |
|    std                  | 0.826       |
|    value_loss           | 1.07e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 159         |
|    time_elapsed         | 90476       |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.035400547 |
|    clip_fraction        | 0.268       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -0.344      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.61        |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.0017     |
|    std                  | 0.826       |
|    value_loss           | 1.37        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.89e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 160       |
|    time_elapsed         | 90682     |
|    total_timesteps      | 327680    |
| train/                  |           |
|    approx_kl            | 0.0355626 |
|    clip_fraction        | 0.319     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.79     |
|    explained_variance   | 0.0645    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.615     |
|    n_updates            | 1590      |
|    policy_gradient_loss | -0.00245  |
|    std                  | 0.826     |
|    value_loss           | 1.32      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 161        |
|    time_elapsed         | 90887      |
|    total_timesteps      | 329728     |
| train/                  |            |
|    approx_kl            | 0.03898243 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.78      |
|    explained_variance   | 0.254      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.718      |
|    n_updates            | 1600       |
|    policy_gradient_loss | 0.00288    |
|    std                  | 0.823      |
|    value_loss           | 1.4        |
----------------------------------------
Eval num_timesteps=330000, episode_reward=-99.71 +/- 0.03
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.041633777 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.78       |
|    explained_variance   | 0.281       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.731       |
|    n_updates            | 1610        |
|    policy_gradient_loss | 0.00361     |
|    std                  | 0.826       |
|    value_loss           | 1.24        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.89e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 162      |
|    time_elapsed    | 92897    |
|    total_timesteps | 331776   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.89e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 163        |
|    time_elapsed         | 93103      |
|    total_timesteps      | 333824     |
| train/                  |            |
|    approx_kl            | 0.07000828 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.79      |
|    explained_variance   | -0.00153   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.07e+03   |
|    n_updates            | 1620       |
|    policy_gradient_loss | 0.0078     |
|    std                  | 0.827      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.89e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 164         |
|    time_elapsed         | 93309       |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.044753864 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.79       |
|    explained_variance   | -0.0274     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.489       |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.00682    |
|    std                  | 0.825       |
|    value_loss           | 1.18        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.9e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 165        |
|    time_elapsed         | 93514      |
|    total_timesteps      | 337920     |
| train/                  |            |
|    approx_kl            | 0.06731994 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.77      |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.71       |
|    n_updates            | 1640       |
|    policy_gradient_loss | -0.00103   |
|    std                  | 0.824      |
|    value_loss           | 1.33       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.9e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 166         |
|    time_elapsed         | 93719       |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.052348766 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.75       |
|    explained_variance   | -3.53       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.645       |
|    n_updates            | 1650        |
|    policy_gradient_loss | 0.000956    |
|    std                  | 0.822       |
|    value_loss           | 3.79        |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-99.72 +/- 0.10
Episode length: 3599.40 +/- 3.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.040228773 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.72       |
|    explained_variance   | 0.258       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.535       |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.000683   |
|    std                  | 0.818       |
|    value_loss           | 1.17        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.9e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 167      |
|    time_elapsed    | 95729    |
|    total_timesteps | 342016   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.91e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 168        |
|    time_elapsed         | 95935      |
|    total_timesteps      | 344064     |
| train/                  |            |
|    approx_kl            | 0.02069466 |
|    clip_fraction        | 0.224      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.71      |
|    explained_variance   | -0.00149   |
|    learning_rate        | 0.0003     |
|    loss                 | 333        |
|    n_updates            | 1670       |
|    policy_gradient_loss | 0.0019     |
|    std                  | 0.818      |
|    value_loss           | 1.04e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.91e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 169         |
|    time_elapsed         | 96140       |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.046151873 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.345      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.683       |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0053     |
|    std                  | 0.819       |
|    value_loss           | 1.34        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 170         |
|    time_elapsed         | 96346       |
|    total_timesteps      | 348160      |
| train/                  |             |
|    approx_kl            | 0.040322892 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.191       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.622       |
|    n_updates            | 1690        |
|    policy_gradient_loss | 0.00199     |
|    std                  | 0.817       |
|    value_loss           | 1.29        |
-----------------------------------------
Eval num_timesteps=350000, episode_reward=-99.75 +/- 0.04
Episode length: 3597.60 +/- 6.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.8       |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.042692065 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.7        |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.672       |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.00278    |
|    std                  | 0.819       |
|    value_loss           | 1.16        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.92e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 171      |
|    time_elapsed    | 98356    |
|    total_timesteps | 350208   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.92e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 172         |
|    time_elapsed         | 98562       |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.009000855 |
|    clip_fraction        | 0.0783      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.00378    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.54e+03    |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00275    |
|    std                  | 0.819       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 173         |
|    time_elapsed         | 98768       |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.009153765 |
|    clip_fraction        | 0.0604      |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -6.14       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.21        |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00947    |
|    std                  | 0.819       |
|    value_loss           | 4.19        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 174         |
|    time_elapsed         | 98973       |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.018276293 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.71       |
|    explained_variance   | -0.645      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.621       |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.0137     |
|    std                  | 0.818       |
|    value_loss           | 1.68        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 1.94e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 175       |
|    time_elapsed         | 99179     |
|    total_timesteps      | 358400    |
| train/                  |           |
|    approx_kl            | 0.0718167 |
|    clip_fraction        | 0.322     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.69     |
|    explained_variance   | 0.192     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.675     |
|    n_updates            | 1740      |
|    policy_gradient_loss | 0.00432   |
|    std                  | 0.815     |
|    value_loss           | 1.25      |
---------------------------------------
Eval num_timesteps=360000, episode_reward=-99.65 +/- 0.07
Episode length: 3599.00 +/- 3.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 360000     |
| train/                  |            |
|    approx_kl            | 0.04580868 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.67      |
|    explained_variance   | -1.01      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.781      |
|    n_updates            | 1750       |
|    policy_gradient_loss | -0.00415   |
|    std                  | 0.814      |
|    value_loss           | 2.24       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.93e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 176      |
|    time_elapsed    | 101190   |
|    total_timesteps | 360448   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.93e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 177         |
|    time_elapsed         | 101395      |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.017365074 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.67       |
|    explained_variance   | 0.00382     |
|    learning_rate        | 0.0003      |
|    loss                 | 17.4        |
|    n_updates            | 1760        |
|    policy_gradient_loss | -0.00124    |
|    std                  | 0.814       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.95e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 178        |
|    time_elapsed         | 101601     |
|    total_timesteps      | 364544     |
| train/                  |            |
|    approx_kl            | 0.06965974 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | 0.0814     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.732      |
|    n_updates            | 1770       |
|    policy_gradient_loss | 0.0314     |
|    std                  | 0.809      |
|    value_loss           | 1.48       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.95e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 179        |
|    time_elapsed         | 101806     |
|    total_timesteps      | 366592     |
| train/                  |            |
|    approx_kl            | 0.07052423 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.64      |
|    explained_variance   | 0.154      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.743      |
|    n_updates            | 1780       |
|    policy_gradient_loss | 0.00675    |
|    std                  | 0.814      |
|    value_loss           | 1.44       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.95e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 180         |
|    time_elapsed         | 102012      |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.046336923 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.65       |
|    explained_variance   | 0.23        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.435       |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00382    |
|    std                  | 0.812       |
|    value_loss           | 1.12        |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-99.71 +/- 0.03
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.049470432 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.63       |
|    explained_variance   | 0.261       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.689       |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.00287     |
|    std                  | 0.81        |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.94e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 181      |
|    time_elapsed    | 104020   |
|    total_timesteps | 370688   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.94e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 182         |
|    time_elapsed         | 104225      |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.024986811 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.61       |
|    explained_variance   | 0.0025      |
|    learning_rate        | 0.0003      |
|    loss                 | 60.8        |
|    n_updates            | 1810        |
|    policy_gradient_loss | 0.00449     |
|    std                  | 0.81        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 3.34e+03 |
|    ep_rew_mean          | 1.96e+03 |
| time/                   |          |
|    fps                  | 3        |
|    iterations           | 183      |
|    time_elapsed         | 104431   |
|    total_timesteps      | 374784   |
| train/                  |          |
|    approx_kl            | 0.057738 |
|    clip_fraction        | 0.293    |
|    clip_range           | 0.2      |
|    entropy_loss         | -9.6     |
|    explained_variance   | 0.134    |
|    learning_rate        | 0.0003   |
|    loss                 | 0.79     |
|    n_updates            | 1820     |
|    policy_gradient_loss | 0.00506  |
|    std                  | 0.807    |
|    value_loss           | 1.53     |
--------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.96e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 184        |
|    time_elapsed         | 104638     |
|    total_timesteps      | 376832     |
| train/                  |            |
|    approx_kl            | 0.05151356 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.57      |
|    explained_variance   | 0.208      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.699      |
|    n_updates            | 1830       |
|    policy_gradient_loss | 0.00657    |
|    std                  | 0.805      |
|    value_loss           | 1.35       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 185         |
|    time_elapsed         | 104844      |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.051766932 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.56       |
|    explained_variance   | 0.235       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.03        |
|    n_updates            | 1840        |
|    policy_gradient_loss | 0.00758     |
|    std                  | 0.805       |
|    value_loss           | 1.33        |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-99.70 +/- 0.06
Episode length: 3596.80 +/- 6.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.025478873 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.54       |
|    explained_variance   | -3.65       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.979       |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.00173    |
|    std                  | 0.801       |
|    value_loss           | 2.28        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.96e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 186      |
|    time_elapsed    | 106852   |
|    total_timesteps | 380928   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.96e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 187         |
|    time_elapsed         | 107060      |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.020011578 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.53       |
|    explained_variance   | 0.0035      |
|    learning_rate        | 0.0003      |
|    loss                 | 594         |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.00472     |
|    std                  | 0.802       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.97e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 188        |
|    time_elapsed         | 107266     |
|    total_timesteps      | 385024     |
| train/                  |            |
|    approx_kl            | 0.28277993 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.51      |
|    explained_variance   | -0.106     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.658      |
|    n_updates            | 1870       |
|    policy_gradient_loss | 0.0251     |
|    std                  | 0.797      |
|    value_loss           | 1.48       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.97e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 189        |
|    time_elapsed         | 107474     |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.04297214 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.49      |
|    explained_variance   | -2.68      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.772      |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.00113   |
|    std                  | 0.797      |
|    value_loss           | 1.95       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.98e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 190        |
|    time_elapsed         | 107680     |
|    total_timesteps      | 389120     |
| train/                  |            |
|    approx_kl            | 0.07130137 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | 0.276      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.705      |
|    n_updates            | 1890       |
|    policy_gradient_loss | 0.00684    |
|    std                  | 0.799      |
|    value_loss           | 1.29       |
----------------------------------------
Eval num_timesteps=390000, episode_reward=-99.72 +/- 0.03
Episode length: 3597.20 +/- 7.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 390000      |
| train/                  |             |
|    approx_kl            | 0.031117555 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.5        |
|    explained_variance   | 0.274       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.55        |
|    n_updates            | 1900        |
|    policy_gradient_loss | -0.00439    |
|    std                  | 0.798       |
|    value_loss           | 1.54        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.97e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 191      |
|    time_elapsed    | 109689   |
|    total_timesteps | 391168   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 1.97e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 192        |
|    time_elapsed         | 109895     |
|    total_timesteps      | 393216     |
| train/                  |            |
|    approx_kl            | 0.05429975 |
|    clip_fraction        | 0.206      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.5       |
|    explained_variance   | -0.00145   |
|    learning_rate        | 0.0003     |
|    loss                 | 2.11e+03   |
|    n_updates            | 1910       |
|    policy_gradient_loss | 0.00735    |
|    std                  | 0.797      |
|    value_loss           | 1.06e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 1.98e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 193        |
|    time_elapsed         | 110101     |
|    total_timesteps      | 395264     |
| train/                  |            |
|    approx_kl            | 0.13062863 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.48      |
|    explained_variance   | -0.379     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.799      |
|    n_updates            | 1920       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.796      |
|    value_loss           | 1.48       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.99e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 194         |
|    time_elapsed         | 110306      |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.044203654 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | 0.168       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.488       |
|    n_updates            | 1930        |
|    policy_gradient_loss | 0.000761    |
|    std                  | 0.795       |
|    value_loss           | 1.14        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 1.99e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 195         |
|    time_elapsed         | 110514      |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.021645406 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.47       |
|    explained_variance   | -2.05       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.555       |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00108    |
|    std                  | 0.794       |
|    value_loss           | 2.38        |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-99.73 +/- 0.04
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.058962967 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.45       |
|    explained_variance   | 0.223       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 1950        |
|    policy_gradient_loss | 0.00138     |
|    std                  | 0.794       |
|    value_loss           | 1.35        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.98e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 196      |
|    time_elapsed    | 112521   |
|    total_timesteps | 401408   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 1.98e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 197         |
|    time_elapsed         | 112727      |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.024289185 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.45       |
|    explained_variance   | -0.00359    |
|    learning_rate        | 0.0003      |
|    loss                 | 7.33        |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00428     |
|    std                  | 0.793       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 198        |
|    time_elapsed         | 112936     |
|    total_timesteps      | 405504     |
| train/                  |            |
|    approx_kl            | 0.05095939 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.44      |
|    explained_variance   | 0.0816     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.553      |
|    n_updates            | 1970       |
|    policy_gradient_loss | 8.61e-06   |
|    std                  | 0.793      |
|    value_loss           | 1.2        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 199        |
|    time_elapsed         | 113143     |
|    total_timesteps      | 407552     |
| train/                  |            |
|    approx_kl            | 0.04869154 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.44      |
|    explained_variance   | 0.254      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.895      |
|    n_updates            | 1980       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.793      |
|    value_loss           | 1.31       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2e+03      |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 200        |
|    time_elapsed         | 113348     |
|    total_timesteps      | 409600     |
| train/                  |            |
|    approx_kl            | 0.04585194 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.43      |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.6        |
|    n_updates            | 1990       |
|    policy_gradient_loss | 0.0053     |
|    std                  | 0.793      |
|    value_loss           | 1.26       |
----------------------------------------
Eval num_timesteps=410000, episode_reward=-99.68 +/- 0.03
Episode length: 3600.00 +/- 2.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.048308358 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.43       |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.43        |
|    n_updates            | 2000        |
|    policy_gradient_loss | 0.00552     |
|    std                  | 0.792       |
|    value_loss           | 1.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 1.99e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 201      |
|    time_elapsed    | 115355   |
|    total_timesteps | 411648   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 202        |
|    time_elapsed         | 115561     |
|    total_timesteps      | 413696     |
| train/                  |            |
|    approx_kl            | 0.02633446 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.42      |
|    explained_variance   | 0.00132    |
|    learning_rate        | 0.0003     |
|    loss                 | 169        |
|    n_updates            | 2010       |
|    policy_gradient_loss | -0.00421   |
|    std                  | 0.792      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 203         |
|    time_elapsed         | 115769      |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.036097106 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.42       |
|    explained_variance   | -3.77       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.544       |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00526    |
|    std                  | 0.792       |
|    value_loss           | 1.46        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 204        |
|    time_elapsed         | 115977     |
|    total_timesteps      | 417792     |
| train/                  |            |
|    approx_kl            | 0.04191861 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.39      |
|    explained_variance   | 0.277      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.957      |
|    n_updates            | 2030       |
|    policy_gradient_loss | 0.00666    |
|    std                  | 0.785      |
|    value_loss           | 1.46       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.01e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 205        |
|    time_elapsed         | 116184     |
|    total_timesteps      | 419840     |
| train/                  |            |
|    approx_kl            | 0.07029948 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.34      |
|    explained_variance   | 0.188      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.594      |
|    n_updates            | 2040       |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.782      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=420000, episode_reward=-99.71 +/- 0.04
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.054999493 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.29        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.573       |
|    n_updates            | 2050        |
|    policy_gradient_loss | 0.0106      |
|    std                  | 0.782       |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2e+03    |
| time/              |          |
|    fps             | 3        |
|    iterations      | 206      |
|    time_elapsed    | 118191   |
|    total_timesteps | 421888   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 207         |
|    time_elapsed         | 118396      |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.011619794 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | -0.00258    |
|    learning_rate        | 0.0003      |
|    loss                 | 927         |
|    n_updates            | 2060        |
|    policy_gradient_loss | 0.00291     |
|    std                  | 0.781       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 208        |
|    time_elapsed         | 118602     |
|    total_timesteps      | 425984     |
| train/                  |            |
|    approx_kl            | 0.03635167 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.31      |
|    explained_variance   | -0.378     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.587      |
|    n_updates            | 2070       |
|    policy_gradient_loss | -0.0116    |
|    std                  | 0.781      |
|    value_loss           | 1.83       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.02e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 209        |
|    time_elapsed         | 118808     |
|    total_timesteps      | 428032     |
| train/                  |            |
|    approx_kl            | 0.09055994 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.32      |
|    explained_variance   | 0.136      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.51       |
|    n_updates            | 2080       |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.784      |
|    value_loss           | 1.19       |
----------------------------------------
Eval num_timesteps=430000, episode_reward=-99.66 +/- 0.07
Episode length: 3600.60 +/- 0.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.060532622 |
|    clip_fraction        | 0.43        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | 0.222       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.642       |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.00997     |
|    std                  | 0.786       |
|    value_loss           | 1.14        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.01e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 210      |
|    time_elapsed    | 120818   |
|    total_timesteps | 430080   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.01e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 211         |
|    time_elapsed         | 121023      |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.048642002 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.36       |
|    explained_variance   | 0.00157     |
|    learning_rate        | 0.0003      |
|    loss                 | 16          |
|    n_updates            | 2100        |
|    policy_gradient_loss | 0.00413     |
|    std                  | 0.786       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 212        |
|    time_elapsed         | 121229     |
|    total_timesteps      | 434176     |
| train/                  |            |
|    approx_kl            | 0.06477702 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.33      |
|    explained_variance   | -0.954     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.686      |
|    n_updates            | 2110       |
|    policy_gradient_loss | 0.00442    |
|    std                  | 0.782      |
|    value_loss           | 1.48       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 213         |
|    time_elapsed         | 121434      |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.054883204 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | -1.1        |
|    learning_rate        | 0.0003      |
|    loss                 | 2.8         |
|    n_updates            | 2120        |
|    policy_gradient_loss | 0.00978     |
|    std                  | 0.784       |
|    value_loss           | 5.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 214         |
|    time_elapsed         | 121640      |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.059803747 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.33       |
|    explained_variance   | 0.243       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.658       |
|    n_updates            | 2130        |
|    policy_gradient_loss | 0.0169      |
|    std                  | 0.783       |
|    value_loss           | 1.01        |
-----------------------------------------
Eval num_timesteps=440000, episode_reward=-99.59 +/- 0.05
Episode length: 3596.00 +/- 9.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.044619385 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | -0.845      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.605       |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.00134     |
|    std                  | 0.775       |
|    value_loss           | 2.05        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.02e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 215      |
|    time_elapsed    | 123650   |
|    total_timesteps | 440320   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.02e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 216         |
|    time_elapsed         | 123858      |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.012250533 |
|    clip_fraction        | 0.107       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.25       |
|    explained_variance   | -0.00125    |
|    learning_rate        | 0.0003      |
|    loss                 | 822         |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.775       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.03e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 217        |
|    time_elapsed         | 124064     |
|    total_timesteps      | 444416     |
| train/                  |            |
|    approx_kl            | 0.09746192 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.26      |
|    explained_variance   | 0.0719     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.578      |
|    n_updates            | 2160       |
|    policy_gradient_loss | 0.00759    |
|    std                  | 0.778      |
|    value_loss           | 1.17       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 218         |
|    time_elapsed         | 124269      |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.033574365 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | -1.84       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.538       |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.00178    |
|    std                  | 0.779       |
|    value_loss           | 1.71        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 219         |
|    time_elapsed         | 124475      |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.058337633 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.28       |
|    explained_variance   | 0.249       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.81        |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.00174     |
|    std                  | 0.78        |
|    value_loss           | 1.67        |
-----------------------------------------
Eval num_timesteps=450000, episode_reward=-99.67 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 450000      |
| train/                  |             |
|    approx_kl            | 0.030584387 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.3        |
|    explained_variance   | -0.568      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.457       |
|    n_updates            | 2190        |
|    policy_gradient_loss | 0.00489     |
|    std                  | 0.783       |
|    value_loss           | 1.58        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.03e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 220      |
|    time_elapsed    | 126481   |
|    total_timesteps | 450560   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.03e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 221         |
|    time_elapsed         | 126688      |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.012760356 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | -0.00152    |
|    learning_rate        | 0.0003      |
|    loss                 | 162         |
|    n_updates            | 2200        |
|    policy_gradient_loss | -0.00279    |
|    std                  | 0.782       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.04e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 222        |
|    time_elapsed         | 126894     |
|    total_timesteps      | 454656     |
| train/                  |            |
|    approx_kl            | 0.14294064 |
|    clip_fraction        | 0.525      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.35      |
|    explained_variance   | 0.0421     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.498      |
|    n_updates            | 2210       |
|    policy_gradient_loss | 0.0313     |
|    std                  | 0.788      |
|    value_loss           | 1.02       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 223         |
|    time_elapsed         | 127100      |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.081573084 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.35       |
|    explained_variance   | -0.671      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.356       |
|    n_updates            | 2220        |
|    policy_gradient_loss | 0.00864     |
|    std                  | 0.785       |
|    value_loss           | 1.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 224         |
|    time_elapsed         | 127305      |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.080689356 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.32       |
|    explained_variance   | 0.19        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.58        |
|    n_updates            | 2230        |
|    policy_gradient_loss | 0.0181      |
|    std                  | 0.783       |
|    value_loss           | 1.24        |
-----------------------------------------
Eval num_timesteps=460000, episode_reward=-99.72 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.02974644 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.3       |
|    explained_variance   | 0.0385     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.557      |
|    n_updates            | 2240       |
|    policy_gradient_loss | -0.000537  |
|    std                  | 0.78       |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.04e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 225      |
|    time_elapsed    | 129317   |
|    total_timesteps | 460800   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.04e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 226         |
|    time_elapsed         | 129524      |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.020783368 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.29       |
|    explained_variance   | 0.000389    |
|    learning_rate        | 0.0003      |
|    loss                 | 2e+03       |
|    n_updates            | 2250        |
|    policy_gradient_loss | 0.000791    |
|    std                  | 0.78        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 227        |
|    time_elapsed         | 129731     |
|    total_timesteps      | 464896     |
| train/                  |            |
|    approx_kl            | 0.07367557 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.28      |
|    explained_variance   | -0.44      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.71       |
|    n_updates            | 2260       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.778      |
|    value_loss           | 1.36       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.05e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 228        |
|    time_elapsed         | 129937     |
|    total_timesteps      | 466944     |
| train/                  |            |
|    approx_kl            | 0.04818979 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.24      |
|    explained_variance   | 0.22       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.513      |
|    n_updates            | 2270       |
|    policy_gradient_loss | 0.0045     |
|    std                  | 0.772      |
|    value_loss           | 1.39       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 229         |
|    time_elapsed         | 130143      |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.055493366 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.19       |
|    explained_variance   | 0.176       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.632       |
|    n_updates            | 2280        |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.77        |
|    value_loss           | 1.4         |
-----------------------------------------
Eval num_timesteps=470000, episode_reward=-99.65 +/- 0.02
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.06520635 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.16      |
|    explained_variance   | 0.259      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.716      |
|    n_updates            | 2290       |
|    policy_gradient_loss | 0.00258    |
|    std                  | 0.767      |
|    value_loss           | 1.51       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 230      |
|    time_elapsed    | 132150   |
|    total_timesteps | 471040   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 231         |
|    time_elapsed         | 132359      |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.032629333 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.15       |
|    explained_variance   | -0.0021     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.53        |
|    n_updates            | 2300        |
|    policy_gradient_loss | 0.00364     |
|    std                  | 0.767       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.06e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 232       |
|    time_elapsed         | 132566    |
|    total_timesteps      | 475136    |
| train/                  |           |
|    approx_kl            | 0.1924755 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | -9.15     |
|    explained_variance   | 0.193     |
|    learning_rate        | 0.0003    |
|    loss                 | 6.15      |
|    n_updates            | 2310      |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.767     |
|    value_loss           | 22.5      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 233        |
|    time_elapsed         | 132772     |
|    total_timesteps      | 477184     |
| train/                  |            |
|    approx_kl            | 0.12841058 |
|    clip_fraction        | 0.515      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.14      |
|    explained_variance   | -0.0159    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.682      |
|    n_updates            | 2320       |
|    policy_gradient_loss | 0.0271     |
|    std                  | 0.765      |
|    value_loss           | 1.3        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.06e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 234        |
|    time_elapsed         | 132977     |
|    total_timesteps      | 479232     |
| train/                  |            |
|    approx_kl            | 0.05971656 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -9.12      |
|    explained_variance   | 0.14       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.776      |
|    n_updates            | 2330       |
|    policy_gradient_loss | -0.00424   |
|    std                  | 0.764      |
|    value_loss           | 1.47       |
----------------------------------------
Eval num_timesteps=480000, episode_reward=-99.71 +/- 0.02
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.7       |
| time/                   |             |
|    total_timesteps      | 480000      |
| train/                  |             |
|    approx_kl            | 0.041354798 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.11       |
|    explained_variance   | 0.236       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.589       |
|    n_updates            | 2340        |
|    policy_gradient_loss | 0.0019      |
|    std                  | 0.762       |
|    value_loss           | 1.41        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.05e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 235      |
|    time_elapsed    | 134986   |
|    total_timesteps | 481280   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.05e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 236         |
|    time_elapsed         | 135191      |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.011703124 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.09       |
|    explained_variance   | -0.00534    |
|    learning_rate        | 0.0003      |
|    loss                 | 60.4        |
|    n_updates            | 2350        |
|    policy_gradient_loss | 0.00101     |
|    std                  | 0.762       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.06e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 237         |
|    time_elapsed         | 135397      |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.055319592 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.07       |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.612       |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00362    |
|    std                  | 0.759       |
|    value_loss           | 1.21        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 238         |
|    time_elapsed         | 135603      |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.038726836 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -9.04       |
|    explained_variance   | -0.511      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.654       |
|    n_updates            | 2370        |
|    policy_gradient_loss | -0.011      |
|    std                  | 0.759       |
|    value_loss           | 2.47        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 239        |
|    time_elapsed         | 135808     |
|    total_timesteps      | 489472     |
| train/                  |            |
|    approx_kl            | 0.04270033 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -9         |
|    explained_variance   | 0.0905     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.574      |
|    n_updates            | 2380       |
|    policy_gradient_loss | -0.00725   |
|    std                  | 0.75       |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=490000, episode_reward=-99.65 +/- 0.04
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.044754267 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.94       |
|    explained_variance   | 0.301       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.971       |
|    n_updates            | 2390        |
|    policy_gradient_loss | 0.0052      |
|    std                  | 0.748       |
|    value_loss           | 1.34        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.06e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 240      |
|    time_elapsed    | 137815   |
|    total_timesteps | 491520   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.06e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 241       |
|    time_elapsed         | 138020    |
|    total_timesteps      | 493568    |
| train/                  |           |
|    approx_kl            | 0.1170527 |
|    clip_fraction        | 0.287     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.92     |
|    explained_variance   | -0.00221  |
|    learning_rate        | 0.0003    |
|    loss                 | 4.8       |
|    n_updates            | 2400      |
|    policy_gradient_loss | 0.00378   |
|    std                  | 0.746     |
|    value_loss           | 1.04e+03  |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.07e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 242       |
|    time_elapsed         | 138226    |
|    total_timesteps      | 495616    |
| train/                  |           |
|    approx_kl            | 0.0596272 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.9      |
|    explained_variance   | -0.0452   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.578     |
|    n_updates            | 2410      |
|    policy_gradient_loss | 0.00949   |
|    std                  | 0.743     |
|    value_loss           | 1.16      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.07e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 243        |
|    time_elapsed         | 138437     |
|    total_timesteps      | 497664     |
| train/                  |            |
|    approx_kl            | 0.07338607 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.87      |
|    explained_variance   | -2.74      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.958      |
|    n_updates            | 2420       |
|    policy_gradient_loss | 0.00709    |
|    std                  | 0.741      |
|    value_loss           | 3.62       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.07e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 244         |
|    time_elapsed         | 138643      |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.039690673 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.83       |
|    explained_variance   | 0.3         |
|    learning_rate        | 0.0003      |
|    loss                 | 0.695       |
|    n_updates            | 2430        |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.736       |
|    value_loss           | 1.21        |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-99.64 +/- 0.06
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.03735351 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.79      |
|    explained_variance   | 0.337      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.517      |
|    n_updates            | 2440       |
|    policy_gradient_loss | 0.000605   |
|    std                  | 0.736      |
|    value_loss           | 1.23       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 245      |
|    time_elapsed    | 140650   |
|    total_timesteps | 501760   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 246         |
|    time_elapsed         | 140856      |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.016292946 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.00304     |
|    learning_rate        | 0.0003      |
|    loss                 | 7.5         |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00273    |
|    std                  | 0.736       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 247         |
|    time_elapsed         | 141061      |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.059004135 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | -0.0971     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.01        |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.006      |
|    std                  | 0.735       |
|    value_loss           | 1.48        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 248         |
|    time_elapsed         | 141268      |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.033682093 |
|    clip_fraction        | 0.323       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.78       |
|    explained_variance   | 0.361       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.54        |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.0079     |
|    std                  | 0.735       |
|    value_loss           | 1.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 249         |
|    time_elapsed         | 141473      |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.059867907 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.79       |
|    explained_variance   | 0.289       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.579       |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.00823     |
|    std                  | 0.737       |
|    value_loss           | 1.26        |
-----------------------------------------
Eval num_timesteps=510000, episode_reward=-99.72 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 510000     |
| train/                  |            |
|    approx_kl            | 0.06946662 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.79      |
|    explained_variance   | 0.25       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.442      |
|    n_updates            | 2490       |
|    policy_gradient_loss | 0.00636    |
|    std                  | 0.733      |
|    value_loss           | 1.42       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.07e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 250      |
|    time_elapsed    | 143482   |
|    total_timesteps | 512000   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 251         |
|    time_elapsed         | 143687      |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.010196046 |
|    clip_fraction        | 0.151       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.77       |
|    explained_variance   | -0.000304   |
|    learning_rate        | 0.0003      |
|    loss                 | 79          |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.000647   |
|    std                  | 0.733       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 252         |
|    time_elapsed         | 143893      |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.045215122 |
|    clip_fraction        | 0.302       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.76       |
|    explained_variance   | -2.89       |
|    learning_rate        | 0.0003      |
|    loss                 | 6.14        |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.00127    |
|    std                  | 0.731       |
|    value_loss           | 2.42        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 253         |
|    time_elapsed         | 144099      |
|    total_timesteps      | 518144      |
| train/                  |             |
|    approx_kl            | 0.053223442 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.74       |
|    explained_variance   | 0.23        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.704       |
|    n_updates            | 2520        |
|    policy_gradient_loss | 0.00391     |
|    std                  | 0.728       |
|    value_loss           | 1.84        |
-----------------------------------------
Eval num_timesteps=520000, episode_reward=-99.61 +/- 0.07
Episode length: 3600.60 +/- 0.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 520000    |
| train/                  |           |
|    approx_kl            | 0.0686053 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.7      |
|    explained_variance   | -0.483    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.669     |
|    n_updates            | 2530      |
|    policy_gradient_loss | 0.000976  |
|    std                  | 0.726     |
|    value_loss           | 1.31      |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.08e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 254      |
|    time_elapsed    | 146108   |
|    total_timesteps | 520192   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.08e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 255         |
|    time_elapsed         | 146315      |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.014798167 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.69       |
|    explained_variance   | 0.00145     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.79        |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.726       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 256         |
|    time_elapsed         | 146521      |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.084998995 |
|    clip_fraction        | 0.517       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.67       |
|    explained_variance   | -0.0537     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.629       |
|    n_updates            | 2550        |
|    policy_gradient_loss | 0.0315      |
|    std                  | 0.723       |
|    value_loss           | 0.96        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 257         |
|    time_elapsed         | 146726      |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.043531284 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.137       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.99        |
|    n_updates            | 2560        |
|    policy_gradient_loss | 0.00803     |
|    std                  | 0.72        |
|    value_loss           | 1.43        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 258        |
|    time_elapsed         | 146932     |
|    total_timesteps      | 528384     |
| train/                  |            |
|    approx_kl            | 0.04739818 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.192      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.418      |
|    n_updates            | 2570       |
|    policy_gradient_loss | 0.00791    |
|    std                  | 0.719      |
|    value_loss           | 1.35       |
----------------------------------------
Eval num_timesteps=530000, episode_reward=-99.59 +/- 0.09
Episode length: 3600.80 +/- 0.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.031078076 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.62       |
|    explained_variance   | -2.4        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.717       |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.00697    |
|    std                  | 0.718       |
|    value_loss           | 1.76        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 259      |
|    time_elapsed    | 148939   |
|    total_timesteps | 530432   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.09e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 260        |
|    time_elapsed         | 149144     |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.13270092 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.63      |
|    explained_variance   | 0.00523    |
|    learning_rate        | 0.0003     |
|    loss                 | 32.6       |
|    n_updates            | 2590       |
|    policy_gradient_loss | 0.00572    |
|    std                  | 0.72       |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 261         |
|    time_elapsed         | 149352      |
|    total_timesteps      | 534528      |
| train/                  |             |
|    approx_kl            | 0.059278667 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.66       |
|    explained_variance   | -0.321      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.625       |
|    n_updates            | 2600        |
|    policy_gradient_loss | 0.021       |
|    std                  | 0.723       |
|    value_loss           | 1.29        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 262         |
|    time_elapsed         | 149559      |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.037400097 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.12        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.701       |
|    n_updates            | 2610        |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.725       |
|    value_loss           | 1.46        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 263         |
|    time_elapsed         | 149764      |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.049718812 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.68       |
|    explained_variance   | 0.166       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.873       |
|    n_updates            | 2620        |
|    policy_gradient_loss | -0.00181    |
|    std                  | 0.724       |
|    value_loss           | 1.31        |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-99.62 +/- 0.05
Episode length: 3599.60 +/- 1.74
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 540000      |
| train/                  |             |
|    approx_kl            | 0.039121438 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.65       |
|    explained_variance   | 0.231       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.503       |
|    n_updates            | 2630        |
|    policy_gradient_loss | 0.0059      |
|    std                  | 0.721       |
|    value_loss           | 0.977       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.09e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 264      |
|    time_elapsed    | 151773   |
|    total_timesteps | 540672   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.09e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 265         |
|    time_elapsed         | 151979      |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.034931574 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.64       |
|    explained_variance   | 0.000205    |
|    learning_rate        | 0.0003      |
|    loss                 | 86.6        |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.000938   |
|    std                  | 0.721       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.1e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 266        |
|    time_elapsed         | 152184     |
|    total_timesteps      | 544768     |
| train/                  |            |
|    approx_kl            | 0.11742928 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.61      |
|    explained_variance   | 0.129      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.772      |
|    n_updates            | 2650       |
|    policy_gradient_loss | -0.00142   |
|    std                  | 0.717      |
|    value_loss           | 1.09       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 267         |
|    time_elapsed         | 152389      |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.045451105 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.56       |
|    explained_variance   | -2.07       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.934       |
|    n_updates            | 2660        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.714       |
|    value_loss           | 2.38        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.11e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 268       |
|    time_elapsed         | 152595    |
|    total_timesteps      | 548864    |
| train/                  |           |
|    approx_kl            | 0.0475794 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.54     |
|    explained_variance   | 0.187     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.713     |
|    n_updates            | 2670      |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.712     |
|    value_loss           | 1.1       |
---------------------------------------
Eval num_timesteps=550000, episode_reward=-99.63 +/- 0.05
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.035876017 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | 0.247       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.558       |
|    n_updates            | 2680        |
|    policy_gradient_loss | -0.00329    |
|    std                  | 0.709       |
|    value_loss           | 1.24        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 269      |
|    time_elapsed    | 154603   |
|    total_timesteps | 550912   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 270         |
|    time_elapsed         | 154808      |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.028103517 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.00192     |
|    learning_rate        | 0.0003      |
|    loss                 | 566         |
|    n_updates            | 2690        |
|    policy_gradient_loss | 0.00298     |
|    std                  | 0.709       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 271        |
|    time_elapsed         | 155014     |
|    total_timesteps      | 555008     |
| train/                  |            |
|    approx_kl            | 0.09624581 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.0202     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.806      |
|    n_updates            | 2700       |
|    policy_gradient_loss | 0.0201     |
|    std                  | 0.71       |
|    value_loss           | 1.16       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.11e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 272        |
|    time_elapsed         | 155223     |
|    total_timesteps      | 557056     |
| train/                  |            |
|    approx_kl            | 0.04229421 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.48      |
|    explained_variance   | 0.158      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.575      |
|    n_updates            | 2710       |
|    policy_gradient_loss | 0.000889   |
|    std                  | 0.711      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.11e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 273       |
|    time_elapsed         | 155432    |
|    total_timesteps      | 559104    |
| train/                  |           |
|    approx_kl            | 0.1346167 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.52     |
|    explained_variance   | 0.185     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.496     |
|    n_updates            | 2720      |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.715     |
|    value_loss           | 1.08      |
---------------------------------------
Eval num_timesteps=560000, episode_reward=-99.67 +/- 0.02
Episode length: 3600.20 +/- 1.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.04105124 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.53      |
|    explained_variance   | 0.25       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.634      |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.00181   |
|    std                  | 0.714      |
|    value_loss           | 1.23       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.1e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 274      |
|    time_elapsed    | 157440   |
|    total_timesteps | 561152   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.1e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 275         |
|    time_elapsed         | 157645      |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.035464805 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.53       |
|    explained_variance   | -0.00238    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.18e+03    |
|    n_updates            | 2740        |
|    policy_gradient_loss | 0.00134     |
|    std                  | 0.714       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 276        |
|    time_elapsed         | 157851     |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.09612675 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.55      |
|    explained_variance   | -0.306     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.374      |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.717      |
|    value_loss           | 1.13       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 277         |
|    time_elapsed         | 158056      |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.048127666 |
|    clip_fraction        | 0.386       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.55       |
|    explained_variance   | 0.128       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.915       |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.0117      |
|    std                  | 0.714       |
|    value_loss           | 1.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.12e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 278         |
|    time_elapsed         | 158262      |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.030963853 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.52       |
|    explained_variance   | -3.46       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.781       |
|    n_updates            | 2770        |
|    policy_gradient_loss | -0.00445    |
|    std                  | 0.713       |
|    value_loss           | 3.43        |
-----------------------------------------
Eval num_timesteps=570000, episode_reward=-99.66 +/- 0.02
Episode length: 3595.20 +/- 7.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.7      |
| time/                   |            |
|    total_timesteps      | 570000     |
| train/                  |            |
|    approx_kl            | 0.05382093 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | 0.156      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.523      |
|    n_updates            | 2780       |
|    policy_gradient_loss | -0.000854  |
|    std                  | 0.709      |
|    value_loss           | 1.22       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.11e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 279      |
|    time_elapsed    | 160274   |
|    total_timesteps | 571392   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.11e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 280         |
|    time_elapsed         | 160481      |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.032673247 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.48       |
|    explained_variance   | 0.000769    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.07e+03    |
|    n_updates            | 2790        |
|    policy_gradient_loss | 0.0065      |
|    std                  | 0.709       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.12e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 281        |
|    time_elapsed         | 160686     |
|    total_timesteps      | 575488     |
| train/                  |            |
|    approx_kl            | 0.03735868 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | 0.124      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.673      |
|    n_updates            | 2800       |
|    policy_gradient_loss | 0.000149   |
|    std                  | 0.71       |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 282        |
|    time_elapsed         | 160892     |
|    total_timesteps      | 577536     |
| train/                  |            |
|    approx_kl            | 0.06642747 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | 0.11       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.545      |
|    n_updates            | 2810       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.713      |
|    value_loss           | 1.14       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 283         |
|    time_elapsed         | 161097      |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.051756773 |
|    clip_fraction        | 0.326       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.51       |
|    explained_variance   | -2.16       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.693       |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.0037     |
|    std                  | 0.709       |
|    value_loss           | 1.76        |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=-99.59 +/- 0.07
Episode length: 3599.40 +/- 3.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.06986046 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.49      |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.687      |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.000483  |
|    std                  | 0.71       |
|    value_loss           | 1.39       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.12e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 284      |
|    time_elapsed    | 163108   |
|    total_timesteps | 581632   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 285         |
|    time_elapsed         | 163314      |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.020539854 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.5        |
|    explained_variance   | 0.000267    |
|    learning_rate        | 0.0003      |
|    loss                 | 317         |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.71        |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 286        |
|    time_elapsed         | 163519     |
|    total_timesteps      | 585728     |
| train/                  |            |
|    approx_kl            | 0.03526815 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.5       |
|    explained_variance   | -2.22      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.637      |
|    n_updates            | 2850       |
|    policy_gradient_loss | -0.00798   |
|    std                  | 0.711      |
|    value_loss           | 3.8        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.13e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 287        |
|    time_elapsed         | 163725     |
|    total_timesteps      | 587776     |
| train/                  |            |
|    approx_kl            | 0.08681429 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.52      |
|    explained_variance   | 0.103      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.873      |
|    n_updates            | 2860       |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.713      |
|    value_loss           | 1.16       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 288         |
|    time_elapsed         | 163930      |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.059460588 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.47       |
|    explained_variance   | 0.151       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.44        |
|    n_updates            | 2870        |
|    policy_gradient_loss | 0.00887     |
|    std                  | 0.705       |
|    value_loss           | 1.08        |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-99.62 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 590000     |
| train/                  |            |
|    approx_kl            | 0.06304772 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.42      |
|    explained_variance   | 0.143      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.782      |
|    n_updates            | 2880       |
|    policy_gradient_loss | 0.00261    |
|    std                  | 0.702      |
|    value_loss           | 1.48       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 289      |
|    time_elapsed    | 165936   |
|    total_timesteps | 591872   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 290         |
|    time_elapsed         | 166142      |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.045083925 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | -0.000527   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.53e+03    |
|    n_updates            | 2890        |
|    policy_gradient_loss | 0.0104      |
|    std                  | 0.699       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.14e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 291        |
|    time_elapsed         | 166347     |
|    total_timesteps      | 595968     |
| train/                  |            |
|    approx_kl            | 0.14396042 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.37      |
|    explained_variance   | -2.06      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.56       |
|    n_updates            | 2900       |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.696      |
|    value_loss           | 2.96       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 292         |
|    time_elapsed         | 166552      |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.051510744 |
|    clip_fraction        | 0.41        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.38       |
|    explained_variance   | 0.138       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.465       |
|    n_updates            | 2910        |
|    policy_gradient_loss | 0.00824     |
|    std                  | 0.699       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-99.58 +/- 0.03
Episode length: 3594.40 +/- 13.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.59e+03    |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.024604648 |
|    clip_fraction        | 0.233       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.39       |
|    explained_variance   | -0.311      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.844       |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.698       |
|    value_loss           | 2.06        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.13e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 293      |
|    time_elapsed    | 168565   |
|    total_timesteps | 600064   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.13e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 294         |
|    time_elapsed         | 168771      |
|    total_timesteps      | 602112      |
| train/                  |             |
|    approx_kl            | 0.012506828 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.38       |
|    explained_variance   | -0.000872   |
|    learning_rate        | 0.0003      |
|    loss                 | 4.37e+03    |
|    n_updates            | 2930        |
|    policy_gradient_loss | -0.00283    |
|    std                  | 0.698       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 295         |
|    time_elapsed         | 168977      |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.064314164 |
|    clip_fraction        | 0.452       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.4        |
|    explained_variance   | 0.0729      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.544       |
|    n_updates            | 2940        |
|    policy_gradient_loss | 0.0182      |
|    std                  | 0.7         |
|    value_loss           | 1.2         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 296         |
|    time_elapsed         | 169182      |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.064051285 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.41       |
|    explained_variance   | -4.09       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.74        |
|    n_updates            | 2950        |
|    policy_gradient_loss | 0.00452     |
|    std                  | 0.699       |
|    value_loss           | 2.22        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 297        |
|    time_elapsed         | 169388     |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.05132547 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.38      |
|    explained_variance   | 0.11       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.576      |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.000845   |
|    std                  | 0.695      |
|    value_loss           | 1.16       |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-99.56 +/- 0.07
Episode length: 3596.60 +/- 7.84
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.069507286 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.35       |
|    explained_variance   | 0.124       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.012       |
|    std                  | 0.694       |
|    value_loss           | 1.33        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.14e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 298      |
|    time_elapsed    | 171398   |
|    total_timesteps | 610304   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.14e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 299         |
|    time_elapsed         | 171605      |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.052013353 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.34       |
|    explained_variance   | -0.00291    |
|    learning_rate        | 0.0003      |
|    loss                 | 2e+03       |
|    n_updates            | 2980        |
|    policy_gradient_loss | 0.0133      |
|    std                  | 0.694       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 300         |
|    time_elapsed         | 171810      |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.083620474 |
|    clip_fraction        | 0.354       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.32       |
|    explained_variance   | 0.0178      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.787       |
|    n_updates            | 2990        |
|    policy_gradient_loss | 0.000374    |
|    std                  | 0.692       |
|    value_loss           | 1.11        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 301         |
|    time_elapsed         | 172015      |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.033780064 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.31       |
|    explained_variance   | 0.299       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.6         |
|    n_updates            | 3000        |
|    policy_gradient_loss | -0.00571    |
|    std                  | 0.692       |
|    value_loss           | 1.08        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 302         |
|    time_elapsed         | 172221      |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.044313945 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.27       |
|    explained_variance   | 0.203       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.629       |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.00448    |
|    std                  | 0.687       |
|    value_loss           | 1.21        |
-----------------------------------------
Eval num_timesteps=620000, episode_reward=-99.53 +/- 0.03
Episode length: 3600.40 +/- 1.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.052916177 |
|    clip_fraction        | 0.335       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.24       |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.573       |
|    n_updates            | 3020        |
|    policy_gradient_loss | -0.00439    |
|    std                  | 0.685       |
|    value_loss           | 1.22        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 303      |
|    time_elapsed    | 174230   |
|    total_timesteps | 620544   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.15e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 304        |
|    time_elapsed         | 174436     |
|    total_timesteps      | 622592     |
| train/                  |            |
|    approx_kl            | 0.03801753 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.23      |
|    explained_variance   | -0.00152   |
|    learning_rate        | 0.0003     |
|    loss                 | 941        |
|    n_updates            | 3030       |
|    policy_gradient_loss | 0.00826    |
|    std                  | 0.685      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 305         |
|    time_elapsed         | 174641      |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.048631936 |
|    clip_fraction        | 0.349       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.21       |
|    explained_variance   | 0.0796      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.424       |
|    n_updates            | 3040        |
|    policy_gradient_loss | 0.00432     |
|    std                  | 0.682       |
|    value_loss           | 1.16        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.16e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 306        |
|    time_elapsed         | 174851     |
|    total_timesteps      | 626688     |
| train/                  |            |
|    approx_kl            | 0.07821505 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.19      |
|    explained_variance   | 0.224      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.757      |
|    n_updates            | 3050       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.683      |
|    value_loss           | 1.54       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.16e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 307       |
|    time_elapsed         | 175059    |
|    total_timesteps      | 628736    |
| train/                  |           |
|    approx_kl            | 0.0781216 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.19     |
|    explained_variance   | 0.255     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.647     |
|    n_updates            | 3060      |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.683     |
|    value_loss           | 1.32      |
---------------------------------------
Eval num_timesteps=630000, episode_reward=-99.61 +/- 0.06
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.104650535 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | 0.214       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.672       |
|    n_updates            | 3070        |
|    policy_gradient_loss | 0.0078      |
|    std                  | 0.682       |
|    value_loss           | 1.3         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.15e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 308      |
|    time_elapsed    | 177066   |
|    total_timesteps | 630784   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.15e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 309         |
|    time_elapsed         | 177271      |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.074582234 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.19       |
|    explained_variance   | -0.000533   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.58        |
|    n_updates            | 3080        |
|    policy_gradient_loss | 0.00762     |
|    std                  | 0.682       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.16e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 310       |
|    time_elapsed         | 177477    |
|    total_timesteps      | 634880    |
| train/                  |           |
|    approx_kl            | 0.3057277 |
|    clip_fraction        | 0.553     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.13     |
|    explained_variance   | -0.0728   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.502     |
|    n_updates            | 3090      |
|    policy_gradient_loss | 0.0319    |
|    std                  | 0.676     |
|    value_loss           | 1.27      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.16e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 311       |
|    time_elapsed         | 177682    |
|    total_timesteps      | 636928    |
| train/                  |           |
|    approx_kl            | 0.0664351 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | -8.1      |
|    explained_variance   | 0.114     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.524     |
|    n_updates            | 3100      |
|    policy_gradient_loss | 0.00484   |
|    std                  | 0.675     |
|    value_loss           | 1.08      |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 312        |
|    time_elapsed         | 177888     |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.07172188 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.09      |
|    explained_variance   | 0.185      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.493      |
|    n_updates            | 3110       |
|    policy_gradient_loss | 0.00275    |
|    std                  | 0.673      |
|    value_loss           | 1.11       |
----------------------------------------
Eval num_timesteps=640000, episode_reward=-99.63 +/- 0.04
Episode length: 3595.20 +/- 9.72
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.09938998 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -8.08      |
|    explained_variance   | 0.155      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.674      |
|    n_updates            | 3120       |
|    policy_gradient_loss | 0.00968    |
|    std                  | 0.673      |
|    value_loss           | 1.31       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 313      |
|    time_elapsed    | 179899   |
|    total_timesteps | 641024   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 314         |
|    time_elapsed         | 180106      |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.033083692 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.08       |
|    explained_variance   | 0.00121     |
|    learning_rate        | 0.0003      |
|    loss                 | 16.5        |
|    n_updates            | 3130        |
|    policy_gradient_loss | 0.00399     |
|    std                  | 0.673       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 315         |
|    time_elapsed         | 180312      |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.064723924 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.1        |
|    explained_variance   | 0.148       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.888       |
|    n_updates            | 3140        |
|    policy_gradient_loss | 0.00259     |
|    std                  | 0.676       |
|    value_loss           | 1.39        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 316         |
|    time_elapsed         | 180517      |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.056485552 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.11       |
|    explained_variance   | -2.32       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.697       |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.000346   |
|    std                  | 0.675       |
|    value_loss           | 1.97        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.17e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 317         |
|    time_elapsed         | 180722      |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.041606236 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.09       |
|    explained_variance   | -0.173      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.67        |
|    n_updates            | 3160        |
|    policy_gradient_loss | 0.00361     |
|    std                  | 0.673       |
|    value_loss           | 2.18        |
-----------------------------------------
Eval num_timesteps=650000, episode_reward=-99.64 +/- 0.03
Episode length: 3596.00 +/- 8.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.036878638 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | 0.603       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.738       |
|    n_updates            | 3170        |
|    policy_gradient_loss | -0.0142     |
|    std                  | 0.672       |
|    value_loss           | 1.6         |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.16e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 318      |
|    time_elapsed    | 182734   |
|    total_timesteps | 651264   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.16e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 319         |
|    time_elapsed         | 182941      |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.021816289 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.07       |
|    explained_variance   | -0.00109    |
|    learning_rate        | 0.0003      |
|    loss                 | 16.1        |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.00359     |
|    std                  | 0.672       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 320         |
|    time_elapsed         | 183147      |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.097966485 |
|    clip_fraction        | 0.446       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.06       |
|    explained_variance   | -0.287      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.485       |
|    n_updates            | 3190        |
|    policy_gradient_loss | 0.00753     |
|    std                  | 0.671       |
|    value_loss           | 1.36        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 321         |
|    time_elapsed         | 183352      |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.102605835 |
|    clip_fraction        | 0.461       |
|    clip_range           | 0.2         |
|    entropy_loss         | -8.03       |
|    explained_variance   | 0.125       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.629       |
|    n_updates            | 3200        |
|    policy_gradient_loss | 0.0275      |
|    std                  | 0.667       |
|    value_loss           | 1.11        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 322        |
|    time_elapsed         | 183558     |
|    total_timesteps      | 659456     |
| train/                  |            |
|    approx_kl            | 0.07373573 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.98      |
|    explained_variance   | 0.135      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.745      |
|    n_updates            | 3210       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.662      |
|    value_loss           | 1.38       |
----------------------------------------
Eval num_timesteps=660000, episode_reward=-99.56 +/- 0.05
Episode length: 3599.60 +/- 2.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 660000     |
| train/                  |            |
|    approx_kl            | 0.11505102 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.663      |
|    n_updates            | 3220       |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.663      |
|    value_loss           | 1.2        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 323      |
|    time_elapsed    | 185565   |
|    total_timesteps | 661504   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.17e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 324        |
|    time_elapsed         | 185771     |
|    total_timesteps      | 663552     |
| train/                  |            |
|    approx_kl            | 0.03283231 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.96      |
|    explained_variance   | 0.00315    |
|    learning_rate        | 0.0003     |
|    loss                 | 3.81       |
|    n_updates            | 3230       |
|    policy_gradient_loss | 0.00427    |
|    std                  | 0.663      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.18e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 325        |
|    time_elapsed         | 185978     |
|    total_timesteps      | 665600     |
| train/                  |            |
|    approx_kl            | 0.06512664 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.95      |
|    explained_variance   | 0.167      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.759      |
|    n_updates            | 3240       |
|    policy_gradient_loss | 0.00654    |
|    std                  | 0.663      |
|    value_loss           | 1.67       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 326         |
|    time_elapsed         | 186183      |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.054947283 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.95       |
|    explained_variance   | 0.14        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.707       |
|    n_updates            | 3250        |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.662       |
|    value_loss           | 1.36        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 327       |
|    time_elapsed         | 186389    |
|    total_timesteps      | 669696    |
| train/                  |           |
|    approx_kl            | 0.0866455 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.95     |
|    explained_variance   | -2.41     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.731     |
|    n_updates            | 3260      |
|    policy_gradient_loss | 0.00515   |
|    std                  | 0.663     |
|    value_loss           | 2.05      |
---------------------------------------
Eval num_timesteps=670000, episode_reward=-99.60 +/- 0.05
Episode length: 3596.40 +/- 9.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 670000     |
| train/                  |            |
|    approx_kl            | 0.07838034 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | 0.194      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 3270       |
|    policy_gradient_loss | 0.00968    |
|    std                  | 0.661      |
|    value_loss           | 0.901      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.17e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 328      |
|    time_elapsed    | 190831   |
|    total_timesteps | 671744   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 329         |
|    time_elapsed         | 191039      |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.036495455 |
|    clip_fraction        | 0.254       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | -0.00137    |
|    learning_rate        | 0.0003      |
|    loss                 | 2.08e+03    |
|    n_updates            | 3280        |
|    policy_gradient_loss | 0.00813     |
|    std                  | 0.661       |
|    value_loss           | 5.79e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 330         |
|    time_elapsed         | 191245      |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.014314255 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | -3.8        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.83        |
|    n_updates            | 3290        |
|    policy_gradient_loss | -0.00821    |
|    std                  | 0.661       |
|    value_loss           | 2.31        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 331         |
|    time_elapsed         | 191450      |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.026630836 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.93       |
|    explained_variance   | 0.138       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.489       |
|    n_updates            | 3300        |
|    policy_gradient_loss | -0.00628    |
|    std                  | 0.66        |
|    value_loss           | 1.18        |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.18e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 332       |
|    time_elapsed         | 191656    |
|    total_timesteps      | 679936    |
| train/                  |           |
|    approx_kl            | 0.0767601 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.93     |
|    explained_variance   | 0.192     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.604     |
|    n_updates            | 3310      |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.662     |
|    value_loss           | 1.23      |
---------------------------------------
Eval num_timesteps=680000, episode_reward=-99.57 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 680000     |
| train/                  |            |
|    approx_kl            | 0.06882462 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.94      |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.516      |
|    n_updates            | 3320       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.66       |
|    value_loss           | 1.12       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 333      |
|    time_elapsed    | 193662   |
|    total_timesteps | 681984   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 334        |
|    time_elapsed         | 193867     |
|    total_timesteps      | 684032     |
| train/                  |            |
|    approx_kl            | 0.02506984 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | 0.000194   |
|    learning_rate        | 0.0003     |
|    loss                 | 518        |
|    n_updates            | 3330       |
|    policy_gradient_loss | 0.00201    |
|    std                  | 0.66       |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 335        |
|    time_elapsed         | 194073     |
|    total_timesteps      | 686080     |
| train/                  |            |
|    approx_kl            | 0.17260045 |
|    clip_fraction        | 0.537      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.93      |
|    explained_variance   | -0.262     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.604      |
|    n_updates            | 3340       |
|    policy_gradient_loss | 0.0344     |
|    std                  | 0.661      |
|    value_loss           | 1.15       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 336         |
|    time_elapsed         | 194278      |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.080232546 |
|    clip_fraction        | 0.457       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.94       |
|    explained_variance   | 0.147       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.451       |
|    n_updates            | 3350        |
|    policy_gradient_loss | 0.0195      |
|    std                  | 0.661       |
|    value_loss           | 1.24        |
-----------------------------------------
Eval num_timesteps=690000, episode_reward=-99.59 +/- 0.05
Episode length: 3595.60 +/- 8.52
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 690000     |
| train/                  |            |
|    approx_kl            | 0.06628595 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.92      |
|    explained_variance   | 0.131      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.411      |
|    n_updates            | 3360       |
|    policy_gradient_loss | 0.00177    |
|    std                  | 0.659      |
|    value_loss           | 0.93       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.18e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 337      |
|    time_elapsed    | 196291   |
|    total_timesteps | 690176   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.18e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 338         |
|    time_elapsed         | 196497      |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.040509664 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.9        |
|    explained_variance   | -0.0128     |
|    learning_rate        | 0.0003      |
|    loss                 | 3.92        |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.000403   |
|    std                  | 0.658       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.19e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 339        |
|    time_elapsed         | 196703     |
|    total_timesteps      | 694272     |
| train/                  |            |
|    approx_kl            | 0.10071831 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.9       |
|    explained_variance   | -0.598     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.511      |
|    n_updates            | 3380       |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.658      |
|    value_loss           | 1.13       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 340         |
|    time_elapsed         | 196908      |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.066722766 |
|    clip_fraction        | 0.417       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | -1.14       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.65        |
|    n_updates            | 3390        |
|    policy_gradient_loss | 0.00907     |
|    std                  | 0.656       |
|    value_loss           | 1.9         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 341         |
|    time_elapsed         | 197114      |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.051956445 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.89       |
|    explained_variance   | 0.191       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.599       |
|    n_updates            | 3400        |
|    policy_gradient_loss | 0.00575     |
|    std                  | 0.656       |
|    value_loss           | 1.18        |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-99.60 +/- 0.05
Episode length: 3598.20 +/- 3.92
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.058637302 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.86       |
|    explained_variance   | 0.159       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.347       |
|    n_updates            | 3410        |
|    policy_gradient_loss | 0.00534     |
|    std                  | 0.653       |
|    value_loss           | 1.07        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.19e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 342      |
|    time_elapsed    | 199124   |
|    total_timesteps | 700416   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.19e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 343         |
|    time_elapsed         | 199330      |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.036634848 |
|    clip_fraction        | 0.267       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.84       |
|    explained_variance   | 0.00296     |
|    learning_rate        | 0.0003      |
|    loss                 | 5.16        |
|    n_updates            | 3420        |
|    policy_gradient_loss | 0.00672     |
|    std                  | 0.653       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 344        |
|    time_elapsed         | 199535     |
|    total_timesteps      | 704512     |
| train/                  |            |
|    approx_kl            | 0.04971446 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.83      |
|    explained_variance   | -0.0121    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.641      |
|    n_updates            | 3430       |
|    policy_gradient_loss | -0.00786   |
|    std                  | 0.651      |
|    value_loss           | 1.6        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 345        |
|    time_elapsed         | 199740     |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.07058037 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.81      |
|    explained_variance   | -3.07      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.524      |
|    n_updates            | 3440       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.65       |
|    value_loss           | 2.42       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 346        |
|    time_elapsed         | 199946     |
|    total_timesteps      | 708608     |
| train/                  |            |
|    approx_kl            | 0.12761152 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.8       |
|    explained_variance   | 0.0756     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.555      |
|    n_updates            | 3450       |
|    policy_gradient_loss | 0.0278     |
|    std                  | 0.649      |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=710000, episode_reward=-99.62 +/- 0.08
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 710000     |
| train/                  |            |
|    approx_kl            | 0.09039518 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.77      |
|    explained_variance   | 0.0664     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.494      |
|    n_updates            | 3460       |
|    policy_gradient_loss | 0.03       |
|    std                  | 0.647      |
|    value_loss           | 1.07       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 347      |
|    time_elapsed    | 201954   |
|    total_timesteps | 710656   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.2e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 348        |
|    time_elapsed         | 202164     |
|    total_timesteps      | 712704     |
| train/                  |            |
|    approx_kl            | 0.04810801 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.76      |
|    explained_variance   | 2.92e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.95e+03   |
|    n_updates            | 3470       |
|    policy_gradient_loss | -0.001     |
|    std                  | 0.648      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 349         |
|    time_elapsed         | 202371      |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.053141236 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.75       |
|    explained_variance   | -0.0833     |
|    learning_rate        | 0.0003      |
|    loss                 | 0.566       |
|    n_updates            | 3480        |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.646       |
|    value_loss           | 1.06        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 350        |
|    time_elapsed         | 202576     |
|    total_timesteps      | 716800     |
| train/                  |            |
|    approx_kl            | 0.15312825 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.75      |
|    explained_variance   | 0.0885     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.564      |
|    n_updates            | 3490       |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.646      |
|    value_loss           | 1.11       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 351         |
|    time_elapsed         | 202781      |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.052778214 |
|    clip_fraction        | 0.366       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.72       |
|    explained_variance   | 0.132       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.662       |
|    n_updates            | 3500        |
|    policy_gradient_loss | 0.00239     |
|    std                  | 0.643       |
|    value_loss           | 1.13        |
-----------------------------------------
Eval num_timesteps=720000, episode_reward=-99.59 +/- 0.03
Episode length: 3598.40 +/- 5.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.07973656 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.7       |
|    explained_variance   | 0.0699     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.809      |
|    n_updates            | 3510       |
|    policy_gradient_loss | 0.0087     |
|    std                  | 0.642      |
|    value_loss           | 1.28       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.2e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 352      |
|    time_elapsed    | 204790   |
|    total_timesteps | 720896   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.2e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 353         |
|    time_elapsed         | 204997      |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.030005455 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.7        |
|    explained_variance   | 0.000488    |
|    learning_rate        | 0.0003      |
|    loss                 | 82.3        |
|    n_updates            | 3520        |
|    policy_gradient_loss | 0.00428     |
|    std                  | 0.643       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 354        |
|    time_elapsed         | 205203     |
|    total_timesteps      | 724992     |
| train/                  |            |
|    approx_kl            | 0.12001493 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.0494     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.469      |
|    n_updates            | 3530       |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.641      |
|    value_loss           | 1.16       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.21e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 355        |
|    time_elapsed         | 205408     |
|    total_timesteps      | 727040     |
| train/                  |            |
|    approx_kl            | 0.15192921 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.118      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.502      |
|    n_updates            | 3540       |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.642      |
|    value_loss           | 0.931      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 356        |
|    time_elapsed         | 205614     |
|    total_timesteps      | 729088     |
| train/                  |            |
|    approx_kl            | 0.08060803 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.69      |
|    explained_variance   | 0.193      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.666      |
|    n_updates            | 3550       |
|    policy_gradient_loss | 0.00221    |
|    std                  | 0.641      |
|    value_loss           | 1.13       |
----------------------------------------
Eval num_timesteps=730000, episode_reward=-99.55 +/- 0.05
Episode length: 3593.60 +/- 12.89
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.59e+03   |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.05978816 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.67      |
|    explained_variance   | -1.27      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.746      |
|    n_updates            | 3560       |
|    policy_gradient_loss | -0.000227  |
|    std                  | 0.638      |
|    value_loss           | 2.13       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 357      |
|    time_elapsed    | 207625   |
|    total_timesteps | 731136   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 358         |
|    time_elapsed         | 207833      |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.028759431 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.66       |
|    explained_variance   | -0.000287   |
|    learning_rate        | 0.0003      |
|    loss                 | 1.3e+03     |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.00322    |
|    std                  | 0.639       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 359        |
|    time_elapsed         | 208039     |
|    total_timesteps      | 735232     |
| train/                  |            |
|    approx_kl            | 0.12730005 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.64      |
|    explained_variance   | -0.0301    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.452      |
|    n_updates            | 3580       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.636      |
|    value_loss           | 0.959      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 360        |
|    time_elapsed         | 208244     |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.12799636 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.62      |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.0003     |
|    loss                 | 1.08       |
|    n_updates            | 3590       |
|    policy_gradient_loss | 0.00191    |
|    std                  | 0.636      |
|    value_loss           | 2.42       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.22e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 361        |
|    time_elapsed         | 208449     |
|    total_timesteps      | 739328     |
| train/                  |            |
|    approx_kl            | 0.04107215 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.63      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.6        |
|    n_updates            | 3600       |
|    policy_gradient_loss | -0.00174   |
|    std                  | 0.637      |
|    value_loss           | 1.59       |
----------------------------------------
Eval num_timesteps=740000, episode_reward=-99.52 +/- 0.04
Episode length: 3600.00 +/- 1.26
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.073605396 |
|    clip_fraction        | 0.435       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.64       |
|    explained_variance   | 0.104       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.515       |
|    n_updates            | 3610        |
|    policy_gradient_loss | 0.0144      |
|    std                  | 0.639       |
|    value_loss           | 1.35        |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.21e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 362      |
|    time_elapsed    | 210459   |
|    total_timesteps | 741376   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.21e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 363         |
|    time_elapsed         | 210669      |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.024604306 |
|    clip_fraction        | 0.286       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | -0.00186    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.35        |
|    n_updates            | 3620        |
|    policy_gradient_loss | 0.00403     |
|    std                  | 0.639       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.22e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 364         |
|    time_elapsed         | 210876      |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.087108925 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.0829      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.74        |
|    n_updates            | 3630        |
|    policy_gradient_loss | 0.00285     |
|    std                  | 0.64        |
|    value_loss           | 1.36        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 365        |
|    time_elapsed         | 211081     |
|    total_timesteps      | 747520     |
| train/                  |            |
|    approx_kl            | 0.09842202 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.66      |
|    explained_variance   | 0.206      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.645      |
|    n_updates            | 3640       |
|    policy_gradient_loss | 0.0097     |
|    std                  | 0.641      |
|    value_loss           | 1.14       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 366         |
|    time_elapsed         | 211287      |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.060306408 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.65       |
|    explained_variance   | 0.146       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.691       |
|    n_updates            | 3650        |
|    policy_gradient_loss | -0.000665   |
|    std                  | 0.638       |
|    value_loss           | 1.21        |
-----------------------------------------
Eval num_timesteps=750000, episode_reward=-99.52 +/- 0.06
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 750000     |
| train/                  |            |
|    approx_kl            | 0.07592908 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.6       |
|    explained_variance   | 0.12       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.633      |
|    n_updates            | 3660       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.635      |
|    value_loss           | 1.22       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 367      |
|    time_elapsed    | 213293   |
|    total_timesteps | 751616   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 368         |
|    time_elapsed         | 213500      |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.055250205 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.58       |
|    explained_variance   | -0.0048     |
|    learning_rate        | 0.0003      |
|    loss                 | 469         |
|    n_updates            | 3670        |
|    policy_gradient_loss | 0.00204     |
|    std                  | 0.635       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 369         |
|    time_elapsed         | 213705      |
|    total_timesteps      | 755712      |
| train/                  |             |
|    approx_kl            | 0.017058622 |
|    clip_fraction        | 0.0854      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.58       |
|    explained_variance   | -2.86       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.81        |
|    n_updates            | 3680        |
|    policy_gradient_loss | -0.0121     |
|    std                  | 0.635       |
|    value_loss           | 5.18        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.23e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 370        |
|    time_elapsed         | 213913     |
|    total_timesteps      | 757760     |
| train/                  |            |
|    approx_kl            | 0.09045121 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.58      |
|    explained_variance   | -0.33      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.617      |
|    n_updates            | 3690       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.636      |
|    value_loss           | 1.47       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.23e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 371       |
|    time_elapsed         | 214118    |
|    total_timesteps      | 759808    |
| train/                  |           |
|    approx_kl            | 0.0730031 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.57     |
|    explained_variance   | 0.161     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.567     |
|    n_updates            | 3700      |
|    policy_gradient_loss | 0.00668   |
|    std                  | 0.634     |
|    value_loss           | 1.21      |
---------------------------------------
Eval num_timesteps=760000, episode_reward=-99.47 +/- 0.07
Episode length: 3601.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.5     |
| time/                   |           |
|    total_timesteps      | 760000    |
| train/                  |           |
|    approx_kl            | 0.0608821 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.54     |
|    explained_variance   | 0.217     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.413     |
|    n_updates            | 3710      |
|    policy_gradient_loss | -0.0014   |
|    std                  | 0.631     |
|    value_loss           | 1.26      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.22e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 372      |
|    time_elapsed    | 216129   |
|    total_timesteps | 761856   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 373         |
|    time_elapsed         | 216335      |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.027067648 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.52       |
|    explained_variance   | -0.0032     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.61e+03    |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00381    |
|    std                  | 0.631       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 374         |
|    time_elapsed         | 216540      |
|    total_timesteps      | 765952      |
| train/                  |             |
|    approx_kl            | 0.056513824 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.53       |
|    explained_variance   | -0.124      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.663       |
|    n_updates            | 3730        |
|    policy_gradient_loss | 0.00188     |
|    std                  | 0.633       |
|    value_loss           | 1.45        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 375        |
|    time_elapsed         | 216746     |
|    total_timesteps      | 768000     |
| train/                  |            |
|    approx_kl            | 0.10258629 |
|    clip_fraction        | 0.537      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.55      |
|    explained_variance   | 0.0584     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.501      |
|    n_updates            | 3740       |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.633      |
|    value_loss           | 1.03       |
----------------------------------------
Eval num_timesteps=770000, episode_reward=-99.50 +/- 0.03
Episode length: 3598.80 +/- 4.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.057183146 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | -1.76       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.629       |
|    n_updates            | 3750        |
|    policy_gradient_loss | 0.0027      |
|    std                  | 0.633       |
|    value_loss           | 1.74        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.23e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 376      |
|    time_elapsed    | 218753   |
|    total_timesteps | 770048   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.23e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 377         |
|    time_elapsed         | 218960      |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.033218116 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.55       |
|    explained_variance   | 0.00497     |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+03    |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00485     |
|    std                  | 0.633       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 378        |
|    time_elapsed         | 219165     |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.10692704 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.53      |
|    explained_variance   | -0.0449    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.57       |
|    n_updates            | 3770       |
|    policy_gradient_loss | -0.00379   |
|    std                  | 0.629      |
|    value_loss           | 1.2        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.24e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 379        |
|    time_elapsed         | 219371     |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.08260846 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.47      |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.719      |
|    n_updates            | 3780       |
|    policy_gradient_loss | 0.00513    |
|    std                  | 0.625      |
|    value_loss           | 1.07       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 380        |
|    time_elapsed         | 219580     |
|    total_timesteps      | 778240     |
| train/                  |            |
|    approx_kl            | 0.05069617 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.44      |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.569      |
|    n_updates            | 3790       |
|    policy_gradient_loss | 0.00895    |
|    std                  | 0.625      |
|    value_loss           | 1.06       |
----------------------------------------
Eval num_timesteps=780000, episode_reward=-99.55 +/- 0.04
Episode length: 3595.60 +/- 10.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.045331694 |
|    clip_fraction        | 0.391       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | -1.24       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.733       |
|    n_updates            | 3800        |
|    policy_gradient_loss | 0.00809     |
|    std                  | 0.624       |
|    value_loss           | 1.38        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.24e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 381      |
|    time_elapsed    | 221592   |
|    total_timesteps | 780288   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.24e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 382         |
|    time_elapsed         | 221799      |
|    total_timesteps      | 782336      |
| train/                  |             |
|    approx_kl            | 0.025310367 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.43       |
|    explained_variance   | 0.000472    |
|    learning_rate        | 0.0003      |
|    loss                 | 1.34e+03    |
|    n_updates            | 3810        |
|    policy_gradient_loss | -0.00406    |
|    std                  | 0.624       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 383        |
|    time_elapsed         | 222004     |
|    total_timesteps      | 784384     |
| train/                  |            |
|    approx_kl            | 0.11211045 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.45      |
|    explained_variance   | 0.145      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.722      |
|    n_updates            | 3820       |
|    policy_gradient_loss | 0.00994    |
|    std                  | 0.625      |
|    value_loss           | 1.24       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 384         |
|    time_elapsed         | 222210      |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.099135734 |
|    clip_fraction        | 0.401       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.44       |
|    explained_variance   | 0.288       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.469       |
|    n_updates            | 3830        |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.623       |
|    value_loss           | 0.926       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 385        |
|    time_elapsed         | 222415     |
|    total_timesteps      | 788480     |
| train/                  |            |
|    approx_kl            | 0.07635785 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.42      |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.524      |
|    n_updates            | 3840       |
|    policy_gradient_loss | -0.000113  |
|    std                  | 0.622      |
|    value_loss           | 1.02       |
----------------------------------------
Eval num_timesteps=790000, episode_reward=-99.57 +/- 0.02
Episode length: 3596.00 +/- 9.03
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.6     |
| time/                   |           |
|    total_timesteps      | 790000    |
| train/                  |           |
|    approx_kl            | 0.0593846 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.4      |
|    explained_variance   | 0.472     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.42      |
|    n_updates            | 3850      |
|    policy_gradient_loss | 0.00836   |
|    std                  | 0.62      |
|    value_loss           | 1.1       |
---------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.25e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 386      |
|    time_elapsed    | 224428   |
|    total_timesteps | 790528   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.25e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 387         |
|    time_elapsed         | 224635      |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.027991533 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.39       |
|    explained_variance   | -0.00118    |
|    learning_rate        | 0.0003      |
|    loss                 | 40.7        |
|    n_updates            | 3860        |
|    policy_gradient_loss | 0.00483     |
|    std                  | 0.619       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 388        |
|    time_elapsed         | 224840     |
|    total_timesteps      | 794624     |
| train/                  |            |
|    approx_kl            | 0.06719102 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.35      |
|    explained_variance   | -0.088     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.41       |
|    n_updates            | 3870       |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.615      |
|    value_loss           | 0.866      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 389         |
|    time_elapsed         | 225046      |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.059877113 |
|    clip_fraction        | 0.365       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.34       |
|    explained_variance   | 0.237       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.391       |
|    n_updates            | 3880        |
|    policy_gradient_loss | -0.00569    |
|    std                  | 0.615       |
|    value_loss           | 0.936       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.26e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 390        |
|    time_elapsed         | 225251     |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.11187664 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.32      |
|    explained_variance   | 0.207      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.657      |
|    n_updates            | 3890       |
|    policy_gradient_loss | 0.00733    |
|    std                  | 0.612      |
|    value_loss           | 1.09       |
----------------------------------------
Eval num_timesteps=800000, episode_reward=-99.57 +/- 0.08
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.6       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.051826276 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.27       |
|    explained_variance   | 0.0752      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.385       |
|    n_updates            | 3900        |
|    policy_gradient_loss | 0.00212     |
|    std                  | 0.608       |
|    value_loss           | 1.33        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.25e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 391      |
|    time_elapsed    | 227257   |
|    total_timesteps | 800768   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.25e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 392        |
|    time_elapsed         | 227467     |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.07269056 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | 0.000354   |
|    learning_rate        | 0.0003     |
|    loss                 | 264        |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.00579    |
|    std                  | 0.608      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 393        |
|    time_elapsed         | 227674     |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.13413155 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | -0.0622    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.723      |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.609      |
|    value_loss           | 1.22       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 394        |
|    time_elapsed         | 227880     |
|    total_timesteps      | 806912     |
| train/                  |            |
|    approx_kl            | 0.15404049 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.0957     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.44       |
|    n_updates            | 3930       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.607      |
|    value_loss           | 1.26       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 395        |
|    time_elapsed         | 228087     |
|    total_timesteps      | 808960     |
| train/                  |            |
|    approx_kl            | 0.11582798 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.539      |
|    n_updates            | 3940       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.608      |
|    value_loss           | 0.918      |
----------------------------------------
Eval num_timesteps=810000, episode_reward=-99.61 +/- 0.04
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.08548447 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.449      |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.00972   |
|    std                  | 0.607      |
|    value_loss           | 1.38       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.26e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 396      |
|    time_elapsed    | 230095   |
|    total_timesteps | 811008   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.26e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 397         |
|    time_elapsed         | 230300      |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.022267126 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | -0.000529   |
|    learning_rate        | 0.0003      |
|    loss                 | 430         |
|    n_updates            | 3960        |
|    policy_gradient_loss | 0.00591     |
|    std                  | 0.608       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 398        |
|    time_elapsed         | 230506     |
|    total_timesteps      | 815104     |
| train/                  |            |
|    approx_kl            | 0.06411296 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.25      |
|    explained_variance   | 0.0435     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.631      |
|    n_updates            | 3970       |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.61       |
|    value_loss           | 1.21       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.27e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 399        |
|    time_elapsed         | 230711     |
|    total_timesteps      | 817152     |
| train/                  |            |
|    approx_kl            | 0.06262303 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.551      |
|    n_updates            | 3980       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.608      |
|    value_loss           | 1.54       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.28e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 400        |
|    time_elapsed         | 230917     |
|    total_timesteps      | 819200     |
| train/                  |            |
|    approx_kl            | 0.13454036 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | 0.106      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.588      |
|    n_updates            | 3990       |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.605      |
|    value_loss           | 1.17       |
----------------------------------------
Eval num_timesteps=820000, episode_reward=-99.60 +/- 0.03
Episode length: 3596.20 +/- 5.91
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.08726525 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | -1.87      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.716      |
|    n_updates            | 4000       |
|    policy_gradient_loss | 0.00427    |
|    std                  | 0.607      |
|    value_loss           | 1.11       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.27e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 401      |
|    time_elapsed    | 232928   |
|    total_timesteps | 821248   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.27e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 402         |
|    time_elapsed         | 233136      |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.030001583 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.21       |
|    explained_variance   | 0.000284    |
|    learning_rate        | 0.0003      |
|    loss                 | 127         |
|    n_updates            | 4010        |
|    policy_gradient_loss | 0.00111     |
|    std                  | 0.607       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.28e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 403       |
|    time_elapsed         | 233342    |
|    total_timesteps      | 825344    |
| train/                  |           |
|    approx_kl            | 0.0641938 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.2      |
|    explained_variance   | -0.135    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.519     |
|    n_updates            | 4020      |
|    policy_gradient_loss | 0.00906   |
|    std                  | 0.605     |
|    value_loss           | 1.16      |
---------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 404         |
|    time_elapsed         | 233547      |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.052854415 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.2        |
|    explained_variance   | 0.223       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.813       |
|    n_updates            | 4030        |
|    policy_gradient_loss | 0.00184     |
|    std                  | 0.605       |
|    value_loss           | 1.37        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.28e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 405         |
|    time_elapsed         | 233753      |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.091085225 |
|    clip_fraction        | 0.416       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.572       |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.00787     |
|    std                  | 0.605       |
|    value_loss           | 1.02        |
-----------------------------------------
Eval num_timesteps=830000, episode_reward=-99.57 +/- 0.04
Episode length: 3597.80 +/- 6.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 830000     |
| train/                  |            |
|    approx_kl            | 0.07966043 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.509      |
|    n_updates            | 4050       |
|    policy_gradient_loss | 0.0358     |
|    std                  | 0.604      |
|    value_loss           | 0.89       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 406      |
|    time_elapsed    | 235762   |
|    total_timesteps | 831488   |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.33e+03  |
|    ep_rew_mean          | 2.28e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 407       |
|    time_elapsed         | 235970    |
|    total_timesteps      | 833536    |
| train/                  |           |
|    approx_kl            | 0.1346255 |
|    clip_fraction        | 0.287     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.18     |
|    explained_variance   | -0.000153 |
|    learning_rate        | 0.0003    |
|    loss                 | 5.03      |
|    n_updates            | 4060      |
|    policy_gradient_loss | 0.00273   |
|    std                  | 0.603     |
|    value_loss           | 1.05e+03  |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 408        |
|    time_elapsed         | 236177     |
|    total_timesteps      | 835584     |
| train/                  |            |
|    approx_kl            | 0.15373927 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.0131     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.506      |
|    n_updates            | 4070       |
|    policy_gradient_loss | 0.00679    |
|    std                  | 0.602      |
|    value_loss           | 1.02       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.29e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 409        |
|    time_elapsed         | 236383     |
|    total_timesteps      | 837632     |
| train/                  |            |
|    approx_kl            | 0.08801058 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.16      |
|    explained_variance   | -5.35      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.528      |
|    n_updates            | 4080       |
|    policy_gradient_loss | 0.00846    |
|    std                  | 0.602      |
|    value_loss           | 3.09       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.29e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 410         |
|    time_elapsed         | 236589      |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.085467085 |
|    clip_fraction        | 0.457       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.16       |
|    explained_variance   | -1.17       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.511       |
|    n_updates            | 4090        |
|    policy_gradient_loss | 0.0152      |
|    std                  | 0.602       |
|    value_loss           | 0.984       |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-99.60 +/- 0.06
Episode length: 3600.80 +/- 0.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 840000     |
| train/                  |            |
|    approx_kl            | 0.08792485 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.18      |
|    explained_variance   | 0.163      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.81       |
|    n_updates            | 4100       |
|    policy_gradient_loss | -0.00171   |
|    std                  | 0.603      |
|    value_loss           | 1.3        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.28e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 411      |
|    time_elapsed    | 238595   |
|    total_timesteps | 841728   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 412         |
|    time_elapsed         | 238800      |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.013787679 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | -0.00127    |
|    learning_rate        | 0.0003      |
|    loss                 | 736         |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.003      |
|    std                  | 0.603       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 413        |
|    time_elapsed         | 239009     |
|    total_timesteps      | 845824     |
| train/                  |            |
|    approx_kl            | 0.03271837 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | -0.231     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.38       |
|    n_updates            | 4120       |
|    policy_gradient_loss | -0.00527   |
|    std                  | 0.601      |
|    value_loss           | 0.793      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 414         |
|    time_elapsed         | 239216      |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.119317636 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.18       |
|    explained_variance   | 0.121       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.376       |
|    n_updates            | 4130        |
|    policy_gradient_loss | 0.0179      |
|    std                  | 0.603       |
|    value_loss           | 0.905       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 415        |
|    time_elapsed         | 239421     |
|    total_timesteps      | 849920     |
| train/                  |            |
|    approx_kl            | 0.07987414 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.684      |
|    n_updates            | 4140       |
|    policy_gradient_loss | 0.00378    |
|    std                  | 0.604      |
|    value_loss           | 1.23       |
----------------------------------------
Eval num_timesteps=850000, episode_reward=-99.53 +/- 0.03
Episode length: 3598.80 +/- 3.12
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 850000     |
| train/                  |            |
|    approx_kl            | 0.09763571 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | 0.16       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.508      |
|    n_updates            | 4150       |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.607      |
|    value_loss           | 1.02       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.29e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 416      |
|    time_elapsed    | 241431   |
|    total_timesteps | 851968   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 417        |
|    time_elapsed         | 241637     |
|    total_timesteps      | 854016     |
| train/                  |            |
|    approx_kl            | 0.04319317 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.24      |
|    explained_variance   | -0.000523  |
|    learning_rate        | 0.0003     |
|    loss                 | 215        |
|    n_updates            | 4160       |
|    policy_gradient_loss | 0.00842    |
|    std                  | 0.607      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 418        |
|    time_elapsed         | 241842     |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.04323433 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | -1.29      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.574      |
|    n_updates            | 4170       |
|    policy_gradient_loss | -0.0101    |
|    std                  | 0.607      |
|    value_loss           | 1.47       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.3e+03    |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 419        |
|    time_elapsed         | 242048     |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.02033364 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.23      |
|    explained_variance   | 0.00546    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.511      |
|    n_updates            | 4180       |
|    policy_gradient_loss | -0.00896   |
|    std                  | 0.606      |
|    value_loss           | 1.25       |
----------------------------------------
Eval num_timesteps=860000, episode_reward=-99.53 +/- 0.03
Episode length: 3596.20 +/- 7.76
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.113986015 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.117       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.521       |
|    n_updates            | 4190        |
|    policy_gradient_loss | -0.00394    |
|    std                  | 0.606       |
|    value_loss           | 1.12        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 420      |
|    time_elapsed    | 244059   |
|    total_timesteps | 860160   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 421         |
|    time_elapsed         | 244266      |
|    total_timesteps      | 862208      |
| train/                  |             |
|    approx_kl            | 0.010637352 |
|    clip_fraction        | 0.0873      |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.22       |
|    explained_variance   | 0.00413     |
|    learning_rate        | 0.0003      |
|    loss                 | 97.6        |
|    n_updates            | 4200        |
|    policy_gradient_loss | -0.00508    |
|    std                  | 0.606       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 422        |
|    time_elapsed         | 244472     |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.05844156 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.21      |
|    explained_variance   | -0.412     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.719      |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.00912   |
|    std                  | 0.605      |
|    value_loss           | 1.38       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 423        |
|    time_elapsed         | 244677     |
|    total_timesteps      | 866304     |
| train/                  |            |
|    approx_kl            | 0.08704421 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | 0.0803     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.645      |
|    n_updates            | 4220       |
|    policy_gradient_loss | 0.000194   |
|    std                  | 0.603      |
|    value_loss           | 1.4        |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 424        |
|    time_elapsed         | 244883     |
|    total_timesteps      | 868352     |
| train/                  |            |
|    approx_kl            | 0.20861341 |
|    clip_fraction        | 0.587      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | 0.0252     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.664      |
|    n_updates            | 4230       |
|    policy_gradient_loss | 0.0424     |
|    std                  | 0.605      |
|    value_loss           | 1.14       |
----------------------------------------
Eval num_timesteps=870000, episode_reward=-99.51 +/- 0.06
Episode length: 3596.20 +/- 7.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 870000     |
| train/                  |            |
|    approx_kl            | 0.09619236 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.22      |
|    explained_variance   | -0.0582    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.606      |
|    n_updates            | 4240       |
|    policy_gradient_loss | 0.0302     |
|    std                  | 0.607      |
|    value_loss           | 1.32       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.3e+03  |
| time/              |          |
|    fps             | 3        |
|    iterations      | 425      |
|    time_elapsed    | 246892   |
|    total_timesteps | 870400   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.3e+03     |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 426         |
|    time_elapsed         | 247099      |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.024296675 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.23       |
|    explained_variance   | -0.000265   |
|    learning_rate        | 0.0003      |
|    loss                 | 136         |
|    n_updates            | 4250        |
|    policy_gradient_loss | 0.00408     |
|    std                  | 0.607       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 427        |
|    time_elapsed         | 247306     |
|    total_timesteps      | 874496     |
| train/                  |            |
|    approx_kl            | 0.67807543 |
|    clip_fraction        | 0.626      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.2       |
|    explained_variance   | -0.468     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.558      |
|    n_updates            | 4260       |
|    policy_gradient_loss | 0.0453     |
|    std                  | 0.603      |
|    value_loss           | 0.934      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 428        |
|    time_elapsed         | 247512     |
|    total_timesteps      | 876544     |
| train/                  |            |
|    approx_kl            | 0.08433197 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.19      |
|    explained_variance   | -0.433     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.727      |
|    n_updates            | 4270       |
|    policy_gradient_loss | 0.0037     |
|    std                  | 0.603      |
|    value_loss           | 3.57       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 429        |
|    time_elapsed         | 247717     |
|    total_timesteps      | 878592     |
| train/                  |            |
|    approx_kl            | 0.07494697 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.17      |
|    explained_variance   | 0.126      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.379      |
|    n_updates            | 4280       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.602      |
|    value_loss           | 0.905      |
----------------------------------------
Eval num_timesteps=880000, episode_reward=-99.50 +/- 0.04
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 880000     |
| train/                  |            |
|    approx_kl            | 0.14760104 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.15      |
|    explained_variance   | -0.608     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.565      |
|    n_updates            | 4290       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.6        |
|    value_loss           | 3.8        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 430      |
|    time_elapsed    | 249727   |
|    total_timesteps | 880640   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 431        |
|    time_elapsed         | 249934     |
|    total_timesteps      | 882688     |
| train/                  |            |
|    approx_kl            | 0.05185002 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.15      |
|    explained_variance   | -0.00616   |
|    learning_rate        | 0.0003     |
|    loss                 | 5.98       |
|    n_updates            | 4300       |
|    policy_gradient_loss | 0.000578   |
|    std                  | 0.6        |
|    value_loss           | 1.06e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 432         |
|    time_elapsed         | 250140      |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.072230786 |
|    clip_fraction        | 0.431       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | -0.255      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.586       |
|    n_updates            | 4310        |
|    policy_gradient_loss | 0.00141     |
|    std                  | 0.598       |
|    value_loss           | 1.25        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 433         |
|    time_elapsed         | 250345      |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.066075414 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.14       |
|    explained_variance   | 0.177       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.563       |
|    n_updates            | 4320        |
|    policy_gradient_loss | 0.00153     |
|    std                  | 0.6         |
|    value_loss           | 0.903       |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.32e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 434         |
|    time_elapsed         | 250551      |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.067248985 |
|    clip_fraction        | 0.423       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.1        |
|    explained_variance   | 0.13        |
|    learning_rate        | 0.0003      |
|    loss                 | 0.478       |
|    n_updates            | 4330        |
|    policy_gradient_loss | 0.00747     |
|    std                  | 0.596       |
|    value_loss           | 1.1         |
-----------------------------------------
Eval num_timesteps=890000, episode_reward=-99.51 +/- 0.06
Episode length: 3599.80 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.101866215 |
|    clip_fraction        | 0.45        |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.09       |
|    explained_variance   | 0.109       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.47        |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.0249      |
|    std                  | 0.598       |
|    value_loss           | 1.09        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.31e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 435      |
|    time_elapsed    | 252560   |
|    total_timesteps | 890880   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.31e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 436        |
|    time_elapsed         | 252765     |
|    total_timesteps      | 892928     |
| train/                  |            |
|    approx_kl            | 0.08034141 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.11      |
|    explained_variance   | 0.000299   |
|    learning_rate        | 0.0003     |
|    loss                 | 4.23       |
|    n_updates            | 4350       |
|    policy_gradient_loss | -0.00281   |
|    std                  | 0.598      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 437        |
|    time_elapsed         | 252971     |
|    total_timesteps      | 894976     |
| train/                  |            |
|    approx_kl            | 0.08290081 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.13      |
|    explained_variance   | -0.0469    |
|    learning_rate        | 0.0003     |
|    loss                 | 0.692      |
|    n_updates            | 4360       |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.602      |
|    value_loss           | 1.06       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.32e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 438       |
|    time_elapsed         | 253180    |
|    total_timesteps      | 897024    |
| train/                  |           |
|    approx_kl            | 0.0864466 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.13     |
|    explained_variance   | 0.0702    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.495     |
|    n_updates            | 4370      |
|    policy_gradient_loss | 0.0135    |
|    std                  | 0.599     |
|    value_loss           | 0.997     |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.33e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 439       |
|    time_elapsed         | 253387    |
|    total_timesteps      | 899072    |
| train/                  |           |
|    approx_kl            | 0.0864989 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | -7.09     |
|    explained_variance   | 0.0755    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.499     |
|    n_updates            | 4380      |
|    policy_gradient_loss | 0.00514   |
|    std                  | 0.595     |
|    value_loss           | 0.989     |
---------------------------------------
Eval num_timesteps=900000, episode_reward=-99.50 +/- 0.06
Episode length: 3600.20 +/- 1.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.040790867 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -7.07       |
|    explained_variance   | -1.03       |
|    learning_rate        | 0.0003      |
|    loss                 | 1.46        |
|    n_updates            | 4390        |
|    policy_gradient_loss | 0.00075     |
|    std                  | 0.595       |
|    value_loss           | 3.86        |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 440      |
|    time_elapsed    | 255396   |
|    total_timesteps | 901120   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 441        |
|    time_elapsed         | 255602     |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.05269064 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | -0.000379  |
|    learning_rate        | 0.0003     |
|    loss                 | 96.4       |
|    n_updates            | 4400       |
|    policy_gradient_loss | 0.00493    |
|    std                  | 0.595      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 442        |
|    time_elapsed         | 255807     |
|    total_timesteps      | 905216     |
| train/                  |            |
|    approx_kl            | 0.12275121 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | -0.09      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.605      |
|    n_updates            | 4410       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.598      |
|    value_loss           | 0.978      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 443        |
|    time_elapsed         | 256013     |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.07205833 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.07      |
|    explained_variance   | -1.17      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.29       |
|    n_updates            | 4420       |
|    policy_gradient_loss | 0.00411    |
|    std                  | 0.596      |
|    value_loss           | 2.03       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.33e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 444        |
|    time_elapsed         | 256218     |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.06365352 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -7.04      |
|    explained_variance   | 0.092      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.317      |
|    n_updates            | 4430       |
|    policy_gradient_loss | 0.00836    |
|    std                  | 0.592      |
|    value_loss           | 0.977      |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-99.48 +/- 0.03
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.06610412 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.99      |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.369      |
|    n_updates            | 4440       |
|    policy_gradient_loss | 0.00324    |
|    std                  | 0.589      |
|    value_loss           | 1.1        |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.32e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 445      |
|    time_elapsed    | 258224   |
|    total_timesteps | 911360   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.32e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 446        |
|    time_elapsed         | 258430     |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.01821673 |
|    clip_fraction        | 0.21       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.98      |
|    explained_variance   | -0.00716   |
|    learning_rate        | 0.0003     |
|    loss                 | 173        |
|    n_updates            | 4450       |
|    policy_gradient_loss | -0.00793   |
|    std                  | 0.59       |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 447         |
|    time_elapsed         | 258635      |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.014560633 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.97       |
|    explained_variance   | -1.76       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.54        |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.0138     |
|    std                  | 0.589       |
|    value_loss           | 1.15        |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 448         |
|    time_elapsed         | 258841      |
|    total_timesteps      | 917504      |
| train/                  |             |
|    approx_kl            | 0.029570747 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.96       |
|    explained_variance   | 0.355       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.452       |
|    n_updates            | 4470        |
|    policy_gradient_loss | -0.0101     |
|    std                  | 0.588       |
|    value_loss           | 1.15        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 449        |
|    time_elapsed         | 259046     |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.03665787 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.95      |
|    explained_variance   | 0.31       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.677      |
|    n_updates            | 4480       |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.588      |
|    value_loss           | 1.18       |
----------------------------------------
Eval num_timesteps=920000, episode_reward=-99.54 +/- 0.03
Episode length: 3596.80 +/- 7.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 920000     |
| train/                  |            |
|    approx_kl            | 0.09070945 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.91      |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.37       |
|    n_updates            | 4490       |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.583      |
|    value_loss           | 0.838      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.33e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 450      |
|    time_elapsed    | 261052   |
|    total_timesteps | 921600   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 451        |
|    time_elapsed         | 261258     |
|    total_timesteps      | 923648     |
| train/                  |            |
|    approx_kl            | 0.03104752 |
|    clip_fraction        | 0.22       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | -0.000929  |
|    learning_rate        | 0.0003     |
|    loss                 | 33.6       |
|    n_updates            | 4500       |
|    policy_gradient_loss | 0.00131    |
|    std                  | 0.583      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 452        |
|    time_elapsed         | 261463     |
|    total_timesteps      | 925696     |
| train/                  |            |
|    approx_kl            | 0.03080294 |
|    clip_fraction        | 0.228      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.88      |
|    explained_variance   | -0.384     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.435      |
|    n_updates            | 4510       |
|    policy_gradient_loss | -0.0118    |
|    std                  | 0.582      |
|    value_loss           | 1.23       |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.34e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 453         |
|    time_elapsed         | 261668      |
|    total_timesteps      | 927744      |
| train/                  |             |
|    approx_kl            | 0.090882875 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.87       |
|    explained_variance   | 0.113       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.384       |
|    n_updates            | 4520        |
|    policy_gradient_loss | 0.00609     |
|    std                  | 0.582       |
|    value_loss           | 0.823       |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 454        |
|    time_elapsed         | 261874     |
|    total_timesteps      | 929792     |
| train/                  |            |
|    approx_kl            | 0.12687093 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.86      |
|    explained_variance   | 0.359      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.482      |
|    n_updates            | 4530       |
|    policy_gradient_loss | 0.025      |
|    std                  | 0.58       |
|    value_loss           | 1.04       |
----------------------------------------
Eval num_timesteps=930000, episode_reward=-99.49 +/- 0.06
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 930000     |
| train/                  |            |
|    approx_kl            | 0.20161891 |
|    clip_fraction        | 0.518      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.81      |
|    explained_variance   | 0.136      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.468      |
|    n_updates            | 4540       |
|    policy_gradient_loss | 0.0329     |
|    std                  | 0.575      |
|    value_loss           | 0.876      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 455      |
|    time_elapsed    | 263885   |
|    total_timesteps | 931840   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 456         |
|    time_elapsed         | 264092      |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.036049113 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.79       |
|    explained_variance   | 0.00127     |
|    learning_rate        | 0.0003      |
|    loss                 | 4.01        |
|    n_updates            | 4550        |
|    policy_gradient_loss | 0.0134      |
|    std                  | 0.575       |
|    value_loss           | 1.06e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 457        |
|    time_elapsed         | 264298     |
|    total_timesteps      | 935936     |
| train/                  |            |
|    approx_kl            | 0.12654275 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.0375     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.558      |
|    n_updates            | 4560       |
|    policy_gradient_loss | 0.0295     |
|    std                  | 0.573      |
|    value_loss           | 1.01       |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.35e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 458       |
|    time_elapsed         | 264503    |
|    total_timesteps      | 937984    |
| train/                  |           |
|    approx_kl            | 0.1000981 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.78     |
|    explained_variance   | 0.136     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.471     |
|    n_updates            | 4570      |
|    policy_gradient_loss | 0.0124    |
|    std                  | 0.575     |
|    value_loss           | 0.961     |
---------------------------------------
Eval num_timesteps=940000, episode_reward=-99.49 +/- 0.06
Episode length: 3597.60 +/- 6.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 940000     |
| train/                  |            |
|    approx_kl            | 0.19271664 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.79      |
|    explained_variance   | -0.157     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.646      |
|    n_updates            | 4580       |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.575      |
|    value_loss           | 0.932      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.34e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 459      |
|    time_elapsed    | 266513   |
|    total_timesteps | 940032   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.34e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 460        |
|    time_elapsed         | 266720     |
|    total_timesteps      | 942080     |
| train/                  |            |
|    approx_kl            | 0.03320401 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.79      |
|    explained_variance   | 7.93e-05   |
|    learning_rate        | 0.0003     |
|    loss                 | 24.6       |
|    n_updates            | 4590       |
|    policy_gradient_loss | 0.00661    |
|    std                  | 0.575      |
|    value_loss           | 1.05e+03   |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.36e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 461       |
|    time_elapsed         | 266927    |
|    total_timesteps      | 944128    |
| train/                  |           |
|    approx_kl            | 0.1117571 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.8      |
|    explained_variance   | -0.00881  |
|    learning_rate        | 0.0003    |
|    loss                 | 0.551     |
|    n_updates            | 4600      |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.576     |
|    value_loss           | 0.95      |
---------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.36e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 462       |
|    time_elapsed         | 267132    |
|    total_timesteps      | 946176    |
| train/                  |           |
|    approx_kl            | 0.1301498 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.81     |
|    explained_variance   | 0.273     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.434     |
|    n_updates            | 4610      |
|    policy_gradient_loss | 0.0152    |
|    std                  | 0.576     |
|    value_loss           | 0.899     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 463        |
|    time_elapsed         | 267338     |
|    total_timesteps      | 948224     |
| train/                  |            |
|    approx_kl            | 0.08124888 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.172      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.547      |
|    n_updates            | 4620       |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.573      |
|    value_loss           | 0.927      |
----------------------------------------
Eval num_timesteps=950000, episode_reward=-99.48 +/- 0.07
Episode length: 3600.20 +/- 0.98
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.08617568 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.538      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.334      |
|    n_updates            | 4630       |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.575      |
|    value_loss           | 1.03       |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 464      |
|    time_elapsed    | 269344   |
|    total_timesteps | 950272   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.35e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 465         |
|    time_elapsed         | 269549      |
|    total_timesteps      | 952320      |
| train/                  |             |
|    approx_kl            | 0.054353274 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.8        |
|    explained_variance   | 0.000503    |
|    learning_rate        | 0.0003      |
|    loss                 | 204         |
|    n_updates            | 4640        |
|    policy_gradient_loss | 0.00525     |
|    std                  | 0.575       |
|    value_loss           | 1.05e+03    |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 466        |
|    time_elapsed         | 269755     |
|    total_timesteps      | 954368     |
| train/                  |            |
|    approx_kl            | 0.11952874 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.79      |
|    explained_variance   | 0.0729     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.558      |
|    n_updates            | 4650       |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.574      |
|    value_loss           | 0.913      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 467        |
|    time_elapsed         | 269960     |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.08036783 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.296      |
|    n_updates            | 4660       |
|    policy_gradient_loss | 0.00976    |
|    std                  | 0.573      |
|    value_loss           | 0.823      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 468        |
|    time_elapsed         | 270165     |
|    total_timesteps      | 958464     |
| train/                  |            |
|    approx_kl            | 0.16823983 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.12       |
|    learning_rate        | 0.0003     |
|    loss                 | 0.5        |
|    n_updates            | 4670       |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.574      |
|    value_loss           | 0.911      |
----------------------------------------
Eval num_timesteps=960000, episode_reward=-99.54 +/- 0.04
Episode length: 3601.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 3.6e+03     |
|    mean_reward          | -99.5       |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.069190264 |
|    clip_fraction        | 0.425       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | 0.415       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.393       |
|    n_updates            | 4680        |
|    policy_gradient_loss | 0.00905     |
|    std                  | 0.573       |
|    value_loss           | 0.889       |
-----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.35e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 469      |
|    time_elapsed    | 272171   |
|    total_timesteps | 960512   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.35e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 470        |
|    time_elapsed         | 272377     |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.02603466 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.77      |
|    explained_variance   | -0.000114  |
|    learning_rate        | 0.0003     |
|    loss                 | 307        |
|    n_updates            | 4690       |
|    policy_gradient_loss | 0.00526    |
|    std                  | 0.573      |
|    value_loss           | 1.04e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 471        |
|    time_elapsed         | 272582     |
|    total_timesteps      | 964608     |
| train/                  |            |
|    approx_kl            | 0.08021845 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.148      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.459      |
|    n_updates            | 4700       |
|    policy_gradient_loss | 0.00299    |
|    std                  | 0.571      |
|    value_loss           | 0.978      |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 472         |
|    time_elapsed         | 272788      |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.094345495 |
|    clip_fraction        | 0.42        |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.73       |
|    explained_variance   | 0.368       |
|    learning_rate        | 0.0003      |
|    loss                 | 0.611       |
|    n_updates            | 4710        |
|    policy_gradient_loss | 0.00647     |
|    std                  | 0.569       |
|    value_loss           | 1.11        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 473        |
|    time_elapsed         | 272993     |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.09383098 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.71      |
|    explained_variance   | 0.117      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.534      |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.568      |
|    value_loss           | 0.895      |
----------------------------------------
Eval num_timesteps=970000, episode_reward=-99.47 +/- 0.05
Episode length: 3601.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.12743247 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.7       |
|    explained_variance   | 0.104      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.428      |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.569      |
|    value_loss           | 0.949      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 474      |
|    time_elapsed    | 275000   |
|    total_timesteps | 970752   |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.33e+03    |
|    ep_rew_mean          | 2.36e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 475         |
|    time_elapsed         | 275206      |
|    total_timesteps      | 972800      |
| train/                  |             |
|    approx_kl            | 0.028649349 |
|    clip_fraction        | 0.337       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.71       |
|    explained_variance   | -0.000553   |
|    learning_rate        | 0.0003      |
|    loss                 | 3.37e+03    |
|    n_updates            | 4740        |
|    policy_gradient_loss | 0.00447     |
|    std                  | 0.568       |
|    value_loss           | 1.04e+03    |
-----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.37e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 476       |
|    time_elapsed         | 275411    |
|    total_timesteps      | 974848    |
| train/                  |           |
|    approx_kl            | 0.1307693 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.74     |
|    explained_variance   | -0.0676   |
|    learning_rate        | 0.0003    |
|    loss                 | 0.444     |
|    n_updates            | 4750      |
|    policy_gradient_loss | 0.0155    |
|    std                  | 0.573     |
|    value_loss           | 0.861     |
---------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 477        |
|    time_elapsed         | 275617     |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.16119018 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.111      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.351      |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.0287     |
|    std                  | 0.572      |
|    value_loss           | 0.757      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 478        |
|    time_elapsed         | 275822     |
|    total_timesteps      | 978944     |
| train/                  |            |
|    approx_kl            | 0.14901537 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.75      |
|    explained_variance   | 0.0647     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.423      |
|    n_updates            | 4770       |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.571      |
|    value_loss           | 0.914      |
----------------------------------------
Eval num_timesteps=980000, episode_reward=-99.47 +/- 0.05
Episode length: 3597.20 +/- 7.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.5      |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.09761068 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.76      |
|    explained_variance   | 0.104      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.457      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.573      |
|    value_loss           | 0.88       |
----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.36e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 479      |
|    time_elapsed    | 277829   |
|    total_timesteps | 980992   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.36e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 480        |
|    time_elapsed         | 278035     |
|    total_timesteps      | 983040     |
| train/                  |            |
|    approx_kl            | 0.08086359 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.77      |
|    explained_variance   | -0.000114  |
|    learning_rate        | 0.0003     |
|    loss                 | 187        |
|    n_updates            | 4790       |
|    policy_gradient_loss | 0.000704   |
|    std                  | 0.574      |
|    value_loss           | 1.05e+03   |
----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 3.34e+03    |
|    ep_rew_mean          | 2.38e+03    |
| time/                   |             |
|    fps                  | 3           |
|    iterations           | 481         |
|    time_elapsed         | 278240      |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.098790675 |
|    clip_fraction        | 0.441       |
|    clip_range           | 0.2         |
|    entropy_loss         | -6.78       |
|    explained_variance   | -0.324      |
|    learning_rate        | 0.0003      |
|    loss                 | 0.378       |
|    n_updates            | 4800        |
|    policy_gradient_loss | 0.00813     |
|    std                  | 0.574       |
|    value_loss           | 0.87        |
-----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 482        |
|    time_elapsed         | 278445     |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.22769102 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | -7.94      |
|    learning_rate        | 0.0003     |
|    loss                 | 1.13       |
|    n_updates            | 4810       |
|    policy_gradient_loss | 0.00643    |
|    std                  | 0.575      |
|    value_loss           | 2.75       |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 483        |
|    time_elapsed         | 278651     |
|    total_timesteps      | 989184     |
| train/                  |            |
|    approx_kl            | 0.07673144 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.78      |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.424      |
|    n_updates            | 4820       |
|    policy_gradient_loss | 0.00994    |
|    std                  | 0.573      |
|    value_loss           | 0.806      |
----------------------------------------
Eval num_timesteps=990000, episode_reward=-99.56 +/- 0.05
Episode length: 3597.00 +/- 8.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 3.6e+03    |
|    mean_reward          | -99.6      |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.19626859 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.75      |
|    explained_variance   | 0.108      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.402      |
|    n_updates            | 4830       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.571      |
|    value_loss           | 0.836      |
----------------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.37e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 484      |
|    time_elapsed    | 280657   |
|    total_timesteps | 991232   |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.33e+03   |
|    ep_rew_mean          | 2.37e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 485        |
|    time_elapsed         | 280862     |
|    total_timesteps      | 993280     |
| train/                  |            |
|    approx_kl            | 0.04025131 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.73      |
|    explained_variance   | -0.00645   |
|    learning_rate        | 0.0003     |
|    loss                 | 1.33e+03   |
|    n_updates            | 4840       |
|    policy_gradient_loss | -0.00108   |
|    std                  | 0.571      |
|    value_loss           | 1.05e+03   |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 486        |
|    time_elapsed         | 281068     |
|    total_timesteps      | 995328     |
| train/                  |            |
|    approx_kl            | 0.15283291 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.74      |
|    explained_variance   | -0.201     |
|    learning_rate        | 0.0003     |
|    loss                 | 0.258      |
|    n_updates            | 4850       |
|    policy_gradient_loss | 0.00846    |
|    std                  | 0.571      |
|    value_loss           | 0.789      |
----------------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 3.34e+03   |
|    ep_rew_mean          | 2.38e+03   |
| time/                   |            |
|    fps                  | 3          |
|    iterations           | 487        |
|    time_elapsed         | 281273     |
|    total_timesteps      | 997376     |
| train/                  |            |
|    approx_kl            | 0.12373534 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -6.75      |
|    explained_variance   | -1.12      |
|    learning_rate        | 0.0003     |
|    loss                 | 0.348      |
|    n_updates            | 4860       |
|    policy_gradient_loss | 0.0012     |
|    std                  | 0.573      |
|    value_loss           | 0.918      |
----------------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 3.34e+03  |
|    ep_rew_mean          | 2.38e+03  |
| time/                   |           |
|    fps                  | 3         |
|    iterations           | 488       |
|    time_elapsed         | 281479    |
|    total_timesteps      | 999424    |
| train/                  |           |
|    approx_kl            | 0.2675136 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.76     |
|    explained_variance   | 0.303     |
|    learning_rate        | 0.0003    |
|    loss                 | 0.582     |
|    n_updates            | 4870      |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.572     |
|    value_loss           | 0.933     |
---------------------------------------
Eval num_timesteps=1000000, episode_reward=-99.35 +/- 0.40
Episode length: 3600.80 +/- 0.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 3.6e+03   |
|    mean_reward          | -99.3     |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.0869814 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.77     |
|    explained_variance   | 0.0667    |
|    learning_rate        | 0.0003    |
|    loss                 | 0.288     |
|    n_updates            | 4880      |
|    policy_gradient_loss | 0.0388    |
|    std                  | 0.574     |
|    value_loss           | 1.01      |
---------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 3.33e+03 |
|    ep_rew_mean     | 2.38e+03 |
| time/              |          |
|    fps             | 3        |
|    iterations      | 489      |
|    time_elapsed    | 283485   |
|    total_timesteps | 1001472  |
---------------------------------
Plot saved as src/FM3_MicRo/control_models/2025-01-28_08-31-10_llm_triton_qwen_14b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/r_ratio_plot.png
 100%  1,001,472/1,000, [ 3 days, 6:42:07 < 0:00:00 , 10 it/s ]

Detailed evaluation data:
Timesteps (shape=(100,)): [  10000   20000   30000   40000   50000   60000   70000   80000   90000
  100000  110000  120000  130000  140000  150000  160000  170000  180000
  190000  200000  210000  220000  230000  240000  250000  260000  270000
  280000  290000  300000  310000  320000  330000  340000  350000  360000
  370000  380000  390000  400000  410000  420000  430000  440000  450000
  460000  470000  480000  490000  500000  510000  520000  530000  540000
  550000  560000  570000  580000  590000  600000  610000  620000  630000
  640000  650000  660000  670000  680000  690000  700000  710000  720000
  730000  740000  750000  760000  770000  780000  790000  800000  810000
  820000  830000  840000  850000  860000  870000  880000  890000  900000
  910000  920000  930000  940000  950000  960000  970000  980000  990000
 1000000]
Results (shape=(100, 5)):
[[-99.877197 -99.96662  -99.92336  -99.91295  -99.855628]
 [-99.851988 -99.92622  -99.935798 -99.984067 -99.971039]
 [-99.914106 -99.889395 -99.83609  -99.892913 -99.873252]
 [-99.869999 -99.88342  -99.860111 -99.810573 -99.881206]
 [-99.831138 -99.863704 -99.876393 -99.775462 -99.856179]
 [-99.788553 -99.758162 -99.727507 -99.619437 -99.696298]
 [-99.708813 -99.783684 -99.705426 -99.81709  -99.764311]
 [-99.79631  -99.79095  -99.779227 -99.80986  -99.732315]
 [-99.841899 -99.799412 -99.892096 -99.824299 -99.778858]
 [-99.71932  -99.739076 -99.790118 -99.757343 -99.791736]
 [-99.750036 -99.796934 -99.849261 -99.83882  -99.862737]
 [-99.851992 -99.824313 -99.828438 -99.789297 -99.771215]
 [-99.795814 -99.788693 -99.806773 -99.789569 -99.751404]
 [-99.734764 -99.791234 -99.758374 -99.82139  -99.848332]
 [-99.7704   -99.703728 -99.803284 -99.792394 -99.812751]
 [-99.811553 -99.777342 -99.68859  -99.76865  -99.887227]
 [-99.699606 -99.845745 -99.701951 -99.664966 -99.743624]
 [-99.762584 -99.744949 -99.649324 -99.673924 -99.76715 ]
 [-99.744774 -99.806714 -99.704737 -99.78169  -99.780002]
 [-99.736037 -99.794143 -99.780621 -99.80518  -99.759438]
 [-99.742542 -99.664994 -99.639911 -99.743767 -99.734437]
 [-99.770016 -99.739294 -99.692212 -99.701043 -99.750905]
 [-99.775607 -99.696939 -99.678751 -99.628689 -99.751667]
 [-99.849669 -99.735451 -99.793039 -99.75302  -99.761106]
 [-99.68638  -99.663257 -99.732786 -99.786136 -99.800501]
 [-99.691007 -99.670092 -99.629452 -99.746852 -99.732146]
 [-99.808891 -99.703037 -99.750955 -99.799943 -99.709651]
 [-99.737851 -99.827818 -99.744115 -99.702332 -99.743532]
 [-99.7084   -99.782023 -99.715282 -99.773778 -99.746767]
 [-99.704452 -99.532489 -99.571515 -99.547535 -99.646577]
 [-99.431279 -99.606813 -99.673201 -99.564309 -99.695926]
 [-99.677157 -99.595378 -99.620906 -99.758562 -99.62347 ]
 [-99.668323 -99.685465 -99.754174 -99.699873 -99.751243]
 [-99.789787 -99.723579 -99.73112  -99.543196 -99.814975]
 [-99.804951 -99.708346 -99.779202 -99.781387 -99.695026]
 [-99.781047 -99.664488 -99.628579 -99.63346  -99.561578]
 [-99.68925  -99.709782 -99.762066 -99.685768 -99.690555]
 [-99.640027 -99.628429 -99.780897 -99.69461  -99.734802]
 [-99.713187 -99.751303 -99.718818 -99.676035 -99.743374]
 [-99.753186 -99.725177 -99.672966 -99.702921 -99.778233]
 [-99.721962 -99.716488 -99.651489 -99.643955 -99.6546  ]
 [-99.668723 -99.745512 -99.699332 -99.760215 -99.663454]
 [-99.771786 -99.638392 -99.586748 -99.693063 -99.606916]
 [-99.58158  -99.540863 -99.557865 -99.599047 -99.674547]
 [-99.708695 -99.612332 -99.691233 -99.630941 -99.709285]
 [-99.714568 -99.684348 -99.710617 -99.73036  -99.774703]
 [-99.61598  -99.68149  -99.658703 -99.653759 -99.654867]
 [-99.686618 -99.732435 -99.698291 -99.728883 -99.683409]
 [-99.665247 -99.598296 -99.65468  -99.613296 -99.715676]
 [-99.692914 -99.708916 -99.576989 -99.647724 -99.56572 ]
 [-99.734051 -99.768659 -99.748265 -99.607409 -99.760842]
 [-99.687825 -99.572838 -99.631328 -99.501683 -99.672983]
 [-99.704465 -99.525046 -99.513989 -99.527215 -99.699002]
 [-99.603793 -99.549231 -99.642936 -99.703133 -99.607534]
 [-99.61128  -99.652423 -99.652739 -99.535819 -99.683774]
 [-99.702041 -99.669481 -99.682228 -99.633486 -99.670753]
 [-99.684512 -99.640374 -99.651805 -99.623786 -99.685433]
 [-99.58595  -99.471457 -99.612099 -99.592488 -99.672156]
 [-99.553365 -99.626659 -99.635249 -99.555816 -99.707863]
 [-99.552021 -99.569903 -99.59235  -99.575296 -99.631559]
 [-99.483986 -99.631284 -99.567971 -99.64175  -99.473455]
 [-99.538408 -99.57131  -99.487648 -99.5573   -99.514706]
 [-99.647428 -99.60145  -99.702658 -99.542344 -99.546844]
 [-99.572968 -99.626504 -99.626263 -99.698509 -99.640002]
 [-99.645133 -99.617014 -99.658937 -99.587319 -99.681059]
 [-99.498358 -99.534539 -99.622764 -99.531738 -99.610872]
 [-99.58994  -99.64268  -99.669236 -99.515509 -99.583717]
 [-99.585335 -99.520921 -99.620665 -99.584256 -99.537966]
 [-99.565815 -99.562652 -99.577142 -99.549198 -99.693978]
 [-99.676613 -99.580324 -99.648199 -99.573349 -99.543748]
 [-99.519309 -99.736324 -99.557294 -99.657485 -99.642143]
 [-99.613861 -99.593429 -99.569725 -99.554681 -99.635641]
 [-99.563858 -99.54036  -99.480089 -99.627821 -99.558923]
 [-99.513567 -99.480946 -99.548813 -99.490655 -99.579848]
 [-99.507548 -99.466219 -99.638376 -99.524071 -99.467288]
 [-99.490439 -99.598377 -99.4514   -99.404632 -99.413278]
 [-99.528016 -99.475427 -99.472548 -99.547306 -99.484723]
 [-99.545671 -99.487769 -99.564826 -99.566376 -99.607273]
 [-99.526356 -99.576123 -99.582997 -99.574535 -99.57721 ]
 [-99.636871 -99.640125 -99.426099 -99.557343 -99.572892]
 [-99.615829 -99.624696 -99.666634 -99.59578  -99.55693 ]
 [-99.562467 -99.641233 -99.619249 -99.563054 -99.622234]
 [-99.53429  -99.544928 -99.604546 -99.633932 -99.541569]
 [-99.569148 -99.601358 -99.49083  -99.653969 -99.661049]
 [-99.589712 -99.535838 -99.502609 -99.499073 -99.501822]
 [-99.520021 -99.556207 -99.515351 -99.587121 -99.492861]
 [-99.583291 -99.575979 -99.48127  -99.471022 -99.452005]
 [-99.42909  -99.480451 -99.537902 -99.522745 -99.514596]
 [-99.494439 -99.482858 -99.469324 -99.631127 -99.459064]
 [-99.475582 -99.443283 -99.46042  -99.590882 -99.539106]
 [-99.422405 -99.508919 -99.48456  -99.512039 -99.474821]
 [-99.50206  -99.532114 -99.53799  -99.598865 -99.541446]
 [-99.528579 -99.488446 -99.368985 -99.530792 -99.522206]
 [-99.481929 -99.425627 -99.443152 -99.526628 -99.587549]
 [-99.529944 -99.416666 -99.562473 -99.372369 -99.498145]
 [-99.503955 -99.490559 -99.517582 -99.576025 -99.590226]
 [-99.4047   -99.513873 -99.422442 -99.508082 -99.524454]
 [-99.414645 -99.545824 -99.493065 -99.399896 -99.480167]
 [-99.569692 -99.594009 -99.531209 -99.489504 -99.620218]
 [-99.564794 -99.560386 -99.475681 -98.559712 -99.581895]]
Episode Lengths (shape=(100, 5)):
[[3601 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3600]
 [3601 3601 3601 3601 3601]
 [3601 3601 3594 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3584 3601 3597 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3601 3601 3598 3601]
 [3599 3601 3601 3601 3601]
 [3597 3601 3601 3601 3583]
 [3601 3601 3598 3601 3601]
 [3597 3601 3601 3601 3601]
 [3601 3601 3600 3601 3601]
 [3599 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3579 3601 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3598 3601 3601 3601 3601]
 [3601 3601 3583 3601 3598]
 [3601 3601 3601 3601 3583]
 [3597 3601 3601 3601 3598]
 [3584 3601 3601 3601 3598]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3591]
 [3601 3601 3601 3601 3601]
 [3601 3593 3601 3601 3601]
 [3584 3601 3601 3601 3601]
 [3593 3601 3599 3601 3601]
 [3601 3601 3601 3596 3601]
 [3584 3601 3597 3601 3601]
 [3601 3601 3601 3601 3582]
 [3601 3601 3601 3597 3601]
 [3596 3601 3601 3601 3601]
 [3601 3598 3601 3601 3601]
 [3599 3601 3601 3601 3601]
 [3577 3601 3601 3601 3600]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3600 3601 3601 3601 3601]
 [3601 3601 3597 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3599 3601]
 [3601 3601 3601 3601 3600]
 [3597 3601 3601 3601 3598]
 [3598 3601 3601 3601 3601]
 [3601 3597 3601 3601 3601]
 [3601 3601 3591 3582 3601]
 [3601 3601 3601 3593 3601]
 [3601 3601 3601 3601 3601]
 [3568 3601 3601 3601 3601]
 [3601 3599 3601 3581 3601]
 [3601 3601 3598 3601 3601]
 [3601 3601 3601 3601 3601]
 [3597 3576 3601 3601 3601]
 [3598 3601 3601 3601 3579]
 [3601 3601 3601 3594 3601]
 [3578 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3579 3601 3601 3596 3601]
 [3601 3601 3591 3597 3601]
 [3584 3601 3601 3601 3601]
 [3601 3601 3601 3588 3601]
 [3601 3597 3568 3601 3601]
 [3601 3601 3599 3598 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3590 3601]
 [3574 3601 3601 3601 3601]
 [3601 3601 3599 3578 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3585 3601 3596 3601 3598]
 [3601 3601 3601 3585 3601]
 [3601 3600 3601 3601 3601]
 [3593 3601 3598 3601 3601]
 [3601 3581 3597 3601 3601]
 [3596 3601 3601 3582 3601]
 [3601 3601 3601 3582 3601]
 [3599 3597 3601 3601 3601]
 [3601 3601 3601 3601 3597]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3583 3598]
 [3601 3582 3601 3601 3601]
 [3601 3601 3601 3601 3584]
 [3601 3599 3599 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3601 3601 3601 3601]
 [3601 3582 3601 3601 3601]
 [3601 3601 3601 3601 3581]
 [3600 3601 3601 3601 3601]]
Time Elapsed: Not available
Plot saved to /scratch/work/sattaru1/FM3-MicRo/src/FM3_MicRo/control_models/2025-01-28_08-31-10_llm_triton_qwen_14b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/rewards_plot.png
Model saved as src/FM3_MicRo/control_models/2025-01-28_08-31-10_llm_triton_qwen_14b_binary_rewards_5_examples_1000000-steps_5-obs_ep-time-360.0/model
